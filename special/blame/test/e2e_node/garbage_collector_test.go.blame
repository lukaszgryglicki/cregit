0000000000000000000000000000000000000000;;	/*
0000000000000000000000000000000000000000;;	Copyright 2016 The Kubernetes Authors.
27217450daaea1477aa7b3acda32f341705b12a7;;	
0000000000000000000000000000000000000000;;	Licensed under the Apache License, Version 2.0 (the "License");
0000000000000000000000000000000000000000;;	you may not use this file except in compliance with the License.
0000000000000000000000000000000000000000;;	You may obtain a copy of the License at
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	    http://www.apache.org/licenses/LICENSE-2.0
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	Unless required by applicable law or agreed to in writing, software
0000000000000000000000000000000000000000;;	distributed under the License is distributed on an "AS IS" BASIS,
0000000000000000000000000000000000000000;;	WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
0000000000000000000000000000000000000000;;	See the License for the specific language governing permissions and
0000000000000000000000000000000000000000;;	limitations under the License.
0000000000000000000000000000000000000000;;	*/
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	package e2e_node
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	import (
0000000000000000000000000000000000000000;;		"fmt"
0000000000000000000000000000000000000000;;		"strconv"
0000000000000000000000000000000000000000;;		"strings"
0000000000000000000000000000000000000000;;		"time"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		"k8s.io/api/core/v1"
0000000000000000000000000000000000000000;;		metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/kubelet/dockershim/libdocker"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/test/e2e/framework"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		. "github.com/onsi/ginkgo"
0000000000000000000000000000000000000000;;		. "github.com/onsi/gomega"
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	const (
0000000000000000000000000000000000000000;;		defaultDockerEndpoint = "unix:///var/run/docker.sock"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		//TODO (dashpole): Once dynamic config is possible, test different values for maxPerPodContainer and maxContainers
0000000000000000000000000000000000000000;;		// Currently using default values for maxPerPodContainer and maxTotalContainers
0000000000000000000000000000000000000000;;		maxPerPodContainer = 1
0000000000000000000000000000000000000000;;		maxTotalContainers = -1
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		defaultRuntimeRequestTimeoutDuration = 1 * time.Minute
0000000000000000000000000000000000000000;;		defaultImagePullProgressDeadline     = 1 * time.Minute
0000000000000000000000000000000000000000;;		garbageCollectDuration               = 3 * time.Minute
0000000000000000000000000000000000000000;;		setupDuration                        = 10 * time.Minute
0000000000000000000000000000000000000000;;		runtimePollInterval                  = 10 * time.Second
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type testPodSpec struct {
0000000000000000000000000000000000000000;;		podName string
0000000000000000000000000000000000000000;;		// containerPrefix must be unique for each pod, and cannot end in a number.
0000000000000000000000000000000000000000;;		// containerPrefix is used to identify which containers belong to which pod in the test.
0000000000000000000000000000000000000000;;		containerPrefix string
0000000000000000000000000000000000000000;;		// the number of times each container should restart
0000000000000000000000000000000000000000;;		restartCount int32
0000000000000000000000000000000000000000;;		// the number of containers in the test pod
0000000000000000000000000000000000000000;;		numContainers int
0000000000000000000000000000000000000000;;		// a function that returns the number of containers currently on the node (including dead containers).
0000000000000000000000000000000000000000;;		getContainerNames func() ([]string, error)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (pod *testPodSpec) getContainerName(containerNumber int) string {
0000000000000000000000000000000000000000;;		return fmt.Sprintf("%s%d", pod.containerPrefix, containerNumber)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type testRun struct {
0000000000000000000000000000000000000000;;		// Name for logging purposes
0000000000000000000000000000000000000000;;		testName string
0000000000000000000000000000000000000000;;		// Pod specs for the test
0000000000000000000000000000000000000000;;		testPods []*testPodSpec
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// GarbageCollect tests that the Kubelet conforms to the Kubelet Garbage Collection Policy, found here:
0000000000000000000000000000000000000000;;	// http://kubernetes.io/docs/admin/garbage-collection/
0000000000000000000000000000000000000000;;	var _ = framework.KubeDescribe("GarbageCollect [Serial]", func() {
0000000000000000000000000000000000000000;;		f := framework.NewDefaultFramework("garbage-collect-test")
0000000000000000000000000000000000000000;;		containerNamePrefix := "gc-test-container-"
0000000000000000000000000000000000000000;;		podNamePrefix := "gc-test-pod-"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// These suffixes are appended to pod and container names.
0000000000000000000000000000000000000000;;		// They differentiate pods from one another, and allow filtering
0000000000000000000000000000000000000000;;		// by names to identify which containers belong to which pods
0000000000000000000000000000000000000000;;		// They must be unique, and must not end in a number
0000000000000000000000000000000000000000;;		first_suffix := "one-container-no-restarts"
0000000000000000000000000000000000000000;;		second_suffix := "many-containers-many-restarts-one-pod"
0000000000000000000000000000000000000000;;		third_suffix := "many-containers-many-restarts-"
0000000000000000000000000000000000000000;;		tests := []testRun{
0000000000000000000000000000000000000000;;			{
0000000000000000000000000000000000000000;;				testName: "One Non-restarting Container",
0000000000000000000000000000000000000000;;				testPods: []*testPodSpec{
0000000000000000000000000000000000000000;;					{
0000000000000000000000000000000000000000;;						podName:         podNamePrefix + first_suffix,
0000000000000000000000000000000000000000;;						containerPrefix: containerNamePrefix + first_suffix,
0000000000000000000000000000000000000000;;						restartCount:    0,
0000000000000000000000000000000000000000;;						numContainers:   1,
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			{
0000000000000000000000000000000000000000;;				testName: "Many Restarting Containers",
0000000000000000000000000000000000000000;;				testPods: []*testPodSpec{
0000000000000000000000000000000000000000;;					{
0000000000000000000000000000000000000000;;						podName:         podNamePrefix + second_suffix,
0000000000000000000000000000000000000000;;						containerPrefix: containerNamePrefix + second_suffix,
0000000000000000000000000000000000000000;;						restartCount:    4,
0000000000000000000000000000000000000000;;						numContainers:   4,
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			{
0000000000000000000000000000000000000000;;				testName: "Many Pods with Many Restarting Containers",
0000000000000000000000000000000000000000;;				testPods: []*testPodSpec{
0000000000000000000000000000000000000000;;					{
0000000000000000000000000000000000000000;;						podName:         podNamePrefix + third_suffix + "one",
0000000000000000000000000000000000000000;;						containerPrefix: containerNamePrefix + third_suffix + "one",
0000000000000000000000000000000000000000;;						restartCount:    3,
0000000000000000000000000000000000000000;;						numContainers:   4,
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;					{
0000000000000000000000000000000000000000;;						podName:         podNamePrefix + third_suffix + "two",
0000000000000000000000000000000000000000;;						containerPrefix: containerNamePrefix + third_suffix + "two",
0000000000000000000000000000000000000000;;						restartCount:    2,
0000000000000000000000000000000000000000;;						numContainers:   6,
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;					{
0000000000000000000000000000000000000000;;						podName:         podNamePrefix + third_suffix + "three",
0000000000000000000000000000000000000000;;						containerPrefix: containerNamePrefix + third_suffix + "three",
0000000000000000000000000000000000000000;;						restartCount:    3,
0000000000000000000000000000000000000000;;						numContainers:   5,
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		for _, test := range tests {
0000000000000000000000000000000000000000;;			// TODO (dashpole): Once the Container Runtime Interface (CRI) is complete, generalize run on other runtimes (other than docker)
0000000000000000000000000000000000000000;;			dockerContainerGCTest(f, test)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Tests the following:
0000000000000000000000000000000000000000;;	// 	pods are created, and all containers restart the specified number of times
0000000000000000000000000000000000000000;;	// 	while contianers are running, the number of copies of a single container does not exceed maxPerPodContainer
0000000000000000000000000000000000000000;;	// 	while containers are running, the total number of containers does not exceed maxTotalContainers
0000000000000000000000000000000000000000;;	// 	while containers are running, if not constrained by maxPerPodContainer or maxTotalContainers, keep an extra copy of each container
0000000000000000000000000000000000000000;;	// 	once pods are killed, all containers are eventually cleaned up
0000000000000000000000000000000000000000;;	func containerGCTest(f *framework.Framework, test testRun) {
0000000000000000000000000000000000000000;;		Context(fmt.Sprintf("Garbage Collection Test: %s", test.testName), func() {
0000000000000000000000000000000000000000;;			BeforeEach(func() {
0000000000000000000000000000000000000000;;				realPods := getPods(test.testPods)
0000000000000000000000000000000000000000;;				f.PodClient().CreateBatch(realPods)
0000000000000000000000000000000000000000;;				By("Making sure all containers restart the specified number of times")
0000000000000000000000000000000000000000;;				Eventually(func() error {
0000000000000000000000000000000000000000;;					for _, podSpec := range test.testPods {
0000000000000000000000000000000000000000;;						err := verifyPodRestartCount(f, podSpec.podName, podSpec.numContainers, podSpec.restartCount)
0000000000000000000000000000000000000000;;						if err != nil {
0000000000000000000000000000000000000000;;							return err
0000000000000000000000000000000000000000;;						}
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					return nil
0000000000000000000000000000000000000000;;				}, setupDuration, runtimePollInterval).Should(BeNil())
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			It(fmt.Sprintf("Should eventually garbage collect containers when we exceed the number of dead containers per container"), func() {
0000000000000000000000000000000000000000;;				totalContainers := 0
0000000000000000000000000000000000000000;;				for _, pod := range test.testPods {
0000000000000000000000000000000000000000;;					totalContainers += pod.numContainers*2 + 1
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				Eventually(func() error {
0000000000000000000000000000000000000000;;					total := 0
0000000000000000000000000000000000000000;;					for _, pod := range test.testPods {
0000000000000000000000000000000000000000;;						containerNames, err := pod.getContainerNames()
0000000000000000000000000000000000000000;;						if err != nil {
0000000000000000000000000000000000000000;;							return err
0000000000000000000000000000000000000000;;						}
0000000000000000000000000000000000000000;;						total += len(containerNames)
0000000000000000000000000000000000000000;;						// Check maxPerPodContainer for each container in the pod
0000000000000000000000000000000000000000;;						for i := 0; i < pod.numContainers; i++ {
0000000000000000000000000000000000000000;;							containerCount := 0
0000000000000000000000000000000000000000;;							for _, containerName := range containerNames {
0000000000000000000000000000000000000000;;								if strings.Contains(containerName, pod.getContainerName(i)) {
0000000000000000000000000000000000000000;;									containerCount += 1
0000000000000000000000000000000000000000;;								}
0000000000000000000000000000000000000000;;							}
0000000000000000000000000000000000000000;;							if containerCount > maxPerPodContainer+1 {
0000000000000000000000000000000000000000;;								return fmt.Errorf("expected number of copies of container: %s, to be <= maxPerPodContainer: %d; list of containers: %v",
0000000000000000000000000000000000000000;;									pod.getContainerName(i), maxPerPodContainer, containerNames)
0000000000000000000000000000000000000000;;							}
0000000000000000000000000000000000000000;;						}
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					//Check maxTotalContainers.  Currently, the default is -1, so this will never happen until we can configure maxTotalContainers
0000000000000000000000000000000000000000;;					if maxTotalContainers > 0 && totalContainers <= maxTotalContainers && total > maxTotalContainers {
0000000000000000000000000000000000000000;;						return fmt.Errorf("expected total number of containers: %v, to be <= maxTotalContainers: %v", total, maxTotalContainers)
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					return nil
0000000000000000000000000000000000000000;;				}, garbageCollectDuration, runtimePollInterval).Should(BeNil())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				if maxPerPodContainer >= 2 && maxTotalContainers < 0 { // make sure constraints wouldn't make us gc old containers
0000000000000000000000000000000000000000;;					By("Making sure the kubelet consistently keeps around an extra copy of each container.")
0000000000000000000000000000000000000000;;					Consistently(func() error {
0000000000000000000000000000000000000000;;						for _, pod := range test.testPods {
0000000000000000000000000000000000000000;;							containerNames, err := pod.getContainerNames()
0000000000000000000000000000000000000000;;							if err != nil {
0000000000000000000000000000000000000000;;								return err
0000000000000000000000000000000000000000;;							}
0000000000000000000000000000000000000000;;							for i := 0; i < pod.numContainers; i++ {
0000000000000000000000000000000000000000;;								containerCount := 0
0000000000000000000000000000000000000000;;								for _, containerName := range containerNames {
0000000000000000000000000000000000000000;;									if strings.Contains(containerName, pod.getContainerName(i)) {
0000000000000000000000000000000000000000;;										containerCount += 1
0000000000000000000000000000000000000000;;									}
0000000000000000000000000000000000000000;;								}
0000000000000000000000000000000000000000;;								if pod.restartCount > 0 && containerCount < maxPerPodContainer+1 {
0000000000000000000000000000000000000000;;									return fmt.Errorf("expected pod %v to have extra copies of old containers", pod.podName)
0000000000000000000000000000000000000000;;								}
0000000000000000000000000000000000000000;;							}
0000000000000000000000000000000000000000;;						}
0000000000000000000000000000000000000000;;						return nil
0000000000000000000000000000000000000000;;					}, garbageCollectDuration, runtimePollInterval).Should(BeNil())
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			AfterEach(func() {
0000000000000000000000000000000000000000;;				for _, pod := range test.testPods {
0000000000000000000000000000000000000000;;					By(fmt.Sprintf("Deleting Pod %v", pod.podName))
0000000000000000000000000000000000000000;;					f.PodClient().DeleteSync(pod.podName, &metav1.DeleteOptions{}, framework.DefaultPodDeletionTimeout)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				By("Making sure all containers get cleaned up")
0000000000000000000000000000000000000000;;				Eventually(func() error {
0000000000000000000000000000000000000000;;					for _, pod := range test.testPods {
0000000000000000000000000000000000000000;;						containerNames, err := pod.getContainerNames()
0000000000000000000000000000000000000000;;						if err != nil {
0000000000000000000000000000000000000000;;							return err
0000000000000000000000000000000000000000;;						}
0000000000000000000000000000000000000000;;						if len(containerNames) > 0 {
0000000000000000000000000000000000000000;;							return fmt.Errorf("%v containers still remain", containerNames)
0000000000000000000000000000000000000000;;						}
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					return nil
0000000000000000000000000000000000000000;;				}, garbageCollectDuration, runtimePollInterval).Should(BeNil())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				if CurrentGinkgoTestDescription().Failed && framework.TestContext.DumpLogsOnFailure {
0000000000000000000000000000000000000000;;					logNodeEvents(f)
0000000000000000000000000000000000000000;;					logPodEvents(f)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Runs containerGCTest using the docker runtime.
0000000000000000000000000000000000000000;;	func dockerContainerGCTest(f *framework.Framework, test testRun) {
0000000000000000000000000000000000000000;;		var runtime libdocker.Interface
0000000000000000000000000000000000000000;;		BeforeEach(func() {
0000000000000000000000000000000000000000;;			runtime = libdocker.ConnectToDockerOrDie(defaultDockerEndpoint, defaultRuntimeRequestTimeoutDuration, defaultImagePullProgressDeadline)
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;		for _, pod := range test.testPods {
0000000000000000000000000000000000000000;;			// Initialize the getContainerNames function to use the libdocker api
0000000000000000000000000000000000000000;;			thisPrefix := pod.containerPrefix
0000000000000000000000000000000000000000;;			pod.getContainerNames = func() ([]string, error) {
0000000000000000000000000000000000000000;;				relevantContainers := []string{}
0000000000000000000000000000000000000000;;				dockerContainers, err := libdocker.GetKubeletDockerContainers(runtime, true)
0000000000000000000000000000000000000000;;				if err != nil {
0000000000000000000000000000000000000000;;					return relevantContainers, err
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				for _, container := range dockerContainers {
0000000000000000000000000000000000000000;;					// only look for containers from this testspec
0000000000000000000000000000000000000000;;					if strings.Contains(container.Names[0], thisPrefix) {
0000000000000000000000000000000000000000;;						relevantContainers = append(relevantContainers, container.Names[0])
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				return relevantContainers, nil
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		containerGCTest(f, test)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func getPods(specs []*testPodSpec) (pods []*v1.Pod) {
0000000000000000000000000000000000000000;;		for _, spec := range specs {
0000000000000000000000000000000000000000;;			By(fmt.Sprintf("Creating %v containers with restartCount: %v", spec.numContainers, spec.restartCount))
0000000000000000000000000000000000000000;;			containers := []v1.Container{}
0000000000000000000000000000000000000000;;			for i := 0; i < spec.numContainers; i++ {
0000000000000000000000000000000000000000;;				containers = append(containers, v1.Container{
0000000000000000000000000000000000000000;;					Image:   "gcr.io/google_containers/busybox:1.24",
0000000000000000000000000000000000000000;;					Name:    spec.getContainerName(i),
0000000000000000000000000000000000000000;;					Command: getRestartingContainerCommand("/test-empty-dir-mnt", i, spec.restartCount, ""),
0000000000000000000000000000000000000000;;					VolumeMounts: []v1.VolumeMount{
0000000000000000000000000000000000000000;;						{MountPath: "/test-empty-dir-mnt", Name: "test-empty-dir"},
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;				})
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			pods = append(pods, &v1.Pod{
0000000000000000000000000000000000000000;;				ObjectMeta: metav1.ObjectMeta{Name: spec.podName},
0000000000000000000000000000000000000000;;				Spec: v1.PodSpec{
0000000000000000000000000000000000000000;;					RestartPolicy: v1.RestartPolicyAlways,
0000000000000000000000000000000000000000;;					Containers:    containers,
0000000000000000000000000000000000000000;;					Volumes: []v1.Volume{
0000000000000000000000000000000000000000;;						{Name: "test-empty-dir", VolumeSource: v1.VolumeSource{EmptyDir: &v1.EmptyDirVolumeSource{}}},
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func getRestartingContainerCommand(path string, containerNum int, restarts int32, loopingCommand string) []string {
0000000000000000000000000000000000000000;;		return []string{
0000000000000000000000000000000000000000;;			"sh",
0000000000000000000000000000000000000000;;			"-c",
0000000000000000000000000000000000000000;;			fmt.Sprintf(`
0000000000000000000000000000000000000000;;				f=%s/countfile%s
0000000000000000000000000000000000000000;;				count=$(echo 'hello' >> $f ; wc -l $f | awk {'print $1'})
0000000000000000000000000000000000000000;;				if [ $count -lt %d ]; then
0000000000000000000000000000000000000000;;					exit 0
0000000000000000000000000000000000000000;;				fi
0000000000000000000000000000000000000000;;				while true; do %s sleep 1; done`,
0000000000000000000000000000000000000000;;				path, strconv.Itoa(containerNum), restarts+1, loopingCommand),
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func verifyPodRestartCount(f *framework.Framework, podName string, expectedNumContainers int, expectedRestartCount int32) error {
0000000000000000000000000000000000000000;;		updatedPod, err := f.ClientSet.Core().Pods(f.Namespace.Name).Get(podName, metav1.GetOptions{})
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if len(updatedPod.Status.ContainerStatuses) != expectedNumContainers {
0000000000000000000000000000000000000000;;			return fmt.Errorf("expected pod %s to have %d containers, actual: %d",
0000000000000000000000000000000000000000;;				updatedPod.Name, expectedNumContainers, len(updatedPod.Status.ContainerStatuses))
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		for _, containerStatus := range updatedPod.Status.ContainerStatuses {
0000000000000000000000000000000000000000;;			if containerStatus.RestartCount != expectedRestartCount {
0000000000000000000000000000000000000000;;				return fmt.Errorf("pod %s had container with restartcount %d.  Should have been at least %d",
0000000000000000000000000000000000000000;;					updatedPod.Name, containerStatus.RestartCount, expectedRestartCount)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return nil
0000000000000000000000000000000000000000;;	}
