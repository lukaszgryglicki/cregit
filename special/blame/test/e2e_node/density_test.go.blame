0000000000000000000000000000000000000000;;	// +build linux
9ab5ddcae6f7d20694160d5532a9ed99ddc9c1b6;;	
0000000000000000000000000000000000000000;;	/*
0000000000000000000000000000000000000000;;	Copyright 2015 The Kubernetes Authors.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	Licensed under the Apache License, Version 2.0 (the "License");
0000000000000000000000000000000000000000;;	you may not use this file except in compliance with the License.
0000000000000000000000000000000000000000;;	You may obtain a copy of the License at
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	    http://www.apache.org/licenses/LICENSE-2.0
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	Unless required by applicable law or agreed to in writing, software
0000000000000000000000000000000000000000;;	distributed under the License is distributed on an "AS IS" BASIS,
0000000000000000000000000000000000000000;;	WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
0000000000000000000000000000000000000000;;	See the License for the specific language governing permissions and
0000000000000000000000000000000000000000;;	limitations under the License.
0000000000000000000000000000000000000000;;	*/
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	package e2e_node
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	import (
0000000000000000000000000000000000000000;;		"fmt"
0000000000000000000000000000000000000000;;		"sort"
0000000000000000000000000000000000000000;;		"strconv"
0000000000000000000000000000000000000000;;		"sync"
0000000000000000000000000000000000000000;;		"time"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		"k8s.io/api/core/v1"
0000000000000000000000000000000000000000;;		metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/labels"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/runtime"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/watch"
0000000000000000000000000000000000000000;;		"k8s.io/client-go/tools/cache"
0000000000000000000000000000000000000000;;		stats "k8s.io/kubernetes/pkg/kubelet/apis/stats/v1alpha1"
0000000000000000000000000000000000000000;;		kubemetrics "k8s.io/kubernetes/pkg/kubelet/metrics"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/test/e2e/framework"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/test/e2e/metrics"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		. "github.com/onsi/ginkgo"
0000000000000000000000000000000000000000;;		. "github.com/onsi/gomega"
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	const (
0000000000000000000000000000000000000000;;		kubeletAddr = "localhost:10255"
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	var _ = framework.KubeDescribe("Density [Serial] [Slow]", func() {
0000000000000000000000000000000000000000;;		const (
0000000000000000000000000000000000000000;;			// The data collection time of resource collector and the standalone cadvisor
0000000000000000000000000000000000000000;;			// is not synchronizated, so resource collector may miss data or
0000000000000000000000000000000000000000;;			// collect duplicated data
0000000000000000000000000000000000000000;;			containerStatsPollingPeriod = 500 * time.Millisecond
0000000000000000000000000000000000000000;;		)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		var (
0000000000000000000000000000000000000000;;			rc *ResourceCollector
0000000000000000000000000000000000000000;;		)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		f := framework.NewDefaultFramework("density-test")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		BeforeEach(func() {
0000000000000000000000000000000000000000;;			// Start a standalone cadvisor pod using 'createSync', the pod is running when it returns
0000000000000000000000000000000000000000;;			f.PodClient().CreateSync(getCadvisorPod())
0000000000000000000000000000000000000000;;			// Resource collector monitors fine-grain CPU/memory usage by a standalone Cadvisor with
0000000000000000000000000000000000000000;;			// 1s housingkeeping interval
0000000000000000000000000000000000000000;;			rc = NewResourceCollector(containerStatsPollingPeriod)
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		Context("create a batch of pods", func() {
0000000000000000000000000000000000000000;;			// TODO(coufon): the values are generous, set more precise limits with benchmark data
0000000000000000000000000000000000000000;;			// and add more tests
0000000000000000000000000000000000000000;;			dTests := []densityTest{
0000000000000000000000000000000000000000;;				{
0000000000000000000000000000000000000000;;					podsNr:   10,
0000000000000000000000000000000000000000;;					interval: 0 * time.Millisecond,
0000000000000000000000000000000000000000;;					cpuLimits: framework.ContainersCPUSummary{
0000000000000000000000000000000000000000;;						stats.SystemContainerKubelet: {0.50: 0.30, 0.95: 0.50},
0000000000000000000000000000000000000000;;						stats.SystemContainerRuntime: {0.50: 0.40, 0.95: 0.60},
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;					memLimits: framework.ResourceUsagePerContainer{
0000000000000000000000000000000000000000;;						stats.SystemContainerKubelet: &framework.ContainerResourceUsage{MemoryRSSInBytes: 100 * 1024 * 1024},
0000000000000000000000000000000000000000;;						stats.SystemContainerRuntime: &framework.ContainerResourceUsage{MemoryRSSInBytes: 500 * 1024 * 1024},
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;					// percentile limit of single pod startup latency
0000000000000000000000000000000000000000;;					podStartupLimits: framework.LatencyMetric{
0000000000000000000000000000000000000000;;						Perc50: 16 * time.Second,
0000000000000000000000000000000000000000;;						Perc90: 18 * time.Second,
0000000000000000000000000000000000000000;;						Perc99: 20 * time.Second,
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;					// upbound of startup latency of a batch of pods
0000000000000000000000000000000000000000;;					podBatchStartupLimit: 25 * time.Second,
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			for _, testArg := range dTests {
0000000000000000000000000000000000000000;;				itArg := testArg
0000000000000000000000000000000000000000;;				desc := fmt.Sprintf("latency/resource should be within limit when create %d pods with %v interval", itArg.podsNr, itArg.interval)
0000000000000000000000000000000000000000;;				It(desc, func() {
0000000000000000000000000000000000000000;;					itArg.createMethod = "batch"
0000000000000000000000000000000000000000;;					testInfo := getTestNodeInfo(f, itArg.getTestName(), desc)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;					batchLag, e2eLags := runDensityBatchTest(f, rc, itArg, testInfo, false)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;					By("Verifying latency")
0000000000000000000000000000000000000000;;					logAndVerifyLatency(batchLag, e2eLags, itArg.podStartupLimits, itArg.podBatchStartupLimit, testInfo, true)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;					By("Verifying resource")
0000000000000000000000000000000000000000;;					logAndVerifyResource(f, rc, itArg.cpuLimits, itArg.memLimits, testInfo, true)
0000000000000000000000000000000000000000;;				})
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		Context("create a batch of pods", func() {
0000000000000000000000000000000000000000;;			dTests := []densityTest{
0000000000000000000000000000000000000000;;				{
0000000000000000000000000000000000000000;;					podsNr:   10,
0000000000000000000000000000000000000000;;					interval: 0 * time.Millisecond,
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;				{
0000000000000000000000000000000000000000;;					podsNr:   35,
0000000000000000000000000000000000000000;;					interval: 0 * time.Millisecond,
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;				{
0000000000000000000000000000000000000000;;					podsNr:   105,
0000000000000000000000000000000000000000;;					interval: 0 * time.Millisecond,
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;				{
0000000000000000000000000000000000000000;;					podsNr:   10,
0000000000000000000000000000000000000000;;					interval: 100 * time.Millisecond,
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;				{
0000000000000000000000000000000000000000;;					podsNr:   35,
0000000000000000000000000000000000000000;;					interval: 100 * time.Millisecond,
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;				{
0000000000000000000000000000000000000000;;					podsNr:   105,
0000000000000000000000000000000000000000;;					interval: 100 * time.Millisecond,
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;				{
0000000000000000000000000000000000000000;;					podsNr:   10,
0000000000000000000000000000000000000000;;					interval: 300 * time.Millisecond,
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;				{
0000000000000000000000000000000000000000;;					podsNr:   35,
0000000000000000000000000000000000000000;;					interval: 300 * time.Millisecond,
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;				{
0000000000000000000000000000000000000000;;					podsNr:   105,
0000000000000000000000000000000000000000;;					interval: 300 * time.Millisecond,
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			for _, testArg := range dTests {
0000000000000000000000000000000000000000;;				itArg := testArg
0000000000000000000000000000000000000000;;				desc := fmt.Sprintf("latency/resource should be within limit when create %d pods with %v interval [Benchmark]", itArg.podsNr, itArg.interval)
0000000000000000000000000000000000000000;;				It(desc, func() {
0000000000000000000000000000000000000000;;					itArg.createMethod = "batch"
0000000000000000000000000000000000000000;;					testInfo := getTestNodeInfo(f, itArg.getTestName(), desc)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;					batchLag, e2eLags := runDensityBatchTest(f, rc, itArg, testInfo, true)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;					By("Verifying latency")
0000000000000000000000000000000000000000;;					logAndVerifyLatency(batchLag, e2eLags, itArg.podStartupLimits, itArg.podBatchStartupLimit, testInfo, false)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;					By("Verifying resource")
0000000000000000000000000000000000000000;;					logAndVerifyResource(f, rc, itArg.cpuLimits, itArg.memLimits, testInfo, false)
0000000000000000000000000000000000000000;;				})
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		Context("create a batch of pods with higher API QPS", func() {
0000000000000000000000000000000000000000;;			dTests := []densityTest{
0000000000000000000000000000000000000000;;				{
0000000000000000000000000000000000000000;;					podsNr:      105,
0000000000000000000000000000000000000000;;					interval:    0 * time.Millisecond,
0000000000000000000000000000000000000000;;					APIQPSLimit: 60,
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;				{
0000000000000000000000000000000000000000;;					podsNr:      105,
0000000000000000000000000000000000000000;;					interval:    100 * time.Millisecond,
0000000000000000000000000000000000000000;;					APIQPSLimit: 60,
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;				{
0000000000000000000000000000000000000000;;					podsNr:      105,
0000000000000000000000000000000000000000;;					interval:    300 * time.Millisecond,
0000000000000000000000000000000000000000;;					APIQPSLimit: 60,
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			for _, testArg := range dTests {
0000000000000000000000000000000000000000;;				itArg := testArg
0000000000000000000000000000000000000000;;				desc := fmt.Sprintf("latency/resource should be within limit when create %d pods with %v interval (QPS %d) [Benchmark]", itArg.podsNr, itArg.interval, itArg.APIQPSLimit)
0000000000000000000000000000000000000000;;				It(desc, func() {
0000000000000000000000000000000000000000;;					itArg.createMethod = "batch"
0000000000000000000000000000000000000000;;					testInfo := getTestNodeInfo(f, itArg.getTestName(), desc)
0000000000000000000000000000000000000000;;					// The latency caused by API QPS limit takes a large portion (up to ~33%) of e2e latency.
0000000000000000000000000000000000000000;;					// It makes the pod startup latency of Kubelet (creation throughput as well) under-estimated.
0000000000000000000000000000000000000000;;					// Here we set API QPS limit from default 5 to 60 in order to test real Kubelet performance.
0000000000000000000000000000000000000000;;					// Note that it will cause higher resource usage.
0000000000000000000000000000000000000000;;					setKubeletAPIQPSLimit(f, int32(itArg.APIQPSLimit))
0000000000000000000000000000000000000000;;					batchLag, e2eLags := runDensityBatchTest(f, rc, itArg, testInfo, true)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;					By("Verifying latency")
0000000000000000000000000000000000000000;;					logAndVerifyLatency(batchLag, e2eLags, itArg.podStartupLimits, itArg.podBatchStartupLimit, testInfo, false)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;					By("Verifying resource")
0000000000000000000000000000000000000000;;					logAndVerifyResource(f, rc, itArg.cpuLimits, itArg.memLimits, testInfo, false)
0000000000000000000000000000000000000000;;				})
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		Context("create a sequence of pods", func() {
0000000000000000000000000000000000000000;;			dTests := []densityTest{
0000000000000000000000000000000000000000;;				{
0000000000000000000000000000000000000000;;					podsNr:   10,
0000000000000000000000000000000000000000;;					bgPodsNr: 50,
0000000000000000000000000000000000000000;;					cpuLimits: framework.ContainersCPUSummary{
0000000000000000000000000000000000000000;;						stats.SystemContainerKubelet: {0.50: 0.30, 0.95: 0.50},
0000000000000000000000000000000000000000;;						stats.SystemContainerRuntime: {0.50: 0.40, 0.95: 0.60},
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;					memLimits: framework.ResourceUsagePerContainer{
0000000000000000000000000000000000000000;;						stats.SystemContainerKubelet: &framework.ContainerResourceUsage{MemoryRSSInBytes: 100 * 1024 * 1024},
0000000000000000000000000000000000000000;;						stats.SystemContainerRuntime: &framework.ContainerResourceUsage{MemoryRSSInBytes: 500 * 1024 * 1024},
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;					podStartupLimits: framework.LatencyMetric{
0000000000000000000000000000000000000000;;						Perc50: 5000 * time.Millisecond,
0000000000000000000000000000000000000000;;						Perc90: 9000 * time.Millisecond,
0000000000000000000000000000000000000000;;						Perc99: 10000 * time.Millisecond,
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			for _, testArg := range dTests {
0000000000000000000000000000000000000000;;				itArg := testArg
0000000000000000000000000000000000000000;;				desc := fmt.Sprintf("latency/resource should be within limit when create %d pods with %d background pods", itArg.podsNr, itArg.bgPodsNr)
0000000000000000000000000000000000000000;;				It(desc, func() {
0000000000000000000000000000000000000000;;					itArg.createMethod = "sequence"
0000000000000000000000000000000000000000;;					testInfo := getTestNodeInfo(f, itArg.getTestName(), desc)
0000000000000000000000000000000000000000;;					batchlag, e2eLags := runDensitySeqTest(f, rc, itArg, testInfo)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;					By("Verifying latency")
0000000000000000000000000000000000000000;;					logAndVerifyLatency(batchlag, e2eLags, itArg.podStartupLimits, itArg.podBatchStartupLimit, testInfo, true)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;					By("Verifying resource")
0000000000000000000000000000000000000000;;					logAndVerifyResource(f, rc, itArg.cpuLimits, itArg.memLimits, testInfo, true)
0000000000000000000000000000000000000000;;				})
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		Context("create a sequence of pods", func() {
0000000000000000000000000000000000000000;;			dTests := []densityTest{
0000000000000000000000000000000000000000;;				{
0000000000000000000000000000000000000000;;					podsNr:   10,
0000000000000000000000000000000000000000;;					bgPodsNr: 50,
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;				{
0000000000000000000000000000000000000000;;					podsNr:   30,
0000000000000000000000000000000000000000;;					bgPodsNr: 50,
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;				{
0000000000000000000000000000000000000000;;					podsNr:   50,
0000000000000000000000000000000000000000;;					bgPodsNr: 50,
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			for _, testArg := range dTests {
0000000000000000000000000000000000000000;;				itArg := testArg
0000000000000000000000000000000000000000;;				desc := fmt.Sprintf("latency/resource should be within limit when create %d pods with %d background pods [Benchmark]", itArg.podsNr, itArg.bgPodsNr)
0000000000000000000000000000000000000000;;				It(desc, func() {
0000000000000000000000000000000000000000;;					itArg.createMethod = "sequence"
0000000000000000000000000000000000000000;;					testInfo := getTestNodeInfo(f, itArg.getTestName(), desc)
0000000000000000000000000000000000000000;;					batchlag, e2eLags := runDensitySeqTest(f, rc, itArg, testInfo)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;					By("Verifying latency")
0000000000000000000000000000000000000000;;					logAndVerifyLatency(batchlag, e2eLags, itArg.podStartupLimits, itArg.podBatchStartupLimit, testInfo, false)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;					By("Verifying resource")
0000000000000000000000000000000000000000;;					logAndVerifyResource(f, rc, itArg.cpuLimits, itArg.memLimits, testInfo, false)
0000000000000000000000000000000000000000;;				})
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type densityTest struct {
0000000000000000000000000000000000000000;;		// number of pods
0000000000000000000000000000000000000000;;		podsNr int
0000000000000000000000000000000000000000;;		// number of background pods
0000000000000000000000000000000000000000;;		bgPodsNr int
0000000000000000000000000000000000000000;;		// interval between creating pod (rate control)
0000000000000000000000000000000000000000;;		interval time.Duration
0000000000000000000000000000000000000000;;		// create pods in 'batch' or 'sequence'
0000000000000000000000000000000000000000;;		createMethod string
0000000000000000000000000000000000000000;;		// API QPS limit
0000000000000000000000000000000000000000;;		APIQPSLimit int
0000000000000000000000000000000000000000;;		// performance limits
0000000000000000000000000000000000000000;;		cpuLimits            framework.ContainersCPUSummary
0000000000000000000000000000000000000000;;		memLimits            framework.ResourceUsagePerContainer
0000000000000000000000000000000000000000;;		podStartupLimits     framework.LatencyMetric
0000000000000000000000000000000000000000;;		podBatchStartupLimit time.Duration
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (dt *densityTest) getTestName() string {
0000000000000000000000000000000000000000;;		// The current default API QPS limit is 5
0000000000000000000000000000000000000000;;		// TODO(coufon): is there any way to not hard code this?
0000000000000000000000000000000000000000;;		APIQPSLimit := 5
0000000000000000000000000000000000000000;;		if dt.APIQPSLimit > 0 {
0000000000000000000000000000000000000000;;			APIQPSLimit = dt.APIQPSLimit
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return fmt.Sprintf("density_create_%s_%d_%d_%d_%d", dt.createMethod, dt.podsNr, dt.bgPodsNr,
0000000000000000000000000000000000000000;;			dt.interval.Nanoseconds()/1000000, APIQPSLimit)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// runDensityBatchTest runs the density batch pod creation test
0000000000000000000000000000000000000000;;	func runDensityBatchTest(f *framework.Framework, rc *ResourceCollector, testArg densityTest, testInfo map[string]string,
0000000000000000000000000000000000000000;;		isLogTimeSeries bool) (time.Duration, []framework.PodLatencyData) {
0000000000000000000000000000000000000000;;		const (
0000000000000000000000000000000000000000;;			podType               = "density_test_pod"
0000000000000000000000000000000000000000;;			sleepBeforeCreatePods = 30 * time.Second
0000000000000000000000000000000000000000;;		)
0000000000000000000000000000000000000000;;		var (
0000000000000000000000000000000000000000;;			mutex      = &sync.Mutex{}
0000000000000000000000000000000000000000;;			watchTimes = make(map[string]metav1.Time, 0)
0000000000000000000000000000000000000000;;			stopCh     = make(chan struct{})
0000000000000000000000000000000000000000;;		)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// create test pod data structure
0000000000000000000000000000000000000000;;		pods := newTestPods(testArg.podsNr, true, framework.GetPauseImageNameForHostArch(), podType)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// the controller watches the change of pod status
0000000000000000000000000000000000000000;;		controller := newInformerWatchPod(f, mutex, watchTimes, podType)
0000000000000000000000000000000000000000;;		go controller.Run(stopCh)
0000000000000000000000000000000000000000;;		defer close(stopCh)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// TODO(coufon): in the test we found kubelet starts while it is busy on something, as a result 'syncLoop'
0000000000000000000000000000000000000000;;		// does not response to pod creation immediately. Creating the first pod has a delay around 5s.
0000000000000000000000000000000000000000;;		// The node status has already been 'ready' so `wait and check node being ready does not help here.
0000000000000000000000000000000000000000;;		// Now wait here for a grace period to let 'syncLoop' be ready
0000000000000000000000000000000000000000;;		time.Sleep(sleepBeforeCreatePods)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		rc.Start()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		By("Creating a batch of pods")
0000000000000000000000000000000000000000;;		// It returns a map['pod name']'creation time' containing the creation timestamps
0000000000000000000000000000000000000000;;		createTimes := createBatchPodWithRateControl(f, pods, testArg.interval)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		By("Waiting for all Pods to be observed by the watch...")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		Eventually(func() bool {
0000000000000000000000000000000000000000;;			return len(watchTimes) == testArg.podsNr
0000000000000000000000000000000000000000;;		}, 10*time.Minute, 10*time.Second).Should(BeTrue())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if len(watchTimes) < testArg.podsNr {
0000000000000000000000000000000000000000;;			framework.Failf("Timeout reached waiting for all Pods to be observed by the watch.")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Analyze results
0000000000000000000000000000000000000000;;		var (
0000000000000000000000000000000000000000;;			firstCreate metav1.Time
0000000000000000000000000000000000000000;;			lastRunning metav1.Time
0000000000000000000000000000000000000000;;			init        = true
0000000000000000000000000000000000000000;;			e2eLags     = make([]framework.PodLatencyData, 0)
0000000000000000000000000000000000000000;;		)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		for name, create := range createTimes {
0000000000000000000000000000000000000000;;			watch, ok := watchTimes[name]
0000000000000000000000000000000000000000;;			Expect(ok).To(Equal(true))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			e2eLags = append(e2eLags,
0000000000000000000000000000000000000000;;				framework.PodLatencyData{Name: name, Latency: watch.Time.Sub(create.Time)})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			if !init {
0000000000000000000000000000000000000000;;				if firstCreate.Time.After(create.Time) {
0000000000000000000000000000000000000000;;					firstCreate = create
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				if lastRunning.Time.Before(watch.Time) {
0000000000000000000000000000000000000000;;					lastRunning = watch
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				init = false
0000000000000000000000000000000000000000;;				firstCreate, lastRunning = create, watch
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		sort.Sort(framework.LatencySlice(e2eLags))
0000000000000000000000000000000000000000;;		batchLag := lastRunning.Time.Sub(firstCreate.Time)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		rc.Stop()
0000000000000000000000000000000000000000;;		deletePodsSync(f, pods)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Log time series data.
0000000000000000000000000000000000000000;;		if isLogTimeSeries {
0000000000000000000000000000000000000000;;			logDensityTimeSeries(rc, createTimes, watchTimes, testInfo)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		// Log throughput data.
0000000000000000000000000000000000000000;;		logPodCreateThroughput(batchLag, e2eLags, testArg.podsNr, testInfo)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		deletePodsSync(f, []*v1.Pod{getCadvisorPod()})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return batchLag, e2eLags
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// runDensitySeqTest runs the density sequential pod creation test
0000000000000000000000000000000000000000;;	func runDensitySeqTest(f *framework.Framework, rc *ResourceCollector, testArg densityTest, testInfo map[string]string) (time.Duration, []framework.PodLatencyData) {
0000000000000000000000000000000000000000;;		const (
0000000000000000000000000000000000000000;;			podType               = "density_test_pod"
0000000000000000000000000000000000000000;;			sleepBeforeCreatePods = 30 * time.Second
0000000000000000000000000000000000000000;;		)
0000000000000000000000000000000000000000;;		bgPods := newTestPods(testArg.bgPodsNr, true, framework.GetPauseImageNameForHostArch(), "background_pod")
0000000000000000000000000000000000000000;;		testPods := newTestPods(testArg.podsNr, true, framework.GetPauseImageNameForHostArch(), podType)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		By("Creating a batch of background pods")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// CreatBatch is synchronized, all pods are running when it returns
0000000000000000000000000000000000000000;;		f.PodClient().CreateBatch(bgPods)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		time.Sleep(sleepBeforeCreatePods)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		rc.Start()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Create pods sequentially (back-to-back). e2eLags have been sorted.
0000000000000000000000000000000000000000;;		batchlag, e2eLags := createBatchPodSequential(f, testPods)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		rc.Stop()
0000000000000000000000000000000000000000;;		deletePodsSync(f, append(bgPods, testPods...))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Log throughput data.
0000000000000000000000000000000000000000;;		logPodCreateThroughput(batchlag, e2eLags, testArg.podsNr, testInfo)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		deletePodsSync(f, []*v1.Pod{getCadvisorPod()})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return batchlag, e2eLags
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// createBatchPodWithRateControl creates a batch of pods concurrently, uses one goroutine for each creation.
0000000000000000000000000000000000000000;;	// between creations there is an interval for throughput control
0000000000000000000000000000000000000000;;	func createBatchPodWithRateControl(f *framework.Framework, pods []*v1.Pod, interval time.Duration) map[string]metav1.Time {
0000000000000000000000000000000000000000;;		createTimes := make(map[string]metav1.Time)
0000000000000000000000000000000000000000;;		for _, pod := range pods {
0000000000000000000000000000000000000000;;			createTimes[pod.ObjectMeta.Name] = metav1.Now()
0000000000000000000000000000000000000000;;			go f.PodClient().Create(pod)
0000000000000000000000000000000000000000;;			time.Sleep(interval)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return createTimes
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// getPodStartLatency gets prometheus metric 'pod start latency' from kubelet
0000000000000000000000000000000000000000;;	func getPodStartLatency(node string) (framework.KubeletLatencyMetrics, error) {
0000000000000000000000000000000000000000;;		latencyMetrics := framework.KubeletLatencyMetrics{}
0000000000000000000000000000000000000000;;		ms, err := metrics.GrabKubeletMetricsWithoutProxy(node)
0000000000000000000000000000000000000000;;		Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		for _, samples := range ms {
0000000000000000000000000000000000000000;;			for _, sample := range samples {
0000000000000000000000000000000000000000;;				if sample.Metric["__name__"] == kubemetrics.KubeletSubsystem+"_"+kubemetrics.PodStartLatencyKey {
0000000000000000000000000000000000000000;;					quantile, _ := strconv.ParseFloat(string(sample.Metric["quantile"]), 64)
0000000000000000000000000000000000000000;;					latencyMetrics = append(latencyMetrics,
0000000000000000000000000000000000000000;;						framework.KubeletLatencyMetric{
0000000000000000000000000000000000000000;;							Quantile: quantile,
0000000000000000000000000000000000000000;;							Method:   kubemetrics.PodStartLatencyKey,
0000000000000000000000000000000000000000;;							Latency:  time.Duration(int(sample.Value)) * time.Microsecond})
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return latencyMetrics, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// verifyPodStartupLatency verifies whether 50, 90 and 99th percentiles of PodStartupLatency are
0000000000000000000000000000000000000000;;	// within the threshold.
0000000000000000000000000000000000000000;;	func verifyPodStartupLatency(expect, actual framework.LatencyMetric) error {
0000000000000000000000000000000000000000;;		if actual.Perc50 > expect.Perc50 {
0000000000000000000000000000000000000000;;			return fmt.Errorf("too high pod startup latency 50th percentile: %v", actual.Perc50)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if actual.Perc90 > expect.Perc90 {
0000000000000000000000000000000000000000;;			return fmt.Errorf("too high pod startup latency 90th percentile: %v", actual.Perc90)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if actual.Perc99 > expect.Perc99 {
0000000000000000000000000000000000000000;;			return fmt.Errorf("too high pod startup latency 99th percentile: %v", actual.Perc99)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// newInformerWatchPod creates an informer to check whether all pods are running.
0000000000000000000000000000000000000000;;	func newInformerWatchPod(f *framework.Framework, mutex *sync.Mutex, watchTimes map[string]metav1.Time, podType string) cache.Controller {
0000000000000000000000000000000000000000;;		ns := f.Namespace.Name
0000000000000000000000000000000000000000;;		checkPodRunning := func(p *v1.Pod) {
0000000000000000000000000000000000000000;;			mutex.Lock()
0000000000000000000000000000000000000000;;			defer mutex.Unlock()
0000000000000000000000000000000000000000;;			defer GinkgoRecover()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			if p.Status.Phase == v1.PodRunning {
0000000000000000000000000000000000000000;;				if _, found := watchTimes[p.Name]; !found {
0000000000000000000000000000000000000000;;					watchTimes[p.Name] = metav1.Now()
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		_, controller := cache.NewInformer(
0000000000000000000000000000000000000000;;			&cache.ListWatch{
0000000000000000000000000000000000000000;;				ListFunc: func(options metav1.ListOptions) (runtime.Object, error) {
0000000000000000000000000000000000000000;;					options.LabelSelector = labels.SelectorFromSet(labels.Set{"type": podType}).String()
0000000000000000000000000000000000000000;;					obj, err := f.ClientSet.Core().Pods(ns).List(options)
0000000000000000000000000000000000000000;;					return runtime.Object(obj), err
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;				WatchFunc: func(options metav1.ListOptions) (watch.Interface, error) {
0000000000000000000000000000000000000000;;					options.LabelSelector = labels.SelectorFromSet(labels.Set{"type": podType}).String()
0000000000000000000000000000000000000000;;					return f.ClientSet.Core().Pods(ns).Watch(options)
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			&v1.Pod{},
0000000000000000000000000000000000000000;;			0,
0000000000000000000000000000000000000000;;			cache.ResourceEventHandlerFuncs{
0000000000000000000000000000000000000000;;				AddFunc: func(obj interface{}) {
0000000000000000000000000000000000000000;;					p, ok := obj.(*v1.Pod)
0000000000000000000000000000000000000000;;					Expect(ok).To(Equal(true))
0000000000000000000000000000000000000000;;					go checkPodRunning(p)
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;				UpdateFunc: func(oldObj, newObj interface{}) {
0000000000000000000000000000000000000000;;					p, ok := newObj.(*v1.Pod)
0000000000000000000000000000000000000000;;					Expect(ok).To(Equal(true))
0000000000000000000000000000000000000000;;					go checkPodRunning(p)
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;		)
0000000000000000000000000000000000000000;;		return controller
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// createBatchPodSequential creats pods back-to-back in sequence.
0000000000000000000000000000000000000000;;	func createBatchPodSequential(f *framework.Framework, pods []*v1.Pod) (time.Duration, []framework.PodLatencyData) {
0000000000000000000000000000000000000000;;		batchStartTime := metav1.Now()
0000000000000000000000000000000000000000;;		e2eLags := make([]framework.PodLatencyData, 0)
0000000000000000000000000000000000000000;;		for _, pod := range pods {
0000000000000000000000000000000000000000;;			create := metav1.Now()
0000000000000000000000000000000000000000;;			f.PodClient().CreateSync(pod)
0000000000000000000000000000000000000000;;			e2eLags = append(e2eLags,
0000000000000000000000000000000000000000;;				framework.PodLatencyData{Name: pod.Name, Latency: metav1.Now().Time.Sub(create.Time)})
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		batchLag := metav1.Now().Time.Sub(batchStartTime.Time)
0000000000000000000000000000000000000000;;		sort.Sort(framework.LatencySlice(e2eLags))
0000000000000000000000000000000000000000;;		return batchLag, e2eLags
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// logAndVerifyLatency verifies that whether pod creation latency satisfies the limit.
0000000000000000000000000000000000000000;;	func logAndVerifyLatency(batchLag time.Duration, e2eLags []framework.PodLatencyData, podStartupLimits framework.LatencyMetric,
0000000000000000000000000000000000000000;;		podBatchStartupLimit time.Duration, testInfo map[string]string, isVerify bool) {
0000000000000000000000000000000000000000;;		framework.PrintLatencies(e2eLags, "worst client e2e total latencies")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// TODO(coufon): do not trust 'kubelet' metrics since they are not reset!
0000000000000000000000000000000000000000;;		latencyMetrics, _ := getPodStartLatency(kubeletAddr)
0000000000000000000000000000000000000000;;		framework.Logf("Kubelet Prometheus metrics (not reset):\n%s", framework.PrettyPrintJSON(latencyMetrics))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		podCreateLatency := framework.PodStartupLatency{Latency: framework.ExtractLatencyMetrics(e2eLags)}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// log latency perf data
0000000000000000000000000000000000000000;;		logPerfData(getLatencyPerfData(podCreateLatency.Latency, testInfo), "latency")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if isVerify {
0000000000000000000000000000000000000000;;			// check whether e2e pod startup time is acceptable.
0000000000000000000000000000000000000000;;			framework.ExpectNoError(verifyPodStartupLatency(podStartupLimits, podCreateLatency.Latency))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// check bactch pod creation latency
0000000000000000000000000000000000000000;;			if podBatchStartupLimit > 0 {
0000000000000000000000000000000000000000;;				Expect(batchLag <= podBatchStartupLimit).To(Equal(true), "Batch creation startup time %v exceed limit %v",
0000000000000000000000000000000000000000;;					batchLag, podBatchStartupLimit)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// logThroughput calculates and logs pod creation throughput.
0000000000000000000000000000000000000000;;	func logPodCreateThroughput(batchLag time.Duration, e2eLags []framework.PodLatencyData, podsNr int, testInfo map[string]string) {
0000000000000000000000000000000000000000;;		logPerfData(getThroughputPerfData(batchLag, e2eLags, podsNr, testInfo), "throughput")
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// increaseKubeletAPIQPSLimit sets Kubelet API QPS via ConfigMap. Kubelet will restart with the new QPS.
0000000000000000000000000000000000000000;;	func setKubeletAPIQPSLimit(f *framework.Framework, newAPIQPS int32) {
0000000000000000000000000000000000000000;;		const restartGap = 40 * time.Second
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		resp := pollConfigz(2*time.Minute, 5*time.Second)
0000000000000000000000000000000000000000;;		kubeCfg, err := decodeConfigz(resp)
0000000000000000000000000000000000000000;;		framework.ExpectNoError(err)
0000000000000000000000000000000000000000;;		framework.Logf("Old QPS limit is: %d\n", kubeCfg.KubeAPIQPS)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Set new API QPS limit
0000000000000000000000000000000000000000;;		kubeCfg.KubeAPIQPS = newAPIQPS
0000000000000000000000000000000000000000;;		// TODO(coufon): createConfigMap should firstly check whether configmap already exists, if so, use updateConfigMap.
0000000000000000000000000000000000000000;;		// Calling createConfigMap twice will result in error. It is fine for benchmark test because we only run one test on a new node.
0000000000000000000000000000000000000000;;		_, err = createConfigMap(f, kubeCfg)
0000000000000000000000000000000000000000;;		framework.ExpectNoError(err)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Wait for Kubelet to restart
0000000000000000000000000000000000000000;;		time.Sleep(restartGap)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Check new QPS has been set
0000000000000000000000000000000000000000;;		resp = pollConfigz(2*time.Minute, 5*time.Second)
0000000000000000000000000000000000000000;;		kubeCfg, err = decodeConfigz(resp)
0000000000000000000000000000000000000000;;		framework.ExpectNoError(err)
0000000000000000000000000000000000000000;;		framework.Logf("New QPS limit is: %d\n", kubeCfg.KubeAPIQPS)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// TODO(coufon): check test result to see if we need to retry here
0000000000000000000000000000000000000000;;		if kubeCfg.KubeAPIQPS != newAPIQPS {
0000000000000000000000000000000000000000;;			framework.Failf("Fail to set new kubelet API QPS limit.")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
