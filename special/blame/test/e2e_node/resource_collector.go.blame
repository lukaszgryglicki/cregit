0000000000000000000000000000000000000000;;	// +build linux
9ab5ddcae6f7d20694160d5532a9ed99ddc9c1b6;test/e2e_node/resource_controller.go[test/e2e_node/resource_controller.go][test/e2e_node/resource_collector.go];	
0000000000000000000000000000000000000000;;	/*
0000000000000000000000000000000000000000;;	Copyright 2015 The Kubernetes Authors.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	Licensed under the Apache License, Version 2.0 (the "License");
0000000000000000000000000000000000000000;;	you may not use this file except in compliance with the License.
0000000000000000000000000000000000000000;;	You may obtain a copy of the License at
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	    http://www.apache.org/licenses/LICENSE-2.0
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	Unless required by applicable law or agreed to in writing, software
0000000000000000000000000000000000000000;;	distributed under the License is distributed on an "AS IS" BASIS,
0000000000000000000000000000000000000000;;	WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
0000000000000000000000000000000000000000;;	See the License for the specific language governing permissions and
0000000000000000000000000000000000000000;;	limitations under the License.
0000000000000000000000000000000000000000;;	*/
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	package e2e_node
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	import (
0000000000000000000000000000000000000000;;		"bytes"
0000000000000000000000000000000000000000;;		"fmt"
0000000000000000000000000000000000000000;;		"io/ioutil"
0000000000000000000000000000000000000000;;		"log"
0000000000000000000000000000000000000000;;		"os"
0000000000000000000000000000000000000000;;		"sort"
0000000000000000000000000000000000000000;;		"strconv"
0000000000000000000000000000000000000000;;		"strings"
0000000000000000000000000000000000000000;;		"sync"
0000000000000000000000000000000000000000;;		"text/tabwriter"
0000000000000000000000000000000000000000;;		"time"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		cadvisorclient "github.com/google/cadvisor/client/v2"
0000000000000000000000000000000000000000;;		cadvisorapiv2 "github.com/google/cadvisor/info/v2"
0000000000000000000000000000000000000000;;		"github.com/opencontainers/runc/libcontainer/cgroups"
0000000000000000000000000000000000000000;;		"k8s.io/api/core/v1"
0000000000000000000000000000000000000000;;		metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/labels"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/util/runtime"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/util/uuid"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/util/wait"
0000000000000000000000000000000000000000;;		stats "k8s.io/kubernetes/pkg/kubelet/apis/stats/v1alpha1"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/util/procfs"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/test/e2e/framework"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/test/e2e_node/perftype"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		. "github.com/onsi/gomega"
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	const (
0000000000000000000000000000000000000000;;		// resource monitoring
0000000000000000000000000000000000000000;;		cadvisorImageName = "google/cadvisor:latest"
0000000000000000000000000000000000000000;;		cadvisorPodName   = "cadvisor"
0000000000000000000000000000000000000000;;		cadvisorPort      = 8090
0000000000000000000000000000000000000000;;		// housekeeping interval of Cadvisor (second)
0000000000000000000000000000000000000000;;		houseKeepingInterval = 1
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	var (
0000000000000000000000000000000000000000;;		systemContainers map[string]string
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type ResourceCollector struct {
0000000000000000000000000000000000000000;;		client  *cadvisorclient.Client
0000000000000000000000000000000000000000;;		request *cadvisorapiv2.RequestOptions
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		pollingInterval time.Duration
0000000000000000000000000000000000000000;;		buffers         map[string][]*framework.ContainerResourceUsage
0000000000000000000000000000000000000000;;		lock            sync.RWMutex
0000000000000000000000000000000000000000;;		stopCh          chan struct{}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// NewResourceCollector creates a resource collector object which collects
0000000000000000000000000000000000000000;;	// resource usage periodically from Cadvisor
0000000000000000000000000000000000000000;;	func NewResourceCollector(interval time.Duration) *ResourceCollector {
0000000000000000000000000000000000000000;;		buffers := make(map[string][]*framework.ContainerResourceUsage)
0000000000000000000000000000000000000000;;		return &ResourceCollector{
0000000000000000000000000000000000000000;;			pollingInterval: interval,
0000000000000000000000000000000000000000;;			buffers:         buffers,
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Start starts resource collector and connects to the standalone Cadvisor pod
0000000000000000000000000000000000000000;;	// then repeatedly runs collectStats.
0000000000000000000000000000000000000000;;	func (r *ResourceCollector) Start() {
0000000000000000000000000000000000000000;;		// Get the cgroup container names for kubelet and docker
0000000000000000000000000000000000000000;;		kubeletContainer, err := getContainerNameForProcess(kubeletProcessName, "")
0000000000000000000000000000000000000000;;		dockerContainer, err := getContainerNameForProcess(dockerProcessName, dockerPidFile)
0000000000000000000000000000000000000000;;		if err == nil {
0000000000000000000000000000000000000000;;			systemContainers = map[string]string{
0000000000000000000000000000000000000000;;				stats.SystemContainerKubelet: kubeletContainer,
0000000000000000000000000000000000000000;;				stats.SystemContainerRuntime: dockerContainer,
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		} else {
0000000000000000000000000000000000000000;;			framework.Failf("Failed to get docker container name in test-e2e-node resource collector.")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		wait.Poll(1*time.Second, 1*time.Minute, func() (bool, error) {
0000000000000000000000000000000000000000;;			var err error
0000000000000000000000000000000000000000;;			r.client, err = cadvisorclient.NewClient(fmt.Sprintf("http://localhost:%d/", cadvisorPort))
0000000000000000000000000000000000000000;;			if err == nil {
0000000000000000000000000000000000000000;;				return true, nil
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			return false, err
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		Expect(r.client).NotTo(BeNil(), "cadvisor client not ready")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		r.request = &cadvisorapiv2.RequestOptions{IdType: "name", Count: 1, Recursive: false}
0000000000000000000000000000000000000000;;		r.stopCh = make(chan struct{})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		oldStatsMap := make(map[string]*cadvisorapiv2.ContainerStats)
0000000000000000000000000000000000000000;;		go wait.Until(func() { r.collectStats(oldStatsMap) }, r.pollingInterval, r.stopCh)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Stop stops resource collector collecting stats. It does not clear the buffer
0000000000000000000000000000000000000000;;	func (r *ResourceCollector) Stop() {
0000000000000000000000000000000000000000;;		close(r.stopCh)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Reset clears the stats buffer of resource collector.
0000000000000000000000000000000000000000;;	func (r *ResourceCollector) Reset() {
0000000000000000000000000000000000000000;;		r.lock.Lock()
0000000000000000000000000000000000000000;;		defer r.lock.Unlock()
0000000000000000000000000000000000000000;;		for _, name := range systemContainers {
0000000000000000000000000000000000000000;;			r.buffers[name] = []*framework.ContainerResourceUsage{}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// GetCPUSummary gets CPU usage in percentile.
0000000000000000000000000000000000000000;;	func (r *ResourceCollector) GetCPUSummary() framework.ContainersCPUSummary {
0000000000000000000000000000000000000000;;		result := make(framework.ContainersCPUSummary)
0000000000000000000000000000000000000000;;		for key, name := range systemContainers {
0000000000000000000000000000000000000000;;			data := r.GetBasicCPUStats(name)
0000000000000000000000000000000000000000;;			result[key] = data
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return result
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// LogLatest logs the latest resource usage.
0000000000000000000000000000000000000000;;	func (r *ResourceCollector) LogLatest() {
0000000000000000000000000000000000000000;;		summary, err := r.GetLatest()
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			framework.Logf("%v", err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		framework.Logf("%s", formatResourceUsageStats(summary))
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// collectStats collects resource usage from Cadvisor.
0000000000000000000000000000000000000000;;	func (r *ResourceCollector) collectStats(oldStatsMap map[string]*cadvisorapiv2.ContainerStats) {
0000000000000000000000000000000000000000;;		for _, name := range systemContainers {
0000000000000000000000000000000000000000;;			ret, err := r.client.Stats(name, r.request)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				framework.Logf("Error getting container stats, err: %v", err)
0000000000000000000000000000000000000000;;				return
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			cStats, ok := ret[name]
0000000000000000000000000000000000000000;;			if !ok {
0000000000000000000000000000000000000000;;				framework.Logf("Missing info/stats for container %q", name)
0000000000000000000000000000000000000000;;				return
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			newStats := cStats.Stats[0]
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			if oldStats, ok := oldStatsMap[name]; ok && oldStats.Timestamp.Before(newStats.Timestamp) {
0000000000000000000000000000000000000000;;				if oldStats.Timestamp.Equal(newStats.Timestamp) {
0000000000000000000000000000000000000000;;					continue
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				r.buffers[name] = append(r.buffers[name], computeContainerResourceUsage(name, oldStats, newStats))
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			oldStatsMap[name] = newStats
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// computeContainerResourceUsage computes resource usage based on new data sample.
0000000000000000000000000000000000000000;;	func computeContainerResourceUsage(name string, oldStats, newStats *cadvisorapiv2.ContainerStats) *framework.ContainerResourceUsage {
0000000000000000000000000000000000000000;;		return &framework.ContainerResourceUsage{
0000000000000000000000000000000000000000;;			Name:                    name,
0000000000000000000000000000000000000000;;			Timestamp:               newStats.Timestamp,
0000000000000000000000000000000000000000;;			CPUUsageInCores:         float64(newStats.Cpu.Usage.Total-oldStats.Cpu.Usage.Total) / float64(newStats.Timestamp.Sub(oldStats.Timestamp).Nanoseconds()),
0000000000000000000000000000000000000000;;			MemoryUsageInBytes:      newStats.Memory.Usage,
0000000000000000000000000000000000000000;;			MemoryWorkingSetInBytes: newStats.Memory.WorkingSet,
0000000000000000000000000000000000000000;;			MemoryRSSInBytes:        newStats.Memory.RSS,
0000000000000000000000000000000000000000;;			CPUInterval:             newStats.Timestamp.Sub(oldStats.Timestamp),
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// GetLatest gets the latest resource usage from stats buffer.
0000000000000000000000000000000000000000;;	func (r *ResourceCollector) GetLatest() (framework.ResourceUsagePerContainer, error) {
0000000000000000000000000000000000000000;;		r.lock.RLock()
0000000000000000000000000000000000000000;;		defer r.lock.RUnlock()
0000000000000000000000000000000000000000;;		stats := make(framework.ResourceUsagePerContainer)
0000000000000000000000000000000000000000;;		for key, name := range systemContainers {
0000000000000000000000000000000000000000;;			contStats, ok := r.buffers[name]
0000000000000000000000000000000000000000;;			if !ok || len(contStats) == 0 {
0000000000000000000000000000000000000000;;				return nil, fmt.Errorf("No resource usage data for %s container (%s)", key, name)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			stats[key] = contStats[len(contStats)-1]
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return stats, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type resourceUsageByCPU []*framework.ContainerResourceUsage
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (r resourceUsageByCPU) Len() int           { return len(r) }
0000000000000000000000000000000000000000;;	func (r resourceUsageByCPU) Swap(i, j int)      { r[i], r[j] = r[j], r[i] }
0000000000000000000000000000000000000000;;	func (r resourceUsageByCPU) Less(i, j int) bool { return r[i].CPUUsageInCores < r[j].CPUUsageInCores }
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// The percentiles to report.
0000000000000000000000000000000000000000;;	var percentiles = [...]float64{0.50, 0.90, 0.95, 0.99, 1.00}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// GetBasicCPUStats returns the percentiles the cpu usage in cores for
0000000000000000000000000000000000000000;;	// containerName. This method examines all data currently in the buffer.
0000000000000000000000000000000000000000;;	func (r *ResourceCollector) GetBasicCPUStats(containerName string) map[float64]float64 {
0000000000000000000000000000000000000000;;		r.lock.RLock()
0000000000000000000000000000000000000000;;		defer r.lock.RUnlock()
0000000000000000000000000000000000000000;;		result := make(map[float64]float64, len(percentiles))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// We must make a copy of array, otherwise the timeseries order is changed.
0000000000000000000000000000000000000000;;		usages := make([]*framework.ContainerResourceUsage, 0)
0000000000000000000000000000000000000000;;		for _, usage := range r.buffers[containerName] {
0000000000000000000000000000000000000000;;			usages = append(usages, usage)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		sort.Sort(resourceUsageByCPU(usages))
0000000000000000000000000000000000000000;;		for _, q := range percentiles {
0000000000000000000000000000000000000000;;			index := int(float64(len(usages))*q) - 1
0000000000000000000000000000000000000000;;			if index < 0 {
0000000000000000000000000000000000000000;;				// We don't have enough data.
0000000000000000000000000000000000000000;;				result[q] = 0
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			result[q] = usages[index].CPUUsageInCores
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return result
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func formatResourceUsageStats(containerStats framework.ResourceUsagePerContainer) string {
0000000000000000000000000000000000000000;;		// Example output:
0000000000000000000000000000000000000000;;		//
0000000000000000000000000000000000000000;;		// Resource usage for node "e2e-test-foo-node-abcde":
0000000000000000000000000000000000000000;;		// container        cpu(cores)  memory(MB)
0000000000000000000000000000000000000000;;		// "/"              0.363       2942.09
0000000000000000000000000000000000000000;;		// "/docker-daemon" 0.088       521.80
0000000000000000000000000000000000000000;;		// "/kubelet"       0.086       424.37
0000000000000000000000000000000000000000;;		// "/system"        0.007       119.88
0000000000000000000000000000000000000000;;		buf := &bytes.Buffer{}
0000000000000000000000000000000000000000;;		w := tabwriter.NewWriter(buf, 1, 0, 1, ' ', 0)
0000000000000000000000000000000000000000;;		fmt.Fprintf(w, "container\tcpu(cores)\tmemory_working_set(MB)\tmemory_rss(MB)\n")
0000000000000000000000000000000000000000;;		for name, s := range containerStats {
0000000000000000000000000000000000000000;;			fmt.Fprintf(w, "%q\t%.3f\t%.2f\t%.2f\n", name, s.CPUUsageInCores, float64(s.MemoryWorkingSetInBytes)/(1024*1024), float64(s.MemoryRSSInBytes)/(1024*1024))
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		w.Flush()
0000000000000000000000000000000000000000;;		return fmt.Sprintf("Resource usage:\n%s", buf.String())
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func formatCPUSummary(summary framework.ContainersCPUSummary) string {
0000000000000000000000000000000000000000;;		// Example output for a node (the percentiles may differ):
0000000000000000000000000000000000000000;;		// CPU usage of containers on node "e2e-test-foo-node-0vj7":
0000000000000000000000000000000000000000;;		// container        5th%  50th% 90th% 95th%
0000000000000000000000000000000000000000;;		// "/"              0.051 0.159 0.387 0.455
0000000000000000000000000000000000000000;;		// "/runtime        0.000 0.000 0.146 0.166
0000000000000000000000000000000000000000;;		// "/kubelet"       0.036 0.053 0.091 0.154
0000000000000000000000000000000000000000;;		// "/misc"          0.001 0.001 0.001 0.002
0000000000000000000000000000000000000000;;		var summaryStrings []string
0000000000000000000000000000000000000000;;		var header []string
0000000000000000000000000000000000000000;;		header = append(header, "container")
0000000000000000000000000000000000000000;;		for _, p := range percentiles {
0000000000000000000000000000000000000000;;			header = append(header, fmt.Sprintf("%.0fth%%", p*100))
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		buf := &bytes.Buffer{}
0000000000000000000000000000000000000000;;		w := tabwriter.NewWriter(buf, 1, 0, 1, ' ', 0)
0000000000000000000000000000000000000000;;		fmt.Fprintf(w, "%s\n", strings.Join(header, "\t"))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		for _, containerName := range framework.TargetContainers() {
0000000000000000000000000000000000000000;;			var s []string
0000000000000000000000000000000000000000;;			s = append(s, fmt.Sprintf("%q", containerName))
0000000000000000000000000000000000000000;;			data, ok := summary[containerName]
0000000000000000000000000000000000000000;;			for _, p := range percentiles {
0000000000000000000000000000000000000000;;				value := "N/A"
0000000000000000000000000000000000000000;;				if ok {
0000000000000000000000000000000000000000;;					value = fmt.Sprintf("%.3f", data[p])
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				s = append(s, value)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			fmt.Fprintf(w, "%s\n", strings.Join(s, "\t"))
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		w.Flush()
0000000000000000000000000000000000000000;;		summaryStrings = append(summaryStrings, fmt.Sprintf("CPU usage of containers:\n%s", buf.String()))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return strings.Join(summaryStrings, "\n")
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// createCadvisorPod creates a standalone cadvisor pod for fine-grain resource monitoring.
0000000000000000000000000000000000000000;;	func getCadvisorPod() *v1.Pod {
0000000000000000000000000000000000000000;;		return &v1.Pod{
0000000000000000000000000000000000000000;;			ObjectMeta: metav1.ObjectMeta{
0000000000000000000000000000000000000000;;				Name: cadvisorPodName,
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			Spec: v1.PodSpec{
0000000000000000000000000000000000000000;;				// It uses a host port for the tests to collect data.
0000000000000000000000000000000000000000;;				// Currently we can not use port mapping in test-e2e-node.
0000000000000000000000000000000000000000;;				HostNetwork:     true,
0000000000000000000000000000000000000000;;				SecurityContext: &v1.PodSecurityContext{},
0000000000000000000000000000000000000000;;				Containers: []v1.Container{
0000000000000000000000000000000000000000;;					{
0000000000000000000000000000000000000000;;						Image: cadvisorImageName,
0000000000000000000000000000000000000000;;						Name:  cadvisorPodName,
0000000000000000000000000000000000000000;;						Ports: []v1.ContainerPort{
0000000000000000000000000000000000000000;;							{
0000000000000000000000000000000000000000;;								Name:          "http",
0000000000000000000000000000000000000000;;								HostPort:      cadvisorPort,
0000000000000000000000000000000000000000;;								ContainerPort: cadvisorPort,
0000000000000000000000000000000000000000;;								Protocol:      v1.ProtocolTCP,
0000000000000000000000000000000000000000;;							},
0000000000000000000000000000000000000000;;						},
0000000000000000000000000000000000000000;;						VolumeMounts: []v1.VolumeMount{
0000000000000000000000000000000000000000;;							{
0000000000000000000000000000000000000000;;								Name:      "sys",
0000000000000000000000000000000000000000;;								ReadOnly:  true,
0000000000000000000000000000000000000000;;								MountPath: "/sys",
0000000000000000000000000000000000000000;;							},
0000000000000000000000000000000000000000;;							{
0000000000000000000000000000000000000000;;								Name:      "var-run",
0000000000000000000000000000000000000000;;								ReadOnly:  false,
0000000000000000000000000000000000000000;;								MountPath: "/var/run",
0000000000000000000000000000000000000000;;							},
0000000000000000000000000000000000000000;;							{
0000000000000000000000000000000000000000;;								Name:      "docker",
0000000000000000000000000000000000000000;;								ReadOnly:  true,
0000000000000000000000000000000000000000;;								MountPath: "/var/lib/docker/",
0000000000000000000000000000000000000000;;							},
0000000000000000000000000000000000000000;;							{
0000000000000000000000000000000000000000;;								Name:      "rootfs",
0000000000000000000000000000000000000000;;								ReadOnly:  true,
0000000000000000000000000000000000000000;;								MountPath: "/rootfs",
0000000000000000000000000000000000000000;;							},
0000000000000000000000000000000000000000;;						},
0000000000000000000000000000000000000000;;						Args: []string{
0000000000000000000000000000000000000000;;							"--profiling",
0000000000000000000000000000000000000000;;							fmt.Sprintf("--housekeeping_interval=%ds", houseKeepingInterval),
0000000000000000000000000000000000000000;;							fmt.Sprintf("--port=%d", cadvisorPort),
0000000000000000000000000000000000000000;;						},
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;				Volumes: []v1.Volume{
0000000000000000000000000000000000000000;;					{
0000000000000000000000000000000000000000;;						Name:         "rootfs",
0000000000000000000000000000000000000000;;						VolumeSource: v1.VolumeSource{HostPath: &v1.HostPathVolumeSource{Path: "/"}},
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;					{
0000000000000000000000000000000000000000;;						Name:         "var-run",
0000000000000000000000000000000000000000;;						VolumeSource: v1.VolumeSource{HostPath: &v1.HostPathVolumeSource{Path: "/var/run"}},
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;					{
0000000000000000000000000000000000000000;;						Name:         "sys",
0000000000000000000000000000000000000000;;						VolumeSource: v1.VolumeSource{HostPath: &v1.HostPathVolumeSource{Path: "/sys"}},
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;					{
0000000000000000000000000000000000000000;;						Name:         "docker",
0000000000000000000000000000000000000000;;						VolumeSource: v1.VolumeSource{HostPath: &v1.HostPathVolumeSource{Path: "/var/lib/docker"}},
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// deletePodsSync deletes a list of pods and block until pods disappear.
0000000000000000000000000000000000000000;;	func deletePodsSync(f *framework.Framework, pods []*v1.Pod) {
0000000000000000000000000000000000000000;;		var wg sync.WaitGroup
0000000000000000000000000000000000000000;;		for _, pod := range pods {
0000000000000000000000000000000000000000;;			wg.Add(1)
0000000000000000000000000000000000000000;;			go func(pod *v1.Pod) {
0000000000000000000000000000000000000000;;				defer wg.Done()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				err := f.PodClient().Delete(pod.ObjectMeta.Name, metav1.NewDeleteOptions(30))
0000000000000000000000000000000000000000;;				Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				Expect(framework.WaitForPodToDisappear(f.ClientSet, f.Namespace.Name, pod.ObjectMeta.Name, labels.Everything(),
0000000000000000000000000000000000000000;;					30*time.Second, 10*time.Minute)).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;			}(pod)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		wg.Wait()
0000000000000000000000000000000000000000;;		return
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// newTestPods creates a list of pods (specification) for test.
0000000000000000000000000000000000000000;;	func newTestPods(numPods int, volume bool, imageName, podType string) []*v1.Pod {
0000000000000000000000000000000000000000;;		var pods []*v1.Pod
0000000000000000000000000000000000000000;;		for i := 0; i < numPods; i++ {
0000000000000000000000000000000000000000;;			podName := "test-" + string(uuid.NewUUID())
0000000000000000000000000000000000000000;;			labels := map[string]string{
0000000000000000000000000000000000000000;;				"type": podType,
0000000000000000000000000000000000000000;;				"name": podName,
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if volume {
0000000000000000000000000000000000000000;;				pods = append(pods,
0000000000000000000000000000000000000000;;					&v1.Pod{
0000000000000000000000000000000000000000;;						ObjectMeta: metav1.ObjectMeta{
0000000000000000000000000000000000000000;;							Name:   podName,
0000000000000000000000000000000000000000;;							Labels: labels,
0000000000000000000000000000000000000000;;						},
0000000000000000000000000000000000000000;;						Spec: v1.PodSpec{
0000000000000000000000000000000000000000;;							// Restart policy is always (default).
0000000000000000000000000000000000000000;;							Containers: []v1.Container{
0000000000000000000000000000000000000000;;								{
0000000000000000000000000000000000000000;;									Image: imageName,
0000000000000000000000000000000000000000;;									Name:  podName,
0000000000000000000000000000000000000000;;									VolumeMounts: []v1.VolumeMount{
0000000000000000000000000000000000000000;;										{MountPath: "/test-volume-mnt", Name: podName + "-volume"},
0000000000000000000000000000000000000000;;									},
0000000000000000000000000000000000000000;;								},
0000000000000000000000000000000000000000;;							},
0000000000000000000000000000000000000000;;							Volumes: []v1.Volume{
0000000000000000000000000000000000000000;;								{Name: podName + "-volume", VolumeSource: v1.VolumeSource{EmptyDir: &v1.EmptyDirVolumeSource{}}},
0000000000000000000000000000000000000000;;							},
0000000000000000000000000000000000000000;;						},
0000000000000000000000000000000000000000;;					})
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				pods = append(pods,
0000000000000000000000000000000000000000;;					&v1.Pod{
0000000000000000000000000000000000000000;;						ObjectMeta: metav1.ObjectMeta{
0000000000000000000000000000000000000000;;							Name:   podName,
0000000000000000000000000000000000000000;;							Labels: labels,
0000000000000000000000000000000000000000;;						},
0000000000000000000000000000000000000000;;						Spec: v1.PodSpec{
0000000000000000000000000000000000000000;;							// Restart policy is always (default).
0000000000000000000000000000000000000000;;							Containers: []v1.Container{
0000000000000000000000000000000000000000;;								{
0000000000000000000000000000000000000000;;									Image: imageName,
0000000000000000000000000000000000000000;;									Name:  podName,
0000000000000000000000000000000000000000;;								},
0000000000000000000000000000000000000000;;							},
0000000000000000000000000000000000000000;;						},
0000000000000000000000000000000000000000;;					})
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return pods
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// GetResourceSeriesWithLabels gets the time series of resource usage of each container.
0000000000000000000000000000000000000000;;	func (r *ResourceCollector) GetResourceTimeSeries() map[string]*perftype.ResourceSeries {
0000000000000000000000000000000000000000;;		resourceSeries := make(map[string]*perftype.ResourceSeries)
0000000000000000000000000000000000000000;;		for key, name := range systemContainers {
0000000000000000000000000000000000000000;;			newSeries := &perftype.ResourceSeries{Units: map[string]string{
0000000000000000000000000000000000000000;;				"cpu":    "mCPU",
0000000000000000000000000000000000000000;;				"memory": "MB",
0000000000000000000000000000000000000000;;			}}
0000000000000000000000000000000000000000;;			resourceSeries[key] = newSeries
0000000000000000000000000000000000000000;;			for _, usage := range r.buffers[name] {
0000000000000000000000000000000000000000;;				newSeries.Timestamp = append(newSeries.Timestamp, usage.Timestamp.UnixNano())
0000000000000000000000000000000000000000;;				newSeries.CPUUsageInMilliCores = append(newSeries.CPUUsageInMilliCores, int64(usage.CPUUsageInCores*1000))
0000000000000000000000000000000000000000;;				newSeries.MemoryRSSInMegaBytes = append(newSeries.MemoryRSSInMegaBytes, int64(float64(usage.MemoryUsageInBytes)/(1024*1024)))
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return resourceSeries
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Code for getting container name of docker, copied from pkg/kubelet/cm/container_manager_linux.go
0000000000000000000000000000000000000000;;	// since they are not exposed
0000000000000000000000000000000000000000;;	const (
0000000000000000000000000000000000000000;;		kubeletProcessName    = "kubelet"
0000000000000000000000000000000000000000;;		dockerProcessName     = "docker"
0000000000000000000000000000000000000000;;		dockerPidFile         = "/var/run/docker.pid"
0000000000000000000000000000000000000000;;		containerdProcessName = "docker-containerd"
0000000000000000000000000000000000000000;;		containerdPidFile     = "/run/docker/libcontainerd/docker-containerd.pid"
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func getPidsForProcess(name, pidFile string) ([]int, error) {
0000000000000000000000000000000000000000;;		if len(pidFile) > 0 {
0000000000000000000000000000000000000000;;			if pid, err := getPidFromPidFile(pidFile); err == nil {
0000000000000000000000000000000000000000;;				return []int{pid}, nil
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				// log the error and fall back to pidof
0000000000000000000000000000000000000000;;				runtime.HandleError(err)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return procfs.PidOf(name)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func getPidFromPidFile(pidFile string) (int, error) {
0000000000000000000000000000000000000000;;		file, err := os.Open(pidFile)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return 0, fmt.Errorf("error opening pid file %s: %v", pidFile, err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		defer file.Close()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		data, err := ioutil.ReadAll(file)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return 0, fmt.Errorf("error reading pid file %s: %v", pidFile, err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		pid, err := strconv.Atoi(string(data))
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return 0, fmt.Errorf("error parsing %s as a number: %v", string(data), err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return pid, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func getContainerNameForProcess(name, pidFile string) (string, error) {
0000000000000000000000000000000000000000;;		pids, err := getPidsForProcess(name, pidFile)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return "", fmt.Errorf("failed to detect process id for %q - %v", name, err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if len(pids) == 0 {
0000000000000000000000000000000000000000;;			return "", nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		cont, err := getContainer(pids[0])
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return "", err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return cont, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// getContainer returns the cgroup associated with the specified pid.
0000000000000000000000000000000000000000;;	// It enforces a unified hierarchy for memory and cpu cgroups.
0000000000000000000000000000000000000000;;	// On systemd environments, it uses the name=systemd cgroup for the specified pid.
0000000000000000000000000000000000000000;;	func getContainer(pid int) (string, error) {
0000000000000000000000000000000000000000;;		cgs, err := cgroups.ParseCgroupFile(fmt.Sprintf("/proc/%d/cgroup", pid))
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return "", err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		cpu, found := cgs["cpu"]
0000000000000000000000000000000000000000;;		if !found {
0000000000000000000000000000000000000000;;			return "", cgroups.NewNotFoundError("cpu")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		memory, found := cgs["memory"]
0000000000000000000000000000000000000000;;		if !found {
0000000000000000000000000000000000000000;;			return "", cgroups.NewNotFoundError("memory")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// since we use this container for accounting, we need to ensure its a unified hierarchy.
0000000000000000000000000000000000000000;;		if cpu != memory {
0000000000000000000000000000000000000000;;			return "", fmt.Errorf("cpu and memory cgroup hierarchy not unified.  cpu: %s, memory: %s", cpu, memory)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// on systemd, every pid is in a unified cgroup hierarchy (name=systemd as seen in systemd-cgls)
0000000000000000000000000000000000000000;;		// cpu and memory accounting is off by default, users may choose to enable it per unit or globally.
0000000000000000000000000000000000000000;;		// users could enable CPU and memory accounting globally via /etc/systemd/system.conf (DefaultCPUAccounting=true DefaultMemoryAccounting=true).
0000000000000000000000000000000000000000;;		// users could also enable CPU and memory accounting per unit via CPUAccounting=true and MemoryAccounting=true
0000000000000000000000000000000000000000;;		// we only warn if accounting is not enabled for CPU or memory so as to not break local development flows where kubelet is launched in a terminal.
0000000000000000000000000000000000000000;;		// for example, the cgroup for the user session will be something like /user.slice/user-X.slice/session-X.scope, but the cpu and memory
0000000000000000000000000000000000000000;;		// cgroup will be the closest ancestor where accounting is performed (most likely /) on systems that launch docker containers.
0000000000000000000000000000000000000000;;		// as a result, on those systems, you will not get cpu or memory accounting statistics for kubelet.
0000000000000000000000000000000000000000;;		// in addition, you would not get memory or cpu accounting for the runtime unless accounting was enabled on its unit (or globally).
0000000000000000000000000000000000000000;;		if systemd, found := cgs["name=systemd"]; found {
0000000000000000000000000000000000000000;;			if systemd != cpu {
0000000000000000000000000000000000000000;;				log.Printf("CPUAccounting not enabled for pid: %d", pid)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if systemd != memory {
0000000000000000000000000000000000000000;;				log.Printf("MemoryAccounting not enabled for pid: %d", pid)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			return systemd, nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return cpu, nil
0000000000000000000000000000000000000000;;	}
