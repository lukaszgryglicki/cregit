0000000000000000000000000000000000000000;;	/*
0000000000000000000000000000000000000000;;	Copyright 2017 The Kubernetes Authors.
da9097ec61e8c46761f659308f80b6b2c511f13e;;	
0000000000000000000000000000000000000000;;	Licensed under the Apache License, Version 2.0 (the "License");
0000000000000000000000000000000000000000;;	you may not use this file except in compliance with the License.
0000000000000000000000000000000000000000;;	You may obtain a copy of the License at
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	    http://www.apache.org/licenses/LICENSE-2.0
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	Unless required by applicable law or agreed to in writing, software
0000000000000000000000000000000000000000;;	distributed under the License is distributed on an "AS IS" BASIS,
0000000000000000000000000000000000000000;;	WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
0000000000000000000000000000000000000000;;	See the License for the specific language governing permissions and
0000000000000000000000000000000000000000;;	limitations under the License.
0000000000000000000000000000000000000000;;	*/
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	package upgrades
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	import (
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/labels"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/util/wait"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/controller"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		"k8s.io/api/core/v1"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		extensions "k8s.io/api/extensions/v1beta1"
0000000000000000000000000000000000000000;;		metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/test/e2e/framework"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		. "github.com/onsi/ginkgo"
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// DaemonSetUpgradeTest tests that a DaemonSet is running before and after
0000000000000000000000000000000000000000;;	// a cluster upgrade.
0000000000000000000000000000000000000000;;	type DaemonSetUpgradeTest struct {
0000000000000000000000000000000000000000;;		daemonSet *extensions.DaemonSet
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (DaemonSetUpgradeTest) Name() string { return "[sig-apps] daemonset-upgrade" }
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Setup creates a DaemonSet and verifies that it's running
0000000000000000000000000000000000000000;;	func (t *DaemonSetUpgradeTest) Setup(f *framework.Framework) {
0000000000000000000000000000000000000000;;		daemonSetName := "ds1"
0000000000000000000000000000000000000000;;		labelSet := map[string]string{"ds-name": daemonSetName}
0000000000000000000000000000000000000000;;		image := framework.ServeHostnameImage
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		ns := f.Namespace
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		t.daemonSet = &extensions.DaemonSet{
0000000000000000000000000000000000000000;;			ObjectMeta: metav1.ObjectMeta{
0000000000000000000000000000000000000000;;				Namespace: ns.Name,
0000000000000000000000000000000000000000;;				Name:      daemonSetName,
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			Spec: extensions.DaemonSetSpec{
0000000000000000000000000000000000000000;;				Template: v1.PodTemplateSpec{
0000000000000000000000000000000000000000;;					ObjectMeta: metav1.ObjectMeta{
0000000000000000000000000000000000000000;;						Labels: labelSet,
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;					Spec: v1.PodSpec{
0000000000000000000000000000000000000000;;						Containers: []v1.Container{
0000000000000000000000000000000000000000;;							{
0000000000000000000000000000000000000000;;								Name:  daemonSetName,
0000000000000000000000000000000000000000;;								Image: image,
0000000000000000000000000000000000000000;;								Ports: []v1.ContainerPort{{ContainerPort: 9376}},
0000000000000000000000000000000000000000;;							},
0000000000000000000000000000000000000000;;						},
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		By("Creating a DaemonSet")
0000000000000000000000000000000000000000;;		var err error
0000000000000000000000000000000000000000;;		if t.daemonSet, err = f.ClientSet.Extensions().DaemonSets(ns.Name).Create(t.daemonSet); err != nil {
0000000000000000000000000000000000000000;;			framework.Failf("unable to create test DaemonSet %s: %v", t.daemonSet.Name, err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		By("Waiting for DaemonSet pods to become ready")
0000000000000000000000000000000000000000;;		err = wait.Poll(framework.Poll, framework.PodStartTimeout, func() (bool, error) {
0000000000000000000000000000000000000000;;			return checkRunningOnAllNodes(f, t.daemonSet.Namespace, t.daemonSet.Labels)
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;		framework.ExpectNoError(err)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		By("Validating the DaemonSet after creation")
0000000000000000000000000000000000000000;;		t.validateRunningDaemonSet(f)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Test waits until the upgrade has completed and then verifies that the DaemonSet
0000000000000000000000000000000000000000;;	// is still running
0000000000000000000000000000000000000000;;	func (t *DaemonSetUpgradeTest) Test(f *framework.Framework, done <-chan struct{}, upgrade UpgradeType) {
0000000000000000000000000000000000000000;;		By("Waiting for upgradet to complete before re-validating DaemonSet")
0000000000000000000000000000000000000000;;		<-done
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		By("validating the DaemonSet is still running after upgrade")
0000000000000000000000000000000000000000;;		t.validateRunningDaemonSet(f)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Teardown cleans up any remaining resources.
0000000000000000000000000000000000000000;;	func (t *DaemonSetUpgradeTest) Teardown(f *framework.Framework) {
0000000000000000000000000000000000000000;;		// rely on the namespace deletion to clean up everything
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (t *DaemonSetUpgradeTest) validateRunningDaemonSet(f *framework.Framework) {
0000000000000000000000000000000000000000;;		By("confirming the DaemonSet pods are running on all expected nodes")
0000000000000000000000000000000000000000;;		res, err := checkRunningOnAllNodes(f, t.daemonSet.Namespace, t.daemonSet.Labels)
0000000000000000000000000000000000000000;;		framework.ExpectNoError(err)
0000000000000000000000000000000000000000;;		if !res {
0000000000000000000000000000000000000000;;			framework.Failf("expected DaemonSet pod to be running on all nodes, it was not")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// DaemonSet resource itself should be good
0000000000000000000000000000000000000000;;		By("confirming the DaemonSet resource is in a good state")
0000000000000000000000000000000000000000;;		res, err = checkDaemonStatus(f, t.daemonSet.Namespace, t.daemonSet.Name)
0000000000000000000000000000000000000000;;		framework.ExpectNoError(err)
0000000000000000000000000000000000000000;;		if !res {
0000000000000000000000000000000000000000;;			framework.Failf("expected DaemonSet to be in a good state, it was not")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func checkRunningOnAllNodes(f *framework.Framework, namespace string, selector map[string]string) (bool, error) {
0000000000000000000000000000000000000000;;		nodeList, err := f.ClientSet.Core().Nodes().List(metav1.ListOptions{})
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return false, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		nodeNames := make([]string, 0)
0000000000000000000000000000000000000000;;		for _, node := range nodeList.Items {
0000000000000000000000000000000000000000;;			if len(node.Spec.Taints) == 0 {
0000000000000000000000000000000000000000;;				nodeNames = append(nodeNames, node.Name)
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				framework.Logf("Node %v not expected to have DaemonSet pod, has taints %v", node.Name, node.Spec.Taints)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return checkDaemonPodOnNodes(f, namespace, selector, nodeNames)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func checkDaemonPodOnNodes(f *framework.Framework, namespace string, labelSet map[string]string, nodeNames []string) (bool, error) {
0000000000000000000000000000000000000000;;		selector := labels.Set(labelSet).AsSelector()
0000000000000000000000000000000000000000;;		options := metav1.ListOptions{LabelSelector: selector.String()}
0000000000000000000000000000000000000000;;		podList, err := f.ClientSet.Core().Pods(namespace).List(options)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return false, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		pods := podList.Items
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		nodesToPodCount := make(map[string]int)
0000000000000000000000000000000000000000;;		for _, pod := range pods {
0000000000000000000000000000000000000000;;			if controller.IsPodActive(&pod) {
0000000000000000000000000000000000000000;;				framework.Logf("Pod name: %v\t Node Name: %v", pod.Name, pod.Spec.NodeName)
0000000000000000000000000000000000000000;;				nodesToPodCount[pod.Spec.NodeName]++
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		framework.Logf("nodesToPodCount: %v", nodesToPodCount)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Ensure that exactly 1 pod is running on all nodes in nodeNames.
0000000000000000000000000000000000000000;;		for _, nodeName := range nodeNames {
0000000000000000000000000000000000000000;;			if nodesToPodCount[nodeName] != 1 {
0000000000000000000000000000000000000000;;				return false, nil
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Ensure that sizes of the lists are the same. We've verified that every element of nodeNames is in
0000000000000000000000000000000000000000;;		// nodesToPodCount, so verifying the lengths are equal ensures that there aren't pods running on any
0000000000000000000000000000000000000000;;		// other nodes.
0000000000000000000000000000000000000000;;		return len(nodesToPodCount) == len(nodeNames), nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func checkDaemonStatus(f *framework.Framework, namespace string, dsName string) (bool, error) {
0000000000000000000000000000000000000000;;		ds, err := f.ClientSet.ExtensionsV1beta1().DaemonSets(namespace).Get(dsName, metav1.GetOptions{})
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return false, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		desired, scheduled, ready := ds.Status.DesiredNumberScheduled, ds.Status.CurrentNumberScheduled, ds.Status.NumberReady
0000000000000000000000000000000000000000;;		if desired != scheduled && desired != ready {
0000000000000000000000000000000000000000;;			return false, nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return true, nil
0000000000000000000000000000000000000000;;	}
