0000000000000000000000000000000000000000;;	/*
0000000000000000000000000000000000000000;;	Copyright 2015 The Kubernetes Authors.
f56092800f7b9f9e5e5cc6af7e0e7fe16e08d858;test/e2e/pd.go[test/e2e/pd.go][test/e2e/storage/pd.go];	
0000000000000000000000000000000000000000;;	Licensed under the Apache License, Version 2.0 (the "License");
0000000000000000000000000000000000000000;;	you may not use this file except in compliance with the License.
0000000000000000000000000000000000000000;;	You may obtain a copy of the License at
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	    http://www.apache.org/licenses/LICENSE-2.0
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	Unless required by applicable law or agreed to in writing, software
0000000000000000000000000000000000000000;;	distributed under the License is distributed on an "AS IS" BASIS,
0000000000000000000000000000000000000000;;	WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
0000000000000000000000000000000000000000;;	See the License for the specific language governing permissions and
0000000000000000000000000000000000000000;;	limitations under the License.
0000000000000000000000000000000000000000;;	*/
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	package storage
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	import (
0000000000000000000000000000000000000000;;		"fmt"
0000000000000000000000000000000000000000;;		mathrand "math/rand"
0000000000000000000000000000000000000000;;		"os/exec"
0000000000000000000000000000000000000000;;		"strings"
0000000000000000000000000000000000000000;;		"time"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		"google.golang.org/api/googleapi"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		"github.com/aws/aws-sdk-go/aws"
0000000000000000000000000000000000000000;;		"github.com/aws/aws-sdk-go/aws/session"
0000000000000000000000000000000000000000;;		"github.com/aws/aws-sdk-go/service/ec2"
0000000000000000000000000000000000000000;;		. "github.com/onsi/ginkgo"
0000000000000000000000000000000000000000;;		. "github.com/onsi/gomega"
0000000000000000000000000000000000000000;;		"k8s.io/api/core/v1"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/api/resource"
0000000000000000000000000000000000000000;;		metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/types"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/util/uuid"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/api"
0000000000000000000000000000000000000000;;		v1core "k8s.io/kubernetes/pkg/client/clientset_generated/clientset/typed/core/v1"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/test/e2e/framework"
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	const (
0000000000000000000000000000000000000000;;		gcePDDetachTimeout  = 10 * time.Minute
0000000000000000000000000000000000000000;;		gcePDDetachPollTime = 10 * time.Second
0000000000000000000000000000000000000000;;		nodeStatusTimeout   = 10 * time.Minute
0000000000000000000000000000000000000000;;		nodeStatusPollTime  = 1 * time.Second
0000000000000000000000000000000000000000;;		maxReadRetry        = 3
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	var _ = SIGDescribe("Pod Disks", func() {
0000000000000000000000000000000000000000;;		var (
0000000000000000000000000000000000000000;;			podClient  v1core.PodInterface
0000000000000000000000000000000000000000;;			nodeClient v1core.NodeInterface
0000000000000000000000000000000000000000;;			host0Name  types.NodeName
0000000000000000000000000000000000000000;;			host1Name  types.NodeName
0000000000000000000000000000000000000000;;			nodes      *v1.NodeList
0000000000000000000000000000000000000000;;		)
0000000000000000000000000000000000000000;;		f := framework.NewDefaultFramework("pod-disks")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		BeforeEach(func() {
0000000000000000000000000000000000000000;;			framework.SkipUnlessNodeCountIsAtLeast(2)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			podClient = f.ClientSet.Core().Pods(f.Namespace.Name)
0000000000000000000000000000000000000000;;			nodeClient = f.ClientSet.Core().Nodes()
0000000000000000000000000000000000000000;;			nodes = framework.GetReadySchedulableNodesOrDie(f.ClientSet)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			Expect(len(nodes.Items)).To(BeNumerically(">=", 2), "Requires at least 2 nodes")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			host0Name = types.NodeName(nodes.Items[0].ObjectMeta.Name)
0000000000000000000000000000000000000000;;			host1Name = types.NodeName(nodes.Items[1].ObjectMeta.Name)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			mathrand.Seed(time.Now().UTC().UnixNano())
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		It("should schedule a pod w/ a RW PD, ungracefully remove it, then schedule it on another host [Slow]", func() {
0000000000000000000000000000000000000000;;			framework.SkipUnlessProviderIs("gce", "gke", "aws")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("creating PD")
0000000000000000000000000000000000000000;;			diskName, err := framework.CreatePDWithRetry()
0000000000000000000000000000000000000000;;			framework.ExpectNoError(err, "Error creating PD")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			host0Pod := testPDPod([]string{diskName}, host0Name, false /* readOnly */, 1 /* numContainers */)
0000000000000000000000000000000000000000;;			host1Pod := testPDPod([]string{diskName}, host1Name, false /* readOnly */, 1 /* numContainers */)
0000000000000000000000000000000000000000;;			containerName := "mycontainer"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			defer func() {
0000000000000000000000000000000000000000;;				// Teardown pods, PD. Ignore errors.
0000000000000000000000000000000000000000;;				// Teardown should do nothing unless test failed.
0000000000000000000000000000000000000000;;				By("cleaning up PD-RW test environment")
0000000000000000000000000000000000000000;;				podClient.Delete(host0Pod.Name, metav1.NewDeleteOptions(0))
0000000000000000000000000000000000000000;;				podClient.Delete(host1Pod.Name, metav1.NewDeleteOptions(0))
0000000000000000000000000000000000000000;;				detachAndDeletePDs(diskName, []types.NodeName{host0Name, host1Name})
0000000000000000000000000000000000000000;;			}()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("submitting host0Pod to kubernetes")
0000000000000000000000000000000000000000;;			_, err = podClient.Create(host0Pod)
0000000000000000000000000000000000000000;;			framework.ExpectNoError(err, fmt.Sprintf("Failed to create host0Pod: %v", err))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			framework.ExpectNoError(f.WaitForPodRunningSlow(host0Pod.Name))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			testFile := "/testpd1/tracker"
0000000000000000000000000000000000000000;;			testFileContents := fmt.Sprintf("%v", mathrand.Int())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			framework.ExpectNoError(f.WriteFileViaContainer(host0Pod.Name, containerName, testFile, testFileContents))
0000000000000000000000000000000000000000;;			framework.Logf("Wrote value: %v", testFileContents)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Verify that disk shows up for in node 1's VolumeInUse list
0000000000000000000000000000000000000000;;			framework.ExpectNoError(waitForPDInVolumesInUse(nodeClient, diskName, host0Name, nodeStatusTimeout, true /* shouldExist */))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("deleting host0Pod")
0000000000000000000000000000000000000000;;			// Delete pod with 0 grace period
0000000000000000000000000000000000000000;;			framework.ExpectNoError(podClient.Delete(host0Pod.Name, metav1.NewDeleteOptions(0)), "Failed to delete host0Pod")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("submitting host1Pod to kubernetes")
0000000000000000000000000000000000000000;;			_, err = podClient.Create(host1Pod)
0000000000000000000000000000000000000000;;			framework.ExpectNoError(err, "Failed to create host1Pod")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			framework.ExpectNoError(f.WaitForPodRunningSlow(host1Pod.Name))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			verifyPDContentsViaContainer(f, host1Pod.Name, containerName, map[string]string{testFile: testFileContents})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Verify that disk is removed from node 1's VolumeInUse list
0000000000000000000000000000000000000000;;			framework.ExpectNoError(waitForPDInVolumesInUse(nodeClient, diskName, host0Name, nodeStatusTimeout, false /* shouldExist */))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("deleting host1Pod")
0000000000000000000000000000000000000000;;			framework.ExpectNoError(podClient.Delete(host1Pod.Name, metav1.NewDeleteOptions(0)), "Failed to delete host1Pod")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Test completed successfully, waiting for PD to safely detach")
0000000000000000000000000000000000000000;;			waitForPDDetach(diskName, host0Name)
0000000000000000000000000000000000000000;;			waitForPDDetach(diskName, host1Name)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		It("Should schedule a pod w/ a RW PD, gracefully remove it, then schedule it on another host [Slow]", func() {
0000000000000000000000000000000000000000;;			framework.SkipUnlessProviderIs("gce", "gke", "aws")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("creating PD")
0000000000000000000000000000000000000000;;			diskName, err := framework.CreatePDWithRetry()
0000000000000000000000000000000000000000;;			framework.ExpectNoError(err, "Error creating PD")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			host0Pod := testPDPod([]string{diskName}, host0Name, false /* readOnly */, 1 /* numContainers */)
0000000000000000000000000000000000000000;;			host1Pod := testPDPod([]string{diskName}, host1Name, false /* readOnly */, 1 /* numContainers */)
0000000000000000000000000000000000000000;;			containerName := "mycontainer"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			defer func() {
0000000000000000000000000000000000000000;;				// Teardown pods, PD. Ignore errors.
0000000000000000000000000000000000000000;;				// Teardown should do nothing unless test failed.
0000000000000000000000000000000000000000;;				By("cleaning up PD-RW test environment")
0000000000000000000000000000000000000000;;				podClient.Delete(host0Pod.Name, &metav1.DeleteOptions{})
0000000000000000000000000000000000000000;;				podClient.Delete(host1Pod.Name, &metav1.DeleteOptions{})
0000000000000000000000000000000000000000;;				detachAndDeletePDs(diskName, []types.NodeName{host0Name, host1Name})
0000000000000000000000000000000000000000;;			}()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("submitting host0Pod to kubernetes")
0000000000000000000000000000000000000000;;			_, err = podClient.Create(host0Pod)
0000000000000000000000000000000000000000;;			framework.ExpectNoError(err, fmt.Sprintf("Failed to create host0Pod: %v", err))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			framework.ExpectNoError(f.WaitForPodRunningSlow(host0Pod.Name))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			testFile := "/testpd1/tracker"
0000000000000000000000000000000000000000;;			testFileContents := fmt.Sprintf("%v", mathrand.Int())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			framework.ExpectNoError(f.WriteFileViaContainer(host0Pod.Name, containerName, testFile, testFileContents))
0000000000000000000000000000000000000000;;			framework.Logf("Wrote value: %v", testFileContents)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Verify that disk shows up for in node 1's VolumeInUse list
0000000000000000000000000000000000000000;;			framework.ExpectNoError(waitForPDInVolumesInUse(nodeClient, diskName, host0Name, nodeStatusTimeout, true /* shouldExist */))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("deleting host0Pod")
0000000000000000000000000000000000000000;;			// Delete pod with default grace period 30s
0000000000000000000000000000000000000000;;			framework.ExpectNoError(podClient.Delete(host0Pod.Name, &metav1.DeleteOptions{}), "Failed to delete host0Pod")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("submitting host1Pod to kubernetes")
0000000000000000000000000000000000000000;;			_, err = podClient.Create(host1Pod)
0000000000000000000000000000000000000000;;			framework.ExpectNoError(err, "Failed to create host1Pod")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			framework.ExpectNoError(f.WaitForPodRunningSlow(host1Pod.Name))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			verifyPDContentsViaContainer(f, host1Pod.Name, containerName, map[string]string{testFile: testFileContents})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Verify that disk is removed from node 1's VolumeInUse list
0000000000000000000000000000000000000000;;			framework.ExpectNoError(waitForPDInVolumesInUse(nodeClient, diskName, host0Name, nodeStatusTimeout, false /* shouldExist */))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("deleting host1Pod")
0000000000000000000000000000000000000000;;			framework.ExpectNoError(podClient.Delete(host1Pod.Name, &metav1.DeleteOptions{}), "Failed to delete host1Pod")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Test completed successfully, waiting for PD to safely detach")
0000000000000000000000000000000000000000;;			waitForPDDetach(diskName, host0Name)
0000000000000000000000000000000000000000;;			waitForPDDetach(diskName, host1Name)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		It("should schedule a pod w/ a readonly PD on two hosts, then remove both ungracefully. [Slow]", func() {
0000000000000000000000000000000000000000;;			framework.SkipUnlessProviderIs("gce", "gke")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("creating PD")
0000000000000000000000000000000000000000;;			diskName, err := framework.CreatePDWithRetry()
0000000000000000000000000000000000000000;;			framework.ExpectNoError(err, "Error creating PD")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			rwPod := testPDPod([]string{diskName}, host0Name, false /* readOnly */, 1 /* numContainers */)
0000000000000000000000000000000000000000;;			host0ROPod := testPDPod([]string{diskName}, host0Name, true /* readOnly */, 1 /* numContainers */)
0000000000000000000000000000000000000000;;			host1ROPod := testPDPod([]string{diskName}, host1Name, true /* readOnly */, 1 /* numContainers */)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			defer func() {
0000000000000000000000000000000000000000;;				By("cleaning up PD-RO test environment")
0000000000000000000000000000000000000000;;				// Teardown pods, PD. Ignore errors.
0000000000000000000000000000000000000000;;				// Teardown should do nothing unless test failed.
0000000000000000000000000000000000000000;;				podClient.Delete(rwPod.Name, metav1.NewDeleteOptions(0))
0000000000000000000000000000000000000000;;				podClient.Delete(host0ROPod.Name, metav1.NewDeleteOptions(0))
0000000000000000000000000000000000000000;;				podClient.Delete(host1ROPod.Name, metav1.NewDeleteOptions(0))
0000000000000000000000000000000000000000;;				detachAndDeletePDs(diskName, []types.NodeName{host0Name, host1Name})
0000000000000000000000000000000000000000;;			}()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("submitting rwPod to ensure PD is formatted")
0000000000000000000000000000000000000000;;			_, err = podClient.Create(rwPod)
0000000000000000000000000000000000000000;;			framework.ExpectNoError(err, "Failed to create rwPod")
0000000000000000000000000000000000000000;;			framework.ExpectNoError(f.WaitForPodRunningSlow(rwPod.Name))
0000000000000000000000000000000000000000;;			// Delete pod with 0 grace period
0000000000000000000000000000000000000000;;			framework.ExpectNoError(podClient.Delete(rwPod.Name, metav1.NewDeleteOptions(0)), "Failed to delete host0Pod")
0000000000000000000000000000000000000000;;			framework.ExpectNoError(waitForPDDetach(diskName, host0Name))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("submitting host0ROPod to kubernetes")
0000000000000000000000000000000000000000;;			_, err = podClient.Create(host0ROPod)
0000000000000000000000000000000000000000;;			framework.ExpectNoError(err, "Failed to create host0ROPod")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("submitting host1ROPod to kubernetes")
0000000000000000000000000000000000000000;;			_, err = podClient.Create(host1ROPod)
0000000000000000000000000000000000000000;;			framework.ExpectNoError(err, "Failed to create host1ROPod")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			framework.ExpectNoError(f.WaitForPodRunningSlow(host0ROPod.Name))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			framework.ExpectNoError(f.WaitForPodRunningSlow(host1ROPod.Name))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("deleting host0ROPod")
0000000000000000000000000000000000000000;;			framework.ExpectNoError(podClient.Delete(host0ROPod.Name, metav1.NewDeleteOptions(0)), "Failed to delete host0ROPod")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("deleting host1ROPod")
0000000000000000000000000000000000000000;;			framework.ExpectNoError(podClient.Delete(host1ROPod.Name, metav1.NewDeleteOptions(0)), "Failed to delete host1ROPod")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Test completed successfully, waiting for PD to safely detach")
0000000000000000000000000000000000000000;;			waitForPDDetach(diskName, host0Name)
0000000000000000000000000000000000000000;;			waitForPDDetach(diskName, host1Name)
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		It("Should schedule a pod w/ a readonly PD on two hosts, then remove both gracefully. [Slow]", func() {
0000000000000000000000000000000000000000;;			framework.SkipUnlessProviderIs("gce", "gke")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("creating PD")
0000000000000000000000000000000000000000;;			diskName, err := framework.CreatePDWithRetry()
0000000000000000000000000000000000000000;;			framework.ExpectNoError(err, "Error creating PD")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			rwPod := testPDPod([]string{diskName}, host0Name, false /* readOnly */, 1 /* numContainers */)
0000000000000000000000000000000000000000;;			host0ROPod := testPDPod([]string{diskName}, host0Name, true /* readOnly */, 1 /* numContainers */)
0000000000000000000000000000000000000000;;			host1ROPod := testPDPod([]string{diskName}, host1Name, true /* readOnly */, 1 /* numContainers */)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			defer func() {
0000000000000000000000000000000000000000;;				By("cleaning up PD-RO test environment")
0000000000000000000000000000000000000000;;				// Teardown pods, PD. Ignore errors.
0000000000000000000000000000000000000000;;				// Teardown should do nothing unless test failed.
0000000000000000000000000000000000000000;;				podClient.Delete(rwPod.Name, &metav1.DeleteOptions{})
0000000000000000000000000000000000000000;;				podClient.Delete(host0ROPod.Name, &metav1.DeleteOptions{})
0000000000000000000000000000000000000000;;				podClient.Delete(host1ROPod.Name, &metav1.DeleteOptions{})
0000000000000000000000000000000000000000;;				detachAndDeletePDs(diskName, []types.NodeName{host0Name, host1Name})
0000000000000000000000000000000000000000;;			}()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("submitting rwPod to ensure PD is formatted")
0000000000000000000000000000000000000000;;			_, err = podClient.Create(rwPod)
0000000000000000000000000000000000000000;;			framework.ExpectNoError(err, "Failed to create rwPod")
0000000000000000000000000000000000000000;;			framework.ExpectNoError(f.WaitForPodRunningSlow(rwPod.Name))
0000000000000000000000000000000000000000;;			// Delete pod with default grace period 30s
0000000000000000000000000000000000000000;;			framework.ExpectNoError(podClient.Delete(rwPod.Name, &metav1.DeleteOptions{}), "Failed to delete host0Pod")
0000000000000000000000000000000000000000;;			framework.ExpectNoError(waitForPDDetach(diskName, host0Name))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("submitting host0ROPod to kubernetes")
0000000000000000000000000000000000000000;;			_, err = podClient.Create(host0ROPod)
0000000000000000000000000000000000000000;;			framework.ExpectNoError(err, "Failed to create host0ROPod")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("submitting host1ROPod to kubernetes")
0000000000000000000000000000000000000000;;			_, err = podClient.Create(host1ROPod)
0000000000000000000000000000000000000000;;			framework.ExpectNoError(err, "Failed to create host1ROPod")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			framework.ExpectNoError(f.WaitForPodRunningSlow(host0ROPod.Name))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			framework.ExpectNoError(f.WaitForPodRunningSlow(host1ROPod.Name))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("deleting host0ROPod")
0000000000000000000000000000000000000000;;			framework.ExpectNoError(podClient.Delete(host0ROPod.Name, &metav1.DeleteOptions{}), "Failed to delete host0ROPod")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("deleting host1ROPod")
0000000000000000000000000000000000000000;;			framework.ExpectNoError(podClient.Delete(host1ROPod.Name, &metav1.DeleteOptions{}), "Failed to delete host1ROPod")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Test completed successfully, waiting for PD to safely detach")
0000000000000000000000000000000000000000;;			waitForPDDetach(diskName, host0Name)
0000000000000000000000000000000000000000;;			waitForPDDetach(diskName, host1Name)
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		It("should schedule a pod w/ a RW PD shared between multiple containers, write to PD, delete pod, verify contents, and repeat in rapid succession [Slow]", func() {
0000000000000000000000000000000000000000;;			framework.SkipUnlessProviderIs("gce", "gke", "aws")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("creating PD")
0000000000000000000000000000000000000000;;			diskName, err := framework.CreatePDWithRetry()
0000000000000000000000000000000000000000;;			framework.ExpectNoError(err, "Error creating PD")
0000000000000000000000000000000000000000;;			numContainers := 4
0000000000000000000000000000000000000000;;			var host0Pod *v1.Pod
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			defer func() {
0000000000000000000000000000000000000000;;				By("cleaning up PD-RW test environment")
0000000000000000000000000000000000000000;;				// Teardown pods, PD. Ignore errors.
0000000000000000000000000000000000000000;;				// Teardown should do nothing unless test failed.
0000000000000000000000000000000000000000;;				if host0Pod != nil {
0000000000000000000000000000000000000000;;					podClient.Delete(host0Pod.Name, metav1.NewDeleteOptions(0))
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				detachAndDeletePDs(diskName, []types.NodeName{host0Name})
0000000000000000000000000000000000000000;;			}()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			fileAndContentToVerify := make(map[string]string)
0000000000000000000000000000000000000000;;			for i := 0; i < 3; i++ {
0000000000000000000000000000000000000000;;				framework.Logf("PD Read/Writer Iteration #%v", i)
0000000000000000000000000000000000000000;;				By("submitting host0Pod to kubernetes")
0000000000000000000000000000000000000000;;				host0Pod = testPDPod([]string{diskName}, host0Name, false /* readOnly */, numContainers)
0000000000000000000000000000000000000000;;				_, err = podClient.Create(host0Pod)
0000000000000000000000000000000000000000;;				framework.ExpectNoError(err, fmt.Sprintf("Failed to create host0Pod: %v", err))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				framework.ExpectNoError(f.WaitForPodRunningSlow(host0Pod.Name))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				// randomly select a container and read/verify pd contents from it
0000000000000000000000000000000000000000;;				containerName := fmt.Sprintf("mycontainer%v", mathrand.Intn(numContainers)+1)
0000000000000000000000000000000000000000;;				verifyPDContentsViaContainer(f, host0Pod.Name, containerName, fileAndContentToVerify)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				// Randomly select a container to write a file to PD from
0000000000000000000000000000000000000000;;				containerName = fmt.Sprintf("mycontainer%v", mathrand.Intn(numContainers)+1)
0000000000000000000000000000000000000000;;				testFile := fmt.Sprintf("/testpd1/tracker%v", i)
0000000000000000000000000000000000000000;;				testFileContents := fmt.Sprintf("%v", mathrand.Int())
0000000000000000000000000000000000000000;;				fileAndContentToVerify[testFile] = testFileContents
0000000000000000000000000000000000000000;;				framework.ExpectNoError(f.WriteFileViaContainer(host0Pod.Name, containerName, testFile, testFileContents))
0000000000000000000000000000000000000000;;				framework.Logf("Wrote value: \"%v\" to PD %q from pod %q container %q", testFileContents, diskName, host0Pod.Name, containerName)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				// Randomly select a container and read/verify pd contents from it
0000000000000000000000000000000000000000;;				containerName = fmt.Sprintf("mycontainer%v", mathrand.Intn(numContainers)+1)
0000000000000000000000000000000000000000;;				verifyPDContentsViaContainer(f, host0Pod.Name, containerName, fileAndContentToVerify)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				By("deleting host0Pod")
0000000000000000000000000000000000000000;;				framework.ExpectNoError(podClient.Delete(host0Pod.Name, metav1.NewDeleteOptions(0)), "Failed to delete host0Pod")
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Test completed successfully, waiting for PD to safely detach")
0000000000000000000000000000000000000000;;			waitForPDDetach(diskName, host0Name)
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		It("should schedule a pod w/two RW PDs both mounted to one container, write to PD, verify contents, delete pod, recreate pod, verify contents, and repeat in rapid succession [Slow]", func() {
0000000000000000000000000000000000000000;;			framework.SkipUnlessProviderIs("gce", "gke", "aws")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("creating PD1")
0000000000000000000000000000000000000000;;			disk1Name, err := framework.CreatePDWithRetry()
0000000000000000000000000000000000000000;;			framework.ExpectNoError(err, "Error creating PD1")
0000000000000000000000000000000000000000;;			By("creating PD2")
0000000000000000000000000000000000000000;;			disk2Name, err := framework.CreatePDWithRetry()
0000000000000000000000000000000000000000;;			framework.ExpectNoError(err, "Error creating PD2")
0000000000000000000000000000000000000000;;			var host0Pod *v1.Pod
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			defer func() {
0000000000000000000000000000000000000000;;				By("cleaning up PD-RW test environment")
0000000000000000000000000000000000000000;;				// Teardown pods, PD. Ignore errors.
0000000000000000000000000000000000000000;;				// Teardown should do nothing unless test failed.
0000000000000000000000000000000000000000;;				if host0Pod != nil {
0000000000000000000000000000000000000000;;					podClient.Delete(host0Pod.Name, metav1.NewDeleteOptions(0))
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				detachAndDeletePDs(disk1Name, []types.NodeName{host0Name})
0000000000000000000000000000000000000000;;				detachAndDeletePDs(disk2Name, []types.NodeName{host0Name})
0000000000000000000000000000000000000000;;			}()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			containerName := "mycontainer"
0000000000000000000000000000000000000000;;			fileAndContentToVerify := make(map[string]string)
0000000000000000000000000000000000000000;;			for i := 0; i < 3; i++ {
0000000000000000000000000000000000000000;;				framework.Logf("PD Read/Writer Iteration #%v", i)
0000000000000000000000000000000000000000;;				By("submitting host0Pod to kubernetes")
0000000000000000000000000000000000000000;;				host0Pod = testPDPod([]string{disk1Name, disk2Name}, host0Name, false /* readOnly */, 1 /* numContainers */)
0000000000000000000000000000000000000000;;				_, err = podClient.Create(host0Pod)
0000000000000000000000000000000000000000;;				framework.ExpectNoError(err, fmt.Sprintf("Failed to create host0Pod: %v", err))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				framework.ExpectNoError(f.WaitForPodRunningSlow(host0Pod.Name))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				// Read/verify pd contents for both disks from container
0000000000000000000000000000000000000000;;				verifyPDContentsViaContainer(f, host0Pod.Name, containerName, fileAndContentToVerify)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				// Write a file to both PDs from container
0000000000000000000000000000000000000000;;				testFilePD1 := fmt.Sprintf("/testpd1/tracker%v", i)
0000000000000000000000000000000000000000;;				testFilePD2 := fmt.Sprintf("/testpd2/tracker%v", i)
0000000000000000000000000000000000000000;;				testFilePD1Contents := fmt.Sprintf("%v", mathrand.Int())
0000000000000000000000000000000000000000;;				testFilePD2Contents := fmt.Sprintf("%v", mathrand.Int())
0000000000000000000000000000000000000000;;				fileAndContentToVerify[testFilePD1] = testFilePD1Contents
0000000000000000000000000000000000000000;;				fileAndContentToVerify[testFilePD2] = testFilePD2Contents
0000000000000000000000000000000000000000;;				framework.ExpectNoError(f.WriteFileViaContainer(host0Pod.Name, containerName, testFilePD1, testFilePD1Contents))
0000000000000000000000000000000000000000;;				framework.Logf("Wrote value: \"%v\" to PD1 (%q) from pod %q container %q", testFilePD1Contents, disk1Name, host0Pod.Name, containerName)
0000000000000000000000000000000000000000;;				framework.ExpectNoError(f.WriteFileViaContainer(host0Pod.Name, containerName, testFilePD2, testFilePD2Contents))
0000000000000000000000000000000000000000;;				framework.Logf("Wrote value: \"%v\" to PD2 (%q) from pod %q container %q", testFilePD2Contents, disk2Name, host0Pod.Name, containerName)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				// Read/verify pd contents for both disks from container
0000000000000000000000000000000000000000;;				verifyPDContentsViaContainer(f, host0Pod.Name, containerName, fileAndContentToVerify)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				By("deleting host0Pod")
0000000000000000000000000000000000000000;;				framework.ExpectNoError(podClient.Delete(host0Pod.Name, metav1.NewDeleteOptions(0)), "Failed to delete host0Pod")
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Test completed successfully, waiting for PD to safely detach")
0000000000000000000000000000000000000000;;			waitForPDDetach(disk1Name, host0Name)
0000000000000000000000000000000000000000;;			waitForPDDetach(disk2Name, host0Name)
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		It("should be able to detach from a node which was deleted [Slow] [Disruptive]", func() {
0000000000000000000000000000000000000000;;			framework.SkipUnlessProviderIs("gce")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			initialGroupSize, err := framework.GroupSize(framework.TestContext.CloudConfig.NodeInstanceGroup)
0000000000000000000000000000000000000000;;			framework.ExpectNoError(err, "Error getting group size")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Creating a pd")
0000000000000000000000000000000000000000;;			diskName, err := framework.CreatePDWithRetry()
0000000000000000000000000000000000000000;;			framework.ExpectNoError(err, "Error creating a pd")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			host0Pod := testPDPod([]string{diskName}, host0Name, false, 1)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			containerName := "mycontainer"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			defer func() {
0000000000000000000000000000000000000000;;				By("Cleaning up PD-RW test env")
0000000000000000000000000000000000000000;;				podClient.Delete(host0Pod.Name, metav1.NewDeleteOptions(0))
0000000000000000000000000000000000000000;;				detachAndDeletePDs(diskName, []types.NodeName{host0Name})
0000000000000000000000000000000000000000;;				framework.WaitForNodeToBeReady(f.ClientSet, string(host0Name), nodeStatusTimeout)
0000000000000000000000000000000000000000;;				framework.WaitForAllNodesSchedulable(f.ClientSet, nodeStatusTimeout)
0000000000000000000000000000000000000000;;				nodes = framework.GetReadySchedulableNodesOrDie(f.ClientSet)
0000000000000000000000000000000000000000;;				Expect(len(nodes.Items)).To(Equal(initialGroupSize), "Requires node count to return to initial group size.")
0000000000000000000000000000000000000000;;			}()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("submitting host0Pod to kubernetes")
0000000000000000000000000000000000000000;;			_, err = podClient.Create(host0Pod)
0000000000000000000000000000000000000000;;			framework.ExpectNoError(err, fmt.Sprintf("Failed to create host0pod: %v", err))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			framework.ExpectNoError(f.WaitForPodRunningSlow(host0Pod.Name))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			testFile := "/testpd1/tracker"
0000000000000000000000000000000000000000;;			testFileContents := fmt.Sprintf("%v", mathrand.Int())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			framework.ExpectNoError(f.WriteFileViaContainer(host0Pod.Name, containerName, testFile, testFileContents))
0000000000000000000000000000000000000000;;			framework.Logf("Wrote value: %v", testFileContents)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Verify that disk shows up in node 0's volumeInUse list
0000000000000000000000000000000000000000;;			framework.ExpectNoError(waitForPDInVolumesInUse(nodeClient, diskName, host0Name, nodeStatusTimeout, true /* should exist*/))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			output, err := exec.Command("gcloud", "compute", "instances", "list").CombinedOutput()
0000000000000000000000000000000000000000;;			framework.ExpectNoError(err, fmt.Sprintf("Unable to get list of node instances %v", err))
0000000000000000000000000000000000000000;;			Expect(true, strings.Contains(string(output), string(host0Name)))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("deleting host0")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			output, err = exec.Command("gcloud", "compute", "instances", "delete", string(host0Name), "--project="+framework.TestContext.CloudConfig.ProjectID, "--zone="+framework.TestContext.CloudConfig.Zone).CombinedOutput()
0000000000000000000000000000000000000000;;			framework.ExpectNoError(err, fmt.Sprintf("Failed to delete host0pod: %v", err))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			output, err = exec.Command("gcloud", "compute", "instances", "list").CombinedOutput()
0000000000000000000000000000000000000000;;			framework.ExpectNoError(err, fmt.Sprintf("Unable to get list of node instances %v", err))
0000000000000000000000000000000000000000;;			Expect(false, strings.Contains(string(output), string(host0Name)))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// The disk should be detached from host0 on it's deletion
0000000000000000000000000000000000000000;;			By("Waiting for pd to detach from host0")
0000000000000000000000000000000000000000;;			waitForPDDetach(diskName, host0Name)
0000000000000000000000000000000000000000;;			framework.ExpectNoError(framework.WaitForGroupSize(framework.TestContext.CloudConfig.NodeInstanceGroup, int32(initialGroupSize)), "Unable to get back the cluster to inital size")
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		It("should be able to detach from a node whose api object was deleted [Slow] [Disruptive]", func() {
0000000000000000000000000000000000000000;;			framework.SkipUnlessProviderIs("gce")
0000000000000000000000000000000000000000;;			initialGroupSize, err := framework.GroupSize(framework.TestContext.CloudConfig.NodeInstanceGroup)
0000000000000000000000000000000000000000;;			framework.ExpectNoError(err, "Error getting group size")
0000000000000000000000000000000000000000;;			By("Creating a pd")
0000000000000000000000000000000000000000;;			diskName, err := framework.CreatePDWithRetry()
0000000000000000000000000000000000000000;;			framework.ExpectNoError(err, "Error creating a pd")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			host0Pod := testPDPod([]string{diskName}, host0Name, false, 1)
0000000000000000000000000000000000000000;;			originalCount := len(nodes.Items)
0000000000000000000000000000000000000000;;			containerName := "mycontainer"
0000000000000000000000000000000000000000;;			nodeToDelete := &nodes.Items[0]
0000000000000000000000000000000000000000;;			defer func() {
0000000000000000000000000000000000000000;;				By("Cleaning up PD-RW test env")
0000000000000000000000000000000000000000;;				detachAndDeletePDs(diskName, []types.NodeName{host0Name})
0000000000000000000000000000000000000000;;				nodeToDelete.ObjectMeta.SetResourceVersion("0")
0000000000000000000000000000000000000000;;				// need to set the resource version or else the Create() fails
0000000000000000000000000000000000000000;;				_, err := nodeClient.Create(nodeToDelete)
0000000000000000000000000000000000000000;;				framework.ExpectNoError(err, "Unable to re-create the deleted node")
0000000000000000000000000000000000000000;;				framework.ExpectNoError(framework.WaitForGroupSize(framework.TestContext.CloudConfig.NodeInstanceGroup, int32(initialGroupSize)), "Unable to get the node group back to the original size")
0000000000000000000000000000000000000000;;				framework.WaitForNodeToBeReady(f.ClientSet, nodeToDelete.Name, nodeStatusTimeout)
0000000000000000000000000000000000000000;;				framework.WaitForAllNodesSchedulable(f.ClientSet, nodeStatusTimeout)
0000000000000000000000000000000000000000;;				nodes = framework.GetReadySchedulableNodesOrDie(f.ClientSet)
0000000000000000000000000000000000000000;;				Expect(len(nodes.Items)).To(Equal(originalCount), "Requires node count to return to original node count.")
0000000000000000000000000000000000000000;;			}()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("submitting host0Pod to kubernetes")
0000000000000000000000000000000000000000;;			_, err = podClient.Create(host0Pod)
0000000000000000000000000000000000000000;;			framework.ExpectNoError(err, fmt.Sprintf("Failed to create host0pod: %v", err))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			framework.ExpectNoError(f.WaitForPodRunningSlow(host0Pod.Name))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			testFile := "/testpd1/tracker"
0000000000000000000000000000000000000000;;			testFileContents := fmt.Sprintf("%v", mathrand.Int())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			framework.ExpectNoError(f.WriteFileViaContainer(host0Pod.Name, containerName, testFile, testFileContents))
0000000000000000000000000000000000000000;;			framework.Logf("Wrote value: %v", testFileContents)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Verify that disk shows up in node 0's volumeInUse list
0000000000000000000000000000000000000000;;			framework.ExpectNoError(waitForPDInVolumesInUse(nodeClient, diskName, host0Name, nodeStatusTimeout, true /* should exist*/))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("deleting api object of host0")
0000000000000000000000000000000000000000;;			framework.ExpectNoError(nodeClient.Delete(string(host0Name), metav1.NewDeleteOptions(0)), "Unable to delete host0")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("deleting host0pod")
0000000000000000000000000000000000000000;;			framework.ExpectNoError(podClient.Delete(host0Pod.Name, metav1.NewDeleteOptions(0)), "Unable to delete host0Pod")
0000000000000000000000000000000000000000;;			// The disk should be detached from host0 on its deletion
0000000000000000000000000000000000000000;;			By("Waiting for pd to detach from host0")
0000000000000000000000000000000000000000;;			framework.ExpectNoError(waitForPDDetach(diskName, host0Name), "Timed out waiting for detach pd")
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		It("should be able to delete a non-existent PD without error", func() {
0000000000000000000000000000000000000000;;			framework.SkipUnlessProviderIs("gce")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("delete a PD")
0000000000000000000000000000000000000000;;			framework.ExpectNoError(framework.DeletePDWithRetry("non-exist"))
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func verifyPDContentsViaContainer(f *framework.Framework, podName, containerName string, fileAndContentToVerify map[string]string) {
0000000000000000000000000000000000000000;;		for filePath, expectedContents := range fileAndContentToVerify {
0000000000000000000000000000000000000000;;			var value string
0000000000000000000000000000000000000000;;			// Add a retry to avoid temporal failure in reading the content
0000000000000000000000000000000000000000;;			for i := 0; i < maxReadRetry; i++ {
0000000000000000000000000000000000000000;;				v, err := f.ReadFileViaContainer(podName, containerName, filePath)
0000000000000000000000000000000000000000;;				value = v
0000000000000000000000000000000000000000;;				if err != nil {
0000000000000000000000000000000000000000;;					framework.Logf("Error reading file: %v", err)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				framework.ExpectNoError(err)
0000000000000000000000000000000000000000;;				framework.Logf("Read file %q with content: %v (iteration %d)", filePath, v, i)
0000000000000000000000000000000000000000;;				if strings.TrimSpace(v) != strings.TrimSpace(expectedContents) {
0000000000000000000000000000000000000000;;					framework.Logf("Warning: read content <%q> does not match execpted content <%q>.", v, expectedContents)
0000000000000000000000000000000000000000;;					size, err := f.CheckFileSizeViaContainer(podName, containerName, filePath)
0000000000000000000000000000000000000000;;					if err != nil {
0000000000000000000000000000000000000000;;						framework.Logf("Error checking file size: %v", err)
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					framework.Logf("Check file %q size: %q", filePath, size)
0000000000000000000000000000000000000000;;				} else {
0000000000000000000000000000000000000000;;					break
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			Expect(strings.TrimSpace(value)).To(Equal(strings.TrimSpace(expectedContents)))
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func detachPD(nodeName types.NodeName, pdName string) error {
0000000000000000000000000000000000000000;;		if framework.TestContext.Provider == "gce" || framework.TestContext.Provider == "gke" {
0000000000000000000000000000000000000000;;			gceCloud, err := framework.GetGCECloud()
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				return err
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			err = gceCloud.DetachDisk(pdName, nodeName)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				if gerr, ok := err.(*googleapi.Error); ok && strings.Contains(gerr.Message, "Invalid value for field 'disk'") {
0000000000000000000000000000000000000000;;					// PD already detached, ignore error.
0000000000000000000000000000000000000000;;					return nil
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				framework.Logf("Error detaching PD %q: %v", pdName, err)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		} else if framework.TestContext.Provider == "aws" {
0000000000000000000000000000000000000000;;			client := ec2.New(session.New())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			tokens := strings.Split(pdName, "/")
0000000000000000000000000000000000000000;;			awsVolumeID := tokens[len(tokens)-1]
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			request := ec2.DetachVolumeInput{
0000000000000000000000000000000000000000;;				VolumeId: aws.String(awsVolumeID),
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			_, err := client.DetachVolume(&request)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				return fmt.Errorf("error detaching EBS volume: %v", err)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			return nil
0000000000000000000000000000000000000000;;		} else {
0000000000000000000000000000000000000000;;			return fmt.Errorf("Provider does not support volume detaching")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func testPDPod(diskNames []string, targetNode types.NodeName, readOnly bool, numContainers int) *v1.Pod {
0000000000000000000000000000000000000000;;		containers := make([]v1.Container, numContainers)
0000000000000000000000000000000000000000;;		for i := range containers {
0000000000000000000000000000000000000000;;			containers[i].Name = "mycontainer"
0000000000000000000000000000000000000000;;			if numContainers > 1 {
0000000000000000000000000000000000000000;;				containers[i].Name = fmt.Sprintf("mycontainer%v", i+1)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			containers[i].Image = "gcr.io/google_containers/busybox:1.24"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			containers[i].Command = []string{"sleep", "6000"}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			containers[i].VolumeMounts = make([]v1.VolumeMount, len(diskNames))
0000000000000000000000000000000000000000;;			for k := range diskNames {
0000000000000000000000000000000000000000;;				containers[i].VolumeMounts[k].Name = fmt.Sprintf("testpd%v", k+1)
0000000000000000000000000000000000000000;;				containers[i].VolumeMounts[k].MountPath = fmt.Sprintf("/testpd%v", k+1)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			containers[i].Resources.Limits = v1.ResourceList{}
0000000000000000000000000000000000000000;;			containers[i].Resources.Limits[v1.ResourceCPU] = *resource.NewQuantity(int64(0), resource.DecimalSI)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		pod := &v1.Pod{
0000000000000000000000000000000000000000;;			TypeMeta: metav1.TypeMeta{
0000000000000000000000000000000000000000;;				Kind:       "Pod",
0000000000000000000000000000000000000000;;				APIVersion: api.Registry.GroupOrDie(v1.GroupName).GroupVersion.String(),
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			ObjectMeta: metav1.ObjectMeta{
0000000000000000000000000000000000000000;;				Name: "pd-test-" + string(uuid.NewUUID()),
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			Spec: v1.PodSpec{
0000000000000000000000000000000000000000;;				Containers: containers,
0000000000000000000000000000000000000000;;				NodeName:   string(targetNode),
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if framework.TestContext.Provider == "gce" || framework.TestContext.Provider == "gke" {
0000000000000000000000000000000000000000;;			pod.Spec.Volumes = make([]v1.Volume, len(diskNames))
0000000000000000000000000000000000000000;;			for k, diskName := range diskNames {
0000000000000000000000000000000000000000;;				pod.Spec.Volumes[k].Name = fmt.Sprintf("testpd%v", k+1)
0000000000000000000000000000000000000000;;				pod.Spec.Volumes[k].VolumeSource = v1.VolumeSource{
0000000000000000000000000000000000000000;;					GCEPersistentDisk: &v1.GCEPersistentDiskVolumeSource{
0000000000000000000000000000000000000000;;						PDName:   diskName,
0000000000000000000000000000000000000000;;						FSType:   "ext4",
0000000000000000000000000000000000000000;;						ReadOnly: readOnly,
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		} else if framework.TestContext.Provider == "aws" {
0000000000000000000000000000000000000000;;			pod.Spec.Volumes = make([]v1.Volume, len(diskNames))
0000000000000000000000000000000000000000;;			for k, diskName := range diskNames {
0000000000000000000000000000000000000000;;				pod.Spec.Volumes[k].Name = fmt.Sprintf("testpd%v", k+1)
0000000000000000000000000000000000000000;;				pod.Spec.Volumes[k].VolumeSource = v1.VolumeSource{
0000000000000000000000000000000000000000;;					AWSElasticBlockStore: &v1.AWSElasticBlockStoreVolumeSource{
0000000000000000000000000000000000000000;;						VolumeID: diskName,
0000000000000000000000000000000000000000;;						FSType:   "ext4",
0000000000000000000000000000000000000000;;						ReadOnly: readOnly,
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		} else {
0000000000000000000000000000000000000000;;			panic("Unknown provider: " + framework.TestContext.Provider)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return pod
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Waits for specified PD to to detach from specified hostName
0000000000000000000000000000000000000000;;	func waitForPDDetach(diskName string, nodeName types.NodeName) error {
0000000000000000000000000000000000000000;;		if framework.TestContext.Provider == "gce" || framework.TestContext.Provider == "gke" {
0000000000000000000000000000000000000000;;			framework.Logf("Waiting for GCE PD %q to detach from node %q.", diskName, nodeName)
0000000000000000000000000000000000000000;;			gceCloud, err := framework.GetGCECloud()
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				return err
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			for start := time.Now(); time.Since(start) < gcePDDetachTimeout; time.Sleep(gcePDDetachPollTime) {
0000000000000000000000000000000000000000;;				diskAttached, err := gceCloud.DiskIsAttached(diskName, nodeName)
0000000000000000000000000000000000000000;;				if err != nil {
0000000000000000000000000000000000000000;;					framework.Logf("Error waiting for PD %q to detach from node %q. 'DiskIsAttached(...)' failed with %v", diskName, nodeName, err)
0000000000000000000000000000000000000000;;					return err
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				if !diskAttached {
0000000000000000000000000000000000000000;;					// Specified disk does not appear to be attached to specified node
0000000000000000000000000000000000000000;;					framework.Logf("GCE PD %q appears to have successfully detached from %q.", diskName, nodeName)
0000000000000000000000000000000000000000;;					return nil
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				framework.Logf("Waiting for GCE PD %q to detach from %q.", diskName, nodeName)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			return fmt.Errorf("Gave up waiting for GCE PD %q to detach from %q after %v", diskName, nodeName, gcePDDetachTimeout)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func detachAndDeletePDs(diskName string, hosts []types.NodeName) {
0000000000000000000000000000000000000000;;		for _, host := range hosts {
0000000000000000000000000000000000000000;;			framework.Logf("Detaching GCE PD %q from node %q.", diskName, host)
0000000000000000000000000000000000000000;;			detachPD(host, diskName)
0000000000000000000000000000000000000000;;			By(fmt.Sprintf("Waiting for PD %q to detach from %q", diskName, host))
0000000000000000000000000000000000000000;;			waitForPDDetach(diskName, host)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		By(fmt.Sprintf("Deleting PD %q", diskName))
0000000000000000000000000000000000000000;;		framework.ExpectNoError(framework.DeletePDWithRetry(diskName))
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func waitForPDInVolumesInUse(
0000000000000000000000000000000000000000;;		nodeClient v1core.NodeInterface,
0000000000000000000000000000000000000000;;		diskName string,
0000000000000000000000000000000000000000;;		nodeName types.NodeName,
0000000000000000000000000000000000000000;;		timeout time.Duration,
0000000000000000000000000000000000000000;;		shouldExist bool) error {
0000000000000000000000000000000000000000;;		logStr := "to contain"
0000000000000000000000000000000000000000;;		if !shouldExist {
0000000000000000000000000000000000000000;;			logStr = "to NOT contain"
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		framework.Logf(
0000000000000000000000000000000000000000;;			"Waiting for node %s's VolumesInUse Status %s PD %q",
0000000000000000000000000000000000000000;;			nodeName, logStr, diskName)
0000000000000000000000000000000000000000;;		for start := time.Now(); time.Since(start) < timeout; time.Sleep(nodeStatusPollTime) {
0000000000000000000000000000000000000000;;			nodeObj, err := nodeClient.Get(string(nodeName), metav1.GetOptions{})
0000000000000000000000000000000000000000;;			if err != nil || nodeObj == nil {
0000000000000000000000000000000000000000;;				framework.Logf(
0000000000000000000000000000000000000000;;					"Failed to fetch node object %q from API server. err=%v",
0000000000000000000000000000000000000000;;					nodeName, err)
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			exists := false
0000000000000000000000000000000000000000;;			for _, volumeInUse := range nodeObj.Status.VolumesInUse {
0000000000000000000000000000000000000000;;				volumeInUseStr := string(volumeInUse)
0000000000000000000000000000000000000000;;				if strings.Contains(volumeInUseStr, diskName) {
0000000000000000000000000000000000000000;;					if shouldExist {
0000000000000000000000000000000000000000;;						framework.Logf(
0000000000000000000000000000000000000000;;							"Found PD %q in node %q's VolumesInUse Status: %q",
0000000000000000000000000000000000000000;;							diskName, nodeName, volumeInUseStr)
0000000000000000000000000000000000000000;;						return nil
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;					exists = true
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			if !shouldExist && !exists {
0000000000000000000000000000000000000000;;				framework.Logf(
0000000000000000000000000000000000000000;;					"Verified PD %q does not exist in node %q's VolumesInUse Status.",
0000000000000000000000000000000000000000;;					diskName, nodeName)
0000000000000000000000000000000000000000;;				return nil
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return fmt.Errorf(
0000000000000000000000000000000000000000;;			"Timed out waiting for node %s VolumesInUse Status %s diskName %q",
0000000000000000000000000000000000000000;;			nodeName, logStr, diskName)
0000000000000000000000000000000000000000;;	}
