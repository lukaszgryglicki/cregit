0000000000000000000000000000000000000000;;	/*
0000000000000000000000000000000000000000;;	Copyright 2016 The Kubernetes Authors.
7378a0cb38d21d9c5b6304002e679b9e0c9d364d;test/e2e/cluster_dns.go[test/e2e/cluster_dns.go][test/e2e/service.go];	
0000000000000000000000000000000000000000;;	Licensed under the Apache License, Version 2.0 (the "License");
0000000000000000000000000000000000000000;;	you may not use this file except in compliance with the License.
0000000000000000000000000000000000000000;;	You may obtain a copy of the License at
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	    http://www.apache.org/licenses/LICENSE-2.0
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	Unless required by applicable law or agreed to in writing, software
0000000000000000000000000000000000000000;;	distributed under the License is distributed on an "AS IS" BASIS,
0000000000000000000000000000000000000000;;	WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
0000000000000000000000000000000000000000;;	See the License for the specific language governing permissions and
0000000000000000000000000000000000000000;;	limitations under the License.
0000000000000000000000000000000000000000;;	*/
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	package e2e
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	import (
0000000000000000000000000000000000000000;;		"bytes"
0000000000000000000000000000000000000000;;		"fmt"
0000000000000000000000000000000000000000;;		"math/rand"
0000000000000000000000000000000000000000;;		"strings"
0000000000000000000000000000000000000000;;		"time"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		"k8s.io/api/core/v1"
0000000000000000000000000000000000000000;;		metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/labels"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/util/intstr"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/util/wait"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/api/v1/service"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/client/clientset_generated/clientset"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/client/clientset_generated/internalclientset"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/cloudprovider"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/controller/endpoint"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/test/e2e/framework"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		. "github.com/onsi/ginkgo"
0000000000000000000000000000000000000000;;		. "github.com/onsi/gomega"
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	var _ = framework.KubeDescribe("Services", func() {
0000000000000000000000000000000000000000;;		f := framework.NewDefaultFramework("services")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		var cs clientset.Interface
0000000000000000000000000000000000000000;;		var internalClientset internalclientset.Interface
0000000000000000000000000000000000000000;;		serviceLBNames := []string{}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		BeforeEach(func() {
0000000000000000000000000000000000000000;;			cs = f.ClientSet
0000000000000000000000000000000000000000;;			internalClientset = f.InternalClientset
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		AfterEach(func() {
0000000000000000000000000000000000000000;;			if CurrentGinkgoTestDescription().Failed {
0000000000000000000000000000000000000000;;				framework.DescribeSvc(f.Namespace.Name)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			for _, lb := range serviceLBNames {
0000000000000000000000000000000000000000;;				framework.Logf("cleaning gce resource for %s", lb)
0000000000000000000000000000000000000000;;				framework.CleanupServiceGCEResources(cs, lb, framework.TestContext.CloudConfig.Zone)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			//reset serviceLBNames
0000000000000000000000000000000000000000;;			serviceLBNames = []string{}
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// TODO: We get coverage of TCP/UDP and multi-port services through the DNS test. We should have a simpler test for multi-port TCP here.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		It("should provide secure master service [Conformance]", func() {
0000000000000000000000000000000000000000;;			_, err := cs.Core().Services(metav1.NamespaceDefault).Get("kubernetes", metav1.GetOptions{})
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		It("should serve a basic endpoint from pods [Conformance]", func() {
0000000000000000000000000000000000000000;;			// TODO: use the ServiceTestJig here
0000000000000000000000000000000000000000;;			serviceName := "endpoint-test2"
0000000000000000000000000000000000000000;;			ns := f.Namespace.Name
0000000000000000000000000000000000000000;;			labels := map[string]string{
0000000000000000000000000000000000000000;;				"foo": "bar",
0000000000000000000000000000000000000000;;				"baz": "blah",
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("creating service " + serviceName + " in namespace " + ns)
0000000000000000000000000000000000000000;;			defer func() {
0000000000000000000000000000000000000000;;				err := cs.Core().Services(ns).Delete(serviceName, nil)
0000000000000000000000000000000000000000;;				Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;			}()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			service := &v1.Service{
0000000000000000000000000000000000000000;;				ObjectMeta: metav1.ObjectMeta{
0000000000000000000000000000000000000000;;					Name: serviceName,
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;				Spec: v1.ServiceSpec{
0000000000000000000000000000000000000000;;					Selector: labels,
0000000000000000000000000000000000000000;;					Ports: []v1.ServicePort{{
0000000000000000000000000000000000000000;;						Port:       80,
0000000000000000000000000000000000000000;;						TargetPort: intstr.FromInt(80),
0000000000000000000000000000000000000000;;					}},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			_, err := cs.Core().Services(ns).Create(service)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			framework.ValidateEndpointsOrFail(cs, ns, serviceName, framework.PortsByPodName{})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			names := map[string]bool{}
0000000000000000000000000000000000000000;;			defer func() {
0000000000000000000000000000000000000000;;				for name := range names {
0000000000000000000000000000000000000000;;					err := cs.Core().Pods(ns).Delete(name, nil)
0000000000000000000000000000000000000000;;					Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			name1 := "pod1"
0000000000000000000000000000000000000000;;			name2 := "pod2"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			framework.CreatePodOrFail(cs, ns, name1, labels, []v1.ContainerPort{{ContainerPort: 80}})
0000000000000000000000000000000000000000;;			names[name1] = true
0000000000000000000000000000000000000000;;			framework.ValidateEndpointsOrFail(cs, ns, serviceName, framework.PortsByPodName{name1: {80}})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			framework.CreatePodOrFail(cs, ns, name2, labels, []v1.ContainerPort{{ContainerPort: 80}})
0000000000000000000000000000000000000000;;			names[name2] = true
0000000000000000000000000000000000000000;;			framework.ValidateEndpointsOrFail(cs, ns, serviceName, framework.PortsByPodName{name1: {80}, name2: {80}})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			framework.DeletePodOrFail(cs, ns, name1)
0000000000000000000000000000000000000000;;			delete(names, name1)
0000000000000000000000000000000000000000;;			framework.ValidateEndpointsOrFail(cs, ns, serviceName, framework.PortsByPodName{name2: {80}})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			framework.DeletePodOrFail(cs, ns, name2)
0000000000000000000000000000000000000000;;			delete(names, name2)
0000000000000000000000000000000000000000;;			framework.ValidateEndpointsOrFail(cs, ns, serviceName, framework.PortsByPodName{})
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		It("should serve multiport endpoints from pods [Conformance]", func() {
0000000000000000000000000000000000000000;;			// TODO: use the ServiceTestJig here
0000000000000000000000000000000000000000;;			// repacking functionality is intentionally not tested here - it's better to test it in an integration test.
0000000000000000000000000000000000000000;;			serviceName := "multi-endpoint-test"
0000000000000000000000000000000000000000;;			ns := f.Namespace.Name
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			defer func() {
0000000000000000000000000000000000000000;;				err := cs.Core().Services(ns).Delete(serviceName, nil)
0000000000000000000000000000000000000000;;				Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;			}()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			labels := map[string]string{"foo": "bar"}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			svc1port := "svc1"
0000000000000000000000000000000000000000;;			svc2port := "svc2"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("creating service " + serviceName + " in namespace " + ns)
0000000000000000000000000000000000000000;;			service := &v1.Service{
0000000000000000000000000000000000000000;;				ObjectMeta: metav1.ObjectMeta{
0000000000000000000000000000000000000000;;					Name: serviceName,
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;				Spec: v1.ServiceSpec{
0000000000000000000000000000000000000000;;					Selector: labels,
0000000000000000000000000000000000000000;;					Ports: []v1.ServicePort{
0000000000000000000000000000000000000000;;						{
0000000000000000000000000000000000000000;;							Name:       "portname1",
0000000000000000000000000000000000000000;;							Port:       80,
0000000000000000000000000000000000000000;;							TargetPort: intstr.FromString(svc1port),
0000000000000000000000000000000000000000;;						},
0000000000000000000000000000000000000000;;						{
0000000000000000000000000000000000000000;;							Name:       "portname2",
0000000000000000000000000000000000000000;;							Port:       81,
0000000000000000000000000000000000000000;;							TargetPort: intstr.FromString(svc2port),
0000000000000000000000000000000000000000;;						},
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			_, err := cs.Core().Services(ns).Create(service)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;			port1 := 100
0000000000000000000000000000000000000000;;			port2 := 101
0000000000000000000000000000000000000000;;			framework.ValidateEndpointsOrFail(cs, ns, serviceName, framework.PortsByPodName{})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			names := map[string]bool{}
0000000000000000000000000000000000000000;;			defer func() {
0000000000000000000000000000000000000000;;				for name := range names {
0000000000000000000000000000000000000000;;					err := cs.Core().Pods(ns).Delete(name, nil)
0000000000000000000000000000000000000000;;					Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			containerPorts1 := []v1.ContainerPort{
0000000000000000000000000000000000000000;;				{
0000000000000000000000000000000000000000;;					Name:          svc1port,
0000000000000000000000000000000000000000;;					ContainerPort: int32(port1),
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			containerPorts2 := []v1.ContainerPort{
0000000000000000000000000000000000000000;;				{
0000000000000000000000000000000000000000;;					Name:          svc2port,
0000000000000000000000000000000000000000;;					ContainerPort: int32(port2),
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			podname1 := "pod1"
0000000000000000000000000000000000000000;;			podname2 := "pod2"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			framework.CreatePodOrFail(cs, ns, podname1, labels, containerPorts1)
0000000000000000000000000000000000000000;;			names[podname1] = true
0000000000000000000000000000000000000000;;			framework.ValidateEndpointsOrFail(cs, ns, serviceName, framework.PortsByPodName{podname1: {port1}})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			framework.CreatePodOrFail(cs, ns, podname2, labels, containerPorts2)
0000000000000000000000000000000000000000;;			names[podname2] = true
0000000000000000000000000000000000000000;;			framework.ValidateEndpointsOrFail(cs, ns, serviceName, framework.PortsByPodName{podname1: {port1}, podname2: {port2}})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			framework.DeletePodOrFail(cs, ns, podname1)
0000000000000000000000000000000000000000;;			delete(names, podname1)
0000000000000000000000000000000000000000;;			framework.ValidateEndpointsOrFail(cs, ns, serviceName, framework.PortsByPodName{podname2: {port2}})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			framework.DeletePodOrFail(cs, ns, podname2)
0000000000000000000000000000000000000000;;			delete(names, podname2)
0000000000000000000000000000000000000000;;			framework.ValidateEndpointsOrFail(cs, ns, serviceName, framework.PortsByPodName{})
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		It("should preserve source pod IP for traffic thru service cluster IP", func() {
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// This behavior is not supported if Kube-proxy is in "userspace" mode.
0000000000000000000000000000000000000000;;			// So we check the kube-proxy mode and skip this test if that's the case.
0000000000000000000000000000000000000000;;			if proxyMode, err := framework.ProxyMode(f); err == nil {
0000000000000000000000000000000000000000;;				if proxyMode == "userspace" {
0000000000000000000000000000000000000000;;					framework.Skipf("The test doesn't work with kube-proxy in userspace mode")
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				framework.Logf("Couldn't detect KubeProxy mode - test failure may be expected: %v", err)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			serviceName := "sourceip-test"
0000000000000000000000000000000000000000;;			ns := f.Namespace.Name
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("creating a TCP service " + serviceName + " with type=ClusterIP in namespace " + ns)
0000000000000000000000000000000000000000;;			jig := framework.NewServiceTestJig(cs, serviceName)
0000000000000000000000000000000000000000;;			servicePort := 8080
0000000000000000000000000000000000000000;;			tcpService := jig.CreateTCPServiceWithPort(ns, nil, int32(servicePort))
0000000000000000000000000000000000000000;;			jig.SanityCheckService(tcpService, v1.ServiceTypeClusterIP)
0000000000000000000000000000000000000000;;			defer func() {
0000000000000000000000000000000000000000;;				framework.Logf("Cleaning up the sourceip test service")
0000000000000000000000000000000000000000;;				err := cs.Core().Services(ns).Delete(serviceName, nil)
0000000000000000000000000000000000000000;;				Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;			}()
0000000000000000000000000000000000000000;;			serviceIp := tcpService.Spec.ClusterIP
0000000000000000000000000000000000000000;;			framework.Logf("sourceip-test cluster ip: %s", serviceIp)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Picking multiple nodes")
0000000000000000000000000000000000000000;;			nodes := framework.GetReadySchedulableNodesOrDie(f.ClientSet)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			if len(nodes.Items) == 1 {
0000000000000000000000000000000000000000;;				framework.Skipf("The test requires two Ready nodes on %s, but found just one.", framework.TestContext.Provider)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			node1 := nodes.Items[0]
0000000000000000000000000000000000000000;;			node2 := nodes.Items[1]
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Creating a webserver pod be part of the TCP service which echoes back source ip")
0000000000000000000000000000000000000000;;			serverPodName := "echoserver-sourceip"
0000000000000000000000000000000000000000;;			jig.LaunchEchoserverPodOnNode(f, node1.Name, serverPodName)
0000000000000000000000000000000000000000;;			defer func() {
0000000000000000000000000000000000000000;;				framework.Logf("Cleaning up the echo server pod")
0000000000000000000000000000000000000000;;				err := cs.Core().Pods(ns).Delete(serverPodName, nil)
0000000000000000000000000000000000000000;;				Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;			}()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Waiting for service to expose endpoint.
0000000000000000000000000000000000000000;;			framework.ValidateEndpointsOrFail(cs, ns, serviceName, framework.PortsByPodName{serverPodName: {servicePort}})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Retrieve sourceip from a pod on the same node")
0000000000000000000000000000000000000000;;			sourceIp1, execPodIp1 := execSourceipTest(f, cs, ns, node1.Name, serviceIp, servicePort)
0000000000000000000000000000000000000000;;			By("Verifying the preserved source ip")
0000000000000000000000000000000000000000;;			Expect(sourceIp1).To(Equal(execPodIp1))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Retrieve sourceip from a pod on a different node")
0000000000000000000000000000000000000000;;			sourceIp2, execPodIp2 := execSourceipTest(f, cs, ns, node2.Name, serviceIp, servicePort)
0000000000000000000000000000000000000000;;			By("Verifying the preserved source ip")
0000000000000000000000000000000000000000;;			Expect(sourceIp2).To(Equal(execPodIp2))
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		It("should be able to up and down services", func() {
0000000000000000000000000000000000000000;;			// TODO: use the ServiceTestJig here
0000000000000000000000000000000000000000;;			// this test uses framework.NodeSSHHosts that does not work if a Node only reports LegacyHostIP
0000000000000000000000000000000000000000;;			framework.SkipUnlessProviderIs(framework.ProvidersWithSSH...)
0000000000000000000000000000000000000000;;			// this test does not work if the Node does not support SSH Key
0000000000000000000000000000000000000000;;			framework.SkipUnlessSSHKeyPresent()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			ns := f.Namespace.Name
0000000000000000000000000000000000000000;;			numPods, servicePort := 3, 80
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("creating service1 in namespace " + ns)
0000000000000000000000000000000000000000;;			podNames1, svc1IP, err := framework.StartServeHostnameService(cs, internalClientset, ns, "service1", servicePort, numPods)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;			By("creating service2 in namespace " + ns)
0000000000000000000000000000000000000000;;			podNames2, svc2IP, err := framework.StartServeHostnameService(cs, internalClientset, ns, "service2", servicePort, numPods)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			hosts, err := framework.NodeSSHHosts(cs)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;			if len(hosts) == 0 {
0000000000000000000000000000000000000000;;				framework.Failf("No ssh-able nodes")
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			host := hosts[0]
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("verifying service1 is up")
0000000000000000000000000000000000000000;;			framework.ExpectNoError(framework.VerifyServeHostnameServiceUp(cs, ns, host, podNames1, svc1IP, servicePort))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("verifying service2 is up")
0000000000000000000000000000000000000000;;			framework.ExpectNoError(framework.VerifyServeHostnameServiceUp(cs, ns, host, podNames2, svc2IP, servicePort))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Stop service 1 and make sure it is gone.
0000000000000000000000000000000000000000;;			By("stopping service1")
0000000000000000000000000000000000000000;;			framework.ExpectNoError(framework.StopServeHostnameService(f.ClientSet, f.InternalClientset, ns, "service1"))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("verifying service1 is not up")
0000000000000000000000000000000000000000;;			framework.ExpectNoError(framework.VerifyServeHostnameServiceDown(cs, host, svc1IP, servicePort))
0000000000000000000000000000000000000000;;			By("verifying service2 is still up")
0000000000000000000000000000000000000000;;			framework.ExpectNoError(framework.VerifyServeHostnameServiceUp(cs, ns, host, podNames2, svc2IP, servicePort))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Start another service and verify both are up.
0000000000000000000000000000000000000000;;			By("creating service3 in namespace " + ns)
0000000000000000000000000000000000000000;;			podNames3, svc3IP, err := framework.StartServeHostnameService(cs, internalClientset, ns, "service3", servicePort, numPods)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			if svc2IP == svc3IP {
0000000000000000000000000000000000000000;;				framework.Failf("service IPs conflict: %v", svc2IP)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("verifying service2 is still up")
0000000000000000000000000000000000000000;;			framework.ExpectNoError(framework.VerifyServeHostnameServiceUp(cs, ns, host, podNames2, svc2IP, servicePort))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("verifying service3 is up")
0000000000000000000000000000000000000000;;			framework.ExpectNoError(framework.VerifyServeHostnameServiceUp(cs, ns, host, podNames3, svc3IP, servicePort))
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		It("should work after restarting kube-proxy [Disruptive]", func() {
0000000000000000000000000000000000000000;;			// TODO: use the ServiceTestJig here
0000000000000000000000000000000000000000;;			framework.SkipUnlessProviderIs("gce", "gke")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			ns := f.Namespace.Name
0000000000000000000000000000000000000000;;			numPods, servicePort := 3, 80
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			svc1 := "service1"
0000000000000000000000000000000000000000;;			svc2 := "service2"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			defer func() {
0000000000000000000000000000000000000000;;				framework.ExpectNoError(framework.StopServeHostnameService(f.ClientSet, f.InternalClientset, ns, svc1))
0000000000000000000000000000000000000000;;			}()
0000000000000000000000000000000000000000;;			podNames1, svc1IP, err := framework.StartServeHostnameService(cs, internalClientset, ns, svc1, servicePort, numPods)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			defer func() {
0000000000000000000000000000000000000000;;				framework.ExpectNoError(framework.StopServeHostnameService(f.ClientSet, f.InternalClientset, ns, svc2))
0000000000000000000000000000000000000000;;			}()
0000000000000000000000000000000000000000;;			podNames2, svc2IP, err := framework.StartServeHostnameService(cs, internalClientset, ns, svc2, servicePort, numPods)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			if svc1IP == svc2IP {
0000000000000000000000000000000000000000;;				framework.Failf("VIPs conflict: %v", svc1IP)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			hosts, err := framework.NodeSSHHosts(cs)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;			if len(hosts) == 0 {
0000000000000000000000000000000000000000;;				framework.Failf("No ssh-able nodes")
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			host := hosts[0]
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			framework.ExpectNoError(framework.VerifyServeHostnameServiceUp(cs, ns, host, podNames1, svc1IP, servicePort))
0000000000000000000000000000000000000000;;			framework.ExpectNoError(framework.VerifyServeHostnameServiceUp(cs, ns, host, podNames2, svc2IP, servicePort))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By(fmt.Sprintf("Restarting kube-proxy on %v", host))
0000000000000000000000000000000000000000;;			if err := framework.RestartKubeProxy(host); err != nil {
0000000000000000000000000000000000000000;;				framework.Failf("error restarting kube-proxy: %v", err)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			framework.ExpectNoError(framework.VerifyServeHostnameServiceUp(cs, ns, host, podNames1, svc1IP, servicePort))
0000000000000000000000000000000000000000;;			framework.ExpectNoError(framework.VerifyServeHostnameServiceUp(cs, ns, host, podNames2, svc2IP, servicePort))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Removing iptable rules")
0000000000000000000000000000000000000000;;			result, err := framework.SSH(`
0000000000000000000000000000000000000000;;				sudo iptables -t nat -F KUBE-SERVICES || true;
0000000000000000000000000000000000000000;;				sudo iptables -t nat -F KUBE-PORTALS-HOST || true;
0000000000000000000000000000000000000000;;				sudo iptables -t nat -F KUBE-PORTALS-CONTAINER || true`, host, framework.TestContext.Provider)
0000000000000000000000000000000000000000;;			if err != nil || result.Code != 0 {
0000000000000000000000000000000000000000;;				framework.LogSSHResult(result)
0000000000000000000000000000000000000000;;				framework.Failf("couldn't remove iptable rules: %v", err)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			framework.ExpectNoError(framework.VerifyServeHostnameServiceUp(cs, ns, host, podNames1, svc1IP, servicePort))
0000000000000000000000000000000000000000;;			framework.ExpectNoError(framework.VerifyServeHostnameServiceUp(cs, ns, host, podNames2, svc2IP, servicePort))
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		It("should work after restarting apiserver [Disruptive]", func() {
0000000000000000000000000000000000000000;;			// TODO: use the ServiceTestJig here
0000000000000000000000000000000000000000;;			framework.SkipUnlessProviderIs("gce", "gke")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			ns := f.Namespace.Name
0000000000000000000000000000000000000000;;			numPods, servicePort := 3, 80
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			defer func() {
0000000000000000000000000000000000000000;;				framework.ExpectNoError(framework.StopServeHostnameService(f.ClientSet, f.InternalClientset, ns, "service1"))
0000000000000000000000000000000000000000;;			}()
0000000000000000000000000000000000000000;;			podNames1, svc1IP, err := framework.StartServeHostnameService(cs, internalClientset, ns, "service1", servicePort, numPods)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			hosts, err := framework.NodeSSHHosts(cs)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;			if len(hosts) == 0 {
0000000000000000000000000000000000000000;;				framework.Failf("No ssh-able nodes")
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			host := hosts[0]
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			framework.ExpectNoError(framework.VerifyServeHostnameServiceUp(cs, ns, host, podNames1, svc1IP, servicePort))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Restart apiserver
0000000000000000000000000000000000000000;;			By("Restarting apiserver")
0000000000000000000000000000000000000000;;			if err := framework.RestartApiserver(cs.Discovery()); err != nil {
0000000000000000000000000000000000000000;;				framework.Failf("error restarting apiserver: %v", err)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			By("Waiting for apiserver to come up by polling /healthz")
0000000000000000000000000000000000000000;;			if err := framework.WaitForApiserverUp(cs); err != nil {
0000000000000000000000000000000000000000;;				framework.Failf("error while waiting for apiserver up: %v", err)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			framework.ExpectNoError(framework.VerifyServeHostnameServiceUp(cs, ns, host, podNames1, svc1IP, servicePort))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Create a new service and check if it's not reusing IP.
0000000000000000000000000000000000000000;;			defer func() {
0000000000000000000000000000000000000000;;				framework.ExpectNoError(framework.StopServeHostnameService(f.ClientSet, f.InternalClientset, ns, "service2"))
0000000000000000000000000000000000000000;;			}()
0000000000000000000000000000000000000000;;			podNames2, svc2IP, err := framework.StartServeHostnameService(cs, internalClientset, ns, "service2", servicePort, numPods)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			if svc1IP == svc2IP {
0000000000000000000000000000000000000000;;				framework.Failf("VIPs conflict: %v", svc1IP)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			framework.ExpectNoError(framework.VerifyServeHostnameServiceUp(cs, ns, host, podNames1, svc1IP, servicePort))
0000000000000000000000000000000000000000;;			framework.ExpectNoError(framework.VerifyServeHostnameServiceUp(cs, ns, host, podNames2, svc2IP, servicePort))
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// TODO: Run this test against the userspace proxy and nodes
0000000000000000000000000000000000000000;;		// configured with a default deny firewall to validate that the
0000000000000000000000000000000000000000;;		// proxy whitelists NodePort traffic.
0000000000000000000000000000000000000000;;		It("should be able to create a functioning NodePort service", func() {
0000000000000000000000000000000000000000;;			serviceName := "nodeport-test"
0000000000000000000000000000000000000000;;			ns := f.Namespace.Name
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			jig := framework.NewServiceTestJig(cs, serviceName)
0000000000000000000000000000000000000000;;			nodeIP := framework.PickNodeIP(jig.Client) // for later
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("creating service " + serviceName + " with type=NodePort in namespace " + ns)
0000000000000000000000000000000000000000;;			service := jig.CreateTCPServiceOrFail(ns, func(svc *v1.Service) {
0000000000000000000000000000000000000000;;				svc.Spec.Type = v1.ServiceTypeNodePort
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;			jig.SanityCheckService(service, v1.ServiceTypeNodePort)
0000000000000000000000000000000000000000;;			nodePort := int(service.Spec.Ports[0].NodePort)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("creating pod to be part of service " + serviceName)
0000000000000000000000000000000000000000;;			jig.RunOrFail(ns, nil)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("hitting the pod through the service's NodePort")
0000000000000000000000000000000000000000;;			jig.TestReachableHTTP(nodeIP, nodePort, framework.KubeProxyLagTimeout)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("verifying the node port is locked")
0000000000000000000000000000000000000000;;			hostExec := framework.LaunchHostExecPod(f.ClientSet, f.Namespace.Name, "hostexec")
0000000000000000000000000000000000000000;;			// Even if the node-ip:node-port check above passed, this hostexec pod
0000000000000000000000000000000000000000;;			// might fall on a node with a laggy kube-proxy.
0000000000000000000000000000000000000000;;			cmd := fmt.Sprintf(`for i in $(seq 1 300); do if ss -ant46 'sport = :%d' | grep ^LISTEN; then exit 0; fi; sleep 1; done; exit 1`, nodePort)
0000000000000000000000000000000000000000;;			stdout, err := framework.RunHostCmd(hostExec.Namespace, hostExec.Name, cmd)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				framework.Failf("expected node port %d to be in use, stdout: %v. err: %v", nodePort, stdout, err)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		It("should be able to change the type and ports of a service [Slow]", func() {
0000000000000000000000000000000000000000;;			// requires cloud load-balancer support
0000000000000000000000000000000000000000;;			framework.SkipUnlessProviderIs("gce", "gke", "aws")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			loadBalancerSupportsUDP := !framework.ProviderIs("aws")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			loadBalancerLagTimeout := framework.LoadBalancerLagTimeoutDefault
0000000000000000000000000000000000000000;;			if framework.ProviderIs("aws") {
0000000000000000000000000000000000000000;;				loadBalancerLagTimeout = framework.LoadBalancerLagTimeoutAWS
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			loadBalancerCreateTimeout := framework.LoadBalancerCreateTimeoutDefault
0000000000000000000000000000000000000000;;			if nodes := framework.GetReadySchedulableNodesOrDie(cs); len(nodes.Items) > framework.LargeClusterMinNodesNumber {
0000000000000000000000000000000000000000;;				loadBalancerCreateTimeout = framework.LoadBalancerCreateTimeoutLarge
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// This test is more monolithic than we'd like because LB turnup can be
0000000000000000000000000000000000000000;;			// very slow, so we lumped all the tests into one LB lifecycle.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			serviceName := "mutability-test"
0000000000000000000000000000000000000000;;			ns1 := f.Namespace.Name // LB1 in ns1 on TCP
0000000000000000000000000000000000000000;;			framework.Logf("namespace for TCP test: %s", ns1)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("creating a second namespace")
0000000000000000000000000000000000000000;;			namespacePtr, err := f.CreateNamespace("services", nil)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;			ns2 := namespacePtr.Name // LB2 in ns2 on UDP
0000000000000000000000000000000000000000;;			framework.Logf("namespace for UDP test: %s", ns2)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			jig := framework.NewServiceTestJig(cs, serviceName)
0000000000000000000000000000000000000000;;			nodeIP := framework.PickNodeIP(jig.Client) // for later
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Test TCP and UDP Services.  Services with the same name in different
0000000000000000000000000000000000000000;;			// namespaces should get different node ports and load balancers.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("creating a TCP service " + serviceName + " with type=ClusterIP in namespace " + ns1)
0000000000000000000000000000000000000000;;			tcpService := jig.CreateTCPServiceOrFail(ns1, nil)
0000000000000000000000000000000000000000;;			jig.SanityCheckService(tcpService, v1.ServiceTypeClusterIP)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("creating a UDP service " + serviceName + " with type=ClusterIP in namespace " + ns2)
0000000000000000000000000000000000000000;;			udpService := jig.CreateUDPServiceOrFail(ns2, nil)
0000000000000000000000000000000000000000;;			jig.SanityCheckService(udpService, v1.ServiceTypeClusterIP)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("verifying that TCP and UDP use the same port")
0000000000000000000000000000000000000000;;			if tcpService.Spec.Ports[0].Port != udpService.Spec.Ports[0].Port {
0000000000000000000000000000000000000000;;				framework.Failf("expected to use the same port for TCP and UDP")
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			svcPort := int(tcpService.Spec.Ports[0].Port)
0000000000000000000000000000000000000000;;			framework.Logf("service port (TCP and UDP): %d", svcPort)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("creating a pod to be part of the TCP service " + serviceName)
0000000000000000000000000000000000000000;;			jig.RunOrFail(ns1, nil)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("creating a pod to be part of the UDP service " + serviceName)
0000000000000000000000000000000000000000;;			jig.RunOrFail(ns2, nil)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Change the services to NodePort.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("changing the TCP service to type=NodePort")
0000000000000000000000000000000000000000;;			tcpService = jig.UpdateServiceOrFail(ns1, tcpService.Name, func(s *v1.Service) {
0000000000000000000000000000000000000000;;				s.Spec.Type = v1.ServiceTypeNodePort
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;			jig.SanityCheckService(tcpService, v1.ServiceTypeNodePort)
0000000000000000000000000000000000000000;;			tcpNodePort := int(tcpService.Spec.Ports[0].NodePort)
0000000000000000000000000000000000000000;;			framework.Logf("TCP node port: %d", tcpNodePort)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("changing the UDP service to type=NodePort")
0000000000000000000000000000000000000000;;			udpService = jig.UpdateServiceOrFail(ns2, udpService.Name, func(s *v1.Service) {
0000000000000000000000000000000000000000;;				s.Spec.Type = v1.ServiceTypeNodePort
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;			jig.SanityCheckService(udpService, v1.ServiceTypeNodePort)
0000000000000000000000000000000000000000;;			udpNodePort := int(udpService.Spec.Ports[0].NodePort)
0000000000000000000000000000000000000000;;			framework.Logf("UDP node port: %d", udpNodePort)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("hitting the TCP service's NodePort")
0000000000000000000000000000000000000000;;			jig.TestReachableHTTP(nodeIP, tcpNodePort, framework.KubeProxyLagTimeout)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("hitting the UDP service's NodePort")
0000000000000000000000000000000000000000;;			jig.TestReachableUDP(nodeIP, udpNodePort, framework.KubeProxyLagTimeout)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Change the services to LoadBalancer.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Here we test that LoadBalancers can receive static IP addresses.  This isn't
0000000000000000000000000000000000000000;;			// necessary, but is an additional feature this monolithic test checks.
0000000000000000000000000000000000000000;;			requestedIP := ""
0000000000000000000000000000000000000000;;			staticIPName := ""
0000000000000000000000000000000000000000;;			if framework.ProviderIs("gce", "gke") {
0000000000000000000000000000000000000000;;				By("creating a static load balancer IP")
0000000000000000000000000000000000000000;;				staticIPName = fmt.Sprintf("e2e-external-lb-test-%s", framework.RunId)
0000000000000000000000000000000000000000;;				requestedIP, err = framework.CreateGCEStaticIP(staticIPName)
0000000000000000000000000000000000000000;;				defer func() {
0000000000000000000000000000000000000000;;					if staticIPName != "" {
0000000000000000000000000000000000000000;;						// Release GCE static IP - this is not kube-managed and will not be automatically released.
0000000000000000000000000000000000000000;;						if err := framework.DeleteGCEStaticIP(staticIPName); err != nil {
0000000000000000000000000000000000000000;;							framework.Logf("failed to release static IP %s: %v", staticIPName, err)
0000000000000000000000000000000000000000;;						}
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;				}()
0000000000000000000000000000000000000000;;				Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;				framework.Logf("Allocated static load balancer IP: %s", requestedIP)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("changing the TCP service to type=LoadBalancer")
0000000000000000000000000000000000000000;;			tcpService = jig.UpdateServiceOrFail(ns1, tcpService.Name, func(s *v1.Service) {
0000000000000000000000000000000000000000;;				s.Spec.LoadBalancerIP = requestedIP // will be "" if not applicable
0000000000000000000000000000000000000000;;				s.Spec.Type = v1.ServiceTypeLoadBalancer
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			if loadBalancerSupportsUDP {
0000000000000000000000000000000000000000;;				By("changing the UDP service to type=LoadBalancer")
0000000000000000000000000000000000000000;;				udpService = jig.UpdateServiceOrFail(ns2, udpService.Name, func(s *v1.Service) {
0000000000000000000000000000000000000000;;					s.Spec.Type = v1.ServiceTypeLoadBalancer
0000000000000000000000000000000000000000;;				})
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			serviceLBNames = append(serviceLBNames, cloudprovider.GetLoadBalancerName(tcpService))
0000000000000000000000000000000000000000;;			if loadBalancerSupportsUDP {
0000000000000000000000000000000000000000;;				serviceLBNames = append(serviceLBNames, cloudprovider.GetLoadBalancerName(udpService))
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("waiting for the TCP service to have a load balancer")
0000000000000000000000000000000000000000;;			// Wait for the load balancer to be created asynchronously
0000000000000000000000000000000000000000;;			tcpService = jig.WaitForLoadBalancerOrFail(ns1, tcpService.Name, loadBalancerCreateTimeout)
0000000000000000000000000000000000000000;;			jig.SanityCheckService(tcpService, v1.ServiceTypeLoadBalancer)
0000000000000000000000000000000000000000;;			if int(tcpService.Spec.Ports[0].NodePort) != tcpNodePort {
0000000000000000000000000000000000000000;;				framework.Failf("TCP Spec.Ports[0].NodePort changed (%d -> %d) when not expected", tcpNodePort, tcpService.Spec.Ports[0].NodePort)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if requestedIP != "" && framework.GetIngressPoint(&tcpService.Status.LoadBalancer.Ingress[0]) != requestedIP {
0000000000000000000000000000000000000000;;				framework.Failf("unexpected TCP Status.LoadBalancer.Ingress (expected %s, got %s)", requestedIP, framework.GetIngressPoint(&tcpService.Status.LoadBalancer.Ingress[0]))
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			tcpIngressIP := framework.GetIngressPoint(&tcpService.Status.LoadBalancer.Ingress[0])
0000000000000000000000000000000000000000;;			framework.Logf("TCP load balancer: %s", tcpIngressIP)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			if framework.ProviderIs("gce", "gke") {
0000000000000000000000000000000000000000;;				// Do this as early as possible, which overrides the `defer` above.
0000000000000000000000000000000000000000;;				// This is mostly out of fear of leaking the IP in a timeout case
0000000000000000000000000000000000000000;;				// (as of this writing we're not 100% sure where the leaks are
0000000000000000000000000000000000000000;;				// coming from, so this is first-aid rather than surgery).
0000000000000000000000000000000000000000;;				By("demoting the static IP to ephemeral")
0000000000000000000000000000000000000000;;				if staticIPName != "" {
0000000000000000000000000000000000000000;;					// Deleting it after it is attached "demotes" it to an
0000000000000000000000000000000000000000;;					// ephemeral IP, which can be auto-released.
0000000000000000000000000000000000000000;;					if err := framework.DeleteGCEStaticIP(staticIPName); err != nil {
0000000000000000000000000000000000000000;;						framework.Failf("failed to release static IP %s: %v", staticIPName, err)
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					staticIPName = ""
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			var udpIngressIP string
0000000000000000000000000000000000000000;;			if loadBalancerSupportsUDP {
0000000000000000000000000000000000000000;;				By("waiting for the UDP service to have a load balancer")
0000000000000000000000000000000000000000;;				// 2nd one should be faster since they ran in parallel.
0000000000000000000000000000000000000000;;				udpService = jig.WaitForLoadBalancerOrFail(ns2, udpService.Name, loadBalancerCreateTimeout)
0000000000000000000000000000000000000000;;				jig.SanityCheckService(udpService, v1.ServiceTypeLoadBalancer)
0000000000000000000000000000000000000000;;				if int(udpService.Spec.Ports[0].NodePort) != udpNodePort {
0000000000000000000000000000000000000000;;					framework.Failf("UDP Spec.Ports[0].NodePort changed (%d -> %d) when not expected", udpNodePort, udpService.Spec.Ports[0].NodePort)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				udpIngressIP = framework.GetIngressPoint(&udpService.Status.LoadBalancer.Ingress[0])
0000000000000000000000000000000000000000;;				framework.Logf("UDP load balancer: %s", udpIngressIP)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				By("verifying that TCP and UDP use different load balancers")
0000000000000000000000000000000000000000;;				if tcpIngressIP == udpIngressIP {
0000000000000000000000000000000000000000;;					framework.Failf("Load balancers are not different: %s", framework.GetIngressPoint(&tcpService.Status.LoadBalancer.Ingress[0]))
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("hitting the TCP service's NodePort")
0000000000000000000000000000000000000000;;			jig.TestReachableHTTP(nodeIP, tcpNodePort, framework.KubeProxyLagTimeout)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("hitting the UDP service's NodePort")
0000000000000000000000000000000000000000;;			jig.TestReachableUDP(nodeIP, udpNodePort, framework.KubeProxyLagTimeout)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("hitting the TCP service's LoadBalancer")
0000000000000000000000000000000000000000;;			jig.TestReachableHTTP(tcpIngressIP, svcPort, loadBalancerLagTimeout)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			if loadBalancerSupportsUDP {
0000000000000000000000000000000000000000;;				By("hitting the UDP service's LoadBalancer")
0000000000000000000000000000000000000000;;				jig.TestReachableUDP(udpIngressIP, svcPort, loadBalancerLagTimeout)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Change the services' node ports.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("changing the TCP service's NodePort")
0000000000000000000000000000000000000000;;			tcpService = jig.ChangeServiceNodePortOrFail(ns1, tcpService.Name, tcpNodePort)
0000000000000000000000000000000000000000;;			jig.SanityCheckService(tcpService, v1.ServiceTypeLoadBalancer)
0000000000000000000000000000000000000000;;			tcpNodePortOld := tcpNodePort
0000000000000000000000000000000000000000;;			tcpNodePort = int(tcpService.Spec.Ports[0].NodePort)
0000000000000000000000000000000000000000;;			if tcpNodePort == tcpNodePortOld {
0000000000000000000000000000000000000000;;				framework.Failf("TCP Spec.Ports[0].NodePort (%d) did not change", tcpNodePort)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if framework.GetIngressPoint(&tcpService.Status.LoadBalancer.Ingress[0]) != tcpIngressIP {
0000000000000000000000000000000000000000;;				framework.Failf("TCP Status.LoadBalancer.Ingress changed (%s -> %s) when not expected", tcpIngressIP, framework.GetIngressPoint(&tcpService.Status.LoadBalancer.Ingress[0]))
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			framework.Logf("TCP node port: %d", tcpNodePort)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("changing the UDP service's NodePort")
0000000000000000000000000000000000000000;;			udpService = jig.ChangeServiceNodePortOrFail(ns2, udpService.Name, udpNodePort)
0000000000000000000000000000000000000000;;			if loadBalancerSupportsUDP {
0000000000000000000000000000000000000000;;				jig.SanityCheckService(udpService, v1.ServiceTypeLoadBalancer)
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				jig.SanityCheckService(udpService, v1.ServiceTypeNodePort)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			udpNodePortOld := udpNodePort
0000000000000000000000000000000000000000;;			udpNodePort = int(udpService.Spec.Ports[0].NodePort)
0000000000000000000000000000000000000000;;			if udpNodePort == udpNodePortOld {
0000000000000000000000000000000000000000;;				framework.Failf("UDP Spec.Ports[0].NodePort (%d) did not change", udpNodePort)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if loadBalancerSupportsUDP && framework.GetIngressPoint(&udpService.Status.LoadBalancer.Ingress[0]) != udpIngressIP {
0000000000000000000000000000000000000000;;				framework.Failf("UDP Status.LoadBalancer.Ingress changed (%s -> %s) when not expected", udpIngressIP, framework.GetIngressPoint(&udpService.Status.LoadBalancer.Ingress[0]))
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			framework.Logf("UDP node port: %d", udpNodePort)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("hitting the TCP service's new NodePort")
0000000000000000000000000000000000000000;;			jig.TestReachableHTTP(nodeIP, tcpNodePort, framework.KubeProxyLagTimeout)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("hitting the UDP service's new NodePort")
0000000000000000000000000000000000000000;;			jig.TestReachableUDP(nodeIP, udpNodePort, framework.KubeProxyLagTimeout)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("checking the old TCP NodePort is closed")
0000000000000000000000000000000000000000;;			jig.TestNotReachableHTTP(nodeIP, tcpNodePortOld, framework.KubeProxyLagTimeout)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("checking the old UDP NodePort is closed")
0000000000000000000000000000000000000000;;			jig.TestNotReachableUDP(nodeIP, udpNodePortOld, framework.KubeProxyLagTimeout)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("hitting the TCP service's LoadBalancer")
0000000000000000000000000000000000000000;;			jig.TestReachableHTTP(tcpIngressIP, svcPort, loadBalancerLagTimeout)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			if loadBalancerSupportsUDP {
0000000000000000000000000000000000000000;;				By("hitting the UDP service's LoadBalancer")
0000000000000000000000000000000000000000;;				jig.TestReachableUDP(udpIngressIP, svcPort, loadBalancerLagTimeout)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Change the services' main ports.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("changing the TCP service's port")
0000000000000000000000000000000000000000;;			tcpService = jig.UpdateServiceOrFail(ns1, tcpService.Name, func(s *v1.Service) {
0000000000000000000000000000000000000000;;				s.Spec.Ports[0].Port++
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;			jig.SanityCheckService(tcpService, v1.ServiceTypeLoadBalancer)
0000000000000000000000000000000000000000;;			svcPortOld := svcPort
0000000000000000000000000000000000000000;;			svcPort = int(tcpService.Spec.Ports[0].Port)
0000000000000000000000000000000000000000;;			if svcPort == svcPortOld {
0000000000000000000000000000000000000000;;				framework.Failf("TCP Spec.Ports[0].Port (%d) did not change", svcPort)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if int(tcpService.Spec.Ports[0].NodePort) != tcpNodePort {
0000000000000000000000000000000000000000;;				framework.Failf("TCP Spec.Ports[0].NodePort (%d) changed", tcpService.Spec.Ports[0].NodePort)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if framework.GetIngressPoint(&tcpService.Status.LoadBalancer.Ingress[0]) != tcpIngressIP {
0000000000000000000000000000000000000000;;				framework.Failf("TCP Status.LoadBalancer.Ingress changed (%s -> %s) when not expected", tcpIngressIP, framework.GetIngressPoint(&tcpService.Status.LoadBalancer.Ingress[0]))
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("changing the UDP service's port")
0000000000000000000000000000000000000000;;			udpService = jig.UpdateServiceOrFail(ns2, udpService.Name, func(s *v1.Service) {
0000000000000000000000000000000000000000;;				s.Spec.Ports[0].Port++
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;			if loadBalancerSupportsUDP {
0000000000000000000000000000000000000000;;				jig.SanityCheckService(udpService, v1.ServiceTypeLoadBalancer)
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				jig.SanityCheckService(udpService, v1.ServiceTypeNodePort)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if int(udpService.Spec.Ports[0].Port) != svcPort {
0000000000000000000000000000000000000000;;				framework.Failf("UDP Spec.Ports[0].Port (%d) did not change", udpService.Spec.Ports[0].Port)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if int(udpService.Spec.Ports[0].NodePort) != udpNodePort {
0000000000000000000000000000000000000000;;				framework.Failf("UDP Spec.Ports[0].NodePort (%d) changed", udpService.Spec.Ports[0].NodePort)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if loadBalancerSupportsUDP && framework.GetIngressPoint(&udpService.Status.LoadBalancer.Ingress[0]) != udpIngressIP {
0000000000000000000000000000000000000000;;				framework.Failf("UDP Status.LoadBalancer.Ingress changed (%s -> %s) when not expected", udpIngressIP, framework.GetIngressPoint(&udpService.Status.LoadBalancer.Ingress[0]))
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			framework.Logf("service port (TCP and UDP): %d", svcPort)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("hitting the TCP service's NodePort")
0000000000000000000000000000000000000000;;			jig.TestReachableHTTP(nodeIP, tcpNodePort, framework.KubeProxyLagTimeout)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("hitting the UDP service's NodePort")
0000000000000000000000000000000000000000;;			jig.TestReachableUDP(nodeIP, udpNodePort, framework.KubeProxyLagTimeout)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("hitting the TCP service's LoadBalancer")
0000000000000000000000000000000000000000;;			jig.TestReachableHTTP(tcpIngressIP, svcPort, loadBalancerCreateTimeout) // this may actually recreate the LB
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			if loadBalancerSupportsUDP {
0000000000000000000000000000000000000000;;				By("hitting the UDP service's LoadBalancer")
0000000000000000000000000000000000000000;;				jig.TestReachableUDP(udpIngressIP, svcPort, loadBalancerCreateTimeout) // this may actually recreate the LB)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Change the services back to ClusterIP.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("changing TCP service back to type=ClusterIP")
0000000000000000000000000000000000000000;;			tcpService = jig.UpdateServiceOrFail(ns1, tcpService.Name, func(s *v1.Service) {
0000000000000000000000000000000000000000;;				s.Spec.Type = v1.ServiceTypeClusterIP
0000000000000000000000000000000000000000;;				s.Spec.Ports[0].NodePort = 0
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;			// Wait for the load balancer to be destroyed asynchronously
0000000000000000000000000000000000000000;;			tcpService = jig.WaitForLoadBalancerDestroyOrFail(ns1, tcpService.Name, tcpIngressIP, svcPort, loadBalancerCreateTimeout)
0000000000000000000000000000000000000000;;			jig.SanityCheckService(tcpService, v1.ServiceTypeClusterIP)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("changing UDP service back to type=ClusterIP")
0000000000000000000000000000000000000000;;			udpService = jig.UpdateServiceOrFail(ns2, udpService.Name, func(s *v1.Service) {
0000000000000000000000000000000000000000;;				s.Spec.Type = v1.ServiceTypeClusterIP
0000000000000000000000000000000000000000;;				s.Spec.Ports[0].NodePort = 0
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;			if loadBalancerSupportsUDP {
0000000000000000000000000000000000000000;;				// Wait for the load balancer to be destroyed asynchronously
0000000000000000000000000000000000000000;;				udpService = jig.WaitForLoadBalancerDestroyOrFail(ns2, udpService.Name, udpIngressIP, svcPort, loadBalancerCreateTimeout)
0000000000000000000000000000000000000000;;				jig.SanityCheckService(udpService, v1.ServiceTypeClusterIP)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("checking the TCP NodePort is closed")
0000000000000000000000000000000000000000;;			jig.TestNotReachableHTTP(nodeIP, tcpNodePort, framework.KubeProxyLagTimeout)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("checking the UDP NodePort is closed")
0000000000000000000000000000000000000000;;			jig.TestNotReachableUDP(nodeIP, udpNodePort, framework.KubeProxyLagTimeout)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("checking the TCP LoadBalancer is closed")
0000000000000000000000000000000000000000;;			jig.TestNotReachableHTTP(tcpIngressIP, svcPort, loadBalancerLagTimeout)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			if loadBalancerSupportsUDP {
0000000000000000000000000000000000000000;;				By("checking the UDP LoadBalancer is closed")
0000000000000000000000000000000000000000;;				jig.TestNotReachableUDP(udpIngressIP, svcPort, loadBalancerLagTimeout)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		It("should be able to change the type from ExternalName to ClusterIP", func() {
0000000000000000000000000000000000000000;;			serviceName := "externalname-service"
0000000000000000000000000000000000000000;;			ns := f.Namespace.Name
0000000000000000000000000000000000000000;;			jig := framework.NewServiceTestJig(cs, serviceName)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("creating a service " + serviceName + " with the type=ExternalName in namespace " + ns)
0000000000000000000000000000000000000000;;			externalNameService := jig.CreateExternalNameServiceOrFail(ns, nil)
0000000000000000000000000000000000000000;;			defer func() {
0000000000000000000000000000000000000000;;				framework.Logf("Cleaning up the ExternalName to ClusterIP test service")
0000000000000000000000000000000000000000;;				err := cs.Core().Services(ns).Delete(serviceName, nil)
0000000000000000000000000000000000000000;;				Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;			}()
0000000000000000000000000000000000000000;;			jig.SanityCheckService(externalNameService, v1.ServiceTypeExternalName)
0000000000000000000000000000000000000000;;			By("changing the ExternalName service to type=ClusterIP")
0000000000000000000000000000000000000000;;			clusterIPService := jig.UpdateServiceOrFail(ns, externalNameService.Name, func(s *v1.Service) {
0000000000000000000000000000000000000000;;				s.Spec.Type = v1.ServiceTypeClusterIP
0000000000000000000000000000000000000000;;				s.Spec.ExternalName = ""
0000000000000000000000000000000000000000;;				s.Spec.Ports = []v1.ServicePort{
0000000000000000000000000000000000000000;;					{Port: 80, Name: "http", Protocol: "TCP"},
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;			jig.SanityCheckService(clusterIPService, v1.ServiceTypeClusterIP)
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		It("should be able to change the type from ExternalName to NodePort", func() {
0000000000000000000000000000000000000000;;			serviceName := "externalname-service"
0000000000000000000000000000000000000000;;			ns := f.Namespace.Name
0000000000000000000000000000000000000000;;			jig := framework.NewServiceTestJig(cs, serviceName)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("creating a service " + serviceName + " with the type=ExternalName in namespace " + ns)
0000000000000000000000000000000000000000;;			externalNameService := jig.CreateExternalNameServiceOrFail(ns, nil)
0000000000000000000000000000000000000000;;			defer func() {
0000000000000000000000000000000000000000;;				framework.Logf("Cleaning up the ExternalName to NodePort test service")
0000000000000000000000000000000000000000;;				err := cs.Core().Services(ns).Delete(serviceName, nil)
0000000000000000000000000000000000000000;;				Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;			}()
0000000000000000000000000000000000000000;;			jig.SanityCheckService(externalNameService, v1.ServiceTypeExternalName)
0000000000000000000000000000000000000000;;			By("changing the ExternalName service to type=NodePort")
0000000000000000000000000000000000000000;;			nodePortService := jig.UpdateServiceOrFail(ns, externalNameService.Name, func(s *v1.Service) {
0000000000000000000000000000000000000000;;				s.Spec.Type = v1.ServiceTypeNodePort
0000000000000000000000000000000000000000;;				s.Spec.ExternalName = ""
0000000000000000000000000000000000000000;;				s.Spec.Ports = []v1.ServicePort{
0000000000000000000000000000000000000000;;					{Port: 80, Name: "http", Protocol: "TCP"},
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;			jig.SanityCheckService(nodePortService, v1.ServiceTypeNodePort)
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		It("should be able to change the type from ClusterIP to ExternalName", func() {
0000000000000000000000000000000000000000;;			serviceName := "clusterip-service"
0000000000000000000000000000000000000000;;			ns := f.Namespace.Name
0000000000000000000000000000000000000000;;			jig := framework.NewServiceTestJig(cs, serviceName)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("creating a service " + serviceName + " with the type=ClusterIP in namespace " + ns)
0000000000000000000000000000000000000000;;			clusterIPService := jig.CreateTCPServiceOrFail(ns, nil)
0000000000000000000000000000000000000000;;			defer func() {
0000000000000000000000000000000000000000;;				framework.Logf("Cleaning up the ClusterIP to ExternalName test service")
0000000000000000000000000000000000000000;;				err := cs.Core().Services(ns).Delete(serviceName, nil)
0000000000000000000000000000000000000000;;				Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;			}()
0000000000000000000000000000000000000000;;			jig.SanityCheckService(clusterIPService, v1.ServiceTypeClusterIP)
0000000000000000000000000000000000000000;;			By("changing the ClusterIP service to type=ExternalName")
0000000000000000000000000000000000000000;;			externalNameService := jig.UpdateServiceOrFail(ns, clusterIPService.Name, func(s *v1.Service) {
0000000000000000000000000000000000000000;;				s.Spec.Type = v1.ServiceTypeExternalName
0000000000000000000000000000000000000000;;				s.Spec.ExternalName = "foo.example.com"
0000000000000000000000000000000000000000;;				s.Spec.ClusterIP = ""
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;			jig.SanityCheckService(externalNameService, v1.ServiceTypeExternalName)
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		It("should be able to change the type from NodePort to ExternalName", func() {
0000000000000000000000000000000000000000;;			serviceName := "nodeport-service"
0000000000000000000000000000000000000000;;			ns := f.Namespace.Name
0000000000000000000000000000000000000000;;			jig := framework.NewServiceTestJig(cs, serviceName)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("creating a service " + serviceName + " with the type=NodePort in namespace " + ns)
0000000000000000000000000000000000000000;;			nodePortService := jig.CreateTCPServiceOrFail(ns, func(svc *v1.Service) {
0000000000000000000000000000000000000000;;				svc.Spec.Type = v1.ServiceTypeNodePort
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;			defer func() {
0000000000000000000000000000000000000000;;				framework.Logf("Cleaning up the NodePort to ExternalName test service")
0000000000000000000000000000000000000000;;				err := cs.Core().Services(ns).Delete(serviceName, nil)
0000000000000000000000000000000000000000;;				Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;			}()
0000000000000000000000000000000000000000;;			jig.SanityCheckService(nodePortService, v1.ServiceTypeNodePort)
0000000000000000000000000000000000000000;;			By("changing the NodePort service to type=ExternalName")
0000000000000000000000000000000000000000;;			externalNameService := jig.UpdateServiceOrFail(ns, nodePortService.Name, func(s *v1.Service) {
0000000000000000000000000000000000000000;;				s.Spec.Type = v1.ServiceTypeExternalName
0000000000000000000000000000000000000000;;				s.Spec.ExternalName = "foo.example.com"
0000000000000000000000000000000000000000;;				s.Spec.ClusterIP = ""
0000000000000000000000000000000000000000;;				s.Spec.Ports[0].NodePort = 0
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;			jig.SanityCheckService(externalNameService, v1.ServiceTypeExternalName)
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		It("should use same NodePort with same port but different protocols", func() {
0000000000000000000000000000000000000000;;			serviceName := "nodeports"
0000000000000000000000000000000000000000;;			ns := f.Namespace.Name
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			t := framework.NewServerTest(cs, ns, serviceName)
0000000000000000000000000000000000000000;;			defer func() {
0000000000000000000000000000000000000000;;				defer GinkgoRecover()
0000000000000000000000000000000000000000;;				errs := t.Cleanup()
0000000000000000000000000000000000000000;;				if len(errs) != 0 {
0000000000000000000000000000000000000000;;					framework.Failf("errors in cleanup: %v", errs)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("creating service " + serviceName + " with same NodePort but different protocols in namespace " + ns)
0000000000000000000000000000000000000000;;			service := &v1.Service{
0000000000000000000000000000000000000000;;				ObjectMeta: metav1.ObjectMeta{
0000000000000000000000000000000000000000;;					Name:      t.ServiceName,
0000000000000000000000000000000000000000;;					Namespace: t.Namespace,
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;				Spec: v1.ServiceSpec{
0000000000000000000000000000000000000000;;					Selector: t.Labels,
0000000000000000000000000000000000000000;;					Type:     v1.ServiceTypeNodePort,
0000000000000000000000000000000000000000;;					Ports: []v1.ServicePort{
0000000000000000000000000000000000000000;;						{
0000000000000000000000000000000000000000;;							Name:     "tcp-port",
0000000000000000000000000000000000000000;;							Port:     53,
0000000000000000000000000000000000000000;;							Protocol: v1.ProtocolTCP,
0000000000000000000000000000000000000000;;						},
0000000000000000000000000000000000000000;;						{
0000000000000000000000000000000000000000;;							Name:     "udp-port",
0000000000000000000000000000000000000000;;							Port:     53,
0000000000000000000000000000000000000000;;							Protocol: v1.ProtocolUDP,
0000000000000000000000000000000000000000;;						},
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			result, err := t.CreateService(service)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			if len(result.Spec.Ports) != 2 {
0000000000000000000000000000000000000000;;				framework.Failf("got unexpected len(Spec.Ports) for new service: %v", result)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if result.Spec.Ports[0].NodePort != result.Spec.Ports[1].NodePort {
0000000000000000000000000000000000000000;;				framework.Failf("should use same NodePort for new service: %v", result)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		It("should prevent NodePort collisions", func() {
0000000000000000000000000000000000000000;;			// TODO: use the ServiceTestJig here
0000000000000000000000000000000000000000;;			baseName := "nodeport-collision-"
0000000000000000000000000000000000000000;;			serviceName1 := baseName + "1"
0000000000000000000000000000000000000000;;			serviceName2 := baseName + "2"
0000000000000000000000000000000000000000;;			ns := f.Namespace.Name
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			t := framework.NewServerTest(cs, ns, serviceName1)
0000000000000000000000000000000000000000;;			defer func() {
0000000000000000000000000000000000000000;;				defer GinkgoRecover()
0000000000000000000000000000000000000000;;				errs := t.Cleanup()
0000000000000000000000000000000000000000;;				if len(errs) != 0 {
0000000000000000000000000000000000000000;;					framework.Failf("errors in cleanup: %v", errs)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("creating service " + serviceName1 + " with type NodePort in namespace " + ns)
0000000000000000000000000000000000000000;;			service := t.BuildServiceSpec()
0000000000000000000000000000000000000000;;			service.Spec.Type = v1.ServiceTypeNodePort
0000000000000000000000000000000000000000;;			result, err := t.CreateService(service)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			if result.Spec.Type != v1.ServiceTypeNodePort {
0000000000000000000000000000000000000000;;				framework.Failf("got unexpected Spec.Type for new service: %v", result)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if len(result.Spec.Ports) != 1 {
0000000000000000000000000000000000000000;;				framework.Failf("got unexpected len(Spec.Ports) for new service: %v", result)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			port := result.Spec.Ports[0]
0000000000000000000000000000000000000000;;			if port.NodePort == 0 {
0000000000000000000000000000000000000000;;				framework.Failf("got unexpected Spec.Ports[0].NodePort for new service: %v", result)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("creating service " + serviceName2 + " with conflicting NodePort")
0000000000000000000000000000000000000000;;			service2 := t.BuildServiceSpec()
0000000000000000000000000000000000000000;;			service2.Name = serviceName2
0000000000000000000000000000000000000000;;			service2.Spec.Type = v1.ServiceTypeNodePort
0000000000000000000000000000000000000000;;			service2.Spec.Ports[0].NodePort = port.NodePort
0000000000000000000000000000000000000000;;			result2, err := t.CreateService(service2)
0000000000000000000000000000000000000000;;			if err == nil {
0000000000000000000000000000000000000000;;				framework.Failf("Created service with conflicting NodePort: %v", result2)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			expectedErr := fmt.Sprintf("%d.*port is already allocated", port.NodePort)
0000000000000000000000000000000000000000;;			Expect(fmt.Sprintf("%v", err)).To(MatchRegexp(expectedErr))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("deleting service " + serviceName1 + " to release NodePort")
0000000000000000000000000000000000000000;;			err = t.DeleteService(serviceName1)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("creating service " + serviceName2 + " with no-longer-conflicting NodePort")
0000000000000000000000000000000000000000;;			_, err = t.CreateService(service2)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		It("should check NodePort out-of-range", func() {
0000000000000000000000000000000000000000;;			// TODO: use the ServiceTestJig here
0000000000000000000000000000000000000000;;			serviceName := "nodeport-range-test"
0000000000000000000000000000000000000000;;			ns := f.Namespace.Name
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			t := framework.NewServerTest(cs, ns, serviceName)
0000000000000000000000000000000000000000;;			defer func() {
0000000000000000000000000000000000000000;;				defer GinkgoRecover()
0000000000000000000000000000000000000000;;				errs := t.Cleanup()
0000000000000000000000000000000000000000;;				if len(errs) != 0 {
0000000000000000000000000000000000000000;;					framework.Failf("errors in cleanup: %v", errs)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			service := t.BuildServiceSpec()
0000000000000000000000000000000000000000;;			service.Spec.Type = v1.ServiceTypeNodePort
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("creating service " + serviceName + " with type NodePort in namespace " + ns)
0000000000000000000000000000000000000000;;			service, err := t.CreateService(service)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			if service.Spec.Type != v1.ServiceTypeNodePort {
0000000000000000000000000000000000000000;;				framework.Failf("got unexpected Spec.Type for new service: %v", service)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if len(service.Spec.Ports) != 1 {
0000000000000000000000000000000000000000;;				framework.Failf("got unexpected len(Spec.Ports) for new service: %v", service)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			port := service.Spec.Ports[0]
0000000000000000000000000000000000000000;;			if port.NodePort == 0 {
0000000000000000000000000000000000000000;;				framework.Failf("got unexpected Spec.Ports[0].nodePort for new service: %v", service)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if !framework.ServiceNodePortRange.Contains(int(port.NodePort)) {
0000000000000000000000000000000000000000;;				framework.Failf("got unexpected (out-of-range) port for new service: %v", service)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			outOfRangeNodePort := 0
0000000000000000000000000000000000000000;;			rand.Seed(time.Now().UTC().UnixNano())
0000000000000000000000000000000000000000;;			for {
0000000000000000000000000000000000000000;;				outOfRangeNodePort = 1 + rand.Intn(65535)
0000000000000000000000000000000000000000;;				if !framework.ServiceNodePortRange.Contains(outOfRangeNodePort) {
0000000000000000000000000000000000000000;;					break
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			By(fmt.Sprintf("changing service "+serviceName+" to out-of-range NodePort %d", outOfRangeNodePort))
0000000000000000000000000000000000000000;;			result, err := framework.UpdateService(cs, ns, serviceName, func(s *v1.Service) {
0000000000000000000000000000000000000000;;				s.Spec.Ports[0].NodePort = int32(outOfRangeNodePort)
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;			if err == nil {
0000000000000000000000000000000000000000;;				framework.Failf("failed to prevent update of service with out-of-range NodePort: %v", result)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			expectedErr := fmt.Sprintf("%d.*port is not in the valid range", outOfRangeNodePort)
0000000000000000000000000000000000000000;;			Expect(fmt.Sprintf("%v", err)).To(MatchRegexp(expectedErr))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("deleting original service " + serviceName)
0000000000000000000000000000000000000000;;			err = t.DeleteService(serviceName)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By(fmt.Sprintf("creating service "+serviceName+" with out-of-range NodePort %d", outOfRangeNodePort))
0000000000000000000000000000000000000000;;			service = t.BuildServiceSpec()
0000000000000000000000000000000000000000;;			service.Spec.Type = v1.ServiceTypeNodePort
0000000000000000000000000000000000000000;;			service.Spec.Ports[0].NodePort = int32(outOfRangeNodePort)
0000000000000000000000000000000000000000;;			service, err = t.CreateService(service)
0000000000000000000000000000000000000000;;			if err == nil {
0000000000000000000000000000000000000000;;				framework.Failf("failed to prevent create of service with out-of-range NodePort (%d): %v", outOfRangeNodePort, service)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			Expect(fmt.Sprintf("%v", err)).To(MatchRegexp(expectedErr))
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		It("should release NodePorts on delete", func() {
0000000000000000000000000000000000000000;;			// TODO: use the ServiceTestJig here
0000000000000000000000000000000000000000;;			serviceName := "nodeport-reuse"
0000000000000000000000000000000000000000;;			ns := f.Namespace.Name
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			t := framework.NewServerTest(cs, ns, serviceName)
0000000000000000000000000000000000000000;;			defer func() {
0000000000000000000000000000000000000000;;				defer GinkgoRecover()
0000000000000000000000000000000000000000;;				errs := t.Cleanup()
0000000000000000000000000000000000000000;;				if len(errs) != 0 {
0000000000000000000000000000000000000000;;					framework.Failf("errors in cleanup: %v", errs)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			service := t.BuildServiceSpec()
0000000000000000000000000000000000000000;;			service.Spec.Type = v1.ServiceTypeNodePort
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("creating service " + serviceName + " with type NodePort in namespace " + ns)
0000000000000000000000000000000000000000;;			service, err := t.CreateService(service)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			if service.Spec.Type != v1.ServiceTypeNodePort {
0000000000000000000000000000000000000000;;				framework.Failf("got unexpected Spec.Type for new service: %v", service)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if len(service.Spec.Ports) != 1 {
0000000000000000000000000000000000000000;;				framework.Failf("got unexpected len(Spec.Ports) for new service: %v", service)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			port := service.Spec.Ports[0]
0000000000000000000000000000000000000000;;			if port.NodePort == 0 {
0000000000000000000000000000000000000000;;				framework.Failf("got unexpected Spec.Ports[0].nodePort for new service: %v", service)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if !framework.ServiceNodePortRange.Contains(int(port.NodePort)) {
0000000000000000000000000000000000000000;;				framework.Failf("got unexpected (out-of-range) port for new service: %v", service)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			nodePort := port.NodePort
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("deleting original service " + serviceName)
0000000000000000000000000000000000000000;;			err = t.DeleteService(serviceName)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			hostExec := framework.LaunchHostExecPod(f.ClientSet, f.Namespace.Name, "hostexec")
0000000000000000000000000000000000000000;;			cmd := fmt.Sprintf(`! ss -ant46 'sport = :%d' | tail -n +2 | grep LISTEN`, nodePort)
0000000000000000000000000000000000000000;;			var stdout string
0000000000000000000000000000000000000000;;			if pollErr := wait.PollImmediate(framework.Poll, framework.KubeProxyLagTimeout, func() (bool, error) {
0000000000000000000000000000000000000000;;				var err error
0000000000000000000000000000000000000000;;				stdout, err = framework.RunHostCmd(hostExec.Namespace, hostExec.Name, cmd)
0000000000000000000000000000000000000000;;				if err != nil {
0000000000000000000000000000000000000000;;					framework.Logf("expected node port (%d) to not be in use, stdout: %v", nodePort, stdout)
0000000000000000000000000000000000000000;;					return false, nil
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				return true, nil
0000000000000000000000000000000000000000;;			}); pollErr != nil {
0000000000000000000000000000000000000000;;				framework.Failf("expected node port (%d) to not be in use in %v, stdout: %v", nodePort, framework.KubeProxyLagTimeout, stdout)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By(fmt.Sprintf("creating service "+serviceName+" with same NodePort %d", nodePort))
0000000000000000000000000000000000000000;;			service = t.BuildServiceSpec()
0000000000000000000000000000000000000000;;			service.Spec.Type = v1.ServiceTypeNodePort
0000000000000000000000000000000000000000;;			service.Spec.Ports[0].NodePort = nodePort
0000000000000000000000000000000000000000;;			service, err = t.CreateService(service)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		It("should create endpoints for unready pods", func() {
0000000000000000000000000000000000000000;;			serviceName := "tolerate-unready"
0000000000000000000000000000000000000000;;			ns := f.Namespace.Name
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			t := framework.NewServerTest(cs, ns, serviceName)
0000000000000000000000000000000000000000;;			defer func() {
0000000000000000000000000000000000000000;;				defer GinkgoRecover()
0000000000000000000000000000000000000000;;				errs := t.Cleanup()
0000000000000000000000000000000000000000;;				if len(errs) != 0 {
0000000000000000000000000000000000000000;;					framework.Failf("errors in cleanup: %v", errs)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			t.Name = "slow-terminating-unready-pod"
0000000000000000000000000000000000000000;;			t.Image = "gcr.io/google_containers/netexec:1.7"
0000000000000000000000000000000000000000;;			port := 80
0000000000000000000000000000000000000000;;			terminateSeconds := int64(600)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			service := &v1.Service{
0000000000000000000000000000000000000000;;				ObjectMeta: metav1.ObjectMeta{
0000000000000000000000000000000000000000;;					Name:        t.ServiceName,
0000000000000000000000000000000000000000;;					Namespace:   t.Namespace,
0000000000000000000000000000000000000000;;					Annotations: map[string]string{endpoint.TolerateUnreadyEndpointsAnnotation: "true"},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;				Spec: v1.ServiceSpec{
0000000000000000000000000000000000000000;;					Selector: t.Labels,
0000000000000000000000000000000000000000;;					Ports: []v1.ServicePort{{
0000000000000000000000000000000000000000;;						Name:       "http",
0000000000000000000000000000000000000000;;						Port:       int32(port),
0000000000000000000000000000000000000000;;						TargetPort: intstr.FromInt(port),
0000000000000000000000000000000000000000;;					}},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			rcSpec := framework.RcByNameContainer(t.Name, 1, t.Image, t.Labels, v1.Container{
0000000000000000000000000000000000000000;;				Args:  []string{fmt.Sprintf("--http-port=%d", port)},
0000000000000000000000000000000000000000;;				Name:  t.Name,
0000000000000000000000000000000000000000;;				Image: t.Image,
0000000000000000000000000000000000000000;;				Ports: []v1.ContainerPort{{ContainerPort: int32(port), Protocol: v1.ProtocolTCP}},
0000000000000000000000000000000000000000;;				ReadinessProbe: &v1.Probe{
0000000000000000000000000000000000000000;;					Handler: v1.Handler{
0000000000000000000000000000000000000000;;						Exec: &v1.ExecAction{
0000000000000000000000000000000000000000;;							Command: []string{"/bin/false"},
0000000000000000000000000000000000000000;;						},
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;				Lifecycle: &v1.Lifecycle{
0000000000000000000000000000000000000000;;					PreStop: &v1.Handler{
0000000000000000000000000000000000000000;;						Exec: &v1.ExecAction{
0000000000000000000000000000000000000000;;							Command: []string{"/bin/sleep", fmt.Sprintf("%d", terminateSeconds)},
0000000000000000000000000000000000000000;;						},
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			}, nil)
0000000000000000000000000000000000000000;;			rcSpec.Spec.Template.Spec.TerminationGracePeriodSeconds = &terminateSeconds
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By(fmt.Sprintf("creating RC %v with selectors %v", rcSpec.Name, rcSpec.Spec.Selector))
0000000000000000000000000000000000000000;;			_, err := t.CreateRC(rcSpec)
0000000000000000000000000000000000000000;;			framework.ExpectNoError(err)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By(fmt.Sprintf("creating Service %v with selectors %v", service.Name, service.Spec.Selector))
0000000000000000000000000000000000000000;;			_, err = t.CreateService(service)
0000000000000000000000000000000000000000;;			framework.ExpectNoError(err)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Verifying pods for RC " + t.Name)
0000000000000000000000000000000000000000;;			framework.ExpectNoError(framework.VerifyPods(t.Client, t.Namespace, t.Name, false, 1))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			svcName := fmt.Sprintf("%v.%v.svc.cluster.local", serviceName, f.Namespace.Name)
0000000000000000000000000000000000000000;;			By("Waiting for endpoints of Service with DNS name " + svcName)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			execPodName := framework.CreateExecPodOrFail(f.ClientSet, f.Namespace.Name, "execpod-", nil)
0000000000000000000000000000000000000000;;			cmd := fmt.Sprintf("wget -qO- http://%s:%d/", svcName, port)
0000000000000000000000000000000000000000;;			var stdout string
0000000000000000000000000000000000000000;;			if pollErr := wait.PollImmediate(framework.Poll, framework.KubeProxyLagTimeout, func() (bool, error) {
0000000000000000000000000000000000000000;;				var err error
0000000000000000000000000000000000000000;;				stdout, err = framework.RunHostCmd(f.Namespace.Name, execPodName, cmd)
0000000000000000000000000000000000000000;;				if err != nil {
0000000000000000000000000000000000000000;;					framework.Logf("expected un-ready endpoint for Service %v, stdout: %v, err %v", t.Name, stdout, err)
0000000000000000000000000000000000000000;;					return false, nil
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				return true, nil
0000000000000000000000000000000000000000;;			}); pollErr != nil {
0000000000000000000000000000000000000000;;				framework.Failf("expected un-ready endpoint for Service %v within %v, stdout: %v", t.Name, framework.KubeProxyLagTimeout, stdout)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Scaling down replication controller to zero")
0000000000000000000000000000000000000000;;			framework.ScaleRC(f.ClientSet, f.InternalClientset, t.Namespace, rcSpec.Name, 0, false)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Update service to not tolerate unready services")
0000000000000000000000000000000000000000;;			_, err = framework.UpdateService(f.ClientSet, t.Namespace, t.ServiceName, func(s *v1.Service) {
0000000000000000000000000000000000000000;;				s.ObjectMeta.Annotations[endpoint.TolerateUnreadyEndpointsAnnotation] = "false"
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;			framework.ExpectNoError(err)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Check if pod is unreachable")
0000000000000000000000000000000000000000;;			cmd = fmt.Sprintf("wget -qO- -T 2 http://%s:%d/; test \"$?\" -eq \"1\"", svcName, port)
0000000000000000000000000000000000000000;;			if pollErr := wait.PollImmediate(framework.Poll, framework.KubeProxyLagTimeout, func() (bool, error) {
0000000000000000000000000000000000000000;;				var err error
0000000000000000000000000000000000000000;;				stdout, err = framework.RunHostCmd(f.Namespace.Name, execPodName, cmd)
0000000000000000000000000000000000000000;;				if err != nil {
0000000000000000000000000000000000000000;;					framework.Logf("expected un-ready endpoint for Service %v, stdout: %v, err %v", t.Name, stdout, err)
0000000000000000000000000000000000000000;;					return false, nil
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				return true, nil
0000000000000000000000000000000000000000;;			}); pollErr != nil {
0000000000000000000000000000000000000000;;				framework.Failf("expected un-ready endpoint for Service %v within %v, stdout: %v", t.Name, framework.KubeProxyLagTimeout, stdout)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Update service to tolerate unready services again")
0000000000000000000000000000000000000000;;			_, err = framework.UpdateService(f.ClientSet, t.Namespace, t.ServiceName, func(s *v1.Service) {
0000000000000000000000000000000000000000;;				s.ObjectMeta.Annotations[endpoint.TolerateUnreadyEndpointsAnnotation] = "true"
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;			framework.ExpectNoError(err)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Check if terminating pod is available through service")
0000000000000000000000000000000000000000;;			cmd = fmt.Sprintf("wget -qO- http://%s:%d/", svcName, port)
0000000000000000000000000000000000000000;;			if pollErr := wait.PollImmediate(framework.Poll, framework.KubeProxyLagTimeout, func() (bool, error) {
0000000000000000000000000000000000000000;;				var err error
0000000000000000000000000000000000000000;;				stdout, err = framework.RunHostCmd(f.Namespace.Name, execPodName, cmd)
0000000000000000000000000000000000000000;;				if err != nil {
0000000000000000000000000000000000000000;;					framework.Logf("expected un-ready endpoint for Service %v, stdout: %v, err %v", t.Name, stdout, err)
0000000000000000000000000000000000000000;;					return false, nil
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				return true, nil
0000000000000000000000000000000000000000;;			}); pollErr != nil {
0000000000000000000000000000000000000000;;				framework.Failf("expected un-ready endpoint for Service %v within %v, stdout: %v", t.Name, framework.KubeProxyLagTimeout, stdout)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Remove pods immediately")
0000000000000000000000000000000000000000;;			label := labels.SelectorFromSet(labels.Set(t.Labels))
0000000000000000000000000000000000000000;;			options := metav1.ListOptions{LabelSelector: label.String()}
0000000000000000000000000000000000000000;;			podClient := t.Client.Core().Pods(f.Namespace.Name)
0000000000000000000000000000000000000000;;			pods, err := podClient.List(options)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				framework.Logf("warning: error retrieving pods: %s", err)
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				for _, pod := range pods.Items {
0000000000000000000000000000000000000000;;					var gracePeriodSeconds int64 = 0
0000000000000000000000000000000000000000;;					err := podClient.Delete(pod.Name, &metav1.DeleteOptions{GracePeriodSeconds: &gracePeriodSeconds})
0000000000000000000000000000000000000000;;					if err != nil {
0000000000000000000000000000000000000000;;						framework.Logf("warning: error force deleting pod '%s': %s", pod.Name, err)
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		It("should only allow access from service loadbalancer source ranges [Slow]", func() {
0000000000000000000000000000000000000000;;			// this feature currently supported only on GCE/GKE/AWS
0000000000000000000000000000000000000000;;			framework.SkipUnlessProviderIs("gce", "gke", "aws")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			loadBalancerLagTimeout := framework.LoadBalancerLagTimeoutDefault
0000000000000000000000000000000000000000;;			if framework.ProviderIs("aws") {
0000000000000000000000000000000000000000;;				loadBalancerLagTimeout = framework.LoadBalancerLagTimeoutAWS
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			loadBalancerCreateTimeout := framework.LoadBalancerCreateTimeoutDefault
0000000000000000000000000000000000000000;;			if nodes := framework.GetReadySchedulableNodesOrDie(cs); len(nodes.Items) > framework.LargeClusterMinNodesNumber {
0000000000000000000000000000000000000000;;				loadBalancerCreateTimeout = framework.LoadBalancerCreateTimeoutLarge
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			namespace := f.Namespace.Name
0000000000000000000000000000000000000000;;			serviceName := "lb-sourcerange"
0000000000000000000000000000000000000000;;			jig := framework.NewServiceTestJig(cs, serviceName)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Prepare allow source ips")
0000000000000000000000000000000000000000;;			// prepare the exec pods
0000000000000000000000000000000000000000;;			// acceptPod are allowed to access the loadbalancer
0000000000000000000000000000000000000000;;			acceptPodName := framework.CreateExecPodOrFail(cs, namespace, "execpod-accept", nil)
0000000000000000000000000000000000000000;;			dropPodName := framework.CreateExecPodOrFail(cs, namespace, "execpod-drop", nil)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			acceptPod, err := cs.Core().Pods(namespace).Get(acceptPodName, metav1.GetOptions{})
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;			dropPod, err := cs.Core().Pods(namespace).Get(dropPodName, metav1.GetOptions{})
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("creating a pod to be part of the service " + serviceName)
0000000000000000000000000000000000000000;;			// This container is an nginx container listening on port 80
0000000000000000000000000000000000000000;;			// See kubernetes/contrib/ingress/echoheaders/nginx.conf for content of response
0000000000000000000000000000000000000000;;			jig.RunOrFail(namespace, nil)
0000000000000000000000000000000000000000;;			// Create loadbalancer service with source range from node[0] and podAccept
0000000000000000000000000000000000000000;;			svc := jig.CreateTCPServiceOrFail(namespace, func(svc *v1.Service) {
0000000000000000000000000000000000000000;;				svc.Spec.Type = v1.ServiceTypeLoadBalancer
0000000000000000000000000000000000000000;;				svc.Spec.LoadBalancerSourceRanges = []string{acceptPod.Status.PodIP + "/32"}
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Clean up loadbalancer service
0000000000000000000000000000000000000000;;			defer func() {
0000000000000000000000000000000000000000;;				jig.UpdateServiceOrFail(svc.Namespace, svc.Name, func(svc *v1.Service) {
0000000000000000000000000000000000000000;;					svc.Spec.Type = v1.ServiceTypeNodePort
0000000000000000000000000000000000000000;;					svc.Spec.LoadBalancerSourceRanges = nil
0000000000000000000000000000000000000000;;				})
0000000000000000000000000000000000000000;;				Expect(cs.Core().Services(svc.Namespace).Delete(svc.Name, nil)).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;			}()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			svc = jig.WaitForLoadBalancerOrFail(namespace, serviceName, loadBalancerCreateTimeout)
0000000000000000000000000000000000000000;;			jig.SanityCheckService(svc, v1.ServiceTypeLoadBalancer)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// timeout when we haven't just created the load balancer
0000000000000000000000000000000000000000;;			normalReachabilityTimeout := 2 * time.Minute
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("check reachability from different sources")
0000000000000000000000000000000000000000;;			svcIP := framework.GetIngressPoint(&svc.Status.LoadBalancer.Ingress[0])
0000000000000000000000000000000000000000;;			// Wait longer as this is our first request after creation.  We can't check using a separate method,
0000000000000000000000000000000000000000;;			// because the LB should only be reachable from the "accept" pod
0000000000000000000000000000000000000000;;			framework.CheckReachabilityFromPod(true, loadBalancerLagTimeout, namespace, acceptPodName, svcIP)
0000000000000000000000000000000000000000;;			framework.CheckReachabilityFromPod(false, normalReachabilityTimeout, namespace, dropPodName, svcIP)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Update service LoadBalancerSourceRange and check reachability")
0000000000000000000000000000000000000000;;			jig.UpdateServiceOrFail(svc.Namespace, svc.Name, func(svc *v1.Service) {
0000000000000000000000000000000000000000;;				// only allow access from dropPod
0000000000000000000000000000000000000000;;				svc.Spec.LoadBalancerSourceRanges = []string{dropPod.Status.PodIP + "/32"}
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;			framework.CheckReachabilityFromPod(false, normalReachabilityTimeout, namespace, acceptPodName, svcIP)
0000000000000000000000000000000000000000;;			framework.CheckReachabilityFromPod(true, normalReachabilityTimeout, namespace, dropPodName, svcIP)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Delete LoadBalancerSourceRange field and check reachability")
0000000000000000000000000000000000000000;;			jig.UpdateServiceOrFail(svc.Namespace, svc.Name, func(svc *v1.Service) {
0000000000000000000000000000000000000000;;				svc.Spec.LoadBalancerSourceRanges = nil
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;			framework.CheckReachabilityFromPod(true, normalReachabilityTimeout, namespace, acceptPodName, svcIP)
0000000000000000000000000000000000000000;;			framework.CheckReachabilityFromPod(true, normalReachabilityTimeout, namespace, dropPodName, svcIP)
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		It("should be able to create an internal type load balancer on Azure [Slow]", func() {
0000000000000000000000000000000000000000;;			framework.SkipUnlessProviderIs("azure")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			createTimeout := framework.LoadBalancerCreateTimeoutDefault
0000000000000000000000000000000000000000;;			pollInterval := framework.Poll * 10
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			serviceAnnotationLoadBalancerInternal := "service.beta.kubernetes.io/azure-load-balancer-internal"
0000000000000000000000000000000000000000;;			namespace := f.Namespace.Name
0000000000000000000000000000000000000000;;			serviceName := "lb-internal"
0000000000000000000000000000000000000000;;			jig := framework.NewServiceTestJig(cs, serviceName)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			isInternalEndpoint := func(lbIngress *v1.LoadBalancerIngress) bool {
0000000000000000000000000000000000000000;;				ingressEndpoint := framework.GetIngressPoint(lbIngress)
0000000000000000000000000000000000000000;;				// Needs update for providers using hostname as endpoint.
0000000000000000000000000000000000000000;;				return strings.HasPrefix(ingressEndpoint, "10.")
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("creating a service with type LoadBalancer and LoadBalancerInternal annotation set to true")
0000000000000000000000000000000000000000;;			svc := jig.CreateTCPServiceOrFail(namespace, func(svc *v1.Service) {
0000000000000000000000000000000000000000;;				svc.Spec.Type = v1.ServiceTypeLoadBalancer
0000000000000000000000000000000000000000;;				svc.ObjectMeta.Annotations = map[string]string{
0000000000000000000000000000000000000000;;					serviceAnnotationLoadBalancerInternal: "true",
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;			svc = jig.WaitForLoadBalancerOrFail(namespace, serviceName, createTimeout)
0000000000000000000000000000000000000000;;			jig.SanityCheckService(svc, v1.ServiceTypeLoadBalancer)
0000000000000000000000000000000000000000;;			lbIngress := &svc.Status.LoadBalancer.Ingress[0]
0000000000000000000000000000000000000000;;			// should have an internal IP.
0000000000000000000000000000000000000000;;			Expect(isInternalEndpoint(lbIngress)).To(BeTrue())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("switiching to external type LoadBalancer")
0000000000000000000000000000000000000000;;			svc = jig.UpdateServiceOrFail(namespace, serviceName, func(svc *v1.Service) {
0000000000000000000000000000000000000000;;				svc.ObjectMeta.Annotations[serviceAnnotationLoadBalancerInternal] = "false"
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;			framework.Logf("Waiting up to %v for service %q to have an external LoadBalancer", createTimeout, serviceName)
0000000000000000000000000000000000000000;;			if pollErr := wait.PollImmediate(pollInterval, createTimeout, func() (bool, error) {
0000000000000000000000000000000000000000;;				svc, err := jig.Client.Core().Services(namespace).Get(serviceName, metav1.GetOptions{})
0000000000000000000000000000000000000000;;				if err != nil {
0000000000000000000000000000000000000000;;					return false, err
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				lbIngress = &svc.Status.LoadBalancer.Ingress[0]
0000000000000000000000000000000000000000;;				return !isInternalEndpoint(lbIngress), nil
0000000000000000000000000000000000000000;;			}); pollErr != nil {
0000000000000000000000000000000000000000;;				framework.Failf("Loadbalancer IP not changed to external.")
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			// should have an external IP.
0000000000000000000000000000000000000000;;			jig.SanityCheckService(svc, v1.ServiceTypeLoadBalancer)
0000000000000000000000000000000000000000;;			Expect(isInternalEndpoint(lbIngress)).To(BeFalse())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("switiching back to interal type LoadBalancer, with static IP specified.")
0000000000000000000000000000000000000000;;			internalStaticIP := "10.240.11.11"
0000000000000000000000000000000000000000;;			svc = jig.UpdateServiceOrFail(namespace, serviceName, func(svc *v1.Service) {
0000000000000000000000000000000000000000;;				svc.Spec.LoadBalancerIP = internalStaticIP
0000000000000000000000000000000000000000;;				svc.ObjectMeta.Annotations[serviceAnnotationLoadBalancerInternal] = "true"
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;			framework.Logf("Waiting up to %v for service %q to have an internal LoadBalancer", createTimeout, serviceName)
0000000000000000000000000000000000000000;;			if pollErr := wait.PollImmediate(pollInterval, createTimeout, func() (bool, error) {
0000000000000000000000000000000000000000;;				svc, err := jig.Client.Core().Services(namespace).Get(serviceName, metav1.GetOptions{})
0000000000000000000000000000000000000000;;				if err != nil {
0000000000000000000000000000000000000000;;					return false, err
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				lbIngress = &svc.Status.LoadBalancer.Ingress[0]
0000000000000000000000000000000000000000;;				return isInternalEndpoint(lbIngress), nil
0000000000000000000000000000000000000000;;			}); pollErr != nil {
0000000000000000000000000000000000000000;;				framework.Failf("Loadbalancer IP not changed to internal.")
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			// should have the given static internal IP.
0000000000000000000000000000000000000000;;			jig.SanityCheckService(svc, v1.ServiceTypeLoadBalancer)
0000000000000000000000000000000000000000;;			Expect(framework.GetIngressPoint(lbIngress)).To(Equal(internalStaticIP))
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	var _ = framework.KubeDescribe("ESIPP [Slow]", func() {
0000000000000000000000000000000000000000;;		f := framework.NewDefaultFramework("esipp")
0000000000000000000000000000000000000000;;		loadBalancerCreateTimeout := framework.LoadBalancerCreateTimeoutDefault
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		var cs clientset.Interface
0000000000000000000000000000000000000000;;		serviceLBNames := []string{}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		BeforeEach(func() {
0000000000000000000000000000000000000000;;			// requires cloud load-balancer support - this feature currently supported only on GCE/GKE
0000000000000000000000000000000000000000;;			framework.SkipUnlessProviderIs("gce", "gke")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			cs = f.ClientSet
0000000000000000000000000000000000000000;;			if nodes := framework.GetReadySchedulableNodesOrDie(cs); len(nodes.Items) > framework.LargeClusterMinNodesNumber {
0000000000000000000000000000000000000000;;				loadBalancerCreateTimeout = framework.LoadBalancerCreateTimeoutLarge
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		AfterEach(func() {
0000000000000000000000000000000000000000;;			if CurrentGinkgoTestDescription().Failed {
0000000000000000000000000000000000000000;;				framework.DescribeSvc(f.Namespace.Name)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			for _, lb := range serviceLBNames {
0000000000000000000000000000000000000000;;				framework.Logf("cleaning gce resource for %s", lb)
0000000000000000000000000000000000000000;;				framework.CleanupServiceGCEResources(cs, lb, framework.TestContext.CloudConfig.Zone)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			//reset serviceLBNames
0000000000000000000000000000000000000000;;			serviceLBNames = []string{}
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		It("should work for type=LoadBalancer", func() {
0000000000000000000000000000000000000000;;			namespace := f.Namespace.Name
0000000000000000000000000000000000000000;;			serviceName := "external-local"
0000000000000000000000000000000000000000;;			jig := framework.NewServiceTestJig(cs, serviceName)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			svc := jig.CreateOnlyLocalLoadBalancerService(namespace, serviceName, loadBalancerCreateTimeout, true, nil)
0000000000000000000000000000000000000000;;			serviceLBNames = append(serviceLBNames, cloudprovider.GetLoadBalancerName(svc))
0000000000000000000000000000000000000000;;			healthCheckNodePort := int(service.GetServiceHealthCheckNodePort(svc))
0000000000000000000000000000000000000000;;			if healthCheckNodePort == 0 {
0000000000000000000000000000000000000000;;				framework.Failf("Service HealthCheck NodePort was not allocated")
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			defer func() {
0000000000000000000000000000000000000000;;				jig.ChangeServiceType(svc.Namespace, svc.Name, v1.ServiceTypeClusterIP, loadBalancerCreateTimeout)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				// Make sure we didn't leak the health check node port.
0000000000000000000000000000000000000000;;				threshold := 2
0000000000000000000000000000000000000000;;				for _, ips := range jig.GetEndpointNodes(svc) {
0000000000000000000000000000000000000000;;					Expect(jig.TestHTTPHealthCheckNodePort(ips[0], healthCheckNodePort, "/healthz", framework.KubeProxyEndpointLagTimeout, false, threshold)).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				Expect(cs.Core().Services(svc.Namespace).Delete(svc.Name, nil)).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;			}()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			svcTCPPort := int(svc.Spec.Ports[0].Port)
0000000000000000000000000000000000000000;;			ingressIP := framework.GetIngressPoint(&svc.Status.LoadBalancer.Ingress[0])
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("reading clientIP using the TCP service's service port via its external VIP")
0000000000000000000000000000000000000000;;			content := jig.GetHTTPContent(ingressIP, svcTCPPort, framework.KubeProxyLagTimeout, "/clientip")
0000000000000000000000000000000000000000;;			clientIP := content.String()
0000000000000000000000000000000000000000;;			framework.Logf("ClientIP detected by target pod using VIP:SvcPort is %s", clientIP)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("checking if Source IP is preserved")
0000000000000000000000000000000000000000;;			if strings.HasPrefix(clientIP, "10.") {
0000000000000000000000000000000000000000;;				framework.Failf("Source IP was NOT preserved")
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		It("should work for type=NodePort", func() {
0000000000000000000000000000000000000000;;			namespace := f.Namespace.Name
0000000000000000000000000000000000000000;;			serviceName := "external-local"
0000000000000000000000000000000000000000;;			jig := framework.NewServiceTestJig(cs, serviceName)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			svc := jig.CreateOnlyLocalNodePortService(namespace, serviceName, true)
0000000000000000000000000000000000000000;;			defer func() {
0000000000000000000000000000000000000000;;				Expect(cs.Core().Services(svc.Namespace).Delete(svc.Name, nil)).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;			}()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			tcpNodePort := int(svc.Spec.Ports[0].NodePort)
0000000000000000000000000000000000000000;;			endpointsNodeMap := jig.GetEndpointNodes(svc)
0000000000000000000000000000000000000000;;			path := "/clientip"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			for nodeName, nodeIPs := range endpointsNodeMap {
0000000000000000000000000000000000000000;;				nodeIP := nodeIPs[0]
0000000000000000000000000000000000000000;;				By(fmt.Sprintf("reading clientIP using the TCP service's NodePort, on node %v: %v%v%v", nodeName, nodeIP, tcpNodePort, path))
0000000000000000000000000000000000000000;;				content := jig.GetHTTPContent(nodeIP, tcpNodePort, framework.KubeProxyLagTimeout, path)
0000000000000000000000000000000000000000;;				clientIP := content.String()
0000000000000000000000000000000000000000;;				framework.Logf("ClientIP detected by target pod using NodePort is %s", clientIP)
0000000000000000000000000000000000000000;;				if strings.HasPrefix(clientIP, "10.") {
0000000000000000000000000000000000000000;;					framework.Failf("Source IP was NOT preserved")
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		It("should only target nodes with endpoints", func() {
0000000000000000000000000000000000000000;;			namespace := f.Namespace.Name
0000000000000000000000000000000000000000;;			serviceName := "external-local"
0000000000000000000000000000000000000000;;			jig := framework.NewServiceTestJig(cs, serviceName)
0000000000000000000000000000000000000000;;			nodes := jig.GetNodes(framework.MaxNodesForEndpointsTests)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			svc := jig.CreateOnlyLocalLoadBalancerService(namespace, serviceName, loadBalancerCreateTimeout, false,
0000000000000000000000000000000000000000;;				func(svc *v1.Service) {
0000000000000000000000000000000000000000;;					// Change service port to avoid collision with opened hostPorts
0000000000000000000000000000000000000000;;					// in other tests that run in parallel.
0000000000000000000000000000000000000000;;					if len(svc.Spec.Ports) != 0 {
0000000000000000000000000000000000000000;;						svc.Spec.Ports[0].TargetPort = intstr.FromInt(int(svc.Spec.Ports[0].Port))
0000000000000000000000000000000000000000;;						svc.Spec.Ports[0].Port = 8081
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				})
0000000000000000000000000000000000000000;;			serviceLBNames = append(serviceLBNames, cloudprovider.GetLoadBalancerName(svc))
0000000000000000000000000000000000000000;;			defer func() {
0000000000000000000000000000000000000000;;				jig.ChangeServiceType(svc.Namespace, svc.Name, v1.ServiceTypeClusterIP, loadBalancerCreateTimeout)
0000000000000000000000000000000000000000;;				Expect(cs.Core().Services(svc.Namespace).Delete(svc.Name, nil)).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;			}()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			healthCheckNodePort := int(service.GetServiceHealthCheckNodePort(svc))
0000000000000000000000000000000000000000;;			if healthCheckNodePort == 0 {
0000000000000000000000000000000000000000;;				framework.Failf("Service HealthCheck NodePort was not allocated")
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			ips := framework.CollectAddresses(nodes, v1.NodeExternalIP)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			ingressIP := framework.GetIngressPoint(&svc.Status.LoadBalancer.Ingress[0])
0000000000000000000000000000000000000000;;			svcTCPPort := int(svc.Spec.Ports[0].Port)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			threshold := 2
0000000000000000000000000000000000000000;;			path := "/healthz"
0000000000000000000000000000000000000000;;			for i := 0; i < len(nodes.Items); i++ {
0000000000000000000000000000000000000000;;				endpointNodeName := nodes.Items[i].Name
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				By("creating a pod to be part of the service " + serviceName + " on node " + endpointNodeName)
0000000000000000000000000000000000000000;;				jig.RunOrFail(namespace, func(rc *v1.ReplicationController) {
0000000000000000000000000000000000000000;;					rc.Name = serviceName
0000000000000000000000000000000000000000;;					if endpointNodeName != "" {
0000000000000000000000000000000000000000;;						rc.Spec.Template.Spec.NodeName = endpointNodeName
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;				})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				By(fmt.Sprintf("waiting for service endpoint on node %v", endpointNodeName))
0000000000000000000000000000000000000000;;				jig.WaitForEndpointOnNode(namespace, serviceName, endpointNodeName)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				// HealthCheck should pass only on the node where num(endpoints) > 0
0000000000000000000000000000000000000000;;				// All other nodes should fail the healthcheck on the service healthCheckNodePort
0000000000000000000000000000000000000000;;				for n, publicIP := range ips {
0000000000000000000000000000000000000000;;					// Make sure the loadbalancer picked up the health check change.
0000000000000000000000000000000000000000;;					// Confirm traffic can reach backend through LB before checking healthcheck nodeport.
0000000000000000000000000000000000000000;;					jig.TestReachableHTTP(ingressIP, svcTCPPort, framework.KubeProxyLagTimeout)
0000000000000000000000000000000000000000;;					expectedSuccess := nodes.Items[n].Name == endpointNodeName
0000000000000000000000000000000000000000;;					framework.Logf("Health checking %s, http://%s:%d%s, expectedSuccess %v", nodes.Items[n].Name, publicIP, healthCheckNodePort, path, expectedSuccess)
0000000000000000000000000000000000000000;;					Expect(jig.TestHTTPHealthCheckNodePort(publicIP, healthCheckNodePort, path, framework.KubeProxyEndpointLagTimeout, expectedSuccess, threshold)).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				framework.ExpectNoError(framework.DeleteRCAndPods(f.ClientSet, f.InternalClientset, namespace, serviceName))
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		It("should work from pods", func() {
0000000000000000000000000000000000000000;;			namespace := f.Namespace.Name
0000000000000000000000000000000000000000;;			serviceName := "external-local"
0000000000000000000000000000000000000000;;			jig := framework.NewServiceTestJig(cs, serviceName)
0000000000000000000000000000000000000000;;			nodes := jig.GetNodes(framework.MaxNodesForEndpointsTests)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			svc := jig.CreateOnlyLocalLoadBalancerService(namespace, serviceName, loadBalancerCreateTimeout, true, nil)
0000000000000000000000000000000000000000;;			serviceLBNames = append(serviceLBNames, cloudprovider.GetLoadBalancerName(svc))
0000000000000000000000000000000000000000;;			defer func() {
0000000000000000000000000000000000000000;;				jig.ChangeServiceType(svc.Namespace, svc.Name, v1.ServiceTypeClusterIP, loadBalancerCreateTimeout)
0000000000000000000000000000000000000000;;				Expect(cs.Core().Services(svc.Namespace).Delete(svc.Name, nil)).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;			}()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			ingressIP := framework.GetIngressPoint(&svc.Status.LoadBalancer.Ingress[0])
0000000000000000000000000000000000000000;;			path := fmt.Sprintf("%s:%d/clientip", ingressIP, int(svc.Spec.Ports[0].Port))
0000000000000000000000000000000000000000;;			nodeName := nodes.Items[0].Name
0000000000000000000000000000000000000000;;			podName := "execpod-sourceip"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By(fmt.Sprintf("Creating %v on node %v", podName, nodeName))
0000000000000000000000000000000000000000;;			execPodName := framework.CreateExecPodOrFail(f.ClientSet, namespace, podName, func(pod *v1.Pod) {
0000000000000000000000000000000000000000;;				pod.Spec.NodeName = nodeName
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;			defer func() {
0000000000000000000000000000000000000000;;				err := cs.Core().Pods(namespace).Delete(execPodName, nil)
0000000000000000000000000000000000000000;;				Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;			}()
0000000000000000000000000000000000000000;;			execPod, err := f.ClientSet.Core().Pods(namespace).Get(execPodName, metav1.GetOptions{})
0000000000000000000000000000000000000000;;			framework.ExpectNoError(err)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			framework.Logf("Waiting up to %v wget %v", framework.KubeProxyLagTimeout, path)
0000000000000000000000000000000000000000;;			cmd := fmt.Sprintf(`wget -T 30 -qO- %v`, path)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			var srcIP string
0000000000000000000000000000000000000000;;			By(fmt.Sprintf("Hitting external lb %v from pod %v on node %v", ingressIP, podName, nodeName))
0000000000000000000000000000000000000000;;			if pollErr := wait.PollImmediate(framework.Poll, framework.LoadBalancerCreateTimeoutDefault, func() (bool, error) {
0000000000000000000000000000000000000000;;				stdout, err := framework.RunHostCmd(execPod.Namespace, execPod.Name, cmd)
0000000000000000000000000000000000000000;;				if err != nil {
0000000000000000000000000000000000000000;;					framework.Logf("got err: %v, retry until timeout", err)
0000000000000000000000000000000000000000;;					return false, nil
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				srcIP = strings.TrimSpace(strings.Split(stdout, ":")[0])
0000000000000000000000000000000000000000;;				return srcIP == execPod.Status.PodIP, nil
0000000000000000000000000000000000000000;;			}); pollErr != nil {
0000000000000000000000000000000000000000;;				framework.Failf("Source IP not preserved from %v, expected '%v' got '%v'", podName, execPod.Status.PodIP, srcIP)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		It("should handle updates to ExternalTrafficPolicy field", func() {
0000000000000000000000000000000000000000;;			namespace := f.Namespace.Name
0000000000000000000000000000000000000000;;			serviceName := "external-local"
0000000000000000000000000000000000000000;;			jig := framework.NewServiceTestJig(cs, serviceName)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			nodes := jig.GetNodes(framework.MaxNodesForEndpointsTests)
0000000000000000000000000000000000000000;;			if len(nodes.Items) < 2 {
0000000000000000000000000000000000000000;;				framework.Failf("Need at least 2 nodes to verify source ip from a node without endpoint")
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			svc := jig.CreateOnlyLocalLoadBalancerService(namespace, serviceName, loadBalancerCreateTimeout, true, nil)
0000000000000000000000000000000000000000;;			serviceLBNames = append(serviceLBNames, cloudprovider.GetLoadBalancerName(svc))
0000000000000000000000000000000000000000;;			defer func() {
0000000000000000000000000000000000000000;;				jig.ChangeServiceType(svc.Namespace, svc.Name, v1.ServiceTypeClusterIP, loadBalancerCreateTimeout)
0000000000000000000000000000000000000000;;				Expect(cs.Core().Services(svc.Namespace).Delete(svc.Name, nil)).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;			}()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// save the health check node port because it disappears when ESIPP is turned off.
0000000000000000000000000000000000000000;;			healthCheckNodePort := int(service.GetServiceHealthCheckNodePort(svc))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("turning ESIPP off")
0000000000000000000000000000000000000000;;			svc = jig.UpdateServiceOrFail(svc.Namespace, svc.Name, func(svc *v1.Service) {
0000000000000000000000000000000000000000;;				svc.Spec.ExternalTrafficPolicy = v1.ServiceExternalTrafficPolicyTypeCluster
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;			if service.GetServiceHealthCheckNodePort(svc) > 0 {
0000000000000000000000000000000000000000;;				framework.Failf("Service HealthCheck NodePort still present")
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			endpointNodeMap := jig.GetEndpointNodes(svc)
0000000000000000000000000000000000000000;;			noEndpointNodeMap := map[string][]string{}
0000000000000000000000000000000000000000;;			for _, n := range nodes.Items {
0000000000000000000000000000000000000000;;				if _, ok := endpointNodeMap[n.Name]; ok {
0000000000000000000000000000000000000000;;					continue
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				noEndpointNodeMap[n.Name] = framework.GetNodeAddresses(&n, v1.NodeExternalIP)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			svcTCPPort := int(svc.Spec.Ports[0].Port)
0000000000000000000000000000000000000000;;			svcNodePort := int(svc.Spec.Ports[0].NodePort)
0000000000000000000000000000000000000000;;			ingressIP := framework.GetIngressPoint(&svc.Status.LoadBalancer.Ingress[0])
0000000000000000000000000000000000000000;;			path := "/clientip"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By(fmt.Sprintf("endpoints present on nodes %v, absent on nodes %v", endpointNodeMap, noEndpointNodeMap))
0000000000000000000000000000000000000000;;			for nodeName, nodeIPs := range noEndpointNodeMap {
0000000000000000000000000000000000000000;;				By(fmt.Sprintf("Checking %v (%v:%v%v) proxies to endpoints on another node", nodeName, nodeIPs[0], svcNodePort, path))
0000000000000000000000000000000000000000;;				jig.GetHTTPContent(nodeIPs[0], svcNodePort, framework.KubeProxyLagTimeout, path)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			for nodeName, nodeIPs := range endpointNodeMap {
0000000000000000000000000000000000000000;;				By(fmt.Sprintf("checking kube-proxy health check fails on node with endpoint (%s), public IP %s", nodeName, nodeIPs[0]))
0000000000000000000000000000000000000000;;				var body bytes.Buffer
0000000000000000000000000000000000000000;;				var result bool
0000000000000000000000000000000000000000;;				var err error
0000000000000000000000000000000000000000;;				if pollErr := wait.PollImmediate(framework.Poll, framework.ServiceTestTimeout, func() (bool, error) {
0000000000000000000000000000000000000000;;					result, err = framework.TestReachableHTTPWithContent(nodeIPs[0], healthCheckNodePort, "/healthz", "", &body)
0000000000000000000000000000000000000000;;					return !result, nil
0000000000000000000000000000000000000000;;				}); pollErr != nil {
0000000000000000000000000000000000000000;;					framework.Failf("Kube-proxy still exposing health check on node %v:%v, after ESIPP was turned off. Last err %v, last body %v",
0000000000000000000000000000000000000000;;						nodeName, healthCheckNodePort, err, body.String())
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Poll till kube-proxy re-adds the MASQUERADE rule on the node.
0000000000000000000000000000000000000000;;			By(fmt.Sprintf("checking source ip is NOT preserved through loadbalancer %v", ingressIP))
0000000000000000000000000000000000000000;;			var clientIP string
0000000000000000000000000000000000000000;;			pollErr := wait.PollImmediate(framework.Poll, framework.KubeProxyLagTimeout, func() (bool, error) {
0000000000000000000000000000000000000000;;				content := jig.GetHTTPContent(ingressIP, svcTCPPort, framework.KubeProxyLagTimeout, "/clientip")
0000000000000000000000000000000000000000;;				clientIP = content.String()
0000000000000000000000000000000000000000;;				if strings.HasPrefix(clientIP, "10.") {
0000000000000000000000000000000000000000;;					return true, nil
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				return false, nil
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;			if pollErr != nil {
0000000000000000000000000000000000000000;;				framework.Failf("Source IP WAS preserved even after ESIPP turned off. Got %v, expected a ten-dot cluster ip.", clientIP)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// TODO: We need to attempt to create another service with the previously
0000000000000000000000000000000000000000;;			// allocated healthcheck nodePort. If the health check nodePort has been
0000000000000000000000000000000000000000;;			// freed, the new service creation will succeed, upon which we cleanup.
0000000000000000000000000000000000000000;;			// If the health check nodePort has NOT been freed, the new service
0000000000000000000000000000000000000000;;			// creation will fail.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("setting ExternalTraffic field back to OnlyLocal")
0000000000000000000000000000000000000000;;			svc = jig.UpdateServiceOrFail(svc.Namespace, svc.Name, func(svc *v1.Service) {
0000000000000000000000000000000000000000;;				svc.Spec.ExternalTrafficPolicy = v1.ServiceExternalTrafficPolicyTypeLocal
0000000000000000000000000000000000000000;;				// Request the same healthCheckNodePort as before, to test the user-requested allocation path
0000000000000000000000000000000000000000;;				svc.Spec.HealthCheckNodePort = int32(healthCheckNodePort)
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;			pollErr = wait.PollImmediate(framework.Poll, framework.KubeProxyLagTimeout, func() (bool, error) {
0000000000000000000000000000000000000000;;				content := jig.GetHTTPContent(ingressIP, svcTCPPort, framework.KubeProxyLagTimeout, path)
0000000000000000000000000000000000000000;;				clientIP = content.String()
0000000000000000000000000000000000000000;;				By(fmt.Sprintf("Endpoint %v:%v%v returned client ip %v", ingressIP, svcTCPPort, path, clientIP))
0000000000000000000000000000000000000000;;				if !strings.HasPrefix(clientIP, "10.") {
0000000000000000000000000000000000000000;;					return true, nil
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				return false, nil
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;			if pollErr != nil {
0000000000000000000000000000000000000000;;				framework.Failf("Source IP (%v) is not the client IP even after ESIPP turned on, expected a public IP.", clientIP)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func execSourceipTest(f *framework.Framework, c clientset.Interface, ns, nodeName, serviceIP string, servicePort int) (string, string) {
0000000000000000000000000000000000000000;;		framework.Logf("Creating an exec pod on node %v", nodeName)
0000000000000000000000000000000000000000;;		execPodName := framework.CreateExecPodOrFail(f.ClientSet, ns, fmt.Sprintf("execpod-sourceip-%s", nodeName), func(pod *v1.Pod) {
0000000000000000000000000000000000000000;;			pod.Spec.NodeName = nodeName
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;		defer func() {
0000000000000000000000000000000000000000;;			framework.Logf("Cleaning up the exec pod")
0000000000000000000000000000000000000000;;			err := c.Core().Pods(ns).Delete(execPodName, nil)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;		}()
0000000000000000000000000000000000000000;;		execPod, err := f.ClientSet.Core().Pods(ns).Get(execPodName, metav1.GetOptions{})
0000000000000000000000000000000000000000;;		framework.ExpectNoError(err)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		var stdout string
0000000000000000000000000000000000000000;;		timeout := 2 * time.Minute
0000000000000000000000000000000000000000;;		framework.Logf("Waiting up to %v wget %s:%d", timeout, serviceIP, servicePort)
0000000000000000000000000000000000000000;;		cmd := fmt.Sprintf(`wget -T 30 -qO- %s:%d | grep client_address`, serviceIP, servicePort)
0000000000000000000000000000000000000000;;		for start := time.Now(); time.Since(start) < timeout; time.Sleep(2) {
0000000000000000000000000000000000000000;;			stdout, err = framework.RunHostCmd(execPod.Namespace, execPod.Name, cmd)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				framework.Logf("got err: %v, retry until timeout", err)
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			// Need to check output because wget -q might omit the error.
0000000000000000000000000000000000000000;;			if strings.TrimSpace(stdout) == "" {
0000000000000000000000000000000000000000;;				framework.Logf("got empty stdout, retry until timeout")
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			break
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		framework.ExpectNoError(err)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// The stdout return from RunHostCmd seems to come with "\n", so TrimSpace is needed.
0000000000000000000000000000000000000000;;		// Desired stdout in this format: client_address=x.x.x.x
0000000000000000000000000000000000000000;;		outputs := strings.Split(strings.TrimSpace(stdout), "=")
0000000000000000000000000000000000000000;;		if len(outputs) != 2 {
0000000000000000000000000000000000000000;;			// Fail the test if output format is unexpected.
0000000000000000000000000000000000000000;;			framework.Failf("exec pod returned unexpected stdout format: [%v]\n", stdout)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return execPod.Status.PodIP, outputs[1]
0000000000000000000000000000000000000000;;	}
