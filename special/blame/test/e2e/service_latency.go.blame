0000000000000000000000000000000000000000;;	/*
0000000000000000000000000000000000000000;;	Copyright 2015 The Kubernetes Authors.
ea09a7f8b76ae8d2845f6aed2ad79abecdbc403b;;	
0000000000000000000000000000000000000000;;	Licensed under the Apache License, Version 2.0 (the "License");
0000000000000000000000000000000000000000;;	you may not use this file except in compliance with the License.
0000000000000000000000000000000000000000;;	You may obtain a copy of the License at
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	    http://www.apache.org/licenses/LICENSE-2.0
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	Unless required by applicable law or agreed to in writing, software
0000000000000000000000000000000000000000;;	distributed under the License is distributed on an "AS IS" BASIS,
0000000000000000000000000000000000000000;;	WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
0000000000000000000000000000000000000000;;	See the License for the specific language governing permissions and
0000000000000000000000000000000000000000;;	limitations under the License.
0000000000000000000000000000000000000000;;	*/
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	package e2e
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	import (
0000000000000000000000000000000000000000;;		"fmt"
0000000000000000000000000000000000000000;;		"sort"
0000000000000000000000000000000000000000;;		"strings"
0000000000000000000000000000000000000000;;		"time"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		"k8s.io/api/core/v1"
0000000000000000000000000000000000000000;;		metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/runtime"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/util/sets"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/watch"
0000000000000000000000000000000000000000;;		restclient "k8s.io/client-go/rest"
0000000000000000000000000000000000000000;;		"k8s.io/client-go/tools/cache"
0000000000000000000000000000000000000000;;		"k8s.io/client-go/util/flowcontrol"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/test/e2e/framework"
0000000000000000000000000000000000000000;;		testutils "k8s.io/kubernetes/test/utils"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		. "github.com/onsi/ginkgo"
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type durations []time.Duration
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (d durations) Len() int           { return len(d) }
0000000000000000000000000000000000000000;;	func (d durations) Less(i, j int) bool { return d[i] < d[j] }
0000000000000000000000000000000000000000;;	func (d durations) Swap(i, j int)      { d[i], d[j] = d[j], d[i] }
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	var _ = framework.KubeDescribe("Service endpoints latency", func() {
0000000000000000000000000000000000000000;;		f := framework.NewDefaultFramework("svc-latency")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		It("should not be very high [Conformance]", func() {
0000000000000000000000000000000000000000;;			const (
0000000000000000000000000000000000000000;;				// These are very generous criteria. Ideally we will
0000000000000000000000000000000000000000;;				// get this much lower in the future. See issue
0000000000000000000000000000000000000000;;				// #10436.
0000000000000000000000000000000000000000;;				limitMedian = time.Second * 20
0000000000000000000000000000000000000000;;				limitTail   = time.Second * 50
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				// Numbers chosen to make the test complete in a short amount
0000000000000000000000000000000000000000;;				// of time. This sample size is not actually large enough to
0000000000000000000000000000000000000000;;				// reliably measure tails (it may give false positives, but not
0000000000000000000000000000000000000000;;				// false negatives), but it should catch low hanging fruit.
0000000000000000000000000000000000000000;;				//
0000000000000000000000000000000000000000;;				// Note that these are fixed and do not depend on the
0000000000000000000000000000000000000000;;				// size of the cluster. Setting parallelTrials larger
0000000000000000000000000000000000000000;;				// distorts the measurements. Perhaps this wouldn't be
0000000000000000000000000000000000000000;;				// true on HA clusters.
0000000000000000000000000000000000000000;;				totalTrials    = 200
0000000000000000000000000000000000000000;;				parallelTrials = 15
0000000000000000000000000000000000000000;;				minSampleSize  = 100
0000000000000000000000000000000000000000;;			)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Turn off rate limiting--it interferes with our measurements.
0000000000000000000000000000000000000000;;			oldThrottle := f.ClientSet.Core().RESTClient().GetRateLimiter()
0000000000000000000000000000000000000000;;			f.ClientSet.Core().RESTClient().(*restclient.RESTClient).Throttle = flowcontrol.NewFakeAlwaysRateLimiter()
0000000000000000000000000000000000000000;;			defer func() { f.ClientSet.Core().RESTClient().(*restclient.RESTClient).Throttle = oldThrottle }()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			failing := sets.NewString()
0000000000000000000000000000000000000000;;			d, err := runServiceLatencies(f, parallelTrials, totalTrials)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				failing.Insert(fmt.Sprintf("Not all RC/pod/service trials succeeded: %v", err))
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			dSorted := durations(d)
0000000000000000000000000000000000000000;;			sort.Sort(dSorted)
0000000000000000000000000000000000000000;;			n := len(dSorted)
0000000000000000000000000000000000000000;;			if n < minSampleSize {
0000000000000000000000000000000000000000;;				failing.Insert(fmt.Sprintf("Did not get a good sample size: %v", dSorted))
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if n < 2 {
0000000000000000000000000000000000000000;;				failing.Insert("Less than two runs succeeded; aborting.")
0000000000000000000000000000000000000000;;				framework.Failf(strings.Join(failing.List(), "\n"))
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			percentile := func(p int) time.Duration {
0000000000000000000000000000000000000000;;				est := n * p / 100
0000000000000000000000000000000000000000;;				if est >= n {
0000000000000000000000000000000000000000;;					return dSorted[n-1]
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				return dSorted[est]
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			framework.Logf("Latencies: %v", dSorted)
0000000000000000000000000000000000000000;;			p50 := percentile(50)
0000000000000000000000000000000000000000;;			p90 := percentile(90)
0000000000000000000000000000000000000000;;			p99 := percentile(99)
0000000000000000000000000000000000000000;;			framework.Logf("50 %%ile: %v", p50)
0000000000000000000000000000000000000000;;			framework.Logf("90 %%ile: %v", p90)
0000000000000000000000000000000000000000;;			framework.Logf("99 %%ile: %v", p99)
0000000000000000000000000000000000000000;;			framework.Logf("Total sample count: %v", len(dSorted))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			if p50 > limitMedian {
0000000000000000000000000000000000000000;;				failing.Insert("Median latency should be less than " + limitMedian.String())
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if p99 > limitTail {
0000000000000000000000000000000000000000;;				failing.Insert("Tail (99 percentile) latency should be less than " + limitTail.String())
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if failing.Len() > 0 {
0000000000000000000000000000000000000000;;				errList := strings.Join(failing.List(), "\n")
0000000000000000000000000000000000000000;;				helpfulInfo := fmt.Sprintf("\n50, 90, 99 percentiles: %v %v %v", p50, p90, p99)
0000000000000000000000000000000000000000;;				framework.Failf(errList + helpfulInfo)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func runServiceLatencies(f *framework.Framework, inParallel, total int) (output []time.Duration, err error) {
0000000000000000000000000000000000000000;;		cfg := testutils.RCConfig{
0000000000000000000000000000000000000000;;			Client:         f.ClientSet,
0000000000000000000000000000000000000000;;			InternalClient: f.InternalClientset,
0000000000000000000000000000000000000000;;			Image:          framework.GetPauseImageName(f.ClientSet),
0000000000000000000000000000000000000000;;			Name:           "svc-latency-rc",
0000000000000000000000000000000000000000;;			Namespace:      f.Namespace.Name,
0000000000000000000000000000000000000000;;			Replicas:       1,
0000000000000000000000000000000000000000;;			PollInterval:   time.Second,
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if err := framework.RunRC(cfg); err != nil {
0000000000000000000000000000000000000000;;			return nil, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Run a single watcher, to reduce the number of API calls we have to
0000000000000000000000000000000000000000;;		// make; this is to minimize the timing error. It's how kube-proxy
0000000000000000000000000000000000000000;;		// consumes the endpoints data, so it seems like the right thing to
0000000000000000000000000000000000000000;;		// test.
0000000000000000000000000000000000000000;;		endpointQueries := newQuerier()
0000000000000000000000000000000000000000;;		startEndpointWatcher(f, endpointQueries)
0000000000000000000000000000000000000000;;		defer close(endpointQueries.stop)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// run one test and throw it away-- this is to make sure that the pod's
0000000000000000000000000000000000000000;;		// ready status has propagated.
0000000000000000000000000000000000000000;;		singleServiceLatency(f, cfg.Name, endpointQueries)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// These channels are never closed, and each attempt sends on exactly
0000000000000000000000000000000000000000;;		// one of these channels, so the sum of the things sent over them will
0000000000000000000000000000000000000000;;		// be exactly total.
0000000000000000000000000000000000000000;;		errs := make(chan error, total)
0000000000000000000000000000000000000000;;		durations := make(chan time.Duration, total)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		blocker := make(chan struct{}, inParallel)
0000000000000000000000000000000000000000;;		for i := 0; i < total; i++ {
0000000000000000000000000000000000000000;;			go func() {
0000000000000000000000000000000000000000;;				defer GinkgoRecover()
0000000000000000000000000000000000000000;;				blocker <- struct{}{}
0000000000000000000000000000000000000000;;				defer func() { <-blocker }()
0000000000000000000000000000000000000000;;				if d, err := singleServiceLatency(f, cfg.Name, endpointQueries); err != nil {
0000000000000000000000000000000000000000;;					errs <- err
0000000000000000000000000000000000000000;;				} else {
0000000000000000000000000000000000000000;;					durations <- d
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}()
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		errCount := 0
0000000000000000000000000000000000000000;;		for i := 0; i < total; i++ {
0000000000000000000000000000000000000000;;			select {
0000000000000000000000000000000000000000;;			case e := <-errs:
0000000000000000000000000000000000000000;;				framework.Logf("Got error: %v", e)
0000000000000000000000000000000000000000;;				errCount += 1
0000000000000000000000000000000000000000;;			case d := <-durations:
0000000000000000000000000000000000000000;;				output = append(output, d)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if errCount != 0 {
0000000000000000000000000000000000000000;;			return output, fmt.Errorf("got %v errors", errCount)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return output, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type endpointQuery struct {
0000000000000000000000000000000000000000;;		endpointsName string
0000000000000000000000000000000000000000;;		endpoints     *v1.Endpoints
0000000000000000000000000000000000000000;;		result        chan<- struct{}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type endpointQueries struct {
0000000000000000000000000000000000000000;;		requests map[string]*endpointQuery
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		stop        chan struct{}
0000000000000000000000000000000000000000;;		requestChan chan *endpointQuery
0000000000000000000000000000000000000000;;		seenChan    chan *v1.Endpoints
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func newQuerier() *endpointQueries {
0000000000000000000000000000000000000000;;		eq := &endpointQueries{
0000000000000000000000000000000000000000;;			requests: map[string]*endpointQuery{},
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			stop:        make(chan struct{}, 100),
0000000000000000000000000000000000000000;;			requestChan: make(chan *endpointQuery),
0000000000000000000000000000000000000000;;			seenChan:    make(chan *v1.Endpoints, 100),
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		go eq.join()
0000000000000000000000000000000000000000;;		return eq
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// join merges the incoming streams of requests and added endpoints. It has
0000000000000000000000000000000000000000;;	// nice properties like:
0000000000000000000000000000000000000000;;	//  * remembering an endpoint if it happens to arrive before it is requested.
0000000000000000000000000000000000000000;;	//  * closing all outstanding requests (returning nil) if it is stopped.
0000000000000000000000000000000000000000;;	func (eq *endpointQueries) join() {
0000000000000000000000000000000000000000;;		defer func() {
0000000000000000000000000000000000000000;;			// Terminate all pending requests, so that no goroutine will
0000000000000000000000000000000000000000;;			// block indefinitely.
0000000000000000000000000000000000000000;;			for _, req := range eq.requests {
0000000000000000000000000000000000000000;;				if req.result != nil {
0000000000000000000000000000000000000000;;					close(req.result)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		for {
0000000000000000000000000000000000000000;;			select {
0000000000000000000000000000000000000000;;			case <-eq.stop:
0000000000000000000000000000000000000000;;				return
0000000000000000000000000000000000000000;;			case req := <-eq.requestChan:
0000000000000000000000000000000000000000;;				if cur, ok := eq.requests[req.endpointsName]; ok && cur.endpoints != nil {
0000000000000000000000000000000000000000;;					// We've already gotten the result, so we can
0000000000000000000000000000000000000000;;					// immediately satisfy this request.
0000000000000000000000000000000000000000;;					delete(eq.requests, req.endpointsName)
0000000000000000000000000000000000000000;;					req.endpoints = cur.endpoints
0000000000000000000000000000000000000000;;					close(req.result)
0000000000000000000000000000000000000000;;				} else {
0000000000000000000000000000000000000000;;					// Save this request.
0000000000000000000000000000000000000000;;					eq.requests[req.endpointsName] = req
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			case got := <-eq.seenChan:
0000000000000000000000000000000000000000;;				if req, ok := eq.requests[got.Name]; ok {
0000000000000000000000000000000000000000;;					if req.result != nil {
0000000000000000000000000000000000000000;;						// Satisfy a request.
0000000000000000000000000000000000000000;;						delete(eq.requests, got.Name)
0000000000000000000000000000000000000000;;						req.endpoints = got
0000000000000000000000000000000000000000;;						close(req.result)
0000000000000000000000000000000000000000;;					} else {
0000000000000000000000000000000000000000;;						// We've already recorded a result, but
0000000000000000000000000000000000000000;;						// haven't gotten the request yet. Only
0000000000000000000000000000000000000000;;						// keep the first result.
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;				} else {
0000000000000000000000000000000000000000;;					// We haven't gotten the corresponding request
0000000000000000000000000000000000000000;;					// yet, save this result.
0000000000000000000000000000000000000000;;					eq.requests[got.Name] = &endpointQuery{
0000000000000000000000000000000000000000;;						endpoints: got,
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// request blocks until the requested endpoint is seen.
0000000000000000000000000000000000000000;;	func (eq *endpointQueries) request(endpointsName string) *v1.Endpoints {
0000000000000000000000000000000000000000;;		result := make(chan struct{})
0000000000000000000000000000000000000000;;		req := &endpointQuery{
0000000000000000000000000000000000000000;;			endpointsName: endpointsName,
0000000000000000000000000000000000000000;;			result:        result,
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		eq.requestChan <- req
0000000000000000000000000000000000000000;;		<-result
0000000000000000000000000000000000000000;;		return req.endpoints
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// marks e as added; does not block.
0000000000000000000000000000000000000000;;	func (eq *endpointQueries) added(e *v1.Endpoints) {
0000000000000000000000000000000000000000;;		eq.seenChan <- e
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// blocks until it has finished syncing.
0000000000000000000000000000000000000000;;	func startEndpointWatcher(f *framework.Framework, q *endpointQueries) {
0000000000000000000000000000000000000000;;		_, controller := cache.NewInformer(
0000000000000000000000000000000000000000;;			&cache.ListWatch{
0000000000000000000000000000000000000000;;				ListFunc: func(options metav1.ListOptions) (runtime.Object, error) {
0000000000000000000000000000000000000000;;					obj, err := f.ClientSet.Core().Endpoints(f.Namespace.Name).List(options)
0000000000000000000000000000000000000000;;					return runtime.Object(obj), err
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;				WatchFunc: func(options metav1.ListOptions) (watch.Interface, error) {
0000000000000000000000000000000000000000;;					return f.ClientSet.Core().Endpoints(f.Namespace.Name).Watch(options)
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			&v1.Endpoints{},
0000000000000000000000000000000000000000;;			0,
0000000000000000000000000000000000000000;;			cache.ResourceEventHandlerFuncs{
0000000000000000000000000000000000000000;;				AddFunc: func(obj interface{}) {
0000000000000000000000000000000000000000;;					if e, ok := obj.(*v1.Endpoints); ok {
0000000000000000000000000000000000000000;;						if len(e.Subsets) > 0 && len(e.Subsets[0].Addresses) > 0 {
0000000000000000000000000000000000000000;;							q.added(e)
0000000000000000000000000000000000000000;;						}
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;				UpdateFunc: func(old, cur interface{}) {
0000000000000000000000000000000000000000;;					if e, ok := cur.(*v1.Endpoints); ok {
0000000000000000000000000000000000000000;;						if len(e.Subsets) > 0 && len(e.Subsets[0].Addresses) > 0 {
0000000000000000000000000000000000000000;;							q.added(e)
0000000000000000000000000000000000000000;;						}
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;		)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		go controller.Run(q.stop)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Wait for the controller to sync, so that we don't count any warm-up time.
0000000000000000000000000000000000000000;;		for !controller.HasSynced() {
0000000000000000000000000000000000000000;;			time.Sleep(100 * time.Millisecond)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func singleServiceLatency(f *framework.Framework, name string, q *endpointQueries) (time.Duration, error) {
0000000000000000000000000000000000000000;;		// Make a service that points to that pod.
0000000000000000000000000000000000000000;;		svc := &v1.Service{
0000000000000000000000000000000000000000;;			ObjectMeta: metav1.ObjectMeta{
0000000000000000000000000000000000000000;;				GenerateName: "latency-svc-",
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			Spec: v1.ServiceSpec{
0000000000000000000000000000000000000000;;				Ports:           []v1.ServicePort{{Protocol: v1.ProtocolTCP, Port: 80}},
0000000000000000000000000000000000000000;;				Selector:        map[string]string{"name": name},
0000000000000000000000000000000000000000;;				Type:            v1.ServiceTypeClusterIP,
0000000000000000000000000000000000000000;;				SessionAffinity: v1.ServiceAffinityNone,
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		startTime := time.Now()
0000000000000000000000000000000000000000;;		gotSvc, err := f.ClientSet.Core().Services(f.Namespace.Name).Create(svc)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return 0, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		framework.Logf("Created: %v", gotSvc.Name)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if e := q.request(gotSvc.Name); e == nil {
0000000000000000000000000000000000000000;;			return 0, fmt.Errorf("Never got a result for endpoint %v", gotSvc.Name)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		stopTime := time.Now()
0000000000000000000000000000000000000000;;		d := stopTime.Sub(startTime)
0000000000000000000000000000000000000000;;		framework.Logf("Got endpoints: %v [%v]", gotSvc.Name, d)
0000000000000000000000000000000000000000;;		return d, nil
0000000000000000000000000000000000000000;;	}
