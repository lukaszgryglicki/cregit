0000000000000000000000000000000000000000;;	/*
0000000000000000000000000000000000000000;;	Copyright 2015 The Kubernetes Authors.
235bf5c9fb4c3d2556ce2d03cdf1c8a354ff9db6;;	
0000000000000000000000000000000000000000;;	Licensed under the Apache License, Version 2.0 (the "License");
0000000000000000000000000000000000000000;;	you may not use this file except in compliance with the License.
0000000000000000000000000000000000000000;;	You may obtain a copy of the License at
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	    http://www.apache.org/licenses/LICENSE-2.0
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	Unless required by applicable law or agreed to in writing, software
0000000000000000000000000000000000000000;;	distributed under the License is distributed on an "AS IS" BASIS,
0000000000000000000000000000000000000000;;	WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
0000000000000000000000000000000000000000;;	See the License for the specific language governing permissions and
0000000000000000000000000000000000000000;;	limitations under the License.
0000000000000000000000000000000000000000;;	*/
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	package e2e
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	import (
0000000000000000000000000000000000000000;;		"context"
0000000000000000000000000000000000000000;;		"fmt"
0000000000000000000000000000000000000000;;		"io/ioutil"
0000000000000000000000000000000000000000;;		"os"
0000000000000000000000000000000000000000;;		"path/filepath"
0000000000000000000000000000000000000000;;		"regexp"
0000000000000000000000000000000000000000;;		"strings"
0000000000000000000000000000000000000000;;		"sync"
0000000000000000000000000000000000000000;;		"time"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		"k8s.io/api/core/v1"
0000000000000000000000000000000000000000;;		rbacv1beta1 "k8s.io/api/rbac/v1beta1"
0000000000000000000000000000000000000000;;		metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/labels"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/runtime/schema"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/util/wait"
0000000000000000000000000000000000000000;;		"k8s.io/apiserver/pkg/authentication/serviceaccount"
0000000000000000000000000000000000000000;;		podutil "k8s.io/kubernetes/pkg/api/v1/pod"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/client/clientset_generated/clientset"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/test/e2e/framework"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/test/e2e/generated"
0000000000000000000000000000000000000000;;		testutils "k8s.io/kubernetes/test/utils"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		. "github.com/onsi/ginkgo"
0000000000000000000000000000000000000000;;		. "github.com/onsi/gomega"
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	const (
0000000000000000000000000000000000000000;;		serverStartTimeout = framework.PodStartTimeout + 3*time.Minute
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	var _ = framework.KubeDescribe("[Feature:Example]", func() {
0000000000000000000000000000000000000000;;		f := framework.NewDefaultFramework("examples")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Reusable cluster state function.  This won't be adversly affected by lazy initialization of framework.
0000000000000000000000000000000000000000;;		clusterState := func(selectorKey string, selectorValue string) *framework.ClusterVerification {
0000000000000000000000000000000000000000;;			return f.NewClusterVerification(
0000000000000000000000000000000000000000;;				f.Namespace,
0000000000000000000000000000000000000000;;				framework.PodStateVerification{
0000000000000000000000000000000000000000;;					Selectors:   map[string]string{selectorKey: selectorValue},
0000000000000000000000000000000000000000;;					ValidPhases: []v1.PodPhase{v1.PodRunning},
0000000000000000000000000000000000000000;;				})
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		// Customized ForEach wrapper for this test.
0000000000000000000000000000000000000000;;		forEachPod := func(selectorKey string, selectorValue string, fn func(v1.Pod)) {
0000000000000000000000000000000000000000;;			clusterState(selectorKey, selectorValue).ForEach(fn)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		var c clientset.Interface
0000000000000000000000000000000000000000;;		var ns string
0000000000000000000000000000000000000000;;		BeforeEach(func() {
0000000000000000000000000000000000000000;;			c = f.ClientSet
0000000000000000000000000000000000000000;;			ns = f.Namespace.Name
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// this test wants powerful permissions.  Since the namespace names are unique, we can leave this
0000000000000000000000000000000000000000;;			// lying around so we don't have to race any caches
0000000000000000000000000000000000000000;;			framework.BindClusterRoleInNamespace(c.Rbac(), "edit", f.Namespace.Name,
0000000000000000000000000000000000000000;;				rbacv1beta1.Subject{Kind: rbacv1beta1.ServiceAccountKind, Namespace: f.Namespace.Name, Name: "default"})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			err := framework.WaitForAuthorizationUpdate(c.AuthorizationV1beta1(),
0000000000000000000000000000000000000000;;				serviceaccount.MakeUsername(f.Namespace.Name, "default"),
0000000000000000000000000000000000000000;;				f.Namespace.Name, "create", schema.GroupResource{Resource: "pods"}, true)
0000000000000000000000000000000000000000;;			framework.ExpectNoError(err)
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		framework.KubeDescribe("Redis", func() {
0000000000000000000000000000000000000000;;			It("should create and stop redis servers", func() {
0000000000000000000000000000000000000000;;				mkpath := func(file string) string {
0000000000000000000000000000000000000000;;					return filepath.Join(framework.TestContext.RepoRoot, "examples/storage/redis", file)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				bootstrapYaml := mkpath("redis-master.yaml")
0000000000000000000000000000000000000000;;				sentinelServiceYaml := mkpath("redis-sentinel-service.yaml")
0000000000000000000000000000000000000000;;				sentinelControllerYaml := mkpath("redis-sentinel-controller.yaml")
0000000000000000000000000000000000000000;;				controllerYaml := mkpath("redis-controller.yaml")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				bootstrapPodName := "redis-master"
0000000000000000000000000000000000000000;;				redisRC := "redis"
0000000000000000000000000000000000000000;;				sentinelRC := "redis-sentinel"
0000000000000000000000000000000000000000;;				nsFlag := fmt.Sprintf("--namespace=%v", ns)
0000000000000000000000000000000000000000;;				expectedOnServer := "The server is now ready to accept connections"
0000000000000000000000000000000000000000;;				expectedOnSentinel := "+monitor master"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				By("starting redis bootstrap")
0000000000000000000000000000000000000000;;				framework.RunKubectlOrDie("create", "-f", bootstrapYaml, nsFlag)
0000000000000000000000000000000000000000;;				err := framework.WaitForPodNameRunningInNamespace(c, bootstrapPodName, ns)
0000000000000000000000000000000000000000;;				Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				_, err = framework.LookForStringInLog(ns, bootstrapPodName, "master", expectedOnServer, serverStartTimeout)
0000000000000000000000000000000000000000;;				Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;				_, err = framework.LookForStringInLog(ns, bootstrapPodName, "sentinel", expectedOnSentinel, serverStartTimeout)
0000000000000000000000000000000000000000;;				Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				By("setting up services and controllers")
0000000000000000000000000000000000000000;;				framework.RunKubectlOrDie("create", "-f", sentinelServiceYaml, nsFlag)
0000000000000000000000000000000000000000;;				framework.RunKubectlOrDie("create", "-f", sentinelControllerYaml, nsFlag)
0000000000000000000000000000000000000000;;				framework.RunKubectlOrDie("create", "-f", controllerYaml, nsFlag)
0000000000000000000000000000000000000000;;				label := labels.SelectorFromSet(labels.Set(map[string]string{sentinelRC: "true"}))
0000000000000000000000000000000000000000;;				err = testutils.WaitForPodsWithLabelRunning(c, ns, label)
0000000000000000000000000000000000000000;;				Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;				label = labels.SelectorFromSet(labels.Set(map[string]string{"name": redisRC}))
0000000000000000000000000000000000000000;;				err = testutils.WaitForPodsWithLabelRunning(c, ns, label)
0000000000000000000000000000000000000000;;				Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				By("scaling up the deployment")
0000000000000000000000000000000000000000;;				framework.RunKubectlOrDie("scale", "rc", redisRC, "--replicas=3", nsFlag)
0000000000000000000000000000000000000000;;				framework.RunKubectlOrDie("scale", "rc", sentinelRC, "--replicas=3", nsFlag)
0000000000000000000000000000000000000000;;				framework.WaitForRCToStabilize(c, ns, redisRC, framework.PodReadyBeforeTimeout)
0000000000000000000000000000000000000000;;				framework.WaitForRCToStabilize(c, ns, sentinelRC, framework.PodReadyBeforeTimeout)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				By("checking up the services")
0000000000000000000000000000000000000000;;				checkAllLogs := func() {
0000000000000000000000000000000000000000;;					selectorKey, selectorValue := "name", redisRC
0000000000000000000000000000000000000000;;					label := labels.SelectorFromSet(labels.Set(map[string]string{selectorKey: selectorValue}))
0000000000000000000000000000000000000000;;					err = testutils.WaitForPodsWithLabelRunning(c, ns, label)
0000000000000000000000000000000000000000;;					Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;					forEachPod(selectorKey, selectorValue, func(pod v1.Pod) {
0000000000000000000000000000000000000000;;						if pod.Name != bootstrapPodName {
0000000000000000000000000000000000000000;;							_, err := framework.LookForStringInLog(ns, pod.Name, "redis", expectedOnServer, serverStartTimeout)
0000000000000000000000000000000000000000;;							Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;						}
0000000000000000000000000000000000000000;;					})
0000000000000000000000000000000000000000;;					selectorKey, selectorValue = sentinelRC, "true"
0000000000000000000000000000000000000000;;					label = labels.SelectorFromSet(labels.Set(map[string]string{selectorKey: selectorValue}))
0000000000000000000000000000000000000000;;					err = testutils.WaitForPodsWithLabelRunning(c, ns, label)
0000000000000000000000000000000000000000;;					Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;					forEachPod(selectorKey, selectorValue, func(pod v1.Pod) {
0000000000000000000000000000000000000000;;						if pod.Name != bootstrapPodName {
0000000000000000000000000000000000000000;;							_, err := framework.LookForStringInLog(ns, pod.Name, "sentinel", expectedOnSentinel, serverStartTimeout)
0000000000000000000000000000000000000000;;							Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;						}
0000000000000000000000000000000000000000;;					})
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				checkAllLogs()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				By("turning down bootstrap")
0000000000000000000000000000000000000000;;				framework.RunKubectlOrDie("delete", "-f", bootstrapYaml, nsFlag)
0000000000000000000000000000000000000000;;				err = framework.WaitForRCPodToDisappear(c, ns, redisRC, bootstrapPodName)
0000000000000000000000000000000000000000;;				Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;				By("waiting for the new master election")
0000000000000000000000000000000000000000;;				checkAllLogs()
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		framework.KubeDescribe("Spark", func() {
0000000000000000000000000000000000000000;;			It("should start spark master, driver and workers", func() {
0000000000000000000000000000000000000000;;				mkpath := func(file string) string {
0000000000000000000000000000000000000000;;					return filepath.Join(framework.TestContext.RepoRoot, "examples/spark", file)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				// TODO: Add Zepplin and Web UI to this example.
0000000000000000000000000000000000000000;;				serviceYaml := mkpath("spark-master-service.yaml")
0000000000000000000000000000000000000000;;				masterYaml := mkpath("spark-master-controller.yaml")
0000000000000000000000000000000000000000;;				workerControllerYaml := mkpath("spark-worker-controller.yaml")
0000000000000000000000000000000000000000;;				nsFlag := fmt.Sprintf("--namespace=%v", ns)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				master := func() {
0000000000000000000000000000000000000000;;					By("starting master")
0000000000000000000000000000000000000000;;					framework.RunKubectlOrDie("create", "-f", serviceYaml, nsFlag)
0000000000000000000000000000000000000000;;					framework.RunKubectlOrDie("create", "-f", masterYaml, nsFlag)
0000000000000000000000000000000000000000;;					selectorKey, selectorValue := "component", "spark-master"
0000000000000000000000000000000000000000;;					label := labels.SelectorFromSet(labels.Set(map[string]string{selectorKey: selectorValue}))
0000000000000000000000000000000000000000;;					err := testutils.WaitForPodsWithLabelRunning(c, ns, label)
0000000000000000000000000000000000000000;;					Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;					framework.Logf("Now polling for Master startup...")
0000000000000000000000000000000000000000;;					// Only one master pod: But its a natural way to look up pod names.
0000000000000000000000000000000000000000;;					forEachPod(selectorKey, selectorValue, func(pod v1.Pod) {
0000000000000000000000000000000000000000;;						framework.Logf("Now waiting for master to startup in %v", pod.Name)
0000000000000000000000000000000000000000;;						_, err := framework.LookForStringInLog(ns, pod.Name, "spark-master", "Starting Spark master at", serverStartTimeout)
0000000000000000000000000000000000000000;;						Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;					})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;					By("waiting for master endpoint")
0000000000000000000000000000000000000000;;					err = framework.WaitForEndpoint(c, ns, "spark-master")
0000000000000000000000000000000000000000;;					Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;					forEachPod(selectorKey, selectorValue, func(pod v1.Pod) {
0000000000000000000000000000000000000000;;						_, maErr := framework.LookForStringInLog(f.Namespace.Name, pod.Name, "spark-master", "Starting Spark master at", serverStartTimeout)
0000000000000000000000000000000000000000;;						if maErr != nil {
0000000000000000000000000000000000000000;;							framework.Failf("Didn't find target string. error:", maErr)
0000000000000000000000000000000000000000;;						}
0000000000000000000000000000000000000000;;					})
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				worker := func() {
0000000000000000000000000000000000000000;;					By("starting workers")
0000000000000000000000000000000000000000;;					framework.Logf("Now starting Workers")
0000000000000000000000000000000000000000;;					framework.RunKubectlOrDie("create", "-f", workerControllerYaml, nsFlag)
0000000000000000000000000000000000000000;;					selectorKey, selectorValue := "component", "spark-worker"
0000000000000000000000000000000000000000;;					label := labels.SelectorFromSet(labels.Set(map[string]string{selectorKey: selectorValue}))
0000000000000000000000000000000000000000;;					err := testutils.WaitForPodsWithLabelRunning(c, ns, label)
0000000000000000000000000000000000000000;;					Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;					// For now, scaling is orthogonal to the core test.
0000000000000000000000000000000000000000;;					// framework.ScaleRC(c, ns, "spark-worker-controller", 2, true)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;					framework.Logf("Now polling for worker startup...")
0000000000000000000000000000000000000000;;					forEachPod(selectorKey, selectorValue,
0000000000000000000000000000000000000000;;						func(pod v1.Pod) {
0000000000000000000000000000000000000000;;							_, slaveErr := framework.LookForStringInLog(ns, pod.Name, "spark-worker", "Successfully registered with master", serverStartTimeout)
0000000000000000000000000000000000000000;;							Expect(slaveErr).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;						})
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				// Run the worker verification after we turn up the master.
0000000000000000000000000000000000000000;;				defer worker()
0000000000000000000000000000000000000000;;				master()
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		framework.KubeDescribe("Cassandra", func() {
0000000000000000000000000000000000000000;;			It("should create and scale cassandra", func() {
0000000000000000000000000000000000000000;;				mkpath := func(file string) string {
0000000000000000000000000000000000000000;;					return filepath.Join(framework.TestContext.RepoRoot, "examples/storage/cassandra", file)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				serviceYaml := mkpath("cassandra-service.yaml")
0000000000000000000000000000000000000000;;				controllerYaml := mkpath("cassandra-controller.yaml")
0000000000000000000000000000000000000000;;				nsFlag := fmt.Sprintf("--namespace=%v", ns)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				By("Starting the cassandra service")
0000000000000000000000000000000000000000;;				framework.RunKubectlOrDie("create", "-f", serviceYaml, nsFlag)
0000000000000000000000000000000000000000;;				framework.Logf("wait for service")
0000000000000000000000000000000000000000;;				err := framework.WaitForService(c, ns, "cassandra", true, framework.Poll, framework.ServiceRespondingTimeout)
0000000000000000000000000000000000000000;;				Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				// Create an RC with n nodes in it.  Each node will then be verified.
0000000000000000000000000000000000000000;;				By("Creating a Cassandra RC")
0000000000000000000000000000000000000000;;				framework.RunKubectlOrDie("create", "-f", controllerYaml, nsFlag)
0000000000000000000000000000000000000000;;				label := labels.SelectorFromSet(labels.Set(map[string]string{"app": "cassandra"}))
0000000000000000000000000000000000000000;;				err = testutils.WaitForPodsWithLabelRunning(c, ns, label)
0000000000000000000000000000000000000000;;				Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;				forEachPod("app", "cassandra", func(pod v1.Pod) {
0000000000000000000000000000000000000000;;					framework.Logf("Verifying pod %v ", pod.Name)
0000000000000000000000000000000000000000;;					// TODO how do we do this better?  Ready Probe?
0000000000000000000000000000000000000000;;					_, err = framework.LookForStringInLog(ns, pod.Name, "cassandra", "Starting listening for CQL clients", serverStartTimeout)
0000000000000000000000000000000000000000;;					Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;				})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				By("Finding each node in the nodetool status lines")
0000000000000000000000000000000000000000;;				forEachPod("app", "cassandra", func(pod v1.Pod) {
0000000000000000000000000000000000000000;;					output := framework.RunKubectlOrDie("exec", pod.Name, nsFlag, "--", "nodetool", "status")
0000000000000000000000000000000000000000;;					matched, _ := regexp.MatchString("UN.*"+pod.Status.PodIP, output)
0000000000000000000000000000000000000000;;					if matched != true {
0000000000000000000000000000000000000000;;						framework.Failf("Cassandra pod ip %s is not reporting Up and Normal 'UN' via nodetool status", pod.Status.PodIP)
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;				})
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		framework.KubeDescribe("CassandraStatefulSet", func() {
0000000000000000000000000000000000000000;;			It("should create statefulset", func() {
0000000000000000000000000000000000000000;;				mkpath := func(file string) string {
0000000000000000000000000000000000000000;;					return filepath.Join(framework.TestContext.RepoRoot, "examples/storage/cassandra", file)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				serviceYaml := mkpath("cassandra-service.yaml")
0000000000000000000000000000000000000000;;				nsFlag := fmt.Sprintf("--namespace=%v", ns)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				// have to change dns prefix because of the dynamic namespace
0000000000000000000000000000000000000000;;				input := generated.ReadOrDie(mkpath("cassandra-statefulset.yaml"))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				output := strings.Replace(string(input), "cassandra-0.cassandra.default.svc.cluster.local", "cassandra-0.cassandra."+ns+".svc.cluster.local", -1)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				statefulsetYaml := "/tmp/cassandra-statefulset.yaml"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				err := ioutil.WriteFile(statefulsetYaml, []byte(output), 0644)
0000000000000000000000000000000000000000;;				Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				By("Starting the cassandra service")
0000000000000000000000000000000000000000;;				framework.RunKubectlOrDie("create", "-f", serviceYaml, nsFlag)
0000000000000000000000000000000000000000;;				framework.Logf("wait for service")
0000000000000000000000000000000000000000;;				err = framework.WaitForService(c, ns, "cassandra", true, framework.Poll, framework.ServiceRespondingTimeout)
0000000000000000000000000000000000000000;;				Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				// Create an StatefulSet with n nodes in it.  Each node will then be verified.
0000000000000000000000000000000000000000;;				By("Creating a Cassandra StatefulSet")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				framework.RunKubectlOrDie("create", "-f", statefulsetYaml, nsFlag)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				statefulsetPoll := 30 * time.Second
0000000000000000000000000000000000000000;;				statefulsetTimeout := 10 * time.Minute
0000000000000000000000000000000000000000;;				// TODO - parse this number out of the yaml
0000000000000000000000000000000000000000;;				numPets := 3
0000000000000000000000000000000000000000;;				label := labels.SelectorFromSet(labels.Set(map[string]string{"app": "cassandra"}))
0000000000000000000000000000000000000000;;				err = wait.PollImmediate(statefulsetPoll, statefulsetTimeout,
0000000000000000000000000000000000000000;;					func() (bool, error) {
0000000000000000000000000000000000000000;;						podList, err := c.Core().Pods(ns).List(metav1.ListOptions{LabelSelector: label.String()})
0000000000000000000000000000000000000000;;						if err != nil {
0000000000000000000000000000000000000000;;							return false, fmt.Errorf("Unable to get list of pods in statefulset %s", label)
0000000000000000000000000000000000000000;;						}
0000000000000000000000000000000000000000;;						framework.ExpectNoError(err)
0000000000000000000000000000000000000000;;						if len(podList.Items) < numPets {
0000000000000000000000000000000000000000;;							framework.Logf("Found %d pets, waiting for %d", len(podList.Items), numPets)
0000000000000000000000000000000000000000;;							return false, nil
0000000000000000000000000000000000000000;;						}
0000000000000000000000000000000000000000;;						if len(podList.Items) > numPets {
0000000000000000000000000000000000000000;;							return false, fmt.Errorf("Too many pods scheduled, expected %d got %d", numPets, len(podList.Items))
0000000000000000000000000000000000000000;;						}
0000000000000000000000000000000000000000;;						for _, p := range podList.Items {
0000000000000000000000000000000000000000;;							isReady := podutil.IsPodReady(&p)
0000000000000000000000000000000000000000;;							if p.Status.Phase != v1.PodRunning || !isReady {
0000000000000000000000000000000000000000;;								framework.Logf("Waiting for pod %v to enter %v - Ready=True, currently %v - Ready=%v", p.Name, v1.PodRunning, p.Status.Phase, isReady)
0000000000000000000000000000000000000000;;								return false, nil
0000000000000000000000000000000000000000;;							}
0000000000000000000000000000000000000000;;						}
0000000000000000000000000000000000000000;;						return true, nil
0000000000000000000000000000000000000000;;					})
0000000000000000000000000000000000000000;;				Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				By("Finding each node in the nodetool status lines")
0000000000000000000000000000000000000000;;				forEachPod("app", "cassandra", func(pod v1.Pod) {
0000000000000000000000000000000000000000;;					output := framework.RunKubectlOrDie("exec", pod.Name, nsFlag, "--", "nodetool", "status")
0000000000000000000000000000000000000000;;					matched, _ := regexp.MatchString("UN.*"+pod.Status.PodIP, output)
0000000000000000000000000000000000000000;;					if matched != true {
0000000000000000000000000000000000000000;;						framework.Failf("Cassandra pod ip %s is not reporting Up and Normal 'UN' via nodetool status", pod.Status.PodIP)
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;				})
0000000000000000000000000000000000000000;;				// using out of statefulset e2e as deleting pvc is a pain
0000000000000000000000000000000000000000;;				framework.DeleteAllStatefulSets(c, ns)
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		framework.KubeDescribe("Storm", func() {
0000000000000000000000000000000000000000;;			It("should create and stop Zookeeper, Nimbus and Storm worker servers", func() {
0000000000000000000000000000000000000000;;				mkpath := func(file string) string {
0000000000000000000000000000000000000000;;					return filepath.Join(framework.TestContext.RepoRoot, "examples/storm", file)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				zookeeperServiceJson := mkpath("zookeeper-service.json")
0000000000000000000000000000000000000000;;				zookeeperPodJson := mkpath("zookeeper.json")
0000000000000000000000000000000000000000;;				nimbusServiceJson := mkpath("storm-nimbus-service.json")
0000000000000000000000000000000000000000;;				nimbusPodJson := mkpath("storm-nimbus.json")
0000000000000000000000000000000000000000;;				workerControllerJson := mkpath("storm-worker-controller.json")
0000000000000000000000000000000000000000;;				nsFlag := fmt.Sprintf("--namespace=%v", ns)
0000000000000000000000000000000000000000;;				zookeeperPod := "zookeeper"
0000000000000000000000000000000000000000;;				nimbusPod := "nimbus"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				By("starting Zookeeper")
0000000000000000000000000000000000000000;;				framework.RunKubectlOrDie("create", "-f", zookeeperPodJson, nsFlag)
0000000000000000000000000000000000000000;;				framework.RunKubectlOrDie("create", "-f", zookeeperServiceJson, nsFlag)
0000000000000000000000000000000000000000;;				err := f.WaitForPodRunningSlow(zookeeperPod)
0000000000000000000000000000000000000000;;				Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				By("checking if zookeeper is up and running")
0000000000000000000000000000000000000000;;				_, err = framework.LookForStringInLog(ns, zookeeperPod, "zookeeper", "binding to port", serverStartTimeout)
0000000000000000000000000000000000000000;;				Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;				err = framework.WaitForEndpoint(c, ns, "zookeeper")
0000000000000000000000000000000000000000;;				Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				By("starting Nimbus")
0000000000000000000000000000000000000000;;				framework.RunKubectlOrDie("create", "-f", nimbusPodJson, nsFlag)
0000000000000000000000000000000000000000;;				framework.RunKubectlOrDie("create", "-f", nimbusServiceJson, nsFlag)
0000000000000000000000000000000000000000;;				err = f.WaitForPodRunningSlow(nimbusPod)
0000000000000000000000000000000000000000;;				Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				err = framework.WaitForEndpoint(c, ns, "nimbus")
0000000000000000000000000000000000000000;;				Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				By("starting workers")
0000000000000000000000000000000000000000;;				framework.RunKubectlOrDie("create", "-f", workerControllerJson, nsFlag)
0000000000000000000000000000000000000000;;				label := labels.SelectorFromSet(labels.Set(map[string]string{"name": "storm-worker"}))
0000000000000000000000000000000000000000;;				err = testutils.WaitForPodsWithLabelRunning(c, ns, label)
0000000000000000000000000000000000000000;;				Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;				forEachPod("name", "storm-worker", func(pod v1.Pod) {
0000000000000000000000000000000000000000;;					//do nothing, just wait for the pod to be running
0000000000000000000000000000000000000000;;				})
0000000000000000000000000000000000000000;;				// TODO: Add logging configuration to nimbus & workers images and then
0000000000000000000000000000000000000000;;				// look for a string instead of sleeping.
0000000000000000000000000000000000000000;;				time.Sleep(20 * time.Second)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				By("checking if there are established connections to Zookeeper")
0000000000000000000000000000000000000000;;				_, err = framework.LookForStringInLog(ns, zookeeperPod, "zookeeper", "Established session", serverStartTimeout)
0000000000000000000000000000000000000000;;				Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				By("checking if Nimbus responds to requests")
0000000000000000000000000000000000000000;;				framework.LookForString("No topologies running.", time.Minute, func() string {
0000000000000000000000000000000000000000;;					return framework.RunKubectlOrDie("exec", "nimbus", nsFlag, "--", "bin/storm", "list")
0000000000000000000000000000000000000000;;				})
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		framework.KubeDescribe("Liveness", func() {
0000000000000000000000000000000000000000;;			It("liveness pods should be automatically restarted", func() {
0000000000000000000000000000000000000000;;				mkpath := func(file string) string {
0000000000000000000000000000000000000000;;					path := filepath.Join("test/fixtures/doc-yaml/user-guide/liveness", file)
0000000000000000000000000000000000000000;;					framework.ExpectNoError(createFileForGoBinData(path, path))
0000000000000000000000000000000000000000;;					return path
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				execYaml := mkpath("exec-liveness.yaml")
0000000000000000000000000000000000000000;;				httpYaml := mkpath("http-liveness.yaml")
0000000000000000000000000000000000000000;;				nsFlag := fmt.Sprintf("--namespace=%v", ns)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				framework.RunKubectlOrDie("create", "-f", filepath.Join(framework.TestContext.OutputDir, execYaml), nsFlag)
0000000000000000000000000000000000000000;;				framework.RunKubectlOrDie("create", "-f", filepath.Join(framework.TestContext.OutputDir, httpYaml), nsFlag)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				// Since both containers start rapidly, we can easily run this test in parallel.
0000000000000000000000000000000000000000;;				var wg sync.WaitGroup
0000000000000000000000000000000000000000;;				passed := true
0000000000000000000000000000000000000000;;				checkRestart := func(podName string, timeout time.Duration) {
0000000000000000000000000000000000000000;;					err := framework.WaitForPodNameRunningInNamespace(c, podName, ns)
0000000000000000000000000000000000000000;;					Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;					for t := time.Now(); time.Since(t) < timeout; time.Sleep(framework.Poll) {
0000000000000000000000000000000000000000;;						pod, err := c.Core().Pods(ns).Get(podName, metav1.GetOptions{})
0000000000000000000000000000000000000000;;						framework.ExpectNoError(err, fmt.Sprintf("getting pod %s", podName))
0000000000000000000000000000000000000000;;						stat := podutil.GetExistingContainerStatus(pod.Status.ContainerStatuses, podName)
0000000000000000000000000000000000000000;;						framework.Logf("Pod: %s, restart count:%d", stat.Name, stat.RestartCount)
0000000000000000000000000000000000000000;;						if stat.RestartCount > 0 {
0000000000000000000000000000000000000000;;							framework.Logf("Saw %v restart, succeeded...", podName)
0000000000000000000000000000000000000000;;							wg.Done()
0000000000000000000000000000000000000000;;							return
0000000000000000000000000000000000000000;;						}
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					framework.Logf("Failed waiting for %v restart! ", podName)
0000000000000000000000000000000000000000;;					passed = false
0000000000000000000000000000000000000000;;					wg.Done()
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				By("Check restarts")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				// Start the "actual test", and wait for both pods to complete.
0000000000000000000000000000000000000000;;				// If 2 fail: Something is broken with the test (or maybe even with liveness).
0000000000000000000000000000000000000000;;				// If 1 fails: Its probably just an error in the examples/ files themselves.
0000000000000000000000000000000000000000;;				wg.Add(2)
0000000000000000000000000000000000000000;;				for _, c := range []string{"liveness-http", "liveness-exec"} {
0000000000000000000000000000000000000000;;					go checkRestart(c, 2*time.Minute)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				wg.Wait()
0000000000000000000000000000000000000000;;				if !passed {
0000000000000000000000000000000000000000;;					framework.Failf("At least one liveness example failed.  See the logs above.")
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		framework.KubeDescribe("Secret", func() {
0000000000000000000000000000000000000000;;			It("should create a pod that reads a secret", func() {
0000000000000000000000000000000000000000;;				mkpath := func(file string) string {
0000000000000000000000000000000000000000;;					path := filepath.Join("test/fixtures/doc-yaml/user-guide/secrets", file)
0000000000000000000000000000000000000000;;					framework.ExpectNoError(createFileForGoBinData(path, path))
0000000000000000000000000000000000000000;;					return path
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				secretYaml := mkpath("secret.yaml")
0000000000000000000000000000000000000000;;				podYaml := mkpath("secret-pod.yaml")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				nsFlag := fmt.Sprintf("--namespace=%v", ns)
0000000000000000000000000000000000000000;;				podName := "secret-test-pod"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				By("creating secret and pod")
0000000000000000000000000000000000000000;;				framework.RunKubectlOrDie("create", "-f", filepath.Join(framework.TestContext.OutputDir, secretYaml), nsFlag)
0000000000000000000000000000000000000000;;				framework.RunKubectlOrDie("create", "-f", filepath.Join(framework.TestContext.OutputDir, podYaml), nsFlag)
0000000000000000000000000000000000000000;;				err := framework.WaitForPodNoLongerRunningInNamespace(c, podName, ns)
0000000000000000000000000000000000000000;;				Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				By("checking if secret was read correctly")
0000000000000000000000000000000000000000;;				_, err = framework.LookForStringInLog(ns, "secret-test-pod", "test-container", "value-1", serverStartTimeout)
0000000000000000000000000000000000000000;;				Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		framework.KubeDescribe("Downward API", func() {
0000000000000000000000000000000000000000;;			It("should create a pod that prints his name and namespace", func() {
0000000000000000000000000000000000000000;;				mkpath := func(file string) string {
0000000000000000000000000000000000000000;;					path := filepath.Join("test/fixtures/doc-yaml/user-guide/downward-api", file)
0000000000000000000000000000000000000000;;					framework.ExpectNoError(createFileForGoBinData(path, path))
0000000000000000000000000000000000000000;;					return path
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				podYaml := mkpath("dapi-pod.yaml")
0000000000000000000000000000000000000000;;				nsFlag := fmt.Sprintf("--namespace=%v", ns)
0000000000000000000000000000000000000000;;				podName := "dapi-test-pod"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				By("creating the pod")
0000000000000000000000000000000000000000;;				framework.RunKubectlOrDie("create", "-f", filepath.Join(framework.TestContext.OutputDir, podYaml), nsFlag)
0000000000000000000000000000000000000000;;				err := framework.WaitForPodNoLongerRunningInNamespace(c, podName, ns)
0000000000000000000000000000000000000000;;				Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				By("checking if name and namespace were passed correctly")
0000000000000000000000000000000000000000;;				_, err = framework.LookForStringInLog(ns, podName, "test-container", fmt.Sprintf("MY_POD_NAMESPACE=%v", ns), serverStartTimeout)
0000000000000000000000000000000000000000;;				Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;				_, err = framework.LookForStringInLog(ns, podName, "test-container", fmt.Sprintf("MY_POD_NAME=%v", podName), serverStartTimeout)
0000000000000000000000000000000000000000;;				Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		framework.KubeDescribe("RethinkDB", func() {
0000000000000000000000000000000000000000;;			It("should create and stop rethinkdb servers", func() {
0000000000000000000000000000000000000000;;				mkpath := func(file string) string {
0000000000000000000000000000000000000000;;					return filepath.Join(framework.TestContext.RepoRoot, "examples/storage/rethinkdb", file)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				driverServiceYaml := mkpath("driver-service.yaml")
0000000000000000000000000000000000000000;;				rethinkDbControllerYaml := mkpath("rc.yaml")
0000000000000000000000000000000000000000;;				adminPodYaml := mkpath("admin-pod.yaml")
0000000000000000000000000000000000000000;;				adminServiceYaml := mkpath("admin-service.yaml")
0000000000000000000000000000000000000000;;				nsFlag := fmt.Sprintf("--namespace=%v", ns)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				By("starting rethinkdb")
0000000000000000000000000000000000000000;;				framework.RunKubectlOrDie("create", "-f", driverServiceYaml, nsFlag)
0000000000000000000000000000000000000000;;				framework.RunKubectlOrDie("create", "-f", rethinkDbControllerYaml, nsFlag)
0000000000000000000000000000000000000000;;				label := labels.SelectorFromSet(labels.Set(map[string]string{"db": "rethinkdb"}))
0000000000000000000000000000000000000000;;				err := testutils.WaitForPodsWithLabelRunning(c, ns, label)
0000000000000000000000000000000000000000;;				Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;				checkDbInstances := func() {
0000000000000000000000000000000000000000;;					forEachPod("db", "rethinkdb", func(pod v1.Pod) {
0000000000000000000000000000000000000000;;						_, err = framework.LookForStringInLog(ns, pod.Name, "rethinkdb", "Server ready", serverStartTimeout)
0000000000000000000000000000000000000000;;						Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;					})
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				checkDbInstances()
0000000000000000000000000000000000000000;;				err = framework.WaitForEndpoint(c, ns, "rethinkdb-driver")
0000000000000000000000000000000000000000;;				Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				By("scaling rethinkdb")
0000000000000000000000000000000000000000;;				framework.ScaleRC(f.ClientSet, f.InternalClientset, ns, "rethinkdb-rc", 2, true)
0000000000000000000000000000000000000000;;				checkDbInstances()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				By("starting admin")
0000000000000000000000000000000000000000;;				framework.RunKubectlOrDie("create", "-f", adminServiceYaml, nsFlag)
0000000000000000000000000000000000000000;;				framework.RunKubectlOrDie("create", "-f", adminPodYaml, nsFlag)
0000000000000000000000000000000000000000;;				err = framework.WaitForPodNameRunningInNamespace(c, "rethinkdb-admin", ns)
0000000000000000000000000000000000000000;;				Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;				checkDbInstances()
0000000000000000000000000000000000000000;;				content, err := makeHttpRequestToService(c, ns, "rethinkdb-admin", "/", framework.EndpointRegisterTimeout)
0000000000000000000000000000000000000000;;				Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;				if !strings.Contains(content, "<title>RethinkDB Administration Console</title>") {
0000000000000000000000000000000000000000;;					framework.Failf("RethinkDB console is not running")
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		framework.KubeDescribe("Hazelcast", func() {
0000000000000000000000000000000000000000;;			It("should create and scale hazelcast", func() {
0000000000000000000000000000000000000000;;				mkpath := func(file string) string {
0000000000000000000000000000000000000000;;					return filepath.Join(framework.TestContext.RepoRoot, "examples/storage/hazelcast", file)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				serviceYaml := mkpath("hazelcast-service.yaml")
0000000000000000000000000000000000000000;;				deploymentYaml := mkpath("hazelcast-deployment.yaml")
0000000000000000000000000000000000000000;;				nsFlag := fmt.Sprintf("--namespace=%v", ns)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				By("starting hazelcast")
0000000000000000000000000000000000000000;;				framework.RunKubectlOrDie("create", "-f", serviceYaml, nsFlag)
0000000000000000000000000000000000000000;;				framework.RunKubectlOrDie("create", "-f", deploymentYaml, nsFlag)
0000000000000000000000000000000000000000;;				label := labels.SelectorFromSet(labels.Set(map[string]string{"name": "hazelcast"}))
0000000000000000000000000000000000000000;;				err := testutils.WaitForPodsWithLabelRunning(c, ns, label)
0000000000000000000000000000000000000000;;				Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;				forEachPod("name", "hazelcast", func(pod v1.Pod) {
0000000000000000000000000000000000000000;;					_, err := framework.LookForStringInLog(ns, pod.Name, "hazelcast", "Members [1]", serverStartTimeout)
0000000000000000000000000000000000000000;;					Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;					_, err = framework.LookForStringInLog(ns, pod.Name, "hazelcast", "is STARTED", serverStartTimeout)
0000000000000000000000000000000000000000;;					Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;				})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				err = framework.WaitForEndpoint(c, ns, "hazelcast")
0000000000000000000000000000000000000000;;				Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				By("scaling hazelcast")
0000000000000000000000000000000000000000;;				framework.ScaleRC(f.ClientSet, f.InternalClientset, ns, "hazelcast", 2, true)
0000000000000000000000000000000000000000;;				forEachPod("name", "hazelcast", func(pod v1.Pod) {
0000000000000000000000000000000000000000;;					_, err := framework.LookForStringInLog(ns, pod.Name, "hazelcast", "Members [2]", serverStartTimeout)
0000000000000000000000000000000000000000;;					Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;				})
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func makeHttpRequestToService(c clientset.Interface, ns, service, path string, timeout time.Duration) (string, error) {
0000000000000000000000000000000000000000;;		var result []byte
0000000000000000000000000000000000000000;;		var err error
0000000000000000000000000000000000000000;;		for t := time.Now(); time.Since(t) < timeout; time.Sleep(framework.Poll) {
0000000000000000000000000000000000000000;;			proxyRequest, errProxy := framework.GetServicesProxyRequest(c, c.Core().RESTClient().Get())
0000000000000000000000000000000000000000;;			if errProxy != nil {
0000000000000000000000000000000000000000;;				break
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			ctx, cancel := context.WithTimeout(context.Background(), framework.SingleCallTimeout)
0000000000000000000000000000000000000000;;			defer cancel()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			result, err = proxyRequest.Namespace(ns).
0000000000000000000000000000000000000000;;				Context(ctx).
0000000000000000000000000000000000000000;;				Name(service).
0000000000000000000000000000000000000000;;				Suffix(path).
0000000000000000000000000000000000000000;;				Do().
0000000000000000000000000000000000000000;;				Raw()
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				break
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return string(result), err
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// pass enough context with the 'old' parameter so that it replaces what your really intended.
0000000000000000000000000000000000000000;;	func prepareResourceWithReplacedString(inputFile, old, new string) string {
0000000000000000000000000000000000000000;;		f, err := os.Open(inputFile)
0000000000000000000000000000000000000000;;		Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;		defer f.Close()
0000000000000000000000000000000000000000;;		data, err := ioutil.ReadAll(f)
0000000000000000000000000000000000000000;;		Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;		podYaml := strings.Replace(string(data), old, new, 1)
0000000000000000000000000000000000000000;;		return podYaml
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func createFileForGoBinData(gobindataPath, outputFilename string) error {
0000000000000000000000000000000000000000;;		data := generated.ReadOrDie(gobindataPath)
0000000000000000000000000000000000000000;;		if len(data) == 0 {
0000000000000000000000000000000000000000;;			return fmt.Errorf("Failed to read gobindata from %v", gobindataPath)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		fullPath := filepath.Join(framework.TestContext.OutputDir, outputFilename)
0000000000000000000000000000000000000000;;		err := os.MkdirAll(filepath.Dir(fullPath), 0777)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return fmt.Errorf("Error while creating directory %v: %v", filepath.Dir(fullPath), err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		err = ioutil.WriteFile(fullPath, data, 0644)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return fmt.Errorf("Error while trying to write to file %v: %v", fullPath, err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return nil
0000000000000000000000000000000000000000;;	}
