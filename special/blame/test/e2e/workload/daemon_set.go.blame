0000000000000000000000000000000000000000;;	/*
0000000000000000000000000000000000000000;;	Copyright 2015 The Kubernetes Authors.
6b49eb1d763e744c359db1c8048f793033ef9bf8;test/e2e/daemon.go[test/e2e/daemon.go][test/e2e/workload/daemon_set.go];	
0000000000000000000000000000000000000000;;	Licensed under the Apache License, Version 2.0 (the "License");
0000000000000000000000000000000000000000;;	you may not use this file except in compliance with the License.
0000000000000000000000000000000000000000;;	You may obtain a copy of the License at
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	    http://www.apache.org/licenses/LICENSE-2.0
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	Unless required by applicable law or agreed to in writing, software
0000000000000000000000000000000000000000;;	distributed under the License is distributed on an "AS IS" BASIS,
0000000000000000000000000000000000000000;;	WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
0000000000000000000000000000000000000000;;	See the License for the specific language governing permissions and
0000000000000000000000000000000000000000;;	limitations under the License.
0000000000000000000000000000000000000000;;	*/
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	package workload
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	import (
0000000000000000000000000000000000000000;;		"fmt"
0000000000000000000000000000000000000000;;		"reflect"
0000000000000000000000000000000000000000;;		"strings"
0000000000000000000000000000000000000000;;		"time"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		apps "k8s.io/api/apps/v1beta1"
0000000000000000000000000000000000000000;;		"k8s.io/api/core/v1"
0000000000000000000000000000000000000000;;		extensions "k8s.io/api/extensions/v1beta1"
0000000000000000000000000000000000000000;;		apiequality "k8s.io/apimachinery/pkg/api/equality"
0000000000000000000000000000000000000000;;		apierrs "k8s.io/apimachinery/pkg/api/errors"
0000000000000000000000000000000000000000;;		metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/labels"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/runtime"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/types"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/util/wait"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/api"
0000000000000000000000000000000000000000;;		podutil "k8s.io/kubernetes/pkg/api/v1/pod"
0000000000000000000000000000000000000000;;		extensionsinternal "k8s.io/kubernetes/pkg/apis/extensions"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/client/clientset_generated/clientset"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/controller"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/controller/daemon"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/kubectl"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/plugin/pkg/scheduler/schedulercache"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/test/e2e/framework"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		. "github.com/onsi/ginkgo"
0000000000000000000000000000000000000000;;		. "github.com/onsi/gomega"
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	const (
0000000000000000000000000000000000000000;;		// this should not be a multiple of 5, because node status updates
0000000000000000000000000000000000000000;;		// every 5 seconds. See https://github.com/kubernetes/kubernetes/pull/14915.
0000000000000000000000000000000000000000;;		dsRetryPeriod  = 1 * time.Second
0000000000000000000000000000000000000000;;		dsRetryTimeout = 5 * time.Minute
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		daemonsetLabelPrefix = "daemonset-"
0000000000000000000000000000000000000000;;		daemonsetNameLabel   = daemonsetLabelPrefix + "name"
0000000000000000000000000000000000000000;;		daemonsetColorLabel  = daemonsetLabelPrefix + "color"
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// This test must be run in serial because it assumes the Daemon Set pods will
0000000000000000000000000000000000000000;;	// always get scheduled.  If we run other tests in parallel, this may not
0000000000000000000000000000000000000000;;	// happen.  In the future, running in parallel may work if we have an eviction
0000000000000000000000000000000000000000;;	// model which lets the DS controller kick out other pods to make room.
0000000000000000000000000000000000000000;;	// See http://issues.k8s.io/21767 for more details
0000000000000000000000000000000000000000;;	var _ = SIGDescribe("Daemon set [Serial]", func() {
0000000000000000000000000000000000000000;;		var f *framework.Framework
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		AfterEach(func() {
0000000000000000000000000000000000000000;;			// Clean up
0000000000000000000000000000000000000000;;			daemonsets, err := f.ClientSet.Extensions().DaemonSets(f.Namespace.Name).List(metav1.ListOptions{})
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred(), "unable to dump DaemonSets")
0000000000000000000000000000000000000000;;			if daemonsets != nil && len(daemonsets.Items) > 0 {
0000000000000000000000000000000000000000;;				for _, ds := range daemonsets.Items {
0000000000000000000000000000000000000000;;					By(fmt.Sprintf("Deleting DaemonSet %q with reaper", ds.Name))
0000000000000000000000000000000000000000;;					dsReaper, err := kubectl.ReaperFor(extensionsinternal.Kind("DaemonSet"), f.InternalClientset)
0000000000000000000000000000000000000000;;					Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;					err = dsReaper.Stop(f.Namespace.Name, ds.Name, 0, nil)
0000000000000000000000000000000000000000;;					Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;					err = wait.PollImmediate(dsRetryPeriod, dsRetryTimeout, checkRunningOnNoNodes(f, &ds))
0000000000000000000000000000000000000000;;					Expect(err).NotTo(HaveOccurred(), "error waiting for daemon pod to be reaped")
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if daemonsets, err := f.ClientSet.Extensions().DaemonSets(f.Namespace.Name).List(metav1.ListOptions{}); err == nil {
0000000000000000000000000000000000000000;;				framework.Logf("daemonset: %s", runtime.EncodeOrDie(api.Codecs.LegacyCodec(api.Registry.EnabledVersions()...), daemonsets))
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				framework.Logf("unable to dump daemonsets: %v", err)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if pods, err := f.ClientSet.Core().Pods(f.Namespace.Name).List(metav1.ListOptions{}); err == nil {
0000000000000000000000000000000000000000;;				framework.Logf("pods: %s", runtime.EncodeOrDie(api.Codecs.LegacyCodec(api.Registry.EnabledVersions()...), pods))
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				framework.Logf("unable to dump pods: %v", err)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			err = clearDaemonSetNodeLabels(f.ClientSet)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		f = framework.NewDefaultFramework("daemonsets")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		image := framework.ServeHostnameImage
0000000000000000000000000000000000000000;;		dsName := "daemon-set"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		var ns string
0000000000000000000000000000000000000000;;		var c clientset.Interface
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		BeforeEach(func() {
0000000000000000000000000000000000000000;;			ns = f.Namespace.Name
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			c = f.ClientSet
0000000000000000000000000000000000000000;;			err := clearDaemonSetNodeLabels(c)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		It("should run and stop simple daemon", func() {
0000000000000000000000000000000000000000;;			label := map[string]string{daemonsetNameLabel: dsName}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By(fmt.Sprintf("Creating simple DaemonSet %q", dsName))
0000000000000000000000000000000000000000;;			ds, err := c.Extensions().DaemonSets(ns).Create(newDaemonSet(dsName, image, label))
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Check that daemon pods launch on every node of the cluster.")
0000000000000000000000000000000000000000;;			err = wait.PollImmediate(dsRetryPeriod, dsRetryTimeout, checkRunningOnAllNodes(f, ds))
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred(), "error waiting for daemon pod to start")
0000000000000000000000000000000000000000;;			err = checkDaemonStatus(f, dsName)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Stop a daemon pod, check that the daemon pod is revived.")
0000000000000000000000000000000000000000;;			podList := listDaemonPods(c, ns, label)
0000000000000000000000000000000000000000;;			pod := podList.Items[0]
0000000000000000000000000000000000000000;;			err = c.Core().Pods(ns).Delete(pod.Name, nil)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;			err = wait.PollImmediate(dsRetryPeriod, dsRetryTimeout, checkRunningOnAllNodes(f, ds))
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred(), "error waiting for daemon pod to revive")
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		It("should run and stop complex daemon", func() {
0000000000000000000000000000000000000000;;			complexLabel := map[string]string{daemonsetNameLabel: dsName}
0000000000000000000000000000000000000000;;			nodeSelector := map[string]string{daemonsetColorLabel: "blue"}
0000000000000000000000000000000000000000;;			framework.Logf("Creating daemon %q with a node selector", dsName)
0000000000000000000000000000000000000000;;			ds := newDaemonSet(dsName, image, complexLabel)
0000000000000000000000000000000000000000;;			ds.Spec.Template.Spec.NodeSelector = nodeSelector
0000000000000000000000000000000000000000;;			ds, err := c.Extensions().DaemonSets(ns).Create(ds)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Initially, daemon pods should not be running on any nodes.")
0000000000000000000000000000000000000000;;			err = wait.PollImmediate(dsRetryPeriod, dsRetryTimeout, checkRunningOnNoNodes(f, ds))
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred(), "error waiting for daemon pods to be running on no nodes")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Change node label to blue, check that daemon pod is launched.")
0000000000000000000000000000000000000000;;			nodeList := framework.GetReadySchedulableNodesOrDie(f.ClientSet)
0000000000000000000000000000000000000000;;			Expect(len(nodeList.Items)).To(BeNumerically(">", 0))
0000000000000000000000000000000000000000;;			newNode, err := setDaemonSetNodeLabels(c, nodeList.Items[0].Name, nodeSelector)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred(), "error setting labels on node")
0000000000000000000000000000000000000000;;			daemonSetLabels, _ := separateDaemonSetNodeLabels(newNode.Labels)
0000000000000000000000000000000000000000;;			Expect(len(daemonSetLabels)).To(Equal(1))
0000000000000000000000000000000000000000;;			err = wait.PollImmediate(dsRetryPeriod, dsRetryTimeout, checkDaemonPodOnNodes(f, ds, []string{newNode.Name}))
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred(), "error waiting for daemon pods to be running on new nodes")
0000000000000000000000000000000000000000;;			err = checkDaemonStatus(f, dsName)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Update the node label to green, and wait for daemons to be unscheduled")
0000000000000000000000000000000000000000;;			nodeSelector[daemonsetColorLabel] = "green"
0000000000000000000000000000000000000000;;			greenNode, err := setDaemonSetNodeLabels(c, nodeList.Items[0].Name, nodeSelector)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred(), "error removing labels on node")
0000000000000000000000000000000000000000;;			Expect(wait.PollImmediate(dsRetryPeriod, dsRetryTimeout, checkRunningOnNoNodes(f, ds))).
0000000000000000000000000000000000000000;;				NotTo(HaveOccurred(), "error waiting for daemon pod to not be running on nodes")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Update DaemonSet node selector to green, and change its update strategy to RollingUpdate")
0000000000000000000000000000000000000000;;			patch := fmt.Sprintf(`{"spec":{"template":{"spec":{"nodeSelector":{"%s":"%s"}}},"updateStrategy":{"type":"RollingUpdate"}}}`,
0000000000000000000000000000000000000000;;				daemonsetColorLabel, greenNode.Labels[daemonsetColorLabel])
0000000000000000000000000000000000000000;;			ds, err = c.Extensions().DaemonSets(ns).Patch(dsName, types.StrategicMergePatchType, []byte(patch))
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred(), "error patching daemon set")
0000000000000000000000000000000000000000;;			daemonSetLabels, _ = separateDaemonSetNodeLabels(greenNode.Labels)
0000000000000000000000000000000000000000;;			Expect(len(daemonSetLabels)).To(Equal(1))
0000000000000000000000000000000000000000;;			err = wait.PollImmediate(dsRetryPeriod, dsRetryTimeout, checkDaemonPodOnNodes(f, ds, []string{greenNode.Name}))
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred(), "error waiting for daemon pods to be running on new nodes")
0000000000000000000000000000000000000000;;			err = checkDaemonStatus(f, dsName)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		It("should run and stop complex daemon with node affinity", func() {
0000000000000000000000000000000000000000;;			complexLabel := map[string]string{daemonsetNameLabel: dsName}
0000000000000000000000000000000000000000;;			nodeSelector := map[string]string{daemonsetColorLabel: "blue"}
0000000000000000000000000000000000000000;;			framework.Logf("Creating daemon %q with a node affinity", dsName)
0000000000000000000000000000000000000000;;			ds := newDaemonSet(dsName, image, complexLabel)
0000000000000000000000000000000000000000;;			ds.Spec.Template.Spec.Affinity = &v1.Affinity{
0000000000000000000000000000000000000000;;				NodeAffinity: &v1.NodeAffinity{
0000000000000000000000000000000000000000;;					RequiredDuringSchedulingIgnoredDuringExecution: &v1.NodeSelector{
0000000000000000000000000000000000000000;;						NodeSelectorTerms: []v1.NodeSelectorTerm{
0000000000000000000000000000000000000000;;							{
0000000000000000000000000000000000000000;;								MatchExpressions: []v1.NodeSelectorRequirement{
0000000000000000000000000000000000000000;;									{
0000000000000000000000000000000000000000;;										Key:      daemonsetColorLabel,
0000000000000000000000000000000000000000;;										Operator: v1.NodeSelectorOpIn,
0000000000000000000000000000000000000000;;										Values:   []string{nodeSelector[daemonsetColorLabel]},
0000000000000000000000000000000000000000;;									},
0000000000000000000000000000000000000000;;								},
0000000000000000000000000000000000000000;;							},
0000000000000000000000000000000000000000;;						},
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			ds, err := c.Extensions().DaemonSets(ns).Create(ds)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Initially, daemon pods should not be running on any nodes.")
0000000000000000000000000000000000000000;;			err = wait.PollImmediate(dsRetryPeriod, dsRetryTimeout, checkRunningOnNoNodes(f, ds))
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred(), "error waiting for daemon pods to be running on no nodes")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Change node label to blue, check that daemon pod is launched.")
0000000000000000000000000000000000000000;;			nodeList := framework.GetReadySchedulableNodesOrDie(f.ClientSet)
0000000000000000000000000000000000000000;;			Expect(len(nodeList.Items)).To(BeNumerically(">", 0))
0000000000000000000000000000000000000000;;			newNode, err := setDaemonSetNodeLabels(c, nodeList.Items[0].Name, nodeSelector)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred(), "error setting labels on node")
0000000000000000000000000000000000000000;;			daemonSetLabels, _ := separateDaemonSetNodeLabels(newNode.Labels)
0000000000000000000000000000000000000000;;			Expect(len(daemonSetLabels)).To(Equal(1))
0000000000000000000000000000000000000000;;			err = wait.PollImmediate(dsRetryPeriod, dsRetryTimeout, checkDaemonPodOnNodes(f, ds, []string{newNode.Name}))
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred(), "error waiting for daemon pods to be running on new nodes")
0000000000000000000000000000000000000000;;			err = checkDaemonStatus(f, dsName)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Remove the node label and wait for daemons to be unscheduled")
0000000000000000000000000000000000000000;;			_, err = setDaemonSetNodeLabels(c, nodeList.Items[0].Name, map[string]string{})
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred(), "error removing labels on node")
0000000000000000000000000000000000000000;;			Expect(wait.PollImmediate(dsRetryPeriod, dsRetryTimeout, checkRunningOnNoNodes(f, ds))).
0000000000000000000000000000000000000000;;				NotTo(HaveOccurred(), "error waiting for daemon pod to not be running on nodes")
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		It("should retry creating failed daemon pods", func() {
0000000000000000000000000000000000000000;;			label := map[string]string{daemonsetNameLabel: dsName}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By(fmt.Sprintf("Creating a simple DaemonSet %q", dsName))
0000000000000000000000000000000000000000;;			ds, err := c.Extensions().DaemonSets(ns).Create(newDaemonSet(dsName, image, label))
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Check that daemon pods launch on every node of the cluster.")
0000000000000000000000000000000000000000;;			err = wait.PollImmediate(dsRetryPeriod, dsRetryTimeout, checkRunningOnAllNodes(f, ds))
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred(), "error waiting for daemon pod to start")
0000000000000000000000000000000000000000;;			err = checkDaemonStatus(f, dsName)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.")
0000000000000000000000000000000000000000;;			podList := listDaemonPods(c, ns, label)
0000000000000000000000000000000000000000;;			pod := podList.Items[0]
0000000000000000000000000000000000000000;;			pod.ResourceVersion = ""
0000000000000000000000000000000000000000;;			pod.Status.Phase = v1.PodFailed
0000000000000000000000000000000000000000;;			_, err = c.Core().Pods(ns).UpdateStatus(&pod)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred(), "error failing a daemon pod")
0000000000000000000000000000000000000000;;			err = wait.PollImmediate(dsRetryPeriod, dsRetryTimeout, checkRunningOnAllNodes(f, ds))
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred(), "error waiting for daemon pod to revive")
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		It("Should not update pod when spec was updated and update strategy is OnDelete", func() {
0000000000000000000000000000000000000000;;			label := map[string]string{daemonsetNameLabel: dsName}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			framework.Logf("Creating simple daemon set %s", dsName)
0000000000000000000000000000000000000000;;			ds, err := c.Extensions().DaemonSets(ns).Create(newDaemonSet(dsName, image, label))
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;			Expect(ds.Spec.TemplateGeneration).To(Equal(int64(1)))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Check that daemon pods launch on every node of the cluster.")
0000000000000000000000000000000000000000;;			err = wait.PollImmediate(dsRetryPeriod, dsRetryTimeout, checkRunningOnAllNodes(f, ds))
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred(), "error waiting for daemon pod to start")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Make sure all daemon pods have correct template generation 1")
0000000000000000000000000000000000000000;;			templateGeneration := "1"
0000000000000000000000000000000000000000;;			err = checkDaemonPodsTemplateGeneration(c, ns, label, "1")
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Check history and labels
0000000000000000000000000000000000000000;;			ds, err = c.Extensions().DaemonSets(ns).Get(ds.Name, metav1.GetOptions{})
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;			first := curHistory(listDaemonHistories(c, ns, label), ds)
0000000000000000000000000000000000000000;;			firstHash := first.Labels[extensions.DefaultDaemonSetUniqueLabelKey]
0000000000000000000000000000000000000000;;			Expect(first.Revision).To(Equal(int64(1)))
0000000000000000000000000000000000000000;;			checkDaemonSetPodsLabels(listDaemonPods(c, ns, label), firstHash, templateGeneration)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Update daemon pods image.")
0000000000000000000000000000000000000000;;			patch := getDaemonSetImagePatch(ds.Spec.Template.Spec.Containers[0].Name, RedisImage)
0000000000000000000000000000000000000000;;			ds, err = c.Extensions().DaemonSets(ns).Patch(dsName, types.StrategicMergePatchType, []byte(patch))
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;			Expect(ds.Spec.TemplateGeneration).To(Equal(int64(2)))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Check that daemon pods images aren't updated.")
0000000000000000000000000000000000000000;;			err = wait.PollImmediate(dsRetryPeriod, dsRetryTimeout, checkDaemonPodsImageAndAvailability(c, ds, image, 0))
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Make sure all daemon pods have correct template generation 1")
0000000000000000000000000000000000000000;;			err = checkDaemonPodsTemplateGeneration(c, ns, label, templateGeneration)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Check that daemon pods are still running on every node of the cluster.")
0000000000000000000000000000000000000000;;			err = wait.PollImmediate(dsRetryPeriod, dsRetryTimeout, checkRunningOnAllNodes(f, ds))
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred(), "error waiting for daemon pod to start")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Check history and labels
0000000000000000000000000000000000000000;;			ds, err = c.Extensions().DaemonSets(ns).Get(ds.Name, metav1.GetOptions{})
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;			cur := curHistory(listDaemonHistories(c, ns, label), ds)
0000000000000000000000000000000000000000;;			Expect(cur.Revision).To(Equal(int64(2)))
0000000000000000000000000000000000000000;;			Expect(cur.Labels[extensions.DefaultDaemonSetUniqueLabelKey]).NotTo(Equal(firstHash))
0000000000000000000000000000000000000000;;			checkDaemonSetPodsLabels(listDaemonPods(c, ns, label), firstHash, templateGeneration)
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		It("Should update pod when spec was updated and update strategy is RollingUpdate", func() {
0000000000000000000000000000000000000000;;			label := map[string]string{daemonsetNameLabel: dsName}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			templateGeneration := int64(999)
0000000000000000000000000000000000000000;;			framework.Logf("Creating simple daemon set %s with templateGeneration %d", dsName, templateGeneration)
0000000000000000000000000000000000000000;;			ds := newDaemonSet(dsName, image, label)
0000000000000000000000000000000000000000;;			ds.Spec.TemplateGeneration = templateGeneration
0000000000000000000000000000000000000000;;			ds.Spec.UpdateStrategy = extensions.DaemonSetUpdateStrategy{Type: extensions.RollingUpdateDaemonSetStrategyType}
0000000000000000000000000000000000000000;;			ds, err := c.Extensions().DaemonSets(ns).Create(ds)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;			Expect(ds.Spec.TemplateGeneration).To(Equal(templateGeneration))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Check that daemon pods launch on every node of the cluster.")
0000000000000000000000000000000000000000;;			err = wait.PollImmediate(dsRetryPeriod, dsRetryTimeout, checkRunningOnAllNodes(f, ds))
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred(), "error waiting for daemon pod to start")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By(fmt.Sprintf("Make sure all daemon pods have correct template generation %d", templateGeneration))
0000000000000000000000000000000000000000;;			err = checkDaemonPodsTemplateGeneration(c, ns, label, fmt.Sprint(templateGeneration))
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Check history and labels
0000000000000000000000000000000000000000;;			ds, err = c.Extensions().DaemonSets(ns).Get(ds.Name, metav1.GetOptions{})
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;			cur := curHistory(listDaemonHistories(c, ns, label), ds)
0000000000000000000000000000000000000000;;			hash := cur.Labels[extensions.DefaultDaemonSetUniqueLabelKey]
0000000000000000000000000000000000000000;;			Expect(cur.Revision).To(Equal(int64(1)))
0000000000000000000000000000000000000000;;			checkDaemonSetPodsLabels(listDaemonPods(c, ns, label), hash, fmt.Sprint(templateGeneration))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Update daemon pods image.")
0000000000000000000000000000000000000000;;			patch := getDaemonSetImagePatch(ds.Spec.Template.Spec.Containers[0].Name, RedisImage)
0000000000000000000000000000000000000000;;			ds, err = c.Extensions().DaemonSets(ns).Patch(dsName, types.StrategicMergePatchType, []byte(patch))
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;			templateGeneration++
0000000000000000000000000000000000000000;;			Expect(ds.Spec.TemplateGeneration).To(Equal(templateGeneration))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Check that daemon pods images are updated.")
0000000000000000000000000000000000000000;;			err = wait.PollImmediate(dsRetryPeriod, dsRetryTimeout, checkDaemonPodsImageAndAvailability(c, ds, RedisImage, 1))
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By(fmt.Sprintf("Make sure all daemon pods have correct template generation %d", templateGeneration))
0000000000000000000000000000000000000000;;			err = checkDaemonPodsTemplateGeneration(c, ns, label, fmt.Sprint(templateGeneration))
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Check that daemon pods are still running on every node of the cluster.")
0000000000000000000000000000000000000000;;			err = wait.PollImmediate(dsRetryPeriod, dsRetryTimeout, checkRunningOnAllNodes(f, ds))
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred(), "error waiting for daemon pod to start")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Check history and labels
0000000000000000000000000000000000000000;;			ds, err = c.Extensions().DaemonSets(ns).Get(ds.Name, metav1.GetOptions{})
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;			cur = curHistory(listDaemonHistories(c, ns, label), ds)
0000000000000000000000000000000000000000;;			hash = cur.Labels[extensions.DefaultDaemonSetUniqueLabelKey]
0000000000000000000000000000000000000000;;			Expect(cur.Revision).To(Equal(int64(2)))
0000000000000000000000000000000000000000;;			checkDaemonSetPodsLabels(listDaemonPods(c, ns, label), hash, fmt.Sprint(templateGeneration))
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		It("Should adopt existing pods when creating a RollingUpdate DaemonSet regardless of templateGeneration", func() {
0000000000000000000000000000000000000000;;			label := map[string]string{daemonsetNameLabel: dsName}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// 1. Create a RollingUpdate DaemonSet
0000000000000000000000000000000000000000;;			templateGeneration := int64(999)
0000000000000000000000000000000000000000;;			framework.Logf("Creating simple RollingUpdate DaemonSet %s with templateGeneration %d", dsName, templateGeneration)
0000000000000000000000000000000000000000;;			ds := newDaemonSet(dsName, image, label)
0000000000000000000000000000000000000000;;			ds.Spec.TemplateGeneration = templateGeneration
0000000000000000000000000000000000000000;;			ds.Spec.UpdateStrategy = extensions.DaemonSetUpdateStrategy{Type: extensions.RollingUpdateDaemonSetStrategyType}
0000000000000000000000000000000000000000;;			ds, err := c.Extensions().DaemonSets(ns).Create(ds)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;			Expect(ds.Spec.TemplateGeneration).To(Equal(templateGeneration))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			framework.Logf("Check that daemon pods launch on every node of the cluster.")
0000000000000000000000000000000000000000;;			err = wait.PollImmediate(dsRetryPeriod, dsRetryTimeout, checkRunningOnAllNodes(f, ds))
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred(), "error waiting for daemon pod to start")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			framework.Logf("Make sure all daemon pods have correct template generation %d", templateGeneration)
0000000000000000000000000000000000000000;;			err = checkDaemonPodsTemplateGeneration(c, ns, label, fmt.Sprint(templateGeneration))
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// 2. Orphan DaemonSet pods
0000000000000000000000000000000000000000;;			framework.Logf("Deleting DaemonSet %s and orphaning its pods and history", dsName)
0000000000000000000000000000000000000000;;			deleteDaemonSetAndOrphan(c, ds)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// 3. Adopt DaemonSet pods (no restart)
0000000000000000000000000000000000000000;;			newDSName := "adopt"
0000000000000000000000000000000000000000;;			framework.Logf("Creating a new RollingUpdate DaemonSet %s to adopt pods", newDSName)
0000000000000000000000000000000000000000;;			newDS := newDaemonSet(newDSName, image, label)
0000000000000000000000000000000000000000;;			newDS.Spec.TemplateGeneration = templateGeneration
0000000000000000000000000000000000000000;;			newDS.Spec.UpdateStrategy = extensions.DaemonSetUpdateStrategy{Type: extensions.RollingUpdateDaemonSetStrategyType}
0000000000000000000000000000000000000000;;			newDS, err = c.Extensions().DaemonSets(ns).Create(newDS)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;			Expect(newDS.Spec.TemplateGeneration).To(Equal(templateGeneration))
0000000000000000000000000000000000000000;;			Expect(apiequality.Semantic.DeepEqual(newDS.Spec.Template, ds.Spec.Template)).To(BeTrue(), "DaemonSet template should match to adopt pods")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			framework.Logf("Wait for pods and history to be adopted by DaemonSet %s", newDS.Name)
0000000000000000000000000000000000000000;;			waitDaemonSetAdoption(c, newDS, ds.Name, templateGeneration)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// 4. Orphan DaemonSet pods again
0000000000000000000000000000000000000000;;			framework.Logf("Deleting DaemonSet %s and orphaning its pods and history", newDSName)
0000000000000000000000000000000000000000;;			deleteDaemonSetAndOrphan(c, newDS)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// 5. Adopt DaemonSet pods (no restart) as long as template matches, even when templateGeneration doesn't match
0000000000000000000000000000000000000000;;			newAdoptDSName := "adopt-template-matches"
0000000000000000000000000000000000000000;;			framework.Logf("Creating a new RollingUpdate DaemonSet %s to adopt pods", newAdoptDSName)
0000000000000000000000000000000000000000;;			newAdoptDS := newDaemonSet(newAdoptDSName, image, label)
0000000000000000000000000000000000000000;;			newAdoptDS.Spec.UpdateStrategy = extensions.DaemonSetUpdateStrategy{Type: extensions.RollingUpdateDaemonSetStrategyType}
0000000000000000000000000000000000000000;;			newAdoptDS, err = c.Extensions().DaemonSets(ns).Create(newAdoptDS)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;			Expect(newAdoptDS.Spec.TemplateGeneration).To(Equal(int64(1)))
0000000000000000000000000000000000000000;;			Expect(newAdoptDS.Spec.TemplateGeneration).NotTo(Equal(templateGeneration))
0000000000000000000000000000000000000000;;			Expect(apiequality.Semantic.DeepEqual(newAdoptDS.Spec.Template, newDS.Spec.Template)).To(BeTrue(), "DaemonSet template should match to adopt pods")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			framework.Logf(fmt.Sprintf("Wait for pods and history to be adopted by DaemonSet %s", newAdoptDS.Name))
0000000000000000000000000000000000000000;;			waitDaemonSetAdoption(c, newAdoptDS, ds.Name, templateGeneration)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// 6. Orphan DaemonSet pods again
0000000000000000000000000000000000000000;;			framework.Logf("Deleting DaemonSet %s and orphaning its pods and history", newAdoptDSName)
0000000000000000000000000000000000000000;;			deleteDaemonSetAndOrphan(c, newAdoptDS)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// 7. Adopt DaemonSet pods (no restart) as long as templateGeneration matches, even when template doesn't match
0000000000000000000000000000000000000000;;			newAdoptDSName = "adopt-template-generation-matches"
0000000000000000000000000000000000000000;;			framework.Logf("Creating a new RollingUpdate DaemonSet %s to adopt pods", newAdoptDSName)
0000000000000000000000000000000000000000;;			newAdoptDS = newDaemonSet(newAdoptDSName, image, label)
0000000000000000000000000000000000000000;;			newAdoptDS.Spec.Template.Spec.Containers[0].Name = "not-match"
0000000000000000000000000000000000000000;;			newAdoptDS.Spec.UpdateStrategy = extensions.DaemonSetUpdateStrategy{Type: extensions.RollingUpdateDaemonSetStrategyType}
0000000000000000000000000000000000000000;;			newAdoptDS.Spec.TemplateGeneration = templateGeneration
0000000000000000000000000000000000000000;;			newAdoptDS, err = c.Extensions().DaemonSets(ns).Create(newAdoptDS)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;			Expect(newAdoptDS.Spec.TemplateGeneration).To(Equal(templateGeneration))
0000000000000000000000000000000000000000;;			Expect(apiequality.Semantic.DeepEqual(newAdoptDS.Spec.Template, newDS.Spec.Template)).NotTo(BeTrue(), "DaemonSet template should not match")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			framework.Logf("Wait for pods and history to be adopted by DaemonSet %s", newAdoptDS.Name)
0000000000000000000000000000000000000000;;			waitDaemonSetAdoption(c, newAdoptDS, ds.Name, templateGeneration)
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		It("Should rollback without unnecessary restarts", func() {
0000000000000000000000000000000000000000;;			// Skip clusters with only one node, where we cannot have half-done DaemonSet rollout for this test
0000000000000000000000000000000000000000;;			framework.SkipUnlessNodeCountIsAtLeast(2)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			framework.Logf("Create a RollingUpdate DaemonSet")
0000000000000000000000000000000000000000;;			label := map[string]string{daemonsetNameLabel: dsName}
0000000000000000000000000000000000000000;;			ds := newDaemonSet(dsName, image, label)
0000000000000000000000000000000000000000;;			ds.Spec.UpdateStrategy = extensions.DaemonSetUpdateStrategy{Type: extensions.RollingUpdateDaemonSetStrategyType}
0000000000000000000000000000000000000000;;			ds, err := c.Extensions().DaemonSets(ns).Create(ds)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			framework.Logf("Check that daemon pods launch on every node of the cluster")
0000000000000000000000000000000000000000;;			err = wait.PollImmediate(dsRetryPeriod, dsRetryTimeout, checkRunningOnAllNodes(f, ds))
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred(), "error waiting for daemon pod to start")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			framework.Logf("Update the DaemonSet to trigger a rollout")
0000000000000000000000000000000000000000;;			// We use a nonexistent image here, so that we make sure it won't finish
0000000000000000000000000000000000000000;;			newImage := "foo:non-existent"
0000000000000000000000000000000000000000;;			newDS, err := framework.UpdateDaemonSetWithRetries(c, ns, ds.Name, func(update *extensions.DaemonSet) {
0000000000000000000000000000000000000000;;				update.Spec.Template.Spec.Containers[0].Image = newImage
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Make sure we're in the middle of a rollout
0000000000000000000000000000000000000000;;			err = wait.PollImmediate(dsRetryPeriod, dsRetryTimeout, checkAtLeastOneNewPod(c, ns, label, newImage))
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			pods := listDaemonPods(c, ns, label)
0000000000000000000000000000000000000000;;			var existingPods, newPods []*v1.Pod
0000000000000000000000000000000000000000;;			for i := range pods.Items {
0000000000000000000000000000000000000000;;				pod := pods.Items[i]
0000000000000000000000000000000000000000;;				image := pod.Spec.Containers[0].Image
0000000000000000000000000000000000000000;;				switch image {
0000000000000000000000000000000000000000;;				case ds.Spec.Template.Spec.Containers[0].Image:
0000000000000000000000000000000000000000;;					existingPods = append(existingPods, &pod)
0000000000000000000000000000000000000000;;				case newDS.Spec.Template.Spec.Containers[0].Image:
0000000000000000000000000000000000000000;;					newPods = append(newPods, &pod)
0000000000000000000000000000000000000000;;				default:
0000000000000000000000000000000000000000;;					framework.Failf("unexpected pod found, image = %s", image)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			Expect(len(existingPods)).NotTo(Equal(0))
0000000000000000000000000000000000000000;;			Expect(len(newPods)).NotTo(Equal(0))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			framework.Logf("Roll back the DaemonSet before rollout is complete")
0000000000000000000000000000000000000000;;			rollbackDS, err := framework.UpdateDaemonSetWithRetries(c, ns, ds.Name, func(update *extensions.DaemonSet) {
0000000000000000000000000000000000000000;;				update.Spec.Template.Spec.Containers[0].Image = image
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			framework.Logf("Make sure DaemonSet rollback is complete")
0000000000000000000000000000000000000000;;			err = wait.PollImmediate(dsRetryPeriod, dsRetryTimeout, checkDaemonPodsImageAndAvailability(c, rollbackDS, image, 1))
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// After rollback is done, compare current pods with previous old pods during rollout, to make sure they're not restarted
0000000000000000000000000000000000000000;;			pods = listDaemonPods(c, ns, label)
0000000000000000000000000000000000000000;;			rollbackPods := map[string]bool{}
0000000000000000000000000000000000000000;;			for _, pod := range pods.Items {
0000000000000000000000000000000000000000;;				rollbackPods[pod.Name] = true
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			for _, pod := range existingPods {
0000000000000000000000000000000000000000;;				Expect(rollbackPods[pod.Name]).To(BeTrue(), fmt.Sprintf("unexpected pod %s be restarted", pod.Name))
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// getDaemonSetImagePatch generates a patch for updating a DaemonSet's container image
0000000000000000000000000000000000000000;;	func getDaemonSetImagePatch(containerName, containerImage string) string {
0000000000000000000000000000000000000000;;		return fmt.Sprintf(`{"spec":{"template":{"spec":{"containers":[{"name":"%s","image":"%s"}]}}}}`, containerName, containerImage)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// deleteDaemonSetAndOrphan deletes the given DaemonSet and orphans all its dependents.
0000000000000000000000000000000000000000;;	// It also checks that all dependents are orphaned, and the DaemonSet is deleted.
0000000000000000000000000000000000000000;;	func deleteDaemonSetAndOrphan(c clientset.Interface, ds *extensions.DaemonSet) {
0000000000000000000000000000000000000000;;		trueVar := true
0000000000000000000000000000000000000000;;		deleteOptions := &metav1.DeleteOptions{OrphanDependents: &trueVar}
0000000000000000000000000000000000000000;;		deleteOptions.Preconditions = metav1.NewUIDPreconditions(string(ds.UID))
0000000000000000000000000000000000000000;;		err := c.Extensions().DaemonSets(ds.Namespace).Delete(ds.Name, deleteOptions)
0000000000000000000000000000000000000000;;		Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		err = wait.PollImmediate(dsRetryPeriod, dsRetryTimeout, checkDaemonSetPodsOrphaned(c, ds.Namespace, ds.Spec.Template.Labels))
0000000000000000000000000000000000000000;;		Expect(err).NotTo(HaveOccurred(), "error waiting for DaemonSet pods to be orphaned")
0000000000000000000000000000000000000000;;		err = wait.PollImmediate(dsRetryPeriod, dsRetryTimeout, checkDaemonSetHistoryOrphaned(c, ds.Namespace, ds.Spec.Template.Labels))
0000000000000000000000000000000000000000;;		Expect(err).NotTo(HaveOccurred(), "error waiting for DaemonSet history to be orphaned")
0000000000000000000000000000000000000000;;		err = wait.PollImmediate(dsRetryPeriod, dsRetryTimeout, checkDaemonSetDeleted(c, ds.Namespace, ds.Name))
0000000000000000000000000000000000000000;;		Expect(err).NotTo(HaveOccurred(), "error waiting for DaemonSet to be deleted")
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func newDaemonSet(dsName, image string, label map[string]string) *extensions.DaemonSet {
0000000000000000000000000000000000000000;;		return &extensions.DaemonSet{
0000000000000000000000000000000000000000;;			ObjectMeta: metav1.ObjectMeta{
0000000000000000000000000000000000000000;;				Name: dsName,
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			Spec: extensions.DaemonSetSpec{
0000000000000000000000000000000000000000;;				Template: v1.PodTemplateSpec{
0000000000000000000000000000000000000000;;					ObjectMeta: metav1.ObjectMeta{
0000000000000000000000000000000000000000;;						Labels: label,
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;					Spec: v1.PodSpec{
0000000000000000000000000000000000000000;;						Containers: []v1.Container{
0000000000000000000000000000000000000000;;							{
0000000000000000000000000000000000000000;;								Name:  "app",
0000000000000000000000000000000000000000;;								Image: image,
0000000000000000000000000000000000000000;;								Ports: []v1.ContainerPort{{ContainerPort: 9376}},
0000000000000000000000000000000000000000;;							},
0000000000000000000000000000000000000000;;						},
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func listDaemonPods(c clientset.Interface, ns string, label map[string]string) *v1.PodList {
0000000000000000000000000000000000000000;;		selector := labels.Set(label).AsSelector()
0000000000000000000000000000000000000000;;		options := metav1.ListOptions{LabelSelector: selector.String()}
0000000000000000000000000000000000000000;;		podList, err := c.Core().Pods(ns).List(options)
0000000000000000000000000000000000000000;;		Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;		Expect(len(podList.Items)).To(BeNumerically(">", 0))
0000000000000000000000000000000000000000;;		return podList
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func separateDaemonSetNodeLabels(labels map[string]string) (map[string]string, map[string]string) {
0000000000000000000000000000000000000000;;		daemonSetLabels := map[string]string{}
0000000000000000000000000000000000000000;;		otherLabels := map[string]string{}
0000000000000000000000000000000000000000;;		for k, v := range labels {
0000000000000000000000000000000000000000;;			if strings.HasPrefix(k, daemonsetLabelPrefix) {
0000000000000000000000000000000000000000;;				daemonSetLabels[k] = v
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				otherLabels[k] = v
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return daemonSetLabels, otherLabels
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func clearDaemonSetNodeLabels(c clientset.Interface) error {
0000000000000000000000000000000000000000;;		nodeList := framework.GetReadySchedulableNodesOrDie(c)
0000000000000000000000000000000000000000;;		for _, node := range nodeList.Items {
0000000000000000000000000000000000000000;;			_, err := setDaemonSetNodeLabels(c, node.Name, map[string]string{})
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				return err
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func setDaemonSetNodeLabels(c clientset.Interface, nodeName string, labels map[string]string) (*v1.Node, error) {
0000000000000000000000000000000000000000;;		nodeClient := c.Core().Nodes()
0000000000000000000000000000000000000000;;		var newNode *v1.Node
0000000000000000000000000000000000000000;;		var newLabels map[string]string
0000000000000000000000000000000000000000;;		err := wait.PollImmediate(dsRetryPeriod, dsRetryTimeout, func() (bool, error) {
0000000000000000000000000000000000000000;;			node, err := nodeClient.Get(nodeName, metav1.GetOptions{})
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				return false, err
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// remove all labels this test is creating
0000000000000000000000000000000000000000;;			daemonSetLabels, otherLabels := separateDaemonSetNodeLabels(node.Labels)
0000000000000000000000000000000000000000;;			if reflect.DeepEqual(daemonSetLabels, labels) {
0000000000000000000000000000000000000000;;				newNode = node
0000000000000000000000000000000000000000;;				return true, nil
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			node.Labels = otherLabels
0000000000000000000000000000000000000000;;			for k, v := range labels {
0000000000000000000000000000000000000000;;				node.Labels[k] = v
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			newNode, err = nodeClient.Update(node)
0000000000000000000000000000000000000000;;			if err == nil {
0000000000000000000000000000000000000000;;				newLabels, _ = separateDaemonSetNodeLabels(newNode.Labels)
0000000000000000000000000000000000000000;;				return true, err
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if se, ok := err.(*apierrs.StatusError); ok && se.ErrStatus.Reason == metav1.StatusReasonConflict {
0000000000000000000000000000000000000000;;				framework.Logf("failed to update node due to resource version conflict")
0000000000000000000000000000000000000000;;				return false, nil
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			return false, err
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return nil, err
0000000000000000000000000000000000000000;;		} else if len(newLabels) != len(labels) {
0000000000000000000000000000000000000000;;			return nil, fmt.Errorf("Could not set daemon set test labels as expected.")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return newNode, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func checkDaemonPodOnNodes(f *framework.Framework, ds *extensions.DaemonSet, nodeNames []string) func() (bool, error) {
0000000000000000000000000000000000000000;;		return func() (bool, error) {
0000000000000000000000000000000000000000;;			podList, err := f.ClientSet.Core().Pods(f.Namespace.Name).List(metav1.ListOptions{})
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				framework.Logf("could not get the pod list: %v", err)
0000000000000000000000000000000000000000;;				return false, nil
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			pods := podList.Items
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			nodesToPodCount := make(map[string]int)
0000000000000000000000000000000000000000;;			for _, pod := range pods {
0000000000000000000000000000000000000000;;				if controllerRef := controller.GetControllerOf(&pod); controllerRef == nil || controllerRef.UID != ds.UID {
0000000000000000000000000000000000000000;;					continue
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				if pod.DeletionTimestamp != nil {
0000000000000000000000000000000000000000;;					continue
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				if podutil.IsPodAvailable(&pod, ds.Spec.MinReadySeconds, metav1.Now()) {
0000000000000000000000000000000000000000;;					nodesToPodCount[pod.Spec.NodeName] += 1
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			framework.Logf("Number of nodes with available pods: %d", len(nodesToPodCount))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Ensure that exactly 1 pod is running on all nodes in nodeNames.
0000000000000000000000000000000000000000;;			for _, nodeName := range nodeNames {
0000000000000000000000000000000000000000;;				if nodesToPodCount[nodeName] != 1 {
0000000000000000000000000000000000000000;;					framework.Logf("Node %s is running more than one daemon pod", nodeName)
0000000000000000000000000000000000000000;;					return false, nil
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			framework.Logf("Number of running nodes: %d, number of available pods: %d", len(nodeNames), len(nodesToPodCount))
0000000000000000000000000000000000000000;;			// Ensure that sizes of the lists are the same. We've verified that every element of nodeNames is in
0000000000000000000000000000000000000000;;			// nodesToPodCount, so verifying the lengths are equal ensures that there aren't pods running on any
0000000000000000000000000000000000000000;;			// other nodes.
0000000000000000000000000000000000000000;;			return len(nodesToPodCount) == len(nodeNames), nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func checkRunningOnAllNodes(f *framework.Framework, ds *extensions.DaemonSet) func() (bool, error) {
0000000000000000000000000000000000000000;;		return func() (bool, error) {
0000000000000000000000000000000000000000;;			nodeList, err := f.ClientSet.Core().Nodes().List(metav1.ListOptions{})
0000000000000000000000000000000000000000;;			framework.ExpectNoError(err)
0000000000000000000000000000000000000000;;			nodeNames := make([]string, 0)
0000000000000000000000000000000000000000;;			for _, node := range nodeList.Items {
0000000000000000000000000000000000000000;;				if !canScheduleOnNode(node, ds) {
0000000000000000000000000000000000000000;;					framework.Logf("DaemonSet pods can't tolerate node %s with taints %+v, skip checking this node", node.Name, node.Spec.Taints)
0000000000000000000000000000000000000000;;					continue
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				nodeNames = append(nodeNames, node.Name)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			return checkDaemonPodOnNodes(f, ds, nodeNames)()
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func checkAtLeastOneNewPod(c clientset.Interface, ns string, label map[string]string, newImage string) func() (bool, error) {
0000000000000000000000000000000000000000;;		return func() (bool, error) {
0000000000000000000000000000000000000000;;			pods := listDaemonPods(c, ns, label)
0000000000000000000000000000000000000000;;			for _, pod := range pods.Items {
0000000000000000000000000000000000000000;;				if pod.Spec.Containers[0].Image == newImage {
0000000000000000000000000000000000000000;;					return true, nil
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			return false, nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// canScheduleOnNode checks if a given DaemonSet can schedule pods on the given node
0000000000000000000000000000000000000000;;	func canScheduleOnNode(node v1.Node, ds *extensions.DaemonSet) bool {
0000000000000000000000000000000000000000;;		newPod := daemon.NewPod(ds, node.Name)
0000000000000000000000000000000000000000;;		nodeInfo := schedulercache.NewNodeInfo()
0000000000000000000000000000000000000000;;		nodeInfo.SetNode(&node)
0000000000000000000000000000000000000000;;		fit, _, err := daemon.Predicates(newPod, nodeInfo)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			framework.Failf("Can't test DaemonSet predicates for node %s: %v", node.Name, err)
0000000000000000000000000000000000000000;;			return false
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return fit
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func checkRunningOnNoNodes(f *framework.Framework, ds *extensions.DaemonSet) func() (bool, error) {
0000000000000000000000000000000000000000;;		return checkDaemonPodOnNodes(f, ds, make([]string, 0))
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func checkDaemonStatus(f *framework.Framework, dsName string) error {
0000000000000000000000000000000000000000;;		ds, err := f.ClientSet.Extensions().DaemonSets(f.Namespace.Name).Get(dsName, metav1.GetOptions{})
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return fmt.Errorf("Could not get daemon set from v1.")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		desired, scheduled, ready := ds.Status.DesiredNumberScheduled, ds.Status.CurrentNumberScheduled, ds.Status.NumberReady
0000000000000000000000000000000000000000;;		if desired != scheduled && desired != ready {
0000000000000000000000000000000000000000;;			return fmt.Errorf("Error in daemon status. DesiredScheduled: %d, CurrentScheduled: %d, Ready: %d", desired, scheduled, ready)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func checkDaemonPodsImageAndAvailability(c clientset.Interface, ds *extensions.DaemonSet, image string, maxUnavailable int) func() (bool, error) {
0000000000000000000000000000000000000000;;		return func() (bool, error) {
0000000000000000000000000000000000000000;;			podList, err := c.Core().Pods(ds.Namespace).List(metav1.ListOptions{})
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				return false, err
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			pods := podList.Items
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			unavailablePods := 0
0000000000000000000000000000000000000000;;			allImagesUpdated := true
0000000000000000000000000000000000000000;;			for _, pod := range pods {
0000000000000000000000000000000000000000;;				if controllerRef := controller.GetControllerOf(&pod); controllerRef == nil || controllerRef.UID != ds.UID {
0000000000000000000000000000000000000000;;					continue
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				podImage := pod.Spec.Containers[0].Image
0000000000000000000000000000000000000000;;				if podImage != image {
0000000000000000000000000000000000000000;;					allImagesUpdated = false
0000000000000000000000000000000000000000;;					framework.Logf("Wrong image for pod: %s. Expected: %s, got: %s.", pod.Name, image, podImage)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				if !podutil.IsPodAvailable(&pod, ds.Spec.MinReadySeconds, metav1.Now()) {
0000000000000000000000000000000000000000;;					framework.Logf("Pod %s is not available", pod.Name)
0000000000000000000000000000000000000000;;					unavailablePods++
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if unavailablePods > maxUnavailable {
0000000000000000000000000000000000000000;;				return false, fmt.Errorf("number of unavailable pods: %d is greater than maxUnavailable: %d", unavailablePods, maxUnavailable)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if !allImagesUpdated {
0000000000000000000000000000000000000000;;				return false, nil
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			return true, nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func checkDaemonPodsTemplateGeneration(c clientset.Interface, ns string, label map[string]string, templateGeneration string) error {
0000000000000000000000000000000000000000;;		pods := listDaemonPods(c, ns, label)
0000000000000000000000000000000000000000;;		for _, pod := range pods.Items {
0000000000000000000000000000000000000000;;			// We don't care about inactive pods
0000000000000000000000000000000000000000;;			if !controller.IsPodActive(&pod) {
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			podTemplateGeneration := pod.Labels[extensions.DaemonSetTemplateGenerationKey]
0000000000000000000000000000000000000000;;			if podTemplateGeneration != templateGeneration {
0000000000000000000000000000000000000000;;				return fmt.Errorf("expected pod %s/%s template generation %s, but got %s", pod.Namespace, pod.Name, templateGeneration, podTemplateGeneration)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func checkDaemonSetDeleted(c clientset.Interface, ns, name string) func() (bool, error) {
0000000000000000000000000000000000000000;;		return func() (bool, error) {
0000000000000000000000000000000000000000;;			_, err := c.Extensions().DaemonSets(ns).Get(name, metav1.GetOptions{})
0000000000000000000000000000000000000000;;			if !apierrs.IsNotFound(err) {
0000000000000000000000000000000000000000;;				return false, err
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			return true, nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func checkDaemonSetPodsOrphaned(c clientset.Interface, ns string, label map[string]string) func() (bool, error) {
0000000000000000000000000000000000000000;;		return func() (bool, error) {
0000000000000000000000000000000000000000;;			pods := listDaemonPods(c, ns, label)
0000000000000000000000000000000000000000;;			for _, pod := range pods.Items {
0000000000000000000000000000000000000000;;				// This pod is orphaned only when controller ref is cleared
0000000000000000000000000000000000000000;;				if controllerRef := controller.GetControllerOf(&pod); controllerRef != nil {
0000000000000000000000000000000000000000;;					return false, nil
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			return true, nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func checkDaemonSetHistoryOrphaned(c clientset.Interface, ns string, label map[string]string) func() (bool, error) {
0000000000000000000000000000000000000000;;		return func() (bool, error) {
0000000000000000000000000000000000000000;;			histories := listDaemonHistories(c, ns, label)
0000000000000000000000000000000000000000;;			for _, history := range histories.Items {
0000000000000000000000000000000000000000;;				// This history is orphaned only when controller ref is cleared
0000000000000000000000000000000000000000;;				if controllerRef := controller.GetControllerOf(&history); controllerRef != nil {
0000000000000000000000000000000000000000;;					return false, nil
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			return true, nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func checkDaemonSetPodsAdopted(c clientset.Interface, ns string, dsUID types.UID, label map[string]string) func() (bool, error) {
0000000000000000000000000000000000000000;;		return func() (bool, error) {
0000000000000000000000000000000000000000;;			pods := listDaemonPods(c, ns, label)
0000000000000000000000000000000000000000;;			for _, pod := range pods.Items {
0000000000000000000000000000000000000000;;				// This pod is adopted only when its controller ref is update
0000000000000000000000000000000000000000;;				if controllerRef := controller.GetControllerOf(&pod); controllerRef == nil || controllerRef.UID != dsUID {
0000000000000000000000000000000000000000;;					return false, nil
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			return true, nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func checkDaemonSetHistoryAdopted(c clientset.Interface, ns string, dsUID types.UID, label map[string]string) func() (bool, error) {
0000000000000000000000000000000000000000;;		return func() (bool, error) {
0000000000000000000000000000000000000000;;			histories := listDaemonHistories(c, ns, label)
0000000000000000000000000000000000000000;;			for _, history := range histories.Items {
0000000000000000000000000000000000000000;;				// This history is adopted only when its controller ref is update
0000000000000000000000000000000000000000;;				if controllerRef := controller.GetControllerOf(&history); controllerRef == nil || controllerRef.UID != dsUID {
0000000000000000000000000000000000000000;;					return false, nil
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			return true, nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func waitDaemonSetAdoption(c clientset.Interface, ds *extensions.DaemonSet, podPrefix string, podTemplateGeneration int64) {
0000000000000000000000000000000000000000;;		ns := ds.Namespace
0000000000000000000000000000000000000000;;		label := ds.Spec.Template.Labels
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		err := wait.PollImmediate(dsRetryPeriod, dsRetryTimeout, checkDaemonSetPodsAdopted(c, ns, ds.UID, label))
0000000000000000000000000000000000000000;;		Expect(err).NotTo(HaveOccurred(), "error waiting for DaemonSet pods to be adopted")
0000000000000000000000000000000000000000;;		err = wait.PollImmediate(dsRetryPeriod, dsRetryTimeout, checkDaemonSetHistoryAdopted(c, ns, ds.UID, label))
0000000000000000000000000000000000000000;;		Expect(err).NotTo(HaveOccurred(), "error waiting for DaemonSet history to be adopted")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		framework.Logf("Make sure no daemon pod updated its template generation %d", podTemplateGeneration)
0000000000000000000000000000000000000000;;		err = checkDaemonPodsTemplateGeneration(c, ns, label, fmt.Sprint(podTemplateGeneration))
0000000000000000000000000000000000000000;;		Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		framework.Logf("Make sure no pods are recreated by looking at their names")
0000000000000000000000000000000000000000;;		err = checkDaemonSetPodsName(c, ns, podPrefix, label)
0000000000000000000000000000000000000000;;		Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func checkDaemonSetPodsName(c clientset.Interface, ns, prefix string, label map[string]string) error {
0000000000000000000000000000000000000000;;		pods := listDaemonPods(c, ns, label)
0000000000000000000000000000000000000000;;		for _, pod := range pods.Items {
0000000000000000000000000000000000000000;;			if !strings.HasPrefix(pod.Name, prefix) {
0000000000000000000000000000000000000000;;				return fmt.Errorf("expected pod %s name to be prefixed %q", pod.Name, prefix)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func checkDaemonSetPodsLabels(podList *v1.PodList, hash, templateGeneration string) {
0000000000000000000000000000000000000000;;		for _, pod := range podList.Items {
0000000000000000000000000000000000000000;;			podHash := pod.Labels[extensions.DefaultDaemonSetUniqueLabelKey]
0000000000000000000000000000000000000000;;			podTemplate := pod.Labels[extensions.DaemonSetTemplateGenerationKey]
0000000000000000000000000000000000000000;;			Expect(len(podHash)).To(BeNumerically(">", 0))
0000000000000000000000000000000000000000;;			if len(hash) > 0 {
0000000000000000000000000000000000000000;;				Expect(podHash).To(Equal(hash))
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			Expect(len(podTemplate)).To(BeNumerically(">", 0))
0000000000000000000000000000000000000000;;			Expect(podTemplate).To(Equal(templateGeneration))
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func listDaemonHistories(c clientset.Interface, ns string, label map[string]string) *apps.ControllerRevisionList {
0000000000000000000000000000000000000000;;		selector := labels.Set(label).AsSelector()
0000000000000000000000000000000000000000;;		options := metav1.ListOptions{LabelSelector: selector.String()}
0000000000000000000000000000000000000000;;		historyList, err := c.Apps().ControllerRevisions(ns).List(options)
0000000000000000000000000000000000000000;;		Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;		Expect(len(historyList.Items)).To(BeNumerically(">", 0))
0000000000000000000000000000000000000000;;		return historyList
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func curHistory(historyList *apps.ControllerRevisionList, ds *extensions.DaemonSet) *apps.ControllerRevision {
0000000000000000000000000000000000000000;;		var curHistory *apps.ControllerRevision
0000000000000000000000000000000000000000;;		foundCurHistories := 0
0000000000000000000000000000000000000000;;		for i := range historyList.Items {
0000000000000000000000000000000000000000;;			history := &historyList.Items[i]
0000000000000000000000000000000000000000;;			// Every history should have the hash label
0000000000000000000000000000000000000000;;			Expect(len(history.Labels[extensions.DefaultDaemonSetUniqueLabelKey])).To(BeNumerically(">", 0))
0000000000000000000000000000000000000000;;			match, err := daemon.Match(ds, history)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;			if match {
0000000000000000000000000000000000000000;;				curHistory = history
0000000000000000000000000000000000000000;;				foundCurHistories++
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		Expect(foundCurHistories).To(Equal(1))
0000000000000000000000000000000000000000;;		Expect(curHistory).NotTo(BeNil())
0000000000000000000000000000000000000000;;		return curHistory
0000000000000000000000000000000000000000;;	}
