0000000000000000000000000000000000000000;;	/*
0000000000000000000000000000000000000000;;	Copyright 2017 The Kubernetes Authors.
f8bf3881ba12540d20250526c51c363b2ef03de2;test/e2e/job.go[test/e2e/job.go][test/e2e/workload/job.go];	
0000000000000000000000000000000000000000;;	Licensed under the Apache License, Version 2.0 (the "License");
0000000000000000000000000000000000000000;;	you may not use this file except in compliance with the License.
0000000000000000000000000000000000000000;;	You may obtain a copy of the License at
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	    http://www.apache.org/licenses/LICENSE-2.0
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	Unless required by applicable law or agreed to in writing, software
0000000000000000000000000000000000000000;;	distributed under the License is distributed on an "AS IS" BASIS,
0000000000000000000000000000000000000000;;	WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
0000000000000000000000000000000000000000;;	See the License for the specific language governing permissions and
0000000000000000000000000000000000000000;;	limitations under the License.
0000000000000000000000000000000000000000;;	*/
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	package workload
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	import (
0000000000000000000000000000000000000000;;		"fmt"
0000000000000000000000000000000000000000;;		"time"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		"k8s.io/api/core/v1"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/api/errors"
0000000000000000000000000000000000000000;;		metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
0000000000000000000000000000000000000000;;		batchinternal "k8s.io/kubernetes/pkg/apis/batch"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/controller"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/kubectl"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/test/e2e/framework"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		. "github.com/onsi/ginkgo"
0000000000000000000000000000000000000000;;		. "github.com/onsi/gomega"
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	var _ = SIGDescribe("Job", func() {
0000000000000000000000000000000000000000;;		f := framework.NewDefaultFramework("job")
0000000000000000000000000000000000000000;;		parallelism := int32(2)
0000000000000000000000000000000000000000;;		completions := int32(4)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Simplest case: all pods succeed promptly
0000000000000000000000000000000000000000;;		It("should run a job to completion when tasks succeed", func() {
0000000000000000000000000000000000000000;;			By("Creating a job")
0000000000000000000000000000000000000000;;			job := framework.NewTestJob("succeed", "all-succeed", v1.RestartPolicyNever, parallelism, completions)
0000000000000000000000000000000000000000;;			job, err := framework.CreateJob(f.ClientSet, f.Namespace.Name, job)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Ensuring job reaches completions")
0000000000000000000000000000000000000000;;			err = framework.WaitForJobFinish(f.ClientSet, f.Namespace.Name, job.Name, completions)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Pods sometimes fail, but eventually succeed.
0000000000000000000000000000000000000000;;		It("should run a job to completion when tasks sometimes fail and are locally restarted", func() {
0000000000000000000000000000000000000000;;			By("Creating a job")
0000000000000000000000000000000000000000;;			// One failure, then a success, local restarts.
0000000000000000000000000000000000000000;;			// We can't use the random failure approach used by the
0000000000000000000000000000000000000000;;			// non-local test below, because kubelet will throttle
0000000000000000000000000000000000000000;;			// frequently failing containers in a given pod, ramping
0000000000000000000000000000000000000000;;			// up to 5 minutes between restarts, making test timeouts
0000000000000000000000000000000000000000;;			// due to successive failures too likely with a reasonable
0000000000000000000000000000000000000000;;			// test timeout.
0000000000000000000000000000000000000000;;			job := framework.NewTestJob("failOnce", "fail-once-local", v1.RestartPolicyOnFailure, parallelism, completions)
0000000000000000000000000000000000000000;;			job, err := framework.CreateJob(f.ClientSet, f.Namespace.Name, job)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Ensuring job reaches completions")
0000000000000000000000000000000000000000;;			err = framework.WaitForJobFinish(f.ClientSet, f.Namespace.Name, job.Name, completions)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Pods sometimes fail, but eventually succeed, after pod restarts
0000000000000000000000000000000000000000;;		It("should run a job to completion when tasks sometimes fail and are not locally restarted", func() {
0000000000000000000000000000000000000000;;			By("Creating a job")
0000000000000000000000000000000000000000;;			// 50% chance of container success, local restarts.
0000000000000000000000000000000000000000;;			// Can't use the failOnce approach because that relies
0000000000000000000000000000000000000000;;			// on an emptyDir, which is not preserved across new pods.
0000000000000000000000000000000000000000;;			// Worst case analysis: 15 failures, each taking 1 minute to
0000000000000000000000000000000000000000;;			// run due to some slowness, 1 in 2^15 chance of happening,
0000000000000000000000000000000000000000;;			// causing test flake.  Should be very rare.
0000000000000000000000000000000000000000;;			job := framework.NewTestJob("randomlySucceedOrFail", "rand-non-local", v1.RestartPolicyNever, parallelism, completions)
0000000000000000000000000000000000000000;;			job, err := framework.CreateJob(f.ClientSet, f.Namespace.Name, job)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Ensuring job reaches completions")
0000000000000000000000000000000000000000;;			err = framework.WaitForJobFinish(f.ClientSet, f.Namespace.Name, job.Name, completions)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		It("should delete a job", func() {
0000000000000000000000000000000000000000;;			By("Creating a job")
0000000000000000000000000000000000000000;;			job := framework.NewTestJob("notTerminate", "foo", v1.RestartPolicyNever, parallelism, completions)
0000000000000000000000000000000000000000;;			job, err := framework.CreateJob(f.ClientSet, f.Namespace.Name, job)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Ensuring active pods == parallelism")
0000000000000000000000000000000000000000;;			err = framework.WaitForAllJobPodsRunning(f.ClientSet, f.Namespace.Name, job.Name, parallelism)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("delete a job")
0000000000000000000000000000000000000000;;			reaper, err := kubectl.ReaperFor(batchinternal.Kind("Job"), f.InternalClientset)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;			timeout := 1 * time.Minute
0000000000000000000000000000000000000000;;			err = reaper.Stop(f.Namespace.Name, job.Name, timeout, metav1.NewDeleteOptions(0))
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Ensuring job was deleted")
0000000000000000000000000000000000000000;;			_, err = framework.GetJob(f.ClientSet, f.Namespace.Name, job.Name)
0000000000000000000000000000000000000000;;			Expect(err).To(HaveOccurred())
0000000000000000000000000000000000000000;;			Expect(errors.IsNotFound(err)).To(BeTrue())
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		It("should adopt matching orphans and release non-matching pods", func() {
0000000000000000000000000000000000000000;;			By("Creating a job")
0000000000000000000000000000000000000000;;			job := framework.NewTestJob("notTerminate", "adopt-release", v1.RestartPolicyNever, parallelism, completions)
0000000000000000000000000000000000000000;;			// Replace job with the one returned from Create() so it has the UID.
0000000000000000000000000000000000000000;;			// Save Kind since it won't be populated in the returned job.
0000000000000000000000000000000000000000;;			kind := job.Kind
0000000000000000000000000000000000000000;;			job, err := framework.CreateJob(f.ClientSet, f.Namespace.Name, job)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;			job.Kind = kind
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Ensuring active pods == parallelism")
0000000000000000000000000000000000000000;;			err = framework.WaitForAllJobPodsRunning(f.ClientSet, f.Namespace.Name, job.Name, parallelism)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Orphaning one of the Job's Pods")
0000000000000000000000000000000000000000;;			pods, err := framework.GetJobPods(f.ClientSet, f.Namespace.Name, job.Name)
0000000000000000000000000000000000000000;;			Expect(err).NotTo(HaveOccurred())
0000000000000000000000000000000000000000;;			Expect(pods.Items).To(HaveLen(int(parallelism)))
0000000000000000000000000000000000000000;;			pod := pods.Items[0]
0000000000000000000000000000000000000000;;			f.PodClient().Update(pod.Name, func(pod *v1.Pod) {
0000000000000000000000000000000000000000;;				pod.OwnerReferences = nil
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Checking that the Job readopts the Pod")
0000000000000000000000000000000000000000;;			Expect(framework.WaitForPodCondition(f.ClientSet, pod.Namespace, pod.Name, "adopted", framework.JobTimeout,
0000000000000000000000000000000000000000;;				func(pod *v1.Pod) (bool, error) {
0000000000000000000000000000000000000000;;					controllerRef := controller.GetControllerOf(pod)
0000000000000000000000000000000000000000;;					if controllerRef == nil {
0000000000000000000000000000000000000000;;						return false, nil
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					if controllerRef.Kind != job.Kind || controllerRef.Name != job.Name || controllerRef.UID != job.UID {
0000000000000000000000000000000000000000;;						return false, fmt.Errorf("pod has wrong controllerRef: got %v, want %v", controllerRef, job)
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					return true, nil
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			)).To(Succeed(), "wait for pod %q to be readopted", pod.Name)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Removing the labels from the Job's Pod")
0000000000000000000000000000000000000000;;			f.PodClient().Update(pod.Name, func(pod *v1.Pod) {
0000000000000000000000000000000000000000;;				pod.Labels = nil
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			By("Checking that the Job releases the Pod")
0000000000000000000000000000000000000000;;			Expect(framework.WaitForPodCondition(f.ClientSet, pod.Namespace, pod.Name, "released", framework.JobTimeout,
0000000000000000000000000000000000000000;;				func(pod *v1.Pod) (bool, error) {
0000000000000000000000000000000000000000;;					controllerRef := controller.GetControllerOf(pod)
0000000000000000000000000000000000000000;;					if controllerRef != nil {
0000000000000000000000000000000000000000;;						return false, nil
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					return true, nil
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			)).To(Succeed(), "wait for pod %q to be released", pod.Name)
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	})
