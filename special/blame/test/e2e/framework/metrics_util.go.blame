0000000000000000000000000000000000000000;;	/*
0000000000000000000000000000000000000000;;	Copyright 2015 The Kubernetes Authors.
86fcfc28e479366406b3400448c2fc88942e39c1;test/e2e/metrics_util.go[test/e2e/metrics_util.go][test/e2e/framework/metrics_util.go];	
0000000000000000000000000000000000000000;;	Licensed under the Apache License, Version 2.0 (the "License");
0000000000000000000000000000000000000000;;	you may not use this file except in compliance with the License.
0000000000000000000000000000000000000000;;	You may obtain a copy of the License at
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	    http://www.apache.org/licenses/LICENSE-2.0
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	Unless required by applicable law or agreed to in writing, software
0000000000000000000000000000000000000000;;	distributed under the License is distributed on an "AS IS" BASIS,
0000000000000000000000000000000000000000;;	WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
0000000000000000000000000000000000000000;;	See the License for the specific language governing permissions and
0000000000000000000000000000000000000000;;	limitations under the License.
0000000000000000000000000000000000000000;;	*/
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	package framework
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	import (
0000000000000000000000000000000000000000;;		"bytes"
0000000000000000000000000000000000000000;;		"context"
0000000000000000000000000000000000000000;;		"encoding/json"
0000000000000000000000000000000000000000;;		"fmt"
0000000000000000000000000000000000000000;;		"io"
0000000000000000000000000000000000000000;;		"math"
0000000000000000000000000000000000000000;;		"sort"
0000000000000000000000000000000000000000;;		"strconv"
0000000000000000000000000000000000000000;;		"strings"
0000000000000000000000000000000000000000;;		"time"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/util/sets"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/client/clientset_generated/clientset"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/master/ports"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/util/system"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/test/e2e/metrics"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		"github.com/prometheus/common/expfmt"
0000000000000000000000000000000000000000;;		"github.com/prometheus/common/model"
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	const (
0000000000000000000000000000000000000000;;		// NodeStartupThreshold is a rough estimate of the time allocated for a pod to start on a node.
0000000000000000000000000000000000000000;;		NodeStartupThreshold = 4 * time.Second
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		podStartupThreshold time.Duration = 5 * time.Second
0000000000000000000000000000000000000000;;		// We are setting 1s threshold for apicalls even in small clusters to avoid flakes.
0000000000000000000000000000000000000000;;		// The problem is that if long GC is happening in small clusters (where we have e.g.
0000000000000000000000000000000000000000;;		// 1-core master machines) and tests are pretty short, it may consume significant
0000000000000000000000000000000000000000;;		// portion of CPU and basically stop all the real work.
0000000000000000000000000000000000000000;;		// Increasing threshold to 1s is within our SLO and should solve this problem.
0000000000000000000000000000000000000000;;		apiCallLatencyThreshold time.Duration = 1 * time.Second
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// We set a higher threshold for list apicalls as they can take more time when
0000000000000000000000000000000000000000;;		// the list is really big. For eg. list nodes in a 5000-node cluster.
0000000000000000000000000000000000000000;;		apiListCallLatencyThreshold time.Duration = 2 * time.Second
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type MetricsForE2E metrics.MetricsCollection
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (m *MetricsForE2E) filterMetrics() {
0000000000000000000000000000000000000000;;		interestingApiServerMetrics := make(metrics.ApiServerMetrics)
0000000000000000000000000000000000000000;;		for _, metric := range InterestingApiServerMetrics {
0000000000000000000000000000000000000000;;			interestingApiServerMetrics[metric] = (*m).ApiServerMetrics[metric]
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		interestingControllerManagerMetrics := make(metrics.ControllerManagerMetrics)
0000000000000000000000000000000000000000;;		for _, metric := range InterestingControllerManagerMetrics {
0000000000000000000000000000000000000000;;			interestingControllerManagerMetrics[metric] = (*m).ControllerManagerMetrics[metric]
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		interestingKubeletMetrics := make(map[string]metrics.KubeletMetrics)
0000000000000000000000000000000000000000;;		for kubelet, grabbed := range (*m).KubeletMetrics {
0000000000000000000000000000000000000000;;			interestingKubeletMetrics[kubelet] = make(metrics.KubeletMetrics)
0000000000000000000000000000000000000000;;			for _, metric := range InterestingKubeletMetrics {
0000000000000000000000000000000000000000;;				interestingKubeletMetrics[kubelet][metric] = grabbed[metric]
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		(*m).ApiServerMetrics = interestingApiServerMetrics
0000000000000000000000000000000000000000;;		(*m).ControllerManagerMetrics = interestingControllerManagerMetrics
0000000000000000000000000000000000000000;;		(*m).KubeletMetrics = interestingKubeletMetrics
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (m *MetricsForE2E) PrintHumanReadable() string {
0000000000000000000000000000000000000000;;		buf := bytes.Buffer{}
0000000000000000000000000000000000000000;;		for _, interestingMetric := range InterestingApiServerMetrics {
0000000000000000000000000000000000000000;;			buf.WriteString(fmt.Sprintf("For %v:\n", interestingMetric))
0000000000000000000000000000000000000000;;			for _, sample := range (*m).ApiServerMetrics[interestingMetric] {
0000000000000000000000000000000000000000;;				buf.WriteString(fmt.Sprintf("\t%v\n", metrics.PrintSample(sample)))
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		for _, interestingMetric := range InterestingControllerManagerMetrics {
0000000000000000000000000000000000000000;;			buf.WriteString(fmt.Sprintf("For %v:\n", interestingMetric))
0000000000000000000000000000000000000000;;			for _, sample := range (*m).ControllerManagerMetrics[interestingMetric] {
0000000000000000000000000000000000000000;;				buf.WriteString(fmt.Sprintf("\t%v\n", metrics.PrintSample(sample)))
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		for kubelet, grabbed := range (*m).KubeletMetrics {
0000000000000000000000000000000000000000;;			buf.WriteString(fmt.Sprintf("For %v:\n", kubelet))
0000000000000000000000000000000000000000;;			for _, interestingMetric := range InterestingKubeletMetrics {
0000000000000000000000000000000000000000;;				buf.WriteString(fmt.Sprintf("\tFor %v:\n", interestingMetric))
0000000000000000000000000000000000000000;;				for _, sample := range grabbed[interestingMetric] {
0000000000000000000000000000000000000000;;					buf.WriteString(fmt.Sprintf("\t\t%v\n", metrics.PrintSample(sample)))
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return buf.String()
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (m *MetricsForE2E) PrintJSON() string {
0000000000000000000000000000000000000000;;		m.filterMetrics()
0000000000000000000000000000000000000000;;		return PrettyPrintJSON(m)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (m *MetricsForE2E) SummaryKind() string {
0000000000000000000000000000000000000000;;		return "MetricsForE2E"
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	var InterestingApiServerMetrics = []string{
0000000000000000000000000000000000000000;;		"apiserver_request_count",
0000000000000000000000000000000000000000;;		"apiserver_request_latencies_summary",
0000000000000000000000000000000000000000;;		"etcd_helper_cache_entry_count",
0000000000000000000000000000000000000000;;		"etcd_helper_cache_hit_count",
0000000000000000000000000000000000000000;;		"etcd_helper_cache_miss_count",
0000000000000000000000000000000000000000;;		"etcd_request_cache_add_latencies_summary",
0000000000000000000000000000000000000000;;		"etcd_request_cache_get_latencies_summary",
0000000000000000000000000000000000000000;;		"etcd_request_latencies_summary",
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	var InterestingControllerManagerMetrics = []string{
0000000000000000000000000000000000000000;;		"garbage_collector_attempt_to_delete_queue_latency",
0000000000000000000000000000000000000000;;		"garbage_collector_attempt_to_delete_work_duration",
0000000000000000000000000000000000000000;;		"garbage_collector_attempt_to_orphan_queue_latency",
0000000000000000000000000000000000000000;;		"garbage_collector_attempt_to_orphan_work_duration",
0000000000000000000000000000000000000000;;		"garbage_collector_dirty_processing_latency_microseconds",
0000000000000000000000000000000000000000;;		"garbage_collector_event_processing_latency_microseconds",
0000000000000000000000000000000000000000;;		"garbage_collector_graph_changes_queue_latency",
0000000000000000000000000000000000000000;;		"garbage_collector_graph_changes_work_duration",
0000000000000000000000000000000000000000;;		"garbage_collector_orphan_processing_latency_microseconds",
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		"namespace_queue_latency",
0000000000000000000000000000000000000000;;		"namespace_queue_latency_sum",
0000000000000000000000000000000000000000;;		"namespace_queue_latency_count",
0000000000000000000000000000000000000000;;		"namespace_retries",
0000000000000000000000000000000000000000;;		"namespace_work_duration",
0000000000000000000000000000000000000000;;		"namespace_work_duration_sum",
0000000000000000000000000000000000000000;;		"namespace_work_duration_count",
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	var InterestingKubeletMetrics = []string{
0000000000000000000000000000000000000000;;		"kubelet_container_manager_latency_microseconds",
0000000000000000000000000000000000000000;;		"kubelet_docker_errors",
0000000000000000000000000000000000000000;;		"kubelet_docker_operations_latency_microseconds",
0000000000000000000000000000000000000000;;		"kubelet_generate_pod_status_latency_microseconds",
0000000000000000000000000000000000000000;;		"kubelet_pod_start_latency_microseconds",
0000000000000000000000000000000000000000;;		"kubelet_pod_worker_latency_microseconds",
0000000000000000000000000000000000000000;;		"kubelet_pod_worker_start_latency_microseconds",
0000000000000000000000000000000000000000;;		"kubelet_sync_pods_latency_microseconds",
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Dashboard metrics
0000000000000000000000000000000000000000;;	type LatencyMetric struct {
0000000000000000000000000000000000000000;;		Perc50  time.Duration `json:"Perc50"`
0000000000000000000000000000000000000000;;		Perc90  time.Duration `json:"Perc90"`
0000000000000000000000000000000000000000;;		Perc99  time.Duration `json:"Perc99"`
0000000000000000000000000000000000000000;;		Perc100 time.Duration `json:"Perc100"`
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type PodStartupLatency struct {
0000000000000000000000000000000000000000;;		Latency LatencyMetric `json:"latency"`
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (l *PodStartupLatency) SummaryKind() string {
0000000000000000000000000000000000000000;;		return "PodStartupLatency"
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (l *PodStartupLatency) PrintHumanReadable() string {
0000000000000000000000000000000000000000;;		return PrettyPrintJSON(l)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (l *PodStartupLatency) PrintJSON() string {
0000000000000000000000000000000000000000;;		return PrettyPrintJSON(PodStartupLatencyToPerfData(l))
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type SchedulingLatency struct {
0000000000000000000000000000000000000000;;		Scheduling LatencyMetric `json:"scheduling"`
0000000000000000000000000000000000000000;;		Binding    LatencyMetric `json:"binding"`
0000000000000000000000000000000000000000;;		Total      LatencyMetric `json:"total"`
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (l *SchedulingLatency) SummaryKind() string {
0000000000000000000000000000000000000000;;		return "SchedulingLatency"
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (l *SchedulingLatency) PrintHumanReadable() string {
0000000000000000000000000000000000000000;;		return PrettyPrintJSON(l)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (l *SchedulingLatency) PrintJSON() string {
0000000000000000000000000000000000000000;;		return PrettyPrintJSON(l)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type SaturationTime struct {
0000000000000000000000000000000000000000;;		TimeToSaturate time.Duration `json:"timeToStaturate"`
0000000000000000000000000000000000000000;;		NumberOfNodes  int           `json:"numberOfNodes"`
0000000000000000000000000000000000000000;;		NumberOfPods   int           `json:"numberOfPods"`
0000000000000000000000000000000000000000;;		Throughput     float32       `json:"throughput"`
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type APICall struct {
0000000000000000000000000000000000000000;;		Resource    string        `json:"resource"`
0000000000000000000000000000000000000000;;		Subresource string        `json:"subresource"`
0000000000000000000000000000000000000000;;		Verb        string        `json:"verb"`
0000000000000000000000000000000000000000;;		Latency     LatencyMetric `json:"latency"`
0000000000000000000000000000000000000000;;		Count       int           `json:"count"`
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type APIResponsiveness struct {
0000000000000000000000000000000000000000;;		APICalls []APICall `json:"apicalls"`
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (a *APIResponsiveness) SummaryKind() string {
0000000000000000000000000000000000000000;;		return "APIResponsiveness"
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (a *APIResponsiveness) PrintHumanReadable() string {
0000000000000000000000000000000000000000;;		return PrettyPrintJSON(a)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (a *APIResponsiveness) PrintJSON() string {
0000000000000000000000000000000000000000;;		return PrettyPrintJSON(ApiCallToPerfData(a))
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (a *APIResponsiveness) Len() int { return len(a.APICalls) }
0000000000000000000000000000000000000000;;	func (a *APIResponsiveness) Swap(i, j int) {
0000000000000000000000000000000000000000;;		a.APICalls[i], a.APICalls[j] = a.APICalls[j], a.APICalls[i]
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	func (a *APIResponsiveness) Less(i, j int) bool {
0000000000000000000000000000000000000000;;		return a.APICalls[i].Latency.Perc99 < a.APICalls[j].Latency.Perc99
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Set request latency for a particular quantile in the APICall metric entry (creating one if necessary).
0000000000000000000000000000000000000000;;	// 0 <= quantile <=1 (e.g. 0.95 is 95%tile, 0.5 is median)
0000000000000000000000000000000000000000;;	// Only 0.5, 0.9 and 0.99 quantiles are supported.
0000000000000000000000000000000000000000;;	func (a *APIResponsiveness) addMetricRequestLatency(resource, subresource, verb string, quantile float64, latency time.Duration) {
0000000000000000000000000000000000000000;;		for i, apicall := range a.APICalls {
0000000000000000000000000000000000000000;;			if apicall.Resource == resource && apicall.Subresource == subresource && apicall.Verb == verb {
0000000000000000000000000000000000000000;;				a.APICalls[i] = setQuantileAPICall(apicall, quantile, latency)
0000000000000000000000000000000000000000;;				return
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		apicall := setQuantileAPICall(APICall{Resource: resource, Subresource: subresource, Verb: verb}, quantile, latency)
0000000000000000000000000000000000000000;;		a.APICalls = append(a.APICalls, apicall)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// 0 <= quantile <=1 (e.g. 0.95 is 95%tile, 0.5 is median)
0000000000000000000000000000000000000000;;	// Only 0.5, 0.9 and 0.99 quantiles are supported.
0000000000000000000000000000000000000000;;	func setQuantileAPICall(apicall APICall, quantile float64, latency time.Duration) APICall {
0000000000000000000000000000000000000000;;		setQuantile(&apicall.Latency, quantile, latency)
0000000000000000000000000000000000000000;;		return apicall
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Only 0.5, 0.9 and 0.99 quantiles are supported.
0000000000000000000000000000000000000000;;	func setQuantile(metric *LatencyMetric, quantile float64, latency time.Duration) {
0000000000000000000000000000000000000000;;		switch quantile {
0000000000000000000000000000000000000000;;		case 0.5:
0000000000000000000000000000000000000000;;			metric.Perc50 = latency
0000000000000000000000000000000000000000;;		case 0.9:
0000000000000000000000000000000000000000;;			metric.Perc90 = latency
0000000000000000000000000000000000000000;;		case 0.99:
0000000000000000000000000000000000000000;;			metric.Perc99 = latency
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Add request count to the APICall metric entry (creating one if necessary).
0000000000000000000000000000000000000000;;	func (a *APIResponsiveness) addMetricRequestCount(resource, subresource, verb string, count int) {
0000000000000000000000000000000000000000;;		for i, apicall := range a.APICalls {
0000000000000000000000000000000000000000;;			if apicall.Resource == resource && apicall.Subresource == subresource && apicall.Verb == verb {
0000000000000000000000000000000000000000;;				a.APICalls[i].Count += count
0000000000000000000000000000000000000000;;				return
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		apicall := APICall{Resource: resource, Subresource: subresource, Verb: verb, Count: count}
0000000000000000000000000000000000000000;;		a.APICalls = append(a.APICalls, apicall)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func readLatencyMetrics(c clientset.Interface) (*APIResponsiveness, error) {
0000000000000000000000000000000000000000;;		var a APIResponsiveness
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		body, err := getMetrics(c)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return nil, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		samples, err := extractMetricSamples(body)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return nil, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		ignoredResources := sets.NewString("events")
0000000000000000000000000000000000000000;;		// TODO: figure out why we're getting non-capitalized proxy and fix this.
0000000000000000000000000000000000000000;;		ignoredVerbs := sets.NewString("WATCH", "WATCHLIST", "PROXY", "proxy", "CONNECT")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		for _, sample := range samples {
0000000000000000000000000000000000000000;;			// Example line:
0000000000000000000000000000000000000000;;			// apiserver_request_latencies_summary{resource="namespaces",verb="LIST",quantile="0.99"} 908
0000000000000000000000000000000000000000;;			// apiserver_request_count{resource="pods",verb="LIST",client="kubectl",code="200",contentType="json"} 233
0000000000000000000000000000000000000000;;			if sample.Metric[model.MetricNameLabel] != "apiserver_request_latencies_summary" &&
0000000000000000000000000000000000000000;;				sample.Metric[model.MetricNameLabel] != "apiserver_request_count" {
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			resource := string(sample.Metric["resource"])
0000000000000000000000000000000000000000;;			subresource := string(sample.Metric["subresource"])
0000000000000000000000000000000000000000;;			verb := string(sample.Metric["verb"])
0000000000000000000000000000000000000000;;			if ignoredResources.Has(resource) || ignoredVerbs.Has(verb) {
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			switch sample.Metric[model.MetricNameLabel] {
0000000000000000000000000000000000000000;;			case "apiserver_request_latencies_summary":
0000000000000000000000000000000000000000;;				latency := sample.Value
0000000000000000000000000000000000000000;;				quantile, err := strconv.ParseFloat(string(sample.Metric[model.QuantileLabel]), 64)
0000000000000000000000000000000000000000;;				if err != nil {
0000000000000000000000000000000000000000;;					return nil, err
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				a.addMetricRequestLatency(resource, subresource, verb, quantile, time.Duration(int64(latency))*time.Microsecond)
0000000000000000000000000000000000000000;;			case "apiserver_request_count":
0000000000000000000000000000000000000000;;				count := sample.Value
0000000000000000000000000000000000000000;;				a.addMetricRequestCount(resource, subresource, verb, int(count))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return &a, err
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Prints top five summary metrics for request types with latency and returns
0000000000000000000000000000000000000000;;	// number of such request types above threshold.
0000000000000000000000000000000000000000;;	func HighLatencyRequests(c clientset.Interface) (int, *APIResponsiveness, error) {
0000000000000000000000000000000000000000;;		metrics, err := readLatencyMetrics(c)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return 0, metrics, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		sort.Sort(sort.Reverse(metrics))
0000000000000000000000000000000000000000;;		badMetrics := 0
0000000000000000000000000000000000000000;;		top := 5
0000000000000000000000000000000000000000;;		for i := range metrics.APICalls {
0000000000000000000000000000000000000000;;			isBad := false
0000000000000000000000000000000000000000;;			verb := metrics.APICalls[i].Verb
0000000000000000000000000000000000000000;;			if verb != "LIST" && metrics.APICalls[i].Latency.Perc99 > apiCallLatencyThreshold ||
0000000000000000000000000000000000000000;;				verb == "LIST" && metrics.APICalls[i].Latency.Perc99 > apiListCallLatencyThreshold {
0000000000000000000000000000000000000000;;				badMetrics++
0000000000000000000000000000000000000000;;				isBad = true
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if top > 0 || isBad {
0000000000000000000000000000000000000000;;				top--
0000000000000000000000000000000000000000;;				prefix := ""
0000000000000000000000000000000000000000;;				if isBad {
0000000000000000000000000000000000000000;;					prefix = "WARNING "
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				Logf("%vTop latency metric: %+v", prefix, metrics.APICalls[i])
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return badMetrics, metrics, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Verifies whether 50, 90 and 99th percentiles of PodStartupLatency are
0000000000000000000000000000000000000000;;	// within the threshold.
0000000000000000000000000000000000000000;;	func VerifyPodStartupLatency(latency *PodStartupLatency) error {
0000000000000000000000000000000000000000;;		if latency.Latency.Perc50 > podStartupThreshold {
0000000000000000000000000000000000000000;;			return fmt.Errorf("too high pod startup latency 50th percentile: %v", latency.Latency.Perc50)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if latency.Latency.Perc90 > podStartupThreshold {
0000000000000000000000000000000000000000;;			return fmt.Errorf("too high pod startup latency 90th percentile: %v", latency.Latency.Perc90)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if latency.Latency.Perc99 > podStartupThreshold {
0000000000000000000000000000000000000000;;			return fmt.Errorf("too high pod startup latency 99th percentil: %v", latency.Latency.Perc99)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Resets latency metrics in apiserver.
0000000000000000000000000000000000000000;;	func ResetMetrics(c clientset.Interface) error {
0000000000000000000000000000000000000000;;		Logf("Resetting latency metrics in apiserver...")
0000000000000000000000000000000000000000;;		body, err := c.Core().RESTClient().Delete().AbsPath("/metrics").DoRaw()
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if string(body) != "metrics reset\n" {
0000000000000000000000000000000000000000;;			return fmt.Errorf("Unexpected response: %q", string(body))
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Retrieves metrics information.
0000000000000000000000000000000000000000;;	func getMetrics(c clientset.Interface) (string, error) {
0000000000000000000000000000000000000000;;		body, err := c.Core().RESTClient().Get().AbsPath("/metrics").DoRaw()
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return "", err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return string(body), nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Retrieves scheduler metrics information.
0000000000000000000000000000000000000000;;	func getSchedulingLatency(c clientset.Interface) (*SchedulingLatency, error) {
0000000000000000000000000000000000000000;;		result := SchedulingLatency{}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Check if master Node is registered
0000000000000000000000000000000000000000;;		nodes, err := c.Core().Nodes().List(metav1.ListOptions{})
0000000000000000000000000000000000000000;;		ExpectNoError(err)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		subResourceProxyAvailable, err := ServerVersionGTE(SubResourcePodProxyVersion, c.Discovery())
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return nil, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		var data string
0000000000000000000000000000000000000000;;		var masterRegistered = false
0000000000000000000000000000000000000000;;		for _, node := range nodes.Items {
0000000000000000000000000000000000000000;;			if system.IsMasterNode(node.Name) {
0000000000000000000000000000000000000000;;				masterRegistered = true
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if masterRegistered {
0000000000000000000000000000000000000000;;			ctx, cancel := context.WithTimeout(context.Background(), SingleCallTimeout)
0000000000000000000000000000000000000000;;			defer cancel()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			var rawData []byte
0000000000000000000000000000000000000000;;			if subResourceProxyAvailable {
0000000000000000000000000000000000000000;;				rawData, err = c.Core().RESTClient().Get().
0000000000000000000000000000000000000000;;					Context(ctx).
0000000000000000000000000000000000000000;;					Namespace(metav1.NamespaceSystem).
0000000000000000000000000000000000000000;;					Resource("pods").
0000000000000000000000000000000000000000;;					Name(fmt.Sprintf("kube-scheduler-%v:%v", TestContext.CloudConfig.MasterName, ports.SchedulerPort)).
0000000000000000000000000000000000000000;;					SubResource("proxy").
0000000000000000000000000000000000000000;;					Suffix("metrics").
0000000000000000000000000000000000000000;;					Do().Raw()
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				rawData, err = c.Core().RESTClient().Get().
0000000000000000000000000000000000000000;;					Context(ctx).
0000000000000000000000000000000000000000;;					Prefix("proxy").
0000000000000000000000000000000000000000;;					Namespace(metav1.NamespaceSystem).
0000000000000000000000000000000000000000;;					SubResource("pods").
0000000000000000000000000000000000000000;;					Name(fmt.Sprintf("kube-scheduler-%v:%v", TestContext.CloudConfig.MasterName, ports.SchedulerPort)).
0000000000000000000000000000000000000000;;					Suffix("metrics").
0000000000000000000000000000000000000000;;					Do().Raw()
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			ExpectNoError(err)
0000000000000000000000000000000000000000;;			data = string(rawData)
0000000000000000000000000000000000000000;;		} else {
0000000000000000000000000000000000000000;;			// If master is not registered fall back to old method of using SSH.
0000000000000000000000000000000000000000;;			cmd := "curl http://localhost:10251/metrics"
0000000000000000000000000000000000000000;;			sshResult, err := SSH(cmd, GetMasterHost()+":22", TestContext.Provider)
0000000000000000000000000000000000000000;;			if err != nil || sshResult.Code != 0 {
0000000000000000000000000000000000000000;;				return &result, fmt.Errorf("unexpected error (code: %d) in ssh connection to master: %#v", sshResult.Code, err)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			data = sshResult.Stdout
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		samples, err := extractMetricSamples(data)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return nil, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		for _, sample := range samples {
0000000000000000000000000000000000000000;;			var metric *LatencyMetric = nil
0000000000000000000000000000000000000000;;			switch sample.Metric[model.MetricNameLabel] {
0000000000000000000000000000000000000000;;			case "scheduler_scheduling_algorithm_latency_microseconds":
0000000000000000000000000000000000000000;;				metric = &result.Scheduling
0000000000000000000000000000000000000000;;			case "scheduler_binding_latency_microseconds":
0000000000000000000000000000000000000000;;				metric = &result.Binding
0000000000000000000000000000000000000000;;			case "scheduler_e2e_scheduling_latency_microseconds":
0000000000000000000000000000000000000000;;				metric = &result.Total
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if metric == nil {
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			latency := sample.Value
0000000000000000000000000000000000000000;;			quantile, err := strconv.ParseFloat(string(sample.Metric[model.QuantileLabel]), 64)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				return nil, err
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			setQuantile(metric, quantile, time.Duration(int64(latency))*time.Microsecond)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return &result, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Verifies (currently just by logging them) the scheduling latencies.
0000000000000000000000000000000000000000;;	func VerifySchedulerLatency(c clientset.Interface) (*SchedulingLatency, error) {
0000000000000000000000000000000000000000;;		latency, err := getSchedulingLatency(c)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return nil, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return latency, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func PrettyPrintJSON(metrics interface{}) string {
0000000000000000000000000000000000000000;;		output := &bytes.Buffer{}
0000000000000000000000000000000000000000;;		if err := json.NewEncoder(output).Encode(metrics); err != nil {
0000000000000000000000000000000000000000;;			Logf("Error building encoder: %v", err)
0000000000000000000000000000000000000000;;			return ""
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		formatted := &bytes.Buffer{}
0000000000000000000000000000000000000000;;		if err := json.Indent(formatted, output.Bytes(), "", "  "); err != nil {
0000000000000000000000000000000000000000;;			Logf("Error indenting: %v", err)
0000000000000000000000000000000000000000;;			return ""
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return string(formatted.Bytes())
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// extractMetricSamples parses the prometheus metric samples from the input string.
0000000000000000000000000000000000000000;;	func extractMetricSamples(metricsBlob string) ([]*model.Sample, error) {
0000000000000000000000000000000000000000;;		dec := expfmt.NewDecoder(strings.NewReader(metricsBlob), expfmt.FmtText)
0000000000000000000000000000000000000000;;		decoder := expfmt.SampleDecoder{
0000000000000000000000000000000000000000;;			Dec:  dec,
0000000000000000000000000000000000000000;;			Opts: &expfmt.DecodeOptions{},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		var samples []*model.Sample
0000000000000000000000000000000000000000;;		for {
0000000000000000000000000000000000000000;;			var v model.Vector
0000000000000000000000000000000000000000;;			if err := decoder.Decode(&v); err != nil {
0000000000000000000000000000000000000000;;				if err == io.EOF {
0000000000000000000000000000000000000000;;					// Expected loop termination condition.
0000000000000000000000000000000000000000;;					return samples, nil
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				return nil, err
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			samples = append(samples, v...)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// PodLatencyData encapsulates pod startup latency information.
0000000000000000000000000000000000000000;;	type PodLatencyData struct {
0000000000000000000000000000000000000000;;		// Name of the pod
0000000000000000000000000000000000000000;;		Name string
0000000000000000000000000000000000000000;;		// Node this pod was running on
0000000000000000000000000000000000000000;;		Node string
0000000000000000000000000000000000000000;;		// Latency information related to pod startuptime
0000000000000000000000000000000000000000;;		Latency time.Duration
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type LatencySlice []PodLatencyData
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (a LatencySlice) Len() int           { return len(a) }
0000000000000000000000000000000000000000;;	func (a LatencySlice) Swap(i, j int)      { a[i], a[j] = a[j], a[i] }
0000000000000000000000000000000000000000;;	func (a LatencySlice) Less(i, j int) bool { return a[i].Latency < a[j].Latency }
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func ExtractLatencyMetrics(latencies []PodLatencyData) LatencyMetric {
0000000000000000000000000000000000000000;;		length := len(latencies)
0000000000000000000000000000000000000000;;		perc50 := latencies[int(math.Ceil(float64(length*50)/100))-1].Latency
0000000000000000000000000000000000000000;;		perc90 := latencies[int(math.Ceil(float64(length*90)/100))-1].Latency
0000000000000000000000000000000000000000;;		perc99 := latencies[int(math.Ceil(float64(length*99)/100))-1].Latency
0000000000000000000000000000000000000000;;		perc100 := latencies[length-1].Latency
0000000000000000000000000000000000000000;;		return LatencyMetric{Perc50: perc50, Perc90: perc90, Perc99: perc99, Perc100: perc100}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// LogSuspiciousLatency logs metrics/docker errors from all nodes that had slow startup times
0000000000000000000000000000000000000000;;	// If latencyDataLag is nil then it will be populated from latencyData
0000000000000000000000000000000000000000;;	func LogSuspiciousLatency(latencyData []PodLatencyData, latencyDataLag []PodLatencyData, nodeCount int, c clientset.Interface) {
0000000000000000000000000000000000000000;;		if latencyDataLag == nil {
0000000000000000000000000000000000000000;;			latencyDataLag = latencyData
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		for _, l := range latencyData {
0000000000000000000000000000000000000000;;			if l.Latency > NodeStartupThreshold {
0000000000000000000000000000000000000000;;				HighLatencyKubeletOperations(c, 1*time.Second, l.Node, Logf)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		Logf("Approx throughput: %v pods/min",
0000000000000000000000000000000000000000;;			float64(nodeCount)/(latencyDataLag[len(latencyDataLag)-1].Latency.Minutes()))
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func PrintLatencies(latencies []PodLatencyData, header string) {
0000000000000000000000000000000000000000;;		metrics := ExtractLatencyMetrics(latencies)
0000000000000000000000000000000000000000;;		Logf("10%% %s: %v", header, latencies[(len(latencies)*9)/10:])
0000000000000000000000000000000000000000;;		Logf("perc50: %v, perc90: %v, perc99: %v", metrics.Perc50, metrics.Perc90, metrics.Perc99)
0000000000000000000000000000000000000000;;	}
