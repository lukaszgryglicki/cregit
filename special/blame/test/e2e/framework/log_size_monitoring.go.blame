0000000000000000000000000000000000000000;;	/*
0000000000000000000000000000000000000000;;	Copyright 2015 The Kubernetes Authors.
1113fe34323b289487405abb5c037411b66d2484;test/e2e/log_size_monitoring.go[test/e2e/log_size_monitoring.go][test/e2e/framework/log_size_monitoring.go];	
0000000000000000000000000000000000000000;;	Licensed under the Apache License, Version 2.0 (the "License");
0000000000000000000000000000000000000000;;	you may not use this file except in compliance with the License.
0000000000000000000000000000000000000000;;	You may obtain a copy of the License at
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	    http://www.apache.org/licenses/LICENSE-2.0
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	Unless required by applicable law or agreed to in writing, software
0000000000000000000000000000000000000000;;	distributed under the License is distributed on an "AS IS" BASIS,
0000000000000000000000000000000000000000;;	WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
0000000000000000000000000000000000000000;;	See the License for the specific language governing permissions and
0000000000000000000000000000000000000000;;	limitations under the License.
0000000000000000000000000000000000000000;;	*/
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	package framework
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	import (
0000000000000000000000000000000000000000;;		"bytes"
0000000000000000000000000000000000000000;;		"fmt"
0000000000000000000000000000000000000000;;		"strconv"
0000000000000000000000000000000000000000;;		"strings"
0000000000000000000000000000000000000000;;		"sync"
0000000000000000000000000000000000000000;;		"text/tabwriter"
0000000000000000000000000000000000000000;;		"time"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/client/clientset_generated/clientset"
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	const (
0000000000000000000000000000000000000000;;		// Minimal period between polling log sizes from components
0000000000000000000000000000000000000000;;		pollingPeriod            = 60 * time.Second
0000000000000000000000000000000000000000;;		workersNo                = 5
0000000000000000000000000000000000000000;;		kubeletLogsPath          = "/var/log/kubelet.log"
0000000000000000000000000000000000000000;;		kubeProxyLogsPath        = "/var/log/kube-proxy.log"
0000000000000000000000000000000000000000;;		kubeAddonsLogsPath       = "/var/log/kube-addons.log"
0000000000000000000000000000000000000000;;		kubeMasterAddonsLogsPath = "/var/log/kube-master-addons.log"
0000000000000000000000000000000000000000;;		apiServerLogsPath        = "/var/log/kube-apiserver.log"
0000000000000000000000000000000000000000;;		controllersLogsPath      = "/var/log/kube-controller-manager.log"
0000000000000000000000000000000000000000;;		schedulerLogsPath        = "/var/log/kube-scheduler.log"
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	var (
0000000000000000000000000000000000000000;;		nodeLogsToCheck   = []string{kubeletLogsPath, kubeProxyLogsPath}
0000000000000000000000000000000000000000;;		masterLogsToCheck = []string{kubeletLogsPath, kubeAddonsLogsPath, kubeMasterAddonsLogsPath,
0000000000000000000000000000000000000000;;			apiServerLogsPath, controllersLogsPath, schedulerLogsPath}
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// TimestampedSize contains a size together with a time of measurement.
0000000000000000000000000000000000000000;;	type TimestampedSize struct {
0000000000000000000000000000000000000000;;		timestamp time.Time
0000000000000000000000000000000000000000;;		size      int
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// LogSizeGatherer is a worker which grabs a WorkItem from the channel and does assigned work.
0000000000000000000000000000000000000000;;	type LogSizeGatherer struct {
0000000000000000000000000000000000000000;;		stopChannel chan bool
0000000000000000000000000000000000000000;;		data        *LogsSizeData
0000000000000000000000000000000000000000;;		wg          *sync.WaitGroup
0000000000000000000000000000000000000000;;		workChannel chan WorkItem
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// LogsSizeVerifier gathers data about log files sizes from master and node machines.
0000000000000000000000000000000000000000;;	// It oversees a <workersNo> workers which do the gathering.
0000000000000000000000000000000000000000;;	type LogsSizeVerifier struct {
0000000000000000000000000000000000000000;;		client      clientset.Interface
0000000000000000000000000000000000000000;;		stopChannel chan bool
0000000000000000000000000000000000000000;;		// data stores LogSizeData groupped per IP and log_path
0000000000000000000000000000000000000000;;		data          *LogsSizeData
0000000000000000000000000000000000000000;;		masterAddress string
0000000000000000000000000000000000000000;;		nodeAddresses []string
0000000000000000000000000000000000000000;;		wg            sync.WaitGroup
0000000000000000000000000000000000000000;;		workChannel   chan WorkItem
0000000000000000000000000000000000000000;;		workers       []*LogSizeGatherer
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type SingleLogSummary struct {
0000000000000000000000000000000000000000;;		AverageGenerationRate int
0000000000000000000000000000000000000000;;		NumberOfProbes        int
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type LogSizeDataTimeseries map[string]map[string][]TimestampedSize
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// node -> file -> data
0000000000000000000000000000000000000000;;	type LogsSizeDataSummary map[string]map[string]SingleLogSummary
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// TODO: make sure that we don't need locking here
0000000000000000000000000000000000000000;;	func (s *LogsSizeDataSummary) PrintHumanReadable() string {
0000000000000000000000000000000000000000;;		buf := &bytes.Buffer{}
0000000000000000000000000000000000000000;;		w := tabwriter.NewWriter(buf, 1, 0, 1, ' ', 0)
0000000000000000000000000000000000000000;;		fmt.Fprintf(w, "host\tlog_file\taverage_rate (B/s)\tnumber_of_probes\n")
0000000000000000000000000000000000000000;;		for k, v := range *s {
0000000000000000000000000000000000000000;;			fmt.Fprintf(w, "%v\t\t\t\n", k)
0000000000000000000000000000000000000000;;			for path, data := range v {
0000000000000000000000000000000000000000;;				fmt.Fprintf(w, "\t%v\t%v\t%v\n", path, data.AverageGenerationRate, data.NumberOfProbes)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		w.Flush()
0000000000000000000000000000000000000000;;		return buf.String()
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (s *LogsSizeDataSummary) PrintJSON() string {
0000000000000000000000000000000000000000;;		return PrettyPrintJSON(*s)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (s *LogsSizeDataSummary) SummaryKind() string {
0000000000000000000000000000000000000000;;		return "LogSizeSummary"
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type LogsSizeData struct {
0000000000000000000000000000000000000000;;		data LogSizeDataTimeseries
0000000000000000000000000000000000000000;;		lock sync.Mutex
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// WorkItem is a command for a worker that contains an IP of machine from which we want to
0000000000000000000000000000000000000000;;	// gather data and paths to all files we're interested in.
0000000000000000000000000000000000000000;;	type WorkItem struct {
0000000000000000000000000000000000000000;;		ip                string
0000000000000000000000000000000000000000;;		paths             []string
0000000000000000000000000000000000000000;;		backoffMultiplier int
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func prepareData(masterAddress string, nodeAddresses []string) *LogsSizeData {
0000000000000000000000000000000000000000;;		data := make(LogSizeDataTimeseries)
0000000000000000000000000000000000000000;;		ips := append(nodeAddresses, masterAddress)
0000000000000000000000000000000000000000;;		for _, ip := range ips {
0000000000000000000000000000000000000000;;			data[ip] = make(map[string][]TimestampedSize)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return &LogsSizeData{
0000000000000000000000000000000000000000;;			data: data,
0000000000000000000000000000000000000000;;			lock: sync.Mutex{},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (d *LogsSizeData) AddNewData(ip, path string, timestamp time.Time, size int) {
0000000000000000000000000000000000000000;;		d.lock.Lock()
0000000000000000000000000000000000000000;;		defer d.lock.Unlock()
0000000000000000000000000000000000000000;;		d.data[ip][path] = append(
0000000000000000000000000000000000000000;;			d.data[ip][path],
0000000000000000000000000000000000000000;;			TimestampedSize{
0000000000000000000000000000000000000000;;				timestamp: timestamp,
0000000000000000000000000000000000000000;;				size:      size,
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;		)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// NewLogsVerifier creates a new LogsSizeVerifier which will stop when stopChannel is closed
0000000000000000000000000000000000000000;;	func NewLogsVerifier(c clientset.Interface, stopChannel chan bool) *LogsSizeVerifier {
0000000000000000000000000000000000000000;;		nodeAddresses, err := NodeSSHHosts(c)
0000000000000000000000000000000000000000;;		ExpectNoError(err)
0000000000000000000000000000000000000000;;		masterAddress := GetMasterHost() + ":22"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		workChannel := make(chan WorkItem, len(nodeAddresses)+1)
0000000000000000000000000000000000000000;;		workers := make([]*LogSizeGatherer, workersNo)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		verifier := &LogsSizeVerifier{
0000000000000000000000000000000000000000;;			client:        c,
0000000000000000000000000000000000000000;;			stopChannel:   stopChannel,
0000000000000000000000000000000000000000;;			data:          prepareData(masterAddress, nodeAddresses),
0000000000000000000000000000000000000000;;			masterAddress: masterAddress,
0000000000000000000000000000000000000000;;			nodeAddresses: nodeAddresses,
0000000000000000000000000000000000000000;;			wg:            sync.WaitGroup{},
0000000000000000000000000000000000000000;;			workChannel:   workChannel,
0000000000000000000000000000000000000000;;			workers:       workers,
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		verifier.wg.Add(workersNo)
0000000000000000000000000000000000000000;;		for i := 0; i < workersNo; i++ {
0000000000000000000000000000000000000000;;			workers[i] = &LogSizeGatherer{
0000000000000000000000000000000000000000;;				stopChannel: stopChannel,
0000000000000000000000000000000000000000;;				data:        verifier.data,
0000000000000000000000000000000000000000;;				wg:          &verifier.wg,
0000000000000000000000000000000000000000;;				workChannel: workChannel,
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return verifier
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// GetSummary returns a summary (average generation rate and number of probes) of the data gathered by LogSizeVerifier
0000000000000000000000000000000000000000;;	func (s *LogsSizeVerifier) GetSummary() *LogsSizeDataSummary {
0000000000000000000000000000000000000000;;		result := make(LogsSizeDataSummary)
0000000000000000000000000000000000000000;;		for k, v := range s.data.data {
0000000000000000000000000000000000000000;;			result[k] = make(map[string]SingleLogSummary)
0000000000000000000000000000000000000000;;			for path, data := range v {
0000000000000000000000000000000000000000;;				if len(data) > 1 {
0000000000000000000000000000000000000000;;					last := data[len(data)-1]
0000000000000000000000000000000000000000;;					first := data[0]
0000000000000000000000000000000000000000;;					rate := (last.size - first.size) / int(last.timestamp.Sub(first.timestamp)/time.Second)
0000000000000000000000000000000000000000;;					result[k][path] = SingleLogSummary{
0000000000000000000000000000000000000000;;						AverageGenerationRate: rate,
0000000000000000000000000000000000000000;;						NumberOfProbes:        len(data),
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return &result
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Run starts log size gathering. It starts a gorouting for every worker and then blocks until stopChannel is closed
0000000000000000000000000000000000000000;;	func (v *LogsSizeVerifier) Run() {
0000000000000000000000000000000000000000;;		v.workChannel <- WorkItem{
0000000000000000000000000000000000000000;;			ip:                v.masterAddress,
0000000000000000000000000000000000000000;;			paths:             masterLogsToCheck,
0000000000000000000000000000000000000000;;			backoffMultiplier: 1,
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		for _, node := range v.nodeAddresses {
0000000000000000000000000000000000000000;;			v.workChannel <- WorkItem{
0000000000000000000000000000000000000000;;				ip:                node,
0000000000000000000000000000000000000000;;				paths:             nodeLogsToCheck,
0000000000000000000000000000000000000000;;				backoffMultiplier: 1,
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		for _, worker := range v.workers {
0000000000000000000000000000000000000000;;			go worker.Run()
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		<-v.stopChannel
0000000000000000000000000000000000000000;;		v.wg.Wait()
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (g *LogSizeGatherer) Run() {
0000000000000000000000000000000000000000;;		for g.Work() {
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (g *LogSizeGatherer) pushWorkItem(workItem WorkItem) {
0000000000000000000000000000000000000000;;		select {
0000000000000000000000000000000000000000;;		case <-time.After(time.Duration(workItem.backoffMultiplier) * pollingPeriod):
0000000000000000000000000000000000000000;;			g.workChannel <- workItem
0000000000000000000000000000000000000000;;		case <-g.stopChannel:
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Work does a single unit of work: tries to take out a WorkItem from the queue, ssh-es into a given machine,
0000000000000000000000000000000000000000;;	// gathers data, writes it to the shared <data> map, and creates a gorouting which reinserts work item into
0000000000000000000000000000000000000000;;	// the queue with a <pollingPeriod> delay. Returns false if worker should exit.
0000000000000000000000000000000000000000;;	func (g *LogSizeGatherer) Work() bool {
0000000000000000000000000000000000000000;;		var workItem WorkItem
0000000000000000000000000000000000000000;;		select {
0000000000000000000000000000000000000000;;		case <-g.stopChannel:
0000000000000000000000000000000000000000;;			g.wg.Done()
0000000000000000000000000000000000000000;;			return false
0000000000000000000000000000000000000000;;		case workItem = <-g.workChannel:
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		sshResult, err := SSH(
0000000000000000000000000000000000000000;;			fmt.Sprintf("ls -l %v | awk '{print $9, $5}' | tr '\n' ' '", strings.Join(workItem.paths, " ")),
0000000000000000000000000000000000000000;;			workItem.ip,
0000000000000000000000000000000000000000;;			TestContext.Provider,
0000000000000000000000000000000000000000;;		)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			Logf("Error while trying to SSH to %v, skipping probe. Error: %v", workItem.ip, err)
0000000000000000000000000000000000000000;;			// In case of repeated error give up.
0000000000000000000000000000000000000000;;			if workItem.backoffMultiplier >= 128 {
0000000000000000000000000000000000000000;;				Logf("Failed to ssh to a node %v multiple times in a row. Giving up.", workItem.ip)
0000000000000000000000000000000000000000;;				g.wg.Done()
0000000000000000000000000000000000000000;;				return false
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			workItem.backoffMultiplier *= 2
0000000000000000000000000000000000000000;;			go g.pushWorkItem(workItem)
0000000000000000000000000000000000000000;;			return true
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		workItem.backoffMultiplier = 1
0000000000000000000000000000000000000000;;		results := strings.Split(sshResult.Stdout, " ")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		now := time.Now()
0000000000000000000000000000000000000000;;		for i := 0; i+1 < len(results); i = i + 2 {
0000000000000000000000000000000000000000;;			path := results[i]
0000000000000000000000000000000000000000;;			size, err := strconv.Atoi(results[i+1])
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				Logf("Error during conversion to int: %v, skipping data. Error: %v", results[i+1], err)
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			g.data.AddNewData(workItem.ip, path, now, size)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		go g.pushWorkItem(workItem)
0000000000000000000000000000000000000000;;		return true
0000000000000000000000000000000000000000;;	}
