0000000000000000000000000000000000000000;;	/*
0000000000000000000000000000000000000000;;	Copyright 2014 The Kubernetes Authors.
1b6040401a32e6e156ebe6e317db1c66b11e8d97;test/e2e/kubelet_stats.go[test/e2e/kubelet_stats.go][test/e2e/framework/kubelet_stats.go];	
0000000000000000000000000000000000000000;;	Licensed under the Apache License, Version 2.0 (the "License");
0000000000000000000000000000000000000000;;	you may not use this file except in compliance with the License.
0000000000000000000000000000000000000000;;	You may obtain a copy of the License at
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	    http://www.apache.org/licenses/LICENSE-2.0
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	Unless required by applicable law or agreed to in writing, software
0000000000000000000000000000000000000000;;	distributed under the License is distributed on an "AS IS" BASIS,
0000000000000000000000000000000000000000;;	WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
0000000000000000000000000000000000000000;;	See the License for the specific language governing permissions and
0000000000000000000000000000000000000000;;	limitations under the License.
0000000000000000000000000000000000000000;;	*/
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	package framework
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	import (
0000000000000000000000000000000000000000;;		"bytes"
0000000000000000000000000000000000000000;;		"context"
0000000000000000000000000000000000000000;;		"encoding/json"
0000000000000000000000000000000000000000;;		"fmt"
0000000000000000000000000000000000000000;;		"sort"
0000000000000000000000000000000000000000;;		"strconv"
0000000000000000000000000000000000000000;;		"strings"
0000000000000000000000000000000000000000;;		"sync"
0000000000000000000000000000000000000000;;		"text/tabwriter"
0000000000000000000000000000000000000000;;		"time"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
0000000000000000000000000000000000000000;;		utilerrors "k8s.io/apimachinery/pkg/util/errors"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/util/sets"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/util/wait"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/client/clientset_generated/clientset"
0000000000000000000000000000000000000000;;		stats "k8s.io/kubernetes/pkg/kubelet/apis/stats/v1alpha1"
0000000000000000000000000000000000000000;;		kubeletmetrics "k8s.io/kubernetes/pkg/kubelet/metrics"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/master/ports"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/test/e2e/metrics"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		"github.com/prometheus/common/model"
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// KubeletMetric stores metrics scraped from the kubelet server's /metric endpoint.
0000000000000000000000000000000000000000;;	// TODO: Get some more structure around the metrics and this type
0000000000000000000000000000000000000000;;	type KubeletLatencyMetric struct {
0000000000000000000000000000000000000000;;		// eg: list, info, create
0000000000000000000000000000000000000000;;		Operation string
0000000000000000000000000000000000000000;;		// eg: sync_pods, pod_worker
0000000000000000000000000000000000000000;;		Method string
0000000000000000000000000000000000000000;;		// 0 <= quantile <=1, e.g. 0.95 is 95%tile, 0.5 is median.
0000000000000000000000000000000000000000;;		Quantile float64
0000000000000000000000000000000000000000;;		Latency  time.Duration
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// KubeletMetricByLatency implements sort.Interface for []KubeletMetric based on
0000000000000000000000000000000000000000;;	// the latency field.
0000000000000000000000000000000000000000;;	type KubeletLatencyMetrics []KubeletLatencyMetric
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (a KubeletLatencyMetrics) Len() int           { return len(a) }
0000000000000000000000000000000000000000;;	func (a KubeletLatencyMetrics) Swap(i, j int)      { a[i], a[j] = a[j], a[i] }
0000000000000000000000000000000000000000;;	func (a KubeletLatencyMetrics) Less(i, j int) bool { return a[i].Latency > a[j].Latency }
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// If a apiserver client is passed in, the function will try to get kubelet metrics from metrics grabber;
0000000000000000000000000000000000000000;;	// or else, the function will try to get kubelet metrics directly from the node.
0000000000000000000000000000000000000000;;	func getKubeletMetricsFromNode(c clientset.Interface, nodeName string) (metrics.KubeletMetrics, error) {
0000000000000000000000000000000000000000;;		if c == nil {
0000000000000000000000000000000000000000;;			return metrics.GrabKubeletMetricsWithoutProxy(nodeName)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		grabber, err := metrics.NewMetricsGrabber(c, true, false, false, false)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return metrics.KubeletMetrics{}, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return grabber.GrabFromKubelet(nodeName)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// getKubeletMetrics gets all metrics in kubelet subsystem from specified node and trims
0000000000000000000000000000000000000000;;	// the subsystem prefix.
0000000000000000000000000000000000000000;;	func getKubeletMetrics(c clientset.Interface, nodeName string) (metrics.KubeletMetrics, error) {
0000000000000000000000000000000000000000;;		ms, err := getKubeletMetricsFromNode(c, nodeName)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return metrics.KubeletMetrics{}, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		kubeletMetrics := make(metrics.KubeletMetrics)
0000000000000000000000000000000000000000;;		for name, samples := range ms {
0000000000000000000000000000000000000000;;			const prefix = kubeletmetrics.KubeletSubsystem + "_"
0000000000000000000000000000000000000000;;			if !strings.HasPrefix(name, prefix) {
0000000000000000000000000000000000000000;;				// Not a kubelet metric.
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			method := strings.TrimPrefix(name, prefix)
0000000000000000000000000000000000000000;;			kubeletMetrics[method] = samples
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return kubeletMetrics, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// GetKubeletLatencyMetrics gets all latency related kubelet metrics. Note that the KubeletMetrcis
0000000000000000000000000000000000000000;;	// passed in should not contain subsystem prefix.
0000000000000000000000000000000000000000;;	func GetKubeletLatencyMetrics(ms metrics.KubeletMetrics) KubeletLatencyMetrics {
0000000000000000000000000000000000000000;;		latencyMethods := sets.NewString(
0000000000000000000000000000000000000000;;			kubeletmetrics.PodWorkerLatencyKey,
0000000000000000000000000000000000000000;;			kubeletmetrics.PodWorkerStartLatencyKey,
0000000000000000000000000000000000000000;;			kubeletmetrics.PodStartLatencyKey,
0000000000000000000000000000000000000000;;			kubeletmetrics.CgroupManagerOperationsKey,
0000000000000000000000000000000000000000;;			kubeletmetrics.DockerOperationsLatencyKey,
0000000000000000000000000000000000000000;;			kubeletmetrics.PodWorkerStartLatencyKey,
0000000000000000000000000000000000000000;;			kubeletmetrics.PLEGRelistLatencyKey,
0000000000000000000000000000000000000000;;		)
0000000000000000000000000000000000000000;;		return GetKubeletMetrics(ms, latencyMethods)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func GetKubeletMetrics(ms metrics.KubeletMetrics, methods sets.String) KubeletLatencyMetrics {
0000000000000000000000000000000000000000;;		var latencyMetrics KubeletLatencyMetrics
0000000000000000000000000000000000000000;;		for method, samples := range ms {
0000000000000000000000000000000000000000;;			if !methods.Has(method) {
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			for _, sample := range samples {
0000000000000000000000000000000000000000;;				latency := sample.Value
0000000000000000000000000000000000000000;;				operation := string(sample.Metric["operation_type"])
0000000000000000000000000000000000000000;;				var quantile float64
0000000000000000000000000000000000000000;;				if val, ok := sample.Metric[model.QuantileLabel]; ok {
0000000000000000000000000000000000000000;;					var err error
0000000000000000000000000000000000000000;;					if quantile, err = strconv.ParseFloat(string(val), 64); err != nil {
0000000000000000000000000000000000000000;;						continue
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				latencyMetrics = append(latencyMetrics, KubeletLatencyMetric{
0000000000000000000000000000000000000000;;					Operation: operation,
0000000000000000000000000000000000000000;;					Method:    method,
0000000000000000000000000000000000000000;;					Quantile:  quantile,
0000000000000000000000000000000000000000;;					Latency:   time.Duration(int64(latency)) * time.Microsecond,
0000000000000000000000000000000000000000;;				})
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return latencyMetrics
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// RuntimeOperationMonitor is the tool getting and parsing docker operation metrics.
0000000000000000000000000000000000000000;;	type RuntimeOperationMonitor struct {
0000000000000000000000000000000000000000;;		client          clientset.Interface
0000000000000000000000000000000000000000;;		nodesRuntimeOps map[string]NodeRuntimeOperationErrorRate
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// NodeRuntimeOperationErrorRate is the runtime operation error rate on one node.
0000000000000000000000000000000000000000;;	type NodeRuntimeOperationErrorRate map[string]*RuntimeOperationErrorRate
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// RuntimeOperationErrorRate is the error rate of a specified runtime operation.
0000000000000000000000000000000000000000;;	type RuntimeOperationErrorRate struct {
0000000000000000000000000000000000000000;;		TotalNumber float64
0000000000000000000000000000000000000000;;		ErrorRate   float64
0000000000000000000000000000000000000000;;		TimeoutRate float64
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func NewRuntimeOperationMonitor(c clientset.Interface) *RuntimeOperationMonitor {
0000000000000000000000000000000000000000;;		m := &RuntimeOperationMonitor{
0000000000000000000000000000000000000000;;			client:          c,
0000000000000000000000000000000000000000;;			nodesRuntimeOps: make(map[string]NodeRuntimeOperationErrorRate),
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		nodes, err := m.client.Core().Nodes().List(metav1.ListOptions{})
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			Failf("RuntimeOperationMonitor: unable to get list of nodes: %v", err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		for _, node := range nodes.Items {
0000000000000000000000000000000000000000;;			m.nodesRuntimeOps[node.Name] = make(NodeRuntimeOperationErrorRate)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		// Initialize the runtime operation error rate
0000000000000000000000000000000000000000;;		m.GetRuntimeOperationErrorRate()
0000000000000000000000000000000000000000;;		return m
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// GetRuntimeOperationErrorRate gets runtime operation records from kubelet metrics and calculate
0000000000000000000000000000000000000000;;	// error rates of all runtime operations.
0000000000000000000000000000000000000000;;	func (m *RuntimeOperationMonitor) GetRuntimeOperationErrorRate() map[string]NodeRuntimeOperationErrorRate {
0000000000000000000000000000000000000000;;		for node := range m.nodesRuntimeOps {
0000000000000000000000000000000000000000;;			nodeResult, err := getNodeRuntimeOperationErrorRate(m.client, node)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				Logf("GetRuntimeOperationErrorRate: unable to get kubelet metrics from node %q: %v", node, err)
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			m.nodesRuntimeOps[node] = nodeResult
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return m.nodesRuntimeOps
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// GetLatestRuntimeOperationErrorRate gets latest error rate and timeout rate from last observed RuntimeOperationErrorRate.
0000000000000000000000000000000000000000;;	func (m *RuntimeOperationMonitor) GetLatestRuntimeOperationErrorRate() map[string]NodeRuntimeOperationErrorRate {
0000000000000000000000000000000000000000;;		result := make(map[string]NodeRuntimeOperationErrorRate)
0000000000000000000000000000000000000000;;		for node := range m.nodesRuntimeOps {
0000000000000000000000000000000000000000;;			result[node] = make(NodeRuntimeOperationErrorRate)
0000000000000000000000000000000000000000;;			oldNodeResult := m.nodesRuntimeOps[node]
0000000000000000000000000000000000000000;;			curNodeResult, err := getNodeRuntimeOperationErrorRate(m.client, node)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				Logf("GetLatestRuntimeOperationErrorRate: unable to get kubelet metrics from node %q: %v", node, err)
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			for op, cur := range curNodeResult {
0000000000000000000000000000000000000000;;				t := *cur
0000000000000000000000000000000000000000;;				if old, found := oldNodeResult[op]; found {
0000000000000000000000000000000000000000;;					t.ErrorRate = (t.ErrorRate*t.TotalNumber - old.ErrorRate*old.TotalNumber) / (t.TotalNumber - old.TotalNumber)
0000000000000000000000000000000000000000;;					t.TimeoutRate = (t.TimeoutRate*t.TotalNumber - old.TimeoutRate*old.TotalNumber) / (t.TotalNumber - old.TotalNumber)
0000000000000000000000000000000000000000;;					t.TotalNumber -= old.TotalNumber
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				result[node][op] = &t
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			m.nodesRuntimeOps[node] = curNodeResult
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return result
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// FormatRuntimeOperationErrorRate formats the runtime operation error rate to string.
0000000000000000000000000000000000000000;;	func FormatRuntimeOperationErrorRate(nodesResult map[string]NodeRuntimeOperationErrorRate) string {
0000000000000000000000000000000000000000;;		lines := []string{}
0000000000000000000000000000000000000000;;		for node, nodeResult := range nodesResult {
0000000000000000000000000000000000000000;;			lines = append(lines, fmt.Sprintf("node %q runtime operation error rate:", node))
0000000000000000000000000000000000000000;;			for op, result := range nodeResult {
0000000000000000000000000000000000000000;;				line := fmt.Sprintf("operation %q: total - %.0f; error rate - %f; timeout rate - %f", op,
0000000000000000000000000000000000000000;;					result.TotalNumber, result.ErrorRate, result.TimeoutRate)
0000000000000000000000000000000000000000;;				lines = append(lines, line)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			lines = append(lines, fmt.Sprintln())
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return strings.Join(lines, "\n")
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// getNodeRuntimeOperationErrorRate gets runtime operation error rate from specified node.
0000000000000000000000000000000000000000;;	func getNodeRuntimeOperationErrorRate(c clientset.Interface, node string) (NodeRuntimeOperationErrorRate, error) {
0000000000000000000000000000000000000000;;		result := make(NodeRuntimeOperationErrorRate)
0000000000000000000000000000000000000000;;		ms, err := getKubeletMetrics(c, node)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return result, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		// If no corresponding metrics are found, the returned samples will be empty. Then the following
0000000000000000000000000000000000000000;;		// loop will be skipped automatically.
0000000000000000000000000000000000000000;;		allOps := ms[kubeletmetrics.DockerOperationsKey]
0000000000000000000000000000000000000000;;		errOps := ms[kubeletmetrics.DockerOperationsErrorsKey]
0000000000000000000000000000000000000000;;		timeoutOps := ms[kubeletmetrics.DockerOperationsTimeoutKey]
0000000000000000000000000000000000000000;;		for _, sample := range allOps {
0000000000000000000000000000000000000000;;			operation := string(sample.Metric["operation_type"])
0000000000000000000000000000000000000000;;			result[operation] = &RuntimeOperationErrorRate{TotalNumber: float64(sample.Value)}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		for _, sample := range errOps {
0000000000000000000000000000000000000000;;			operation := string(sample.Metric["operation_type"])
0000000000000000000000000000000000000000;;			// Should always find the corresponding item, just in case
0000000000000000000000000000000000000000;;			if _, found := result[operation]; found {
0000000000000000000000000000000000000000;;				result[operation].ErrorRate = float64(sample.Value) / result[operation].TotalNumber
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		for _, sample := range timeoutOps {
0000000000000000000000000000000000000000;;			operation := string(sample.Metric["operation_type"])
0000000000000000000000000000000000000000;;			if _, found := result[operation]; found {
0000000000000000000000000000000000000000;;				result[operation].TimeoutRate = float64(sample.Value) / result[operation].TotalNumber
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return result, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// HighLatencyKubeletOperations logs and counts the high latency metrics exported by the kubelet server via /metrics.
0000000000000000000000000000000000000000;;	func HighLatencyKubeletOperations(c clientset.Interface, threshold time.Duration, nodeName string, logFunc func(fmt string, args ...interface{})) (KubeletLatencyMetrics, error) {
0000000000000000000000000000000000000000;;		ms, err := getKubeletMetrics(c, nodeName)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return KubeletLatencyMetrics{}, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		latencyMetrics := GetKubeletLatencyMetrics(ms)
0000000000000000000000000000000000000000;;		sort.Sort(latencyMetrics)
0000000000000000000000000000000000000000;;		var badMetrics KubeletLatencyMetrics
0000000000000000000000000000000000000000;;		logFunc("\nLatency metrics for node %v", nodeName)
0000000000000000000000000000000000000000;;		for _, m := range latencyMetrics {
0000000000000000000000000000000000000000;;			if m.Latency > threshold {
0000000000000000000000000000000000000000;;				badMetrics = append(badMetrics, m)
0000000000000000000000000000000000000000;;				Logf("%+v", m)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return badMetrics, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// getStatsSummary contacts kubelet for the container information.
0000000000000000000000000000000000000000;;	func getStatsSummary(c clientset.Interface, nodeName string) (*stats.Summary, error) {
0000000000000000000000000000000000000000;;		subResourceProxyAvailable, err := ServerVersionGTE(SubResourceServiceAndNodeProxyVersion, c.Discovery())
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return nil, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		ctx, cancel := context.WithTimeout(context.Background(), SingleCallTimeout)
0000000000000000000000000000000000000000;;		defer cancel()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		var data []byte
0000000000000000000000000000000000000000;;		if subResourceProxyAvailable {
0000000000000000000000000000000000000000;;			data, err = c.Core().RESTClient().Get().
0000000000000000000000000000000000000000;;				Context(ctx).
0000000000000000000000000000000000000000;;				Resource("nodes").
0000000000000000000000000000000000000000;;				SubResource("proxy").
0000000000000000000000000000000000000000;;				Name(fmt.Sprintf("%v:%v", nodeName, ports.KubeletPort)).
0000000000000000000000000000000000000000;;				Suffix("stats/summary").
0000000000000000000000000000000000000000;;				Do().Raw()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		} else {
0000000000000000000000000000000000000000;;			data, err = c.Core().RESTClient().Get().
0000000000000000000000000000000000000000;;				Context(ctx).
0000000000000000000000000000000000000000;;				Prefix("proxy").
0000000000000000000000000000000000000000;;				Resource("nodes").
0000000000000000000000000000000000000000;;				Name(fmt.Sprintf("%v:%v", nodeName, ports.KubeletPort)).
0000000000000000000000000000000000000000;;				Suffix("stats/summary").
0000000000000000000000000000000000000000;;				Do().Raw()
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return nil, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		summary := stats.Summary{}
0000000000000000000000000000000000000000;;		err = json.Unmarshal(data, &summary)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return nil, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return &summary, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func removeUint64Ptr(ptr *uint64) uint64 {
0000000000000000000000000000000000000000;;		if ptr == nil {
0000000000000000000000000000000000000000;;			return 0
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return *ptr
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// getOneTimeResourceUsageOnNode queries the node's /stats/summary endpoint
0000000000000000000000000000000000000000;;	// and returns the resource usage of all containerNames for the past
0000000000000000000000000000000000000000;;	// cpuInterval.
0000000000000000000000000000000000000000;;	// The acceptable range of the interval is 2s~120s. Be warned that as the
0000000000000000000000000000000000000000;;	// interval (and #containers) increases, the size of kubelet's response
0000000000000000000000000000000000000000;;	// could be significant. E.g., the 60s interval stats for ~20 containers is
0000000000000000000000000000000000000000;;	// ~1.5MB. Don't hammer the node with frequent, heavy requests.
0000000000000000000000000000000000000000;;	//
0000000000000000000000000000000000000000;;	// cadvisor records cumulative cpu usage in nanoseconds, so we need to have two
0000000000000000000000000000000000000000;;	// stats points to compute the cpu usage over the interval. Assuming cadvisor
0000000000000000000000000000000000000000;;	// polls every second, we'd need to get N stats points for N-second interval.
0000000000000000000000000000000000000000;;	// Note that this is an approximation and may not be accurate, hence we also
0000000000000000000000000000000000000000;;	// write the actual interval used for calculation (based on the timestamps of
0000000000000000000000000000000000000000;;	// the stats points in ContainerResourceUsage.CPUInterval.
0000000000000000000000000000000000000000;;	//
0000000000000000000000000000000000000000;;	// containerNames is a function returning a collection of container names in which
0000000000000000000000000000000000000000;;	// user is interested in.
0000000000000000000000000000000000000000;;	func getOneTimeResourceUsageOnNode(
0000000000000000000000000000000000000000;;		c clientset.Interface,
0000000000000000000000000000000000000000;;		nodeName string,
0000000000000000000000000000000000000000;;		cpuInterval time.Duration,
0000000000000000000000000000000000000000;;		containerNames func() []string,
0000000000000000000000000000000000000000;;	) (ResourceUsagePerContainer, error) {
0000000000000000000000000000000000000000;;		const (
0000000000000000000000000000000000000000;;			// cadvisor records stats about every second.
0000000000000000000000000000000000000000;;			cadvisorStatsPollingIntervalInSeconds float64 = 1.0
0000000000000000000000000000000000000000;;			// cadvisor caches up to 2 minutes of stats (configured by kubelet).
0000000000000000000000000000000000000000;;			maxNumStatsToRequest int = 120
0000000000000000000000000000000000000000;;		)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		numStats := int(float64(cpuInterval.Seconds()) / cadvisorStatsPollingIntervalInSeconds)
0000000000000000000000000000000000000000;;		if numStats < 2 || numStats > maxNumStatsToRequest {
0000000000000000000000000000000000000000;;			return nil, fmt.Errorf("numStats needs to be > 1 and < %d", maxNumStatsToRequest)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		// Get information of all containers on the node.
0000000000000000000000000000000000000000;;		summary, err := getStatsSummary(c, nodeName)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return nil, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		f := func(name string, newStats *stats.ContainerStats) *ContainerResourceUsage {
0000000000000000000000000000000000000000;;			if newStats == nil || newStats.CPU == nil || newStats.Memory == nil {
0000000000000000000000000000000000000000;;				return nil
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			return &ContainerResourceUsage{
0000000000000000000000000000000000000000;;				Name:                    name,
0000000000000000000000000000000000000000;;				Timestamp:               newStats.StartTime.Time,
0000000000000000000000000000000000000000;;				CPUUsageInCores:         float64(removeUint64Ptr(newStats.CPU.UsageNanoCores)) / 1000000000,
0000000000000000000000000000000000000000;;				MemoryUsageInBytes:      removeUint64Ptr(newStats.Memory.UsageBytes),
0000000000000000000000000000000000000000;;				MemoryWorkingSetInBytes: removeUint64Ptr(newStats.Memory.WorkingSetBytes),
0000000000000000000000000000000000000000;;				MemoryRSSInBytes:        removeUint64Ptr(newStats.Memory.RSSBytes),
0000000000000000000000000000000000000000;;				CPUInterval:             0,
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		// Process container infos that are relevant to us.
0000000000000000000000000000000000000000;;		containers := containerNames()
0000000000000000000000000000000000000000;;		usageMap := make(ResourceUsagePerContainer, len(containers))
0000000000000000000000000000000000000000;;		observedContainers := []string{}
0000000000000000000000000000000000000000;;		for _, pod := range summary.Pods {
0000000000000000000000000000000000000000;;			for _, container := range pod.Containers {
0000000000000000000000000000000000000000;;				isInteresting := false
0000000000000000000000000000000000000000;;				for _, interestingContainerName := range containers {
0000000000000000000000000000000000000000;;					if container.Name == interestingContainerName {
0000000000000000000000000000000000000000;;						isInteresting = true
0000000000000000000000000000000000000000;;						observedContainers = append(observedContainers, container.Name)
0000000000000000000000000000000000000000;;						break
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				if !isInteresting {
0000000000000000000000000000000000000000;;					continue
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				if usage := f(pod.PodRef.Name+"/"+container.Name, &container); usage != nil {
0000000000000000000000000000000000000000;;					usageMap[pod.PodRef.Name+"/"+container.Name] = usage
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return usageMap, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func getNodeStatsSummary(c clientset.Interface, nodeName string) (*stats.Summary, error) {
0000000000000000000000000000000000000000;;		subResourceProxyAvailable, err := ServerVersionGTE(SubResourceServiceAndNodeProxyVersion, c.Discovery())
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return nil, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		var data []byte
0000000000000000000000000000000000000000;;		if subResourceProxyAvailable {
0000000000000000000000000000000000000000;;			data, err = c.Core().RESTClient().Get().
0000000000000000000000000000000000000000;;				Resource("nodes").
0000000000000000000000000000000000000000;;				SubResource("proxy").
0000000000000000000000000000000000000000;;				Name(fmt.Sprintf("%v:%v", nodeName, ports.KubeletPort)).
0000000000000000000000000000000000000000;;				Suffix("stats/summary").
0000000000000000000000000000000000000000;;				SetHeader("Content-Type", "application/json").
0000000000000000000000000000000000000000;;				Do().Raw()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		} else {
0000000000000000000000000000000000000000;;			data, err = c.Core().RESTClient().Get().
0000000000000000000000000000000000000000;;				Prefix("proxy").
0000000000000000000000000000000000000000;;				Resource("nodes").
0000000000000000000000000000000000000000;;				Name(fmt.Sprintf("%v:%v", nodeName, ports.KubeletPort)).
0000000000000000000000000000000000000000;;				Suffix("stats/summary").
0000000000000000000000000000000000000000;;				SetHeader("Content-Type", "application/json").
0000000000000000000000000000000000000000;;				Do().Raw()
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return nil, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		var summary *stats.Summary
0000000000000000000000000000000000000000;;		err = json.Unmarshal(data, &summary)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return nil, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return summary, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func getSystemContainerStats(summary *stats.Summary) map[string]*stats.ContainerStats {
0000000000000000000000000000000000000000;;		statsList := summary.Node.SystemContainers
0000000000000000000000000000000000000000;;		statsMap := make(map[string]*stats.ContainerStats)
0000000000000000000000000000000000000000;;		for i := range statsList {
0000000000000000000000000000000000000000;;			statsMap[statsList[i].Name] = &statsList[i]
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Create a root container stats using information available in
0000000000000000000000000000000000000000;;		// stats.NodeStats. This is necessary since it is a different type.
0000000000000000000000000000000000000000;;		statsMap[rootContainerName] = &stats.ContainerStats{
0000000000000000000000000000000000000000;;			CPU:    summary.Node.CPU,
0000000000000000000000000000000000000000;;			Memory: summary.Node.Memory,
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return statsMap
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	const (
0000000000000000000000000000000000000000;;		rootContainerName = "/"
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// A list of containers for which we want to collect resource usage.
0000000000000000000000000000000000000000;;	func TargetContainers() []string {
0000000000000000000000000000000000000000;;		return []string{
0000000000000000000000000000000000000000;;			rootContainerName,
0000000000000000000000000000000000000000;;			stats.SystemContainerRuntime,
0000000000000000000000000000000000000000;;			stats.SystemContainerKubelet,
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type ContainerResourceUsage struct {
0000000000000000000000000000000000000000;;		Name                    string
0000000000000000000000000000000000000000;;		Timestamp               time.Time
0000000000000000000000000000000000000000;;		CPUUsageInCores         float64
0000000000000000000000000000000000000000;;		MemoryUsageInBytes      uint64
0000000000000000000000000000000000000000;;		MemoryWorkingSetInBytes uint64
0000000000000000000000000000000000000000;;		MemoryRSSInBytes        uint64
0000000000000000000000000000000000000000;;		// The interval used to calculate CPUUsageInCores.
0000000000000000000000000000000000000000;;		CPUInterval time.Duration
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (r *ContainerResourceUsage) isStrictlyGreaterThan(rhs *ContainerResourceUsage) bool {
0000000000000000000000000000000000000000;;		return r.CPUUsageInCores > rhs.CPUUsageInCores && r.MemoryWorkingSetInBytes > rhs.MemoryWorkingSetInBytes
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type ResourceUsagePerContainer map[string]*ContainerResourceUsage
0000000000000000000000000000000000000000;;	type ResourceUsagePerNode map[string]ResourceUsagePerContainer
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func formatResourceUsageStats(nodeName string, containerStats ResourceUsagePerContainer) string {
0000000000000000000000000000000000000000;;		// Example output:
0000000000000000000000000000000000000000;;		//
0000000000000000000000000000000000000000;;		// Resource usage for node "e2e-test-foo-node-abcde":
0000000000000000000000000000000000000000;;		// container        cpu(cores)  memory(MB)
0000000000000000000000000000000000000000;;		// "/"              0.363       2942.09
0000000000000000000000000000000000000000;;		// "/docker-daemon" 0.088       521.80
0000000000000000000000000000000000000000;;		// "/kubelet"       0.086       424.37
0000000000000000000000000000000000000000;;		// "/system"        0.007       119.88
0000000000000000000000000000000000000000;;		buf := &bytes.Buffer{}
0000000000000000000000000000000000000000;;		w := tabwriter.NewWriter(buf, 1, 0, 1, ' ', 0)
0000000000000000000000000000000000000000;;		fmt.Fprintf(w, "container\tcpu(cores)\tmemory_working_set(MB)\tmemory_rss(MB)\n")
0000000000000000000000000000000000000000;;		for name, s := range containerStats {
0000000000000000000000000000000000000000;;			fmt.Fprintf(w, "%q\t%.3f\t%.2f\t%.2f\n", name, s.CPUUsageInCores, float64(s.MemoryWorkingSetInBytes)/(1024*1024), float64(s.MemoryRSSInBytes)/(1024*1024))
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		w.Flush()
0000000000000000000000000000000000000000;;		return fmt.Sprintf("Resource usage on node %q:\n%s", nodeName, buf.String())
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type uint64arr []uint64
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (a uint64arr) Len() int           { return len(a) }
0000000000000000000000000000000000000000;;	func (a uint64arr) Swap(i, j int)      { a[i], a[j] = a[j], a[i] }
0000000000000000000000000000000000000000;;	func (a uint64arr) Less(i, j int) bool { return a[i] < a[j] }
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type usageDataPerContainer struct {
0000000000000000000000000000000000000000;;		cpuData        []float64
0000000000000000000000000000000000000000;;		memUseData     []uint64
0000000000000000000000000000000000000000;;		memWorkSetData []uint64
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func GetKubeletHeapStats(c clientset.Interface, nodeName string) (string, error) {
0000000000000000000000000000000000000000;;		client, err := NodeProxyRequest(c, nodeName, "debug/pprof/heap")
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return "", err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		raw, errRaw := client.Raw()
0000000000000000000000000000000000000000;;		if errRaw != nil {
0000000000000000000000000000000000000000;;			return "", err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		stats := string(raw)
0000000000000000000000000000000000000000;;		// Only dumping the runtime.MemStats numbers to avoid polluting the log.
0000000000000000000000000000000000000000;;		numLines := 23
0000000000000000000000000000000000000000;;		lines := strings.Split(stats, "\n")
0000000000000000000000000000000000000000;;		return strings.Join(lines[len(lines)-numLines:], "\n"), nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func PrintAllKubeletPods(c clientset.Interface, nodeName string) {
0000000000000000000000000000000000000000;;		podList, err := GetKubeletPods(c, nodeName)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			Logf("Unable to retrieve kubelet pods for node %v: %v", nodeName, err)
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		for _, p := range podList.Items {
0000000000000000000000000000000000000000;;			Logf("%v from %v started at %v (%d container statuses recorded)", p.Name, p.Namespace, p.Status.StartTime, len(p.Status.ContainerStatuses))
0000000000000000000000000000000000000000;;			for _, c := range p.Status.ContainerStatuses {
0000000000000000000000000000000000000000;;				Logf("\tContainer %v ready: %v, restart count %v",
0000000000000000000000000000000000000000;;					c.Name, c.Ready, c.RestartCount)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func computeContainerResourceUsage(name string, oldStats, newStats *stats.ContainerStats) *ContainerResourceUsage {
0000000000000000000000000000000000000000;;		return &ContainerResourceUsage{
0000000000000000000000000000000000000000;;			Name:                    name,
0000000000000000000000000000000000000000;;			Timestamp:               newStats.CPU.Time.Time,
0000000000000000000000000000000000000000;;			CPUUsageInCores:         float64(*newStats.CPU.UsageCoreNanoSeconds-*oldStats.CPU.UsageCoreNanoSeconds) / float64(newStats.CPU.Time.Time.Sub(oldStats.CPU.Time.Time).Nanoseconds()),
0000000000000000000000000000000000000000;;			MemoryUsageInBytes:      *newStats.Memory.UsageBytes,
0000000000000000000000000000000000000000;;			MemoryWorkingSetInBytes: *newStats.Memory.WorkingSetBytes,
0000000000000000000000000000000000000000;;			MemoryRSSInBytes:        *newStats.Memory.RSSBytes,
0000000000000000000000000000000000000000;;			CPUInterval:             newStats.CPU.Time.Time.Sub(oldStats.CPU.Time.Time),
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// resourceCollector periodically polls the node, collect stats for a given
0000000000000000000000000000000000000000;;	// list of containers, computes and cache resource usage up to
0000000000000000000000000000000000000000;;	// maxEntriesPerContainer for each container.
0000000000000000000000000000000000000000;;	type resourceCollector struct {
0000000000000000000000000000000000000000;;		lock            sync.RWMutex
0000000000000000000000000000000000000000;;		node            string
0000000000000000000000000000000000000000;;		containers      []string
0000000000000000000000000000000000000000;;		client          clientset.Interface
0000000000000000000000000000000000000000;;		buffers         map[string][]*ContainerResourceUsage
0000000000000000000000000000000000000000;;		pollingInterval time.Duration
0000000000000000000000000000000000000000;;		stopCh          chan struct{}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func newResourceCollector(c clientset.Interface, nodeName string, containerNames []string, pollingInterval time.Duration) *resourceCollector {
0000000000000000000000000000000000000000;;		buffers := make(map[string][]*ContainerResourceUsage)
0000000000000000000000000000000000000000;;		return &resourceCollector{
0000000000000000000000000000000000000000;;			node:            nodeName,
0000000000000000000000000000000000000000;;			containers:      containerNames,
0000000000000000000000000000000000000000;;			client:          c,
0000000000000000000000000000000000000000;;			buffers:         buffers,
0000000000000000000000000000000000000000;;			pollingInterval: pollingInterval,
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Start starts a goroutine to Poll the node every pollingInterval.
0000000000000000000000000000000000000000;;	func (r *resourceCollector) Start() {
0000000000000000000000000000000000000000;;		r.stopCh = make(chan struct{}, 1)
0000000000000000000000000000000000000000;;		// Keep the last observed stats for comparison.
0000000000000000000000000000000000000000;;		oldStats := make(map[string]*stats.ContainerStats)
0000000000000000000000000000000000000000;;		go wait.Until(func() { r.collectStats(oldStats) }, r.pollingInterval, r.stopCh)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Stop sends a signal to terminate the stats collecting goroutine.
0000000000000000000000000000000000000000;;	func (r *resourceCollector) Stop() {
0000000000000000000000000000000000000000;;		close(r.stopCh)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// collectStats gets the latest stats from kubelet stats summary API, computes
0000000000000000000000000000000000000000;;	// the resource usage, and pushes it to the buffer.
0000000000000000000000000000000000000000;;	func (r *resourceCollector) collectStats(oldStatsMap map[string]*stats.ContainerStats) {
0000000000000000000000000000000000000000;;		summary, err := getNodeStatsSummary(r.client, r.node)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			Logf("Error getting node stats summary on %q, err: %v", r.node, err)
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		cStatsMap := getSystemContainerStats(summary)
0000000000000000000000000000000000000000;;		r.lock.Lock()
0000000000000000000000000000000000000000;;		defer r.lock.Unlock()
0000000000000000000000000000000000000000;;		for _, name := range r.containers {
0000000000000000000000000000000000000000;;			cStats, ok := cStatsMap[name]
0000000000000000000000000000000000000000;;			if !ok {
0000000000000000000000000000000000000000;;				Logf("Missing info/stats for container %q on node %q", name, r.node)
0000000000000000000000000000000000000000;;				return
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			if oldStats, ok := oldStatsMap[name]; ok {
0000000000000000000000000000000000000000;;				if oldStats.CPU.Time.Equal(cStats.CPU.Time) {
0000000000000000000000000000000000000000;;					// No change -> skip this stat.
0000000000000000000000000000000000000000;;					continue
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				r.buffers[name] = append(r.buffers[name], computeContainerResourceUsage(name, oldStats, cStats))
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			// Update the old stats.
0000000000000000000000000000000000000000;;			oldStatsMap[name] = cStats
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (r *resourceCollector) GetLatest() (ResourceUsagePerContainer, error) {
0000000000000000000000000000000000000000;;		r.lock.RLock()
0000000000000000000000000000000000000000;;		defer r.lock.RUnlock()
0000000000000000000000000000000000000000;;		stats := make(ResourceUsagePerContainer)
0000000000000000000000000000000000000000;;		for _, name := range r.containers {
0000000000000000000000000000000000000000;;			contStats, ok := r.buffers[name]
0000000000000000000000000000000000000000;;			if !ok || len(contStats) == 0 {
0000000000000000000000000000000000000000;;				return nil, fmt.Errorf("Resource usage on node %q is not ready yet", r.node)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			stats[name] = contStats[len(contStats)-1]
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return stats, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Reset frees the stats and start over.
0000000000000000000000000000000000000000;;	func (r *resourceCollector) Reset() {
0000000000000000000000000000000000000000;;		r.lock.Lock()
0000000000000000000000000000000000000000;;		defer r.lock.Unlock()
0000000000000000000000000000000000000000;;		for _, name := range r.containers {
0000000000000000000000000000000000000000;;			r.buffers[name] = []*ContainerResourceUsage{}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type resourceUsageByCPU []*ContainerResourceUsage
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (r resourceUsageByCPU) Len() int           { return len(r) }
0000000000000000000000000000000000000000;;	func (r resourceUsageByCPU) Swap(i, j int)      { r[i], r[j] = r[j], r[i] }
0000000000000000000000000000000000000000;;	func (r resourceUsageByCPU) Less(i, j int) bool { return r[i].CPUUsageInCores < r[j].CPUUsageInCores }
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// The percentiles to report.
0000000000000000000000000000000000000000;;	var percentiles = [...]float64{0.05, 0.20, 0.50, 0.70, 0.90, 0.95, 0.99}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// GetBasicCPUStats returns the percentiles the cpu usage in cores for
0000000000000000000000000000000000000000;;	// containerName. This method examines all data currently in the buffer.
0000000000000000000000000000000000000000;;	func (r *resourceCollector) GetBasicCPUStats(containerName string) map[float64]float64 {
0000000000000000000000000000000000000000;;		r.lock.RLock()
0000000000000000000000000000000000000000;;		defer r.lock.RUnlock()
0000000000000000000000000000000000000000;;		result := make(map[float64]float64, len(percentiles))
0000000000000000000000000000000000000000;;		usages := r.buffers[containerName]
0000000000000000000000000000000000000000;;		sort.Sort(resourceUsageByCPU(usages))
0000000000000000000000000000000000000000;;		for _, q := range percentiles {
0000000000000000000000000000000000000000;;			index := int(float64(len(usages))*q) - 1
0000000000000000000000000000000000000000;;			if index < 0 {
0000000000000000000000000000000000000000;;				// We don't have enough data.
0000000000000000000000000000000000000000;;				result[q] = 0
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			result[q] = usages[index].CPUUsageInCores
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return result
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// ResourceMonitor manages a resourceCollector per node.
0000000000000000000000000000000000000000;;	type ResourceMonitor struct {
0000000000000000000000000000000000000000;;		client          clientset.Interface
0000000000000000000000000000000000000000;;		containers      []string
0000000000000000000000000000000000000000;;		pollingInterval time.Duration
0000000000000000000000000000000000000000;;		collectors      map[string]*resourceCollector
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func NewResourceMonitor(c clientset.Interface, containerNames []string, pollingInterval time.Duration) *ResourceMonitor {
0000000000000000000000000000000000000000;;		return &ResourceMonitor{
0000000000000000000000000000000000000000;;			containers:      containerNames,
0000000000000000000000000000000000000000;;			client:          c,
0000000000000000000000000000000000000000;;			pollingInterval: pollingInterval,
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (r *ResourceMonitor) Start() {
0000000000000000000000000000000000000000;;		// It should be OK to monitor unschedulable Nodes
0000000000000000000000000000000000000000;;		nodes, err := r.client.Core().Nodes().List(metav1.ListOptions{})
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			Failf("ResourceMonitor: unable to get list of nodes: %v", err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		r.collectors = make(map[string]*resourceCollector, 0)
0000000000000000000000000000000000000000;;		for _, node := range nodes.Items {
0000000000000000000000000000000000000000;;			collector := newResourceCollector(r.client, node.Name, r.containers, r.pollingInterval)
0000000000000000000000000000000000000000;;			r.collectors[node.Name] = collector
0000000000000000000000000000000000000000;;			collector.Start()
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (r *ResourceMonitor) Stop() {
0000000000000000000000000000000000000000;;		for _, collector := range r.collectors {
0000000000000000000000000000000000000000;;			collector.Stop()
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (r *ResourceMonitor) Reset() {
0000000000000000000000000000000000000000;;		for _, collector := range r.collectors {
0000000000000000000000000000000000000000;;			collector.Reset()
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (r *ResourceMonitor) LogLatest() {
0000000000000000000000000000000000000000;;		summary, err := r.GetLatest()
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			Logf("%v", err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		Logf("%s", r.FormatResourceUsage(summary))
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (r *ResourceMonitor) FormatResourceUsage(s ResourceUsagePerNode) string {
0000000000000000000000000000000000000000;;		summary := []string{}
0000000000000000000000000000000000000000;;		for node, usage := range s {
0000000000000000000000000000000000000000;;			summary = append(summary, formatResourceUsageStats(node, usage))
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return strings.Join(summary, "\n")
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (r *ResourceMonitor) GetLatest() (ResourceUsagePerNode, error) {
0000000000000000000000000000000000000000;;		result := make(ResourceUsagePerNode)
0000000000000000000000000000000000000000;;		errs := []error{}
0000000000000000000000000000000000000000;;		for key, collector := range r.collectors {
0000000000000000000000000000000000000000;;			s, err := collector.GetLatest()
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				errs = append(errs, err)
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			result[key] = s
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return result, utilerrors.NewAggregate(errs)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (r *ResourceMonitor) GetMasterNodeLatest(usagePerNode ResourceUsagePerNode) ResourceUsagePerNode {
0000000000000000000000000000000000000000;;		result := make(ResourceUsagePerNode)
0000000000000000000000000000000000000000;;		var masterUsage ResourceUsagePerContainer
0000000000000000000000000000000000000000;;		var nodesUsage []ResourceUsagePerContainer
0000000000000000000000000000000000000000;;		for node, usage := range usagePerNode {
0000000000000000000000000000000000000000;;			if strings.HasSuffix(node, "master") {
0000000000000000000000000000000000000000;;				masterUsage = usage
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				nodesUsage = append(nodesUsage, usage)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		nodeAvgUsage := make(ResourceUsagePerContainer)
0000000000000000000000000000000000000000;;		for _, nodeUsage := range nodesUsage {
0000000000000000000000000000000000000000;;			for c, usage := range nodeUsage {
0000000000000000000000000000000000000000;;				if _, found := nodeAvgUsage[c]; !found {
0000000000000000000000000000000000000000;;					nodeAvgUsage[c] = &ContainerResourceUsage{Name: usage.Name}
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				nodeAvgUsage[c].CPUUsageInCores += usage.CPUUsageInCores
0000000000000000000000000000000000000000;;				nodeAvgUsage[c].MemoryUsageInBytes += usage.MemoryUsageInBytes
0000000000000000000000000000000000000000;;				nodeAvgUsage[c].MemoryWorkingSetInBytes += usage.MemoryWorkingSetInBytes
0000000000000000000000000000000000000000;;				nodeAvgUsage[c].MemoryRSSInBytes += usage.MemoryRSSInBytes
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		for c := range nodeAvgUsage {
0000000000000000000000000000000000000000;;			nodeAvgUsage[c].CPUUsageInCores /= float64(len(nodesUsage))
0000000000000000000000000000000000000000;;			nodeAvgUsage[c].MemoryUsageInBytes /= uint64(len(nodesUsage))
0000000000000000000000000000000000000000;;			nodeAvgUsage[c].MemoryWorkingSetInBytes /= uint64(len(nodesUsage))
0000000000000000000000000000000000000000;;			nodeAvgUsage[c].MemoryRSSInBytes /= uint64(len(nodesUsage))
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		result["master"] = masterUsage
0000000000000000000000000000000000000000;;		result["node"] = nodeAvgUsage
0000000000000000000000000000000000000000;;		return result
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// ContainersCPUSummary is indexed by the container name with each entry a
0000000000000000000000000000000000000000;;	// (percentile, value) map.
0000000000000000000000000000000000000000;;	type ContainersCPUSummary map[string]map[float64]float64
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// NodesCPUSummary is indexed by the node name with each entry a
0000000000000000000000000000000000000000;;	// ContainersCPUSummary map.
0000000000000000000000000000000000000000;;	type NodesCPUSummary map[string]ContainersCPUSummary
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (r *ResourceMonitor) FormatCPUSummary(summary NodesCPUSummary) string {
0000000000000000000000000000000000000000;;		// Example output for a node (the percentiles may differ):
0000000000000000000000000000000000000000;;		// CPU usage of containers on node "e2e-test-foo-node-0vj7":
0000000000000000000000000000000000000000;;		// container        5th%  50th% 90th% 95th%
0000000000000000000000000000000000000000;;		// "/"              0.051 0.159 0.387 0.455
0000000000000000000000000000000000000000;;		// "/runtime        0.000 0.000 0.146 0.166
0000000000000000000000000000000000000000;;		// "/kubelet"       0.036 0.053 0.091 0.154
0000000000000000000000000000000000000000;;		// "/misc"          0.001 0.001 0.001 0.002
0000000000000000000000000000000000000000;;		var summaryStrings []string
0000000000000000000000000000000000000000;;		var header []string
0000000000000000000000000000000000000000;;		header = append(header, "container")
0000000000000000000000000000000000000000;;		for _, p := range percentiles {
0000000000000000000000000000000000000000;;			header = append(header, fmt.Sprintf("%.0fth%%", p*100))
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		for nodeName, containers := range summary {
0000000000000000000000000000000000000000;;			buf := &bytes.Buffer{}
0000000000000000000000000000000000000000;;			w := tabwriter.NewWriter(buf, 1, 0, 1, ' ', 0)
0000000000000000000000000000000000000000;;			fmt.Fprintf(w, "%s\n", strings.Join(header, "\t"))
0000000000000000000000000000000000000000;;			for _, containerName := range TargetContainers() {
0000000000000000000000000000000000000000;;				var s []string
0000000000000000000000000000000000000000;;				s = append(s, fmt.Sprintf("%q", containerName))
0000000000000000000000000000000000000000;;				data, ok := containers[containerName]
0000000000000000000000000000000000000000;;				for _, p := range percentiles {
0000000000000000000000000000000000000000;;					value := "N/A"
0000000000000000000000000000000000000000;;					if ok {
0000000000000000000000000000000000000000;;						value = fmt.Sprintf("%.3f", data[p])
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					s = append(s, value)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				fmt.Fprintf(w, "%s\n", strings.Join(s, "\t"))
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			w.Flush()
0000000000000000000000000000000000000000;;			summaryStrings = append(summaryStrings, fmt.Sprintf("CPU usage of containers on node %q\n:%s", nodeName, buf.String()))
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return strings.Join(summaryStrings, "\n")
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (r *ResourceMonitor) LogCPUSummary() {
0000000000000000000000000000000000000000;;		summary := r.GetCPUSummary()
0000000000000000000000000000000000000000;;		Logf("%s", r.FormatCPUSummary(summary))
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (r *ResourceMonitor) GetCPUSummary() NodesCPUSummary {
0000000000000000000000000000000000000000;;		result := make(NodesCPUSummary)
0000000000000000000000000000000000000000;;		for nodeName, collector := range r.collectors {
0000000000000000000000000000000000000000;;			result[nodeName] = make(ContainersCPUSummary)
0000000000000000000000000000000000000000;;			for _, containerName := range TargetContainers() {
0000000000000000000000000000000000000000;;				data := collector.GetBasicCPUStats(containerName)
0000000000000000000000000000000000000000;;				result[nodeName][containerName] = data
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return result
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (r *ResourceMonitor) GetMasterNodeCPUSummary(summaryPerNode NodesCPUSummary) NodesCPUSummary {
0000000000000000000000000000000000000000;;		result := make(NodesCPUSummary)
0000000000000000000000000000000000000000;;		var masterSummary ContainersCPUSummary
0000000000000000000000000000000000000000;;		var nodesSummaries []ContainersCPUSummary
0000000000000000000000000000000000000000;;		for node, summary := range summaryPerNode {
0000000000000000000000000000000000000000;;			if strings.HasSuffix(node, "master") {
0000000000000000000000000000000000000000;;				masterSummary = summary
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				nodesSummaries = append(nodesSummaries, summary)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		nodeAvgSummary := make(ContainersCPUSummary)
0000000000000000000000000000000000000000;;		for _, nodeSummary := range nodesSummaries {
0000000000000000000000000000000000000000;;			for c, summary := range nodeSummary {
0000000000000000000000000000000000000000;;				if _, found := nodeAvgSummary[c]; !found {
0000000000000000000000000000000000000000;;					nodeAvgSummary[c] = map[float64]float64{}
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				for perc, value := range summary {
0000000000000000000000000000000000000000;;					nodeAvgSummary[c][perc] += value
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		for c := range nodeAvgSummary {
0000000000000000000000000000000000000000;;			for perc := range nodeAvgSummary[c] {
0000000000000000000000000000000000000000;;				nodeAvgSummary[c][perc] /= float64(len(nodesSummaries))
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		result["master"] = masterSummary
0000000000000000000000000000000000000000;;		result["node"] = nodeAvgSummary
0000000000000000000000000000000000000000;;		return result
0000000000000000000000000000000000000000;;	}
