0000000000000000000000000000000000000000;;	/*
0000000000000000000000000000000000000000;;	Copyright 2015 The Kubernetes Authors.
7ae9f03395c6627a081201b94a92727a999ac034;staging/src/k8s.io/client-go/1.4/tools/record/events_cache.go[staging/src/k8s.io/client-go/1.4/tools/record/events_cache.go][staging/src/k8s.io/client-go/tools/record/events_cache.go];	
0000000000000000000000000000000000000000;;	Licensed under the Apache License, Version 2.0 (the "License");
0000000000000000000000000000000000000000;;	you may not use this file except in compliance with the License.
0000000000000000000000000000000000000000;;	You may obtain a copy of the License at
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	    http://www.apache.org/licenses/LICENSE-2.0
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	Unless required by applicable law or agreed to in writing, software
0000000000000000000000000000000000000000;;	distributed under the License is distributed on an "AS IS" BASIS,
0000000000000000000000000000000000000000;;	WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
0000000000000000000000000000000000000000;;	See the License for the specific language governing permissions and
0000000000000000000000000000000000000000;;	limitations under the License.
0000000000000000000000000000000000000000;;	*/
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	package record
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	import (
0000000000000000000000000000000000000000;;		"encoding/json"
0000000000000000000000000000000000000000;;		"fmt"
0000000000000000000000000000000000000000;;		"strings"
0000000000000000000000000000000000000000;;		"sync"
0000000000000000000000000000000000000000;;		"time"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		"github.com/golang/groupcache/lru"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		"k8s.io/api/core/v1"
0000000000000000000000000000000000000000;;		metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/util/clock"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/util/sets"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/util/strategicpatch"
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	const (
0000000000000000000000000000000000000000;;		maxLruCacheEntries = 4096
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// if we see the same event that varies only by message
0000000000000000000000000000000000000000;;		// more than 10 times in a 10 minute period, aggregate the event
0000000000000000000000000000000000000000;;		defaultAggregateMaxEvents         = 10
0000000000000000000000000000000000000000;;		defaultAggregateIntervalInSeconds = 600
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// getEventKey builds unique event key based on source, involvedObject, reason, message
0000000000000000000000000000000000000000;;	func getEventKey(event *v1.Event) string {
0000000000000000000000000000000000000000;;		return strings.Join([]string{
0000000000000000000000000000000000000000;;			event.Source.Component,
0000000000000000000000000000000000000000;;			event.Source.Host,
0000000000000000000000000000000000000000;;			event.InvolvedObject.Kind,
0000000000000000000000000000000000000000;;			event.InvolvedObject.Namespace,
0000000000000000000000000000000000000000;;			event.InvolvedObject.Name,
0000000000000000000000000000000000000000;;			event.InvolvedObject.FieldPath,
0000000000000000000000000000000000000000;;			string(event.InvolvedObject.UID),
0000000000000000000000000000000000000000;;			event.InvolvedObject.APIVersion,
0000000000000000000000000000000000000000;;			event.Type,
0000000000000000000000000000000000000000;;			event.Reason,
0000000000000000000000000000000000000000;;			event.Message,
0000000000000000000000000000000000000000;;		},
0000000000000000000000000000000000000000;;			"")
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// EventFilterFunc is a function that returns true if the event should be skipped
0000000000000000000000000000000000000000;;	type EventFilterFunc func(event *v1.Event) bool
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// DefaultEventFilterFunc returns false for all incoming events
0000000000000000000000000000000000000000;;	func DefaultEventFilterFunc(event *v1.Event) bool {
0000000000000000000000000000000000000000;;		return false
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// EventAggregatorKeyFunc is responsible for grouping events for aggregation
0000000000000000000000000000000000000000;;	// It returns a tuple of the following:
0000000000000000000000000000000000000000;;	// aggregateKey - key the identifies the aggregate group to bucket this event
0000000000000000000000000000000000000000;;	// localKey - key that makes this event in the local group
0000000000000000000000000000000000000000;;	type EventAggregatorKeyFunc func(event *v1.Event) (aggregateKey string, localKey string)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// EventAggregatorByReasonFunc aggregates events by exact match on event.Source, event.InvolvedObject, event.Type and event.Reason
0000000000000000000000000000000000000000;;	func EventAggregatorByReasonFunc(event *v1.Event) (string, string) {
0000000000000000000000000000000000000000;;		return strings.Join([]string{
0000000000000000000000000000000000000000;;			event.Source.Component,
0000000000000000000000000000000000000000;;			event.Source.Host,
0000000000000000000000000000000000000000;;			event.InvolvedObject.Kind,
0000000000000000000000000000000000000000;;			event.InvolvedObject.Namespace,
0000000000000000000000000000000000000000;;			event.InvolvedObject.Name,
0000000000000000000000000000000000000000;;			string(event.InvolvedObject.UID),
0000000000000000000000000000000000000000;;			event.InvolvedObject.APIVersion,
0000000000000000000000000000000000000000;;			event.Type,
0000000000000000000000000000000000000000;;			event.Reason,
0000000000000000000000000000000000000000;;		},
0000000000000000000000000000000000000000;;			""), event.Message
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// EventAggregatorMessageFunc is responsible for producing an aggregation message
0000000000000000000000000000000000000000;;	type EventAggregatorMessageFunc func(event *v1.Event) string
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// EventAggregratorByReasonMessageFunc returns an aggregate message by prefixing the incoming message
0000000000000000000000000000000000000000;;	func EventAggregatorByReasonMessageFunc(event *v1.Event) string {
0000000000000000000000000000000000000000;;		return "(combined from similar events): " + event.Message
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// EventAggregator identifies similar events and aggregates them into a single event
0000000000000000000000000000000000000000;;	type EventAggregator struct {
0000000000000000000000000000000000000000;;		sync.RWMutex
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// The cache that manages aggregation state
0000000000000000000000000000000000000000;;		cache *lru.Cache
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// The function that groups events for aggregation
0000000000000000000000000000000000000000;;		keyFunc EventAggregatorKeyFunc
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// The function that generates a message for an aggregate event
0000000000000000000000000000000000000000;;		messageFunc EventAggregatorMessageFunc
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// The maximum number of events in the specified interval before aggregation occurs
0000000000000000000000000000000000000000;;		maxEvents uint
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// The amount of time in seconds that must transpire since the last occurrence of a similar event before it's considered new
0000000000000000000000000000000000000000;;		maxIntervalInSeconds uint
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// clock is used to allow for testing over a time interval
0000000000000000000000000000000000000000;;		clock clock.Clock
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// NewEventAggregator returns a new instance of an EventAggregator
0000000000000000000000000000000000000000;;	func NewEventAggregator(lruCacheSize int, keyFunc EventAggregatorKeyFunc, messageFunc EventAggregatorMessageFunc,
0000000000000000000000000000000000000000;;		maxEvents int, maxIntervalInSeconds int, clock clock.Clock) *EventAggregator {
0000000000000000000000000000000000000000;;		return &EventAggregator{
0000000000000000000000000000000000000000;;			cache:                lru.New(lruCacheSize),
0000000000000000000000000000000000000000;;			keyFunc:              keyFunc,
0000000000000000000000000000000000000000;;			messageFunc:          messageFunc,
0000000000000000000000000000000000000000;;			maxEvents:            uint(maxEvents),
0000000000000000000000000000000000000000;;			maxIntervalInSeconds: uint(maxIntervalInSeconds),
0000000000000000000000000000000000000000;;			clock:                clock,
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// aggregateRecord holds data used to perform aggregation decisions
0000000000000000000000000000000000000000;;	type aggregateRecord struct {
0000000000000000000000000000000000000000;;		// we track the number of unique local keys we have seen in the aggregate set to know when to actually aggregate
0000000000000000000000000000000000000000;;		// if the size of this set exceeds the max, we know we need to aggregate
0000000000000000000000000000000000000000;;		localKeys sets.String
0000000000000000000000000000000000000000;;		// The last time at which the aggregate was recorded
0000000000000000000000000000000000000000;;		lastTimestamp metav1.Time
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// EventAggregate checks if a similar event has been seen according to the
0000000000000000000000000000000000000000;;	// aggregation configuration (max events, max interval, etc) and returns:
0000000000000000000000000000000000000000;;	//
0000000000000000000000000000000000000000;;	// - The (potentially modified) event that should be created
0000000000000000000000000000000000000000;;	// - The cache key for the event, for correlation purposes. This will be set to
0000000000000000000000000000000000000000;;	//   the full key for normal events, and to the result of
0000000000000000000000000000000000000000;;	//   EventAggregatorMessageFunc for aggregate events.
0000000000000000000000000000000000000000;;	func (e *EventAggregator) EventAggregate(newEvent *v1.Event) (*v1.Event, string) {
0000000000000000000000000000000000000000;;		now := metav1.NewTime(e.clock.Now())
0000000000000000000000000000000000000000;;		var record aggregateRecord
0000000000000000000000000000000000000000;;		// eventKey is the full cache key for this event
0000000000000000000000000000000000000000;;		eventKey := getEventKey(newEvent)
0000000000000000000000000000000000000000;;		// aggregateKey is for the aggregate event, if one is needed.
0000000000000000000000000000000000000000;;		aggregateKey, localKey := e.keyFunc(newEvent)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Do we have a record of similar events in our cache?
0000000000000000000000000000000000000000;;		e.Lock()
0000000000000000000000000000000000000000;;		defer e.Unlock()
0000000000000000000000000000000000000000;;		value, found := e.cache.Get(aggregateKey)
0000000000000000000000000000000000000000;;		if found {
0000000000000000000000000000000000000000;;			record = value.(aggregateRecord)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Is the previous record too old? If so, make a fresh one. Note: if we didn't
0000000000000000000000000000000000000000;;		// find a similar record, its lastTimestamp will be the zero value, so we
0000000000000000000000000000000000000000;;		// create a new one in that case.
0000000000000000000000000000000000000000;;		maxInterval := time.Duration(e.maxIntervalInSeconds) * time.Second
0000000000000000000000000000000000000000;;		interval := now.Time.Sub(record.lastTimestamp.Time)
0000000000000000000000000000000000000000;;		if interval > maxInterval {
0000000000000000000000000000000000000000;;			record = aggregateRecord{localKeys: sets.NewString()}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Write the new event into the aggregation record and put it on the cache
0000000000000000000000000000000000000000;;		record.localKeys.Insert(localKey)
0000000000000000000000000000000000000000;;		record.lastTimestamp = now
0000000000000000000000000000000000000000;;		e.cache.Add(aggregateKey, record)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// If we are not yet over the threshold for unique events, don't correlate them
0000000000000000000000000000000000000000;;		if uint(record.localKeys.Len()) < e.maxEvents {
0000000000000000000000000000000000000000;;			return newEvent, eventKey
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// do not grow our local key set any larger than max
0000000000000000000000000000000000000000;;		record.localKeys.PopAny()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// create a new aggregate event, and return the aggregateKey as the cache key
0000000000000000000000000000000000000000;;		// (so that it can be overwritten.)
0000000000000000000000000000000000000000;;		eventCopy := &v1.Event{
0000000000000000000000000000000000000000;;			ObjectMeta: metav1.ObjectMeta{
0000000000000000000000000000000000000000;;				Name:      fmt.Sprintf("%v.%x", newEvent.InvolvedObject.Name, now.UnixNano()),
0000000000000000000000000000000000000000;;				Namespace: newEvent.Namespace,
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			Count:          1,
0000000000000000000000000000000000000000;;			FirstTimestamp: now,
0000000000000000000000000000000000000000;;			InvolvedObject: newEvent.InvolvedObject,
0000000000000000000000000000000000000000;;			LastTimestamp:  now,
0000000000000000000000000000000000000000;;			Message:        e.messageFunc(newEvent),
0000000000000000000000000000000000000000;;			Type:           newEvent.Type,
0000000000000000000000000000000000000000;;			Reason:         newEvent.Reason,
0000000000000000000000000000000000000000;;			Source:         newEvent.Source,
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return eventCopy, aggregateKey
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// eventLog records data about when an event was observed
0000000000000000000000000000000000000000;;	type eventLog struct {
0000000000000000000000000000000000000000;;		// The number of times the event has occurred since first occurrence.
0000000000000000000000000000000000000000;;		count uint
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// The time at which the event was first recorded.
0000000000000000000000000000000000000000;;		firstTimestamp metav1.Time
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// The unique name of the first occurrence of this event
0000000000000000000000000000000000000000;;		name string
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Resource version returned from previous interaction with server
0000000000000000000000000000000000000000;;		resourceVersion string
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// eventLogger logs occurrences of an event
0000000000000000000000000000000000000000;;	type eventLogger struct {
0000000000000000000000000000000000000000;;		sync.RWMutex
0000000000000000000000000000000000000000;;		cache *lru.Cache
0000000000000000000000000000000000000000;;		clock clock.Clock
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// newEventLogger observes events and counts their frequencies
0000000000000000000000000000000000000000;;	func newEventLogger(lruCacheEntries int, clock clock.Clock) *eventLogger {
0000000000000000000000000000000000000000;;		return &eventLogger{cache: lru.New(lruCacheEntries), clock: clock}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// eventObserve records an event, or updates an existing one if key is a cache hit
0000000000000000000000000000000000000000;;	func (e *eventLogger) eventObserve(newEvent *v1.Event, key string) (*v1.Event, []byte, error) {
0000000000000000000000000000000000000000;;		var (
0000000000000000000000000000000000000000;;			patch []byte
0000000000000000000000000000000000000000;;			err   error
0000000000000000000000000000000000000000;;		)
0000000000000000000000000000000000000000;;		eventCopy := *newEvent
0000000000000000000000000000000000000000;;		event := &eventCopy
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		e.Lock()
0000000000000000000000000000000000000000;;		defer e.Unlock()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Check if there is an existing event we should update
0000000000000000000000000000000000000000;;		lastObservation := e.lastEventObservationFromCache(key)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// If we found a result, prepare a patch
0000000000000000000000000000000000000000;;		if lastObservation.count > 0 {
0000000000000000000000000000000000000000;;			// update the event based on the last observation so patch will work as desired
0000000000000000000000000000000000000000;;			event.Name = lastObservation.name
0000000000000000000000000000000000000000;;			event.ResourceVersion = lastObservation.resourceVersion
0000000000000000000000000000000000000000;;			event.FirstTimestamp = lastObservation.firstTimestamp
0000000000000000000000000000000000000000;;			event.Count = int32(lastObservation.count) + 1
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			eventCopy2 := *event
0000000000000000000000000000000000000000;;			eventCopy2.Count = 0
0000000000000000000000000000000000000000;;			eventCopy2.LastTimestamp = metav1.NewTime(time.Unix(0, 0))
0000000000000000000000000000000000000000;;			eventCopy2.Message = ""
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			newData, _ := json.Marshal(event)
0000000000000000000000000000000000000000;;			oldData, _ := json.Marshal(eventCopy2)
0000000000000000000000000000000000000000;;			patch, err = strategicpatch.CreateTwoWayMergePatch(oldData, newData, event)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// record our new observation
0000000000000000000000000000000000000000;;		e.cache.Add(
0000000000000000000000000000000000000000;;			key,
0000000000000000000000000000000000000000;;			eventLog{
0000000000000000000000000000000000000000;;				count:           uint(event.Count),
0000000000000000000000000000000000000000;;				firstTimestamp:  event.FirstTimestamp,
0000000000000000000000000000000000000000;;				name:            event.Name,
0000000000000000000000000000000000000000;;				resourceVersion: event.ResourceVersion,
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;		)
0000000000000000000000000000000000000000;;		return event, patch, err
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// updateState updates its internal tracking information based on latest server state
0000000000000000000000000000000000000000;;	func (e *eventLogger) updateState(event *v1.Event) {
0000000000000000000000000000000000000000;;		key := getEventKey(event)
0000000000000000000000000000000000000000;;		e.Lock()
0000000000000000000000000000000000000000;;		defer e.Unlock()
0000000000000000000000000000000000000000;;		// record our new observation
0000000000000000000000000000000000000000;;		e.cache.Add(
0000000000000000000000000000000000000000;;			key,
0000000000000000000000000000000000000000;;			eventLog{
0000000000000000000000000000000000000000;;				count:           uint(event.Count),
0000000000000000000000000000000000000000;;				firstTimestamp:  event.FirstTimestamp,
0000000000000000000000000000000000000000;;				name:            event.Name,
0000000000000000000000000000000000000000;;				resourceVersion: event.ResourceVersion,
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;		)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// lastEventObservationFromCache returns the event from the cache, reads must be protected via external lock
0000000000000000000000000000000000000000;;	func (e *eventLogger) lastEventObservationFromCache(key string) eventLog {
0000000000000000000000000000000000000000;;		value, ok := e.cache.Get(key)
0000000000000000000000000000000000000000;;		if ok {
0000000000000000000000000000000000000000;;			observationValue, ok := value.(eventLog)
0000000000000000000000000000000000000000;;			if ok {
0000000000000000000000000000000000000000;;				return observationValue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return eventLog{}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// EventCorrelator processes all incoming events and performs analysis to avoid overwhelming the system.  It can filter all
0000000000000000000000000000000000000000;;	// incoming events to see if the event should be filtered from further processing.  It can aggregate similar events that occur
0000000000000000000000000000000000000000;;	// frequently to protect the system from spamming events that are difficult for users to distinguish.  It performs de-duplication
0000000000000000000000000000000000000000;;	// to ensure events that are observed multiple times are compacted into a single event with increasing counts.
0000000000000000000000000000000000000000;;	type EventCorrelator struct {
0000000000000000000000000000000000000000;;		// the function to filter the event
0000000000000000000000000000000000000000;;		filterFunc EventFilterFunc
0000000000000000000000000000000000000000;;		// the object that performs event aggregation
0000000000000000000000000000000000000000;;		aggregator *EventAggregator
0000000000000000000000000000000000000000;;		// the object that observes events as they come through
0000000000000000000000000000000000000000;;		logger *eventLogger
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// EventCorrelateResult is the result of a Correlate
0000000000000000000000000000000000000000;;	type EventCorrelateResult struct {
0000000000000000000000000000000000000000;;		// the event after correlation
0000000000000000000000000000000000000000;;		Event *v1.Event
0000000000000000000000000000000000000000;;		// if provided, perform a strategic patch when updating the record on the server
0000000000000000000000000000000000000000;;		Patch []byte
0000000000000000000000000000000000000000;;		// if true, do no further processing of the event
0000000000000000000000000000000000000000;;		Skip bool
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// NewEventCorrelator returns an EventCorrelator configured with default values.
0000000000000000000000000000000000000000;;	//
0000000000000000000000000000000000000000;;	// The EventCorrelator is responsible for event filtering, aggregating, and counting
0000000000000000000000000000000000000000;;	// prior to interacting with the API server to record the event.
0000000000000000000000000000000000000000;;	//
0000000000000000000000000000000000000000;;	// The default behavior is as follows:
0000000000000000000000000000000000000000;;	//   * No events are filtered from being recorded
0000000000000000000000000000000000000000;;	//   * Aggregation is performed if a similar event is recorded 10 times in a
0000000000000000000000000000000000000000;;	//     in a 10 minute rolling interval.  A similar event is an event that varies only by
0000000000000000000000000000000000000000;;	//     the Event.Message field.  Rather than recording the precise event, aggregation
0000000000000000000000000000000000000000;;	//     will create a new event whose message reports that it has combined events with
0000000000000000000000000000000000000000;;	//     the same reason.
0000000000000000000000000000000000000000;;	//   * Events are incrementally counted if the exact same event is encountered multiple
0000000000000000000000000000000000000000;;	//     times.
0000000000000000000000000000000000000000;;	func NewEventCorrelator(clock clock.Clock) *EventCorrelator {
0000000000000000000000000000000000000000;;		cacheSize := maxLruCacheEntries
0000000000000000000000000000000000000000;;		return &EventCorrelator{
0000000000000000000000000000000000000000;;			filterFunc: DefaultEventFilterFunc,
0000000000000000000000000000000000000000;;			aggregator: NewEventAggregator(
0000000000000000000000000000000000000000;;				cacheSize,
0000000000000000000000000000000000000000;;				EventAggregatorByReasonFunc,
0000000000000000000000000000000000000000;;				EventAggregatorByReasonMessageFunc,
0000000000000000000000000000000000000000;;				defaultAggregateMaxEvents,
0000000000000000000000000000000000000000;;				defaultAggregateIntervalInSeconds,
0000000000000000000000000000000000000000;;				clock),
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			logger: newEventLogger(cacheSize, clock),
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// EventCorrelate filters, aggregates, counts, and de-duplicates all incoming events
0000000000000000000000000000000000000000;;	func (c *EventCorrelator) EventCorrelate(newEvent *v1.Event) (*EventCorrelateResult, error) {
0000000000000000000000000000000000000000;;		if c.filterFunc(newEvent) {
0000000000000000000000000000000000000000;;			return &EventCorrelateResult{Skip: true}, nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		aggregateEvent, ckey := c.aggregator.EventAggregate(newEvent)
0000000000000000000000000000000000000000;;		observedEvent, patch, err := c.logger.eventObserve(aggregateEvent, ckey)
0000000000000000000000000000000000000000;;		return &EventCorrelateResult{Event: observedEvent, Patch: patch}, err
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// UpdateState based on the latest observed state from server
0000000000000000000000000000000000000000;;	func (c *EventCorrelator) UpdateState(event *v1.Event) {
0000000000000000000000000000000000000000;;		c.logger.updateState(event)
0000000000000000000000000000000000000000;;	}
