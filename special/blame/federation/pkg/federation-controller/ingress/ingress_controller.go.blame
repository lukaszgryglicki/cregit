0000000000000000000000000000000000000000;;	/*
0000000000000000000000000000000000000000;;	Copyright 2016 The Kubernetes Authors.
ae1adb178ecfe767f811d73b11c2dcd113646bc8;;	
0000000000000000000000000000000000000000;;	Licensed under the Apache License, Version 2.0 (the "License");
0000000000000000000000000000000000000000;;	you may not use this file except in compliance with the License.
0000000000000000000000000000000000000000;;	You may obtain a copy of the License at
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	    http://www.apache.org/licenses/LICENSE-2.0
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	Unless required by applicable law or agreed to in writing, software
0000000000000000000000000000000000000000;;	distributed under the License is distributed on an "AS IS" BASIS,
0000000000000000000000000000000000000000;;	WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
0000000000000000000000000000000000000000;;	See the License for the specific language governing permissions and
0000000000000000000000000000000000000000;;	limitations under the License.
0000000000000000000000000000000000000000;;	*/
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	package ingress
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	import (
0000000000000000000000000000000000000000;;		"crypto/md5"
0000000000000000000000000000000000000000;;		"fmt"
0000000000000000000000000000000000000000;;		"sync"
0000000000000000000000000000000000000000;;		"time"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		"k8s.io/api/core/v1"
0000000000000000000000000000000000000000;;		clientv1 "k8s.io/api/core/v1"
0000000000000000000000000000000000000000;;		extensionsv1beta1 "k8s.io/api/extensions/v1beta1"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/api/errors"
0000000000000000000000000000000000000000;;		metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
0000000000000000000000000000000000000000;;		pkgruntime "k8s.io/apimachinery/pkg/runtime"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/runtime/schema"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/types"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/watch"
0000000000000000000000000000000000000000;;		"k8s.io/client-go/tools/cache"
0000000000000000000000000000000000000000;;		"k8s.io/client-go/tools/record"
0000000000000000000000000000000000000000;;		"k8s.io/client-go/util/flowcontrol"
0000000000000000000000000000000000000000;;		federationapi "k8s.io/kubernetes/federation/apis/federation/v1beta1"
0000000000000000000000000000000000000000;;		federationclientset "k8s.io/kubernetes/federation/client/clientset_generated/federation_clientset"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/federation/pkg/federation-controller/util"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/federation/pkg/federation-controller/util/clusterselector"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/federation/pkg/federation-controller/util/deletionhelper"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/federation/pkg/federation-controller/util/eventsink"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/api"
0000000000000000000000000000000000000000;;		kubeclientset "k8s.io/kubernetes/pkg/client/clientset_generated/clientset"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/controller"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		"github.com/golang/glog"
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	const (
0000000000000000000000000000000000000000;;		// Special cluster name which denotes all clusters - only used internally.  It's not a valid cluster name, so effectively reserved.
0000000000000000000000000000000000000000;;		allClustersKey = ".ALL_CLUSTERS"
0000000000000000000000000000000000000000;;		// TODO: Get the constants below directly from the Kubernetes Ingress Controller constants - but thats in a separate repo
0000000000000000000000000000000000000000;;		staticIPNameKeyWritable = "kubernetes.io/ingress.global-static-ip-name" // The writable annotation on Ingress to tell the controller to use a specific, named, static IP
0000000000000000000000000000000000000000;;		staticIPNameKeyReadonly = "ingress.kubernetes.io/static-ip"             // The readonly key via which the cluster's Ingress Controller communicates which static IP it used.  If staticIPNameKeyWritable above is specified, it is used.
0000000000000000000000000000000000000000;;		uidAnnotationKey        = "kubernetes.io/ingress.uid"                   // The annotation on federation clusters, where we store the ingress UID
0000000000000000000000000000000000000000;;		uidConfigMapName        = "ingress-uid"                                 // Name of the config-map and key the ingress controller stores its uid in.
0000000000000000000000000000000000000000;;		uidConfigMapNamespace   = "kube-system"
0000000000000000000000000000000000000000;;		uidKey                  = "uid"
0000000000000000000000000000000000000000;;		providerUidKey          = "provider-uid"
0000000000000000000000000000000000000000;;		// Annotation on the ingress in federation control plane that is used to keep
0000000000000000000000000000000000000000;;		// track of the first cluster in which we create ingress.
0000000000000000000000000000000000000000;;		// We wait for ingress to be created in this cluster before creating it any
0000000000000000000000000000000000000000;;		// other cluster.
0000000000000000000000000000000000000000;;		firstClusterAnnotation = "ingress.federation.kubernetes.io/first-cluster"
0000000000000000000000000000000000000000;;		ControllerName         = "ingresses"
0000000000000000000000000000000000000000;;		UserAgentName          = "federation-ingresses-controller"
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	var (
0000000000000000000000000000000000000000;;		RequiredResources = []schema.GroupVersionResource{extensionsv1beta1.SchemeGroupVersion.WithResource("ingresses")}
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type IngressController struct {
0000000000000000000000000000000000000000;;		sync.Mutex // Lock used for leader election
0000000000000000000000000000000000000000;;		// For triggering single ingress reconciliation. This is used when there is an
0000000000000000000000000000000000000000;;		// add/update/delete operation on an ingress in either federated API server or
0000000000000000000000000000000000000000;;		// in some member of the federation.
0000000000000000000000000000000000000000;;		ingressDeliverer *util.DelayingDeliverer
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// For triggering reconciliation of cluster ingress controller configmap and
0000000000000000000000000000000000000000;;		// all ingresses. This is used when a new cluster becomes available.
0000000000000000000000000000000000000000;;		clusterDeliverer *util.DelayingDeliverer
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// For triggering reconciliation of cluster ingress controller configmap.
0000000000000000000000000000000000000000;;		// This is used when a configmap is updated in the cluster.
0000000000000000000000000000000000000000;;		configMapDeliverer *util.DelayingDeliverer
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Contains ingresses present in members of federation.
0000000000000000000000000000000000000000;;		ingressFederatedInformer util.FederatedInformer
0000000000000000000000000000000000000000;;		// Contains ingress controller configmaps present in members of federation.
0000000000000000000000000000000000000000;;		configMapFederatedInformer util.FederatedInformer
0000000000000000000000000000000000000000;;		// For updating ingresses in members of federation.
0000000000000000000000000000000000000000;;		federatedIngressUpdater util.FederatedUpdater
0000000000000000000000000000000000000000;;		// For updating configmaps in members of federation.
0000000000000000000000000000000000000000;;		federatedConfigMapUpdater util.FederatedUpdater
0000000000000000000000000000000000000000;;		// Definitions of ingresses that should be federated.
0000000000000000000000000000000000000000;;		ingressInformerStore cache.Store
0000000000000000000000000000000000000000;;		// Informer controller for ingresses that should be federated.
0000000000000000000000000000000000000000;;		ingressInformerController cache.Controller
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Client to federated api server.
0000000000000000000000000000000000000000;;		federatedApiClient federationclientset.Interface
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Backoff manager for ingresses
0000000000000000000000000000000000000000;;		ingressBackoff *flowcontrol.Backoff
0000000000000000000000000000000000000000;;		// Backoff manager for configmaps
0000000000000000000000000000000000000000;;		configMapBackoff *flowcontrol.Backoff
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// For events
0000000000000000000000000000000000000000;;		eventRecorder record.EventRecorder
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		deletionHelper *deletionhelper.DeletionHelper
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		ingressReviewDelay    time.Duration
0000000000000000000000000000000000000000;;		configMapReviewDelay  time.Duration
0000000000000000000000000000000000000000;;		clusterAvailableDelay time.Duration
0000000000000000000000000000000000000000;;		smallDelay            time.Duration
0000000000000000000000000000000000000000;;		updateTimeout         time.Duration
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// NewIngressController returns a new ingress controller
0000000000000000000000000000000000000000;;	func NewIngressController(client federationclientset.Interface) *IngressController {
0000000000000000000000000000000000000000;;		glog.V(4).Infof("->NewIngressController V(4)")
0000000000000000000000000000000000000000;;		broadcaster := record.NewBroadcaster()
0000000000000000000000000000000000000000;;		broadcaster.StartRecordingToSink(eventsink.NewFederatedEventSink(client))
0000000000000000000000000000000000000000;;		recorder := broadcaster.NewRecorder(api.Scheme, clientv1.EventSource{Component: UserAgentName})
0000000000000000000000000000000000000000;;		ic := &IngressController{
0000000000000000000000000000000000000000;;			federatedApiClient:    client,
0000000000000000000000000000000000000000;;			ingressReviewDelay:    time.Second * 10,
0000000000000000000000000000000000000000;;			configMapReviewDelay:  time.Second * 10,
0000000000000000000000000000000000000000;;			clusterAvailableDelay: time.Second * 20,
0000000000000000000000000000000000000000;;			smallDelay:            time.Second * 3,
0000000000000000000000000000000000000000;;			updateTimeout:         time.Second * 30,
0000000000000000000000000000000000000000;;			ingressBackoff:        flowcontrol.NewBackOff(5*time.Second, time.Minute),
0000000000000000000000000000000000000000;;			eventRecorder:         recorder,
0000000000000000000000000000000000000000;;			configMapBackoff:      flowcontrol.NewBackOff(5*time.Second, time.Minute),
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Build deliverers for triggering reconciliations.
0000000000000000000000000000000000000000;;		ic.ingressDeliverer = util.NewDelayingDeliverer()
0000000000000000000000000000000000000000;;		ic.clusterDeliverer = util.NewDelayingDeliverer()
0000000000000000000000000000000000000000;;		ic.configMapDeliverer = util.NewDelayingDeliverer()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Start informer in federated API servers on ingresses that should be federated.
0000000000000000000000000000000000000000;;		ic.ingressInformerStore, ic.ingressInformerController = cache.NewInformer(
0000000000000000000000000000000000000000;;			&cache.ListWatch{
0000000000000000000000000000000000000000;;				ListFunc: func(options metav1.ListOptions) (pkgruntime.Object, error) {
0000000000000000000000000000000000000000;;					return client.Extensions().Ingresses(metav1.NamespaceAll).List(options)
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;				WatchFunc: func(options metav1.ListOptions) (watch.Interface, error) {
0000000000000000000000000000000000000000;;					return client.Extensions().Ingresses(metav1.NamespaceAll).Watch(options)
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			&extensionsv1beta1.Ingress{},
0000000000000000000000000000000000000000;;			controller.NoResyncPeriodFunc(),
0000000000000000000000000000000000000000;;			util.NewTriggerOnAllChanges(
0000000000000000000000000000000000000000;;				func(obj pkgruntime.Object) {
0000000000000000000000000000000000000000;;					ic.deliverIngressObj(obj, 0, false)
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Federated informer on ingresses in members of federation.
0000000000000000000000000000000000000000;;		ic.ingressFederatedInformer = util.NewFederatedInformer(
0000000000000000000000000000000000000000;;			client,
0000000000000000000000000000000000000000;;			func(cluster *federationapi.Cluster, targetClient kubeclientset.Interface) (cache.Store, cache.Controller) {
0000000000000000000000000000000000000000;;				return cache.NewInformer(
0000000000000000000000000000000000000000;;					&cache.ListWatch{
0000000000000000000000000000000000000000;;						ListFunc: func(options metav1.ListOptions) (pkgruntime.Object, error) {
0000000000000000000000000000000000000000;;							return targetClient.Extensions().Ingresses(metav1.NamespaceAll).List(options)
0000000000000000000000000000000000000000;;						},
0000000000000000000000000000000000000000;;						WatchFunc: func(options metav1.ListOptions) (watch.Interface, error) {
0000000000000000000000000000000000000000;;							return targetClient.Extensions().Ingresses(metav1.NamespaceAll).Watch(options)
0000000000000000000000000000000000000000;;						},
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;					&extensionsv1beta1.Ingress{},
0000000000000000000000000000000000000000;;					controller.NoResyncPeriodFunc(),
0000000000000000000000000000000000000000;;					// Trigger reconciliation whenever something in federated cluster is changed. In most cases it
0000000000000000000000000000000000000000;;					// would be just confirmation that some ingress operation succeeded.
0000000000000000000000000000000000000000;;					util.NewTriggerOnAllChanges(
0000000000000000000000000000000000000000;;						func(obj pkgruntime.Object) {
0000000000000000000000000000000000000000;;							ic.deliverIngressObj(obj, ic.ingressReviewDelay, false)
0000000000000000000000000000000000000000;;						},
0000000000000000000000000000000000000000;;					))
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			&util.ClusterLifecycleHandlerFuncs{
0000000000000000000000000000000000000000;;				ClusterAvailable: func(cluster *federationapi.Cluster) {
0000000000000000000000000000000000000000;;					// When new cluster becomes available process all the ingresses again, and configure it's ingress controller's configmap with the correct UID
0000000000000000000000000000000000000000;;					ic.clusterDeliverer.DeliverAfter(cluster.Name, cluster, ic.clusterAvailableDelay)
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;		)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Federated informer on configmaps for ingress controllers in members of the federation.
0000000000000000000000000000000000000000;;		ic.configMapFederatedInformer = util.NewFederatedInformer(
0000000000000000000000000000000000000000;;			client,
0000000000000000000000000000000000000000;;			func(cluster *federationapi.Cluster, targetClient kubeclientset.Interface) (cache.Store, cache.Controller) {
0000000000000000000000000000000000000000;;				glog.V(4).Infof("Returning new informer for cluster %q", cluster.Name)
0000000000000000000000000000000000000000;;				return cache.NewInformer(
0000000000000000000000000000000000000000;;					&cache.ListWatch{
0000000000000000000000000000000000000000;;						ListFunc: func(options metav1.ListOptions) (pkgruntime.Object, error) {
0000000000000000000000000000000000000000;;							if targetClient == nil {
0000000000000000000000000000000000000000;;								glog.Errorf("Internal error: targetClient is nil")
0000000000000000000000000000000000000000;;							}
0000000000000000000000000000000000000000;;							return targetClient.Core().ConfigMaps(uidConfigMapNamespace).List(options) // we only want to list one by name - unfortunately Kubernetes don't have a selector for that.
0000000000000000000000000000000000000000;;						},
0000000000000000000000000000000000000000;;						WatchFunc: func(options metav1.ListOptions) (watch.Interface, error) {
0000000000000000000000000000000000000000;;							if targetClient == nil {
0000000000000000000000000000000000000000;;								glog.Errorf("Internal error: targetClient is nil")
0000000000000000000000000000000000000000;;							}
0000000000000000000000000000000000000000;;							return targetClient.Core().ConfigMaps(uidConfigMapNamespace).Watch(options) // as above
0000000000000000000000000000000000000000;;						},
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;					&v1.ConfigMap{},
0000000000000000000000000000000000000000;;					controller.NoResyncPeriodFunc(),
0000000000000000000000000000000000000000;;					// Trigger reconciliation whenever the ingress controller's configmap in a federated cluster is changed. In most cases it
0000000000000000000000000000000000000000;;					// would be just confirmation that the configmap for the ingress controller is correct.
0000000000000000000000000000000000000000;;					util.NewTriggerOnAllChanges(
0000000000000000000000000000000000000000;;						func(obj pkgruntime.Object) {
0000000000000000000000000000000000000000;;							ic.deliverConfigMapObj(cluster.Name, obj, ic.configMapReviewDelay, false)
0000000000000000000000000000000000000000;;						},
0000000000000000000000000000000000000000;;					))
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			&util.ClusterLifecycleHandlerFuncs{
0000000000000000000000000000000000000000;;				ClusterAvailable: func(cluster *federationapi.Cluster) {
0000000000000000000000000000000000000000;;					ic.clusterDeliverer.DeliverAfter(cluster.Name, cluster, ic.clusterAvailableDelay)
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;		)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Federated ingress updater along with Create/Update/Delete operations.
0000000000000000000000000000000000000000;;		ic.federatedIngressUpdater = util.NewFederatedUpdater(ic.ingressFederatedInformer, "ingress", ic.updateTimeout, ic.eventRecorder,
0000000000000000000000000000000000000000;;			func(client kubeclientset.Interface, obj pkgruntime.Object) error {
0000000000000000000000000000000000000000;;				ingress := obj.(*extensionsv1beta1.Ingress)
0000000000000000000000000000000000000000;;				glog.V(4).Infof("Attempting to create Ingress: %v", ingress)
0000000000000000000000000000000000000000;;				_, err := client.Extensions().Ingresses(ingress.Namespace).Create(ingress)
0000000000000000000000000000000000000000;;				if err != nil {
0000000000000000000000000000000000000000;;					glog.Errorf("Error creating ingress %q: %v", types.NamespacedName{Name: ingress.Name, Namespace: ingress.Namespace}, err)
0000000000000000000000000000000000000000;;				} else {
0000000000000000000000000000000000000000;;					glog.V(4).Infof("Successfully created ingress %q", types.NamespacedName{Name: ingress.Name, Namespace: ingress.Namespace})
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				return err
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			func(client kubeclientset.Interface, obj pkgruntime.Object) error {
0000000000000000000000000000000000000000;;				ingress := obj.(*extensionsv1beta1.Ingress)
0000000000000000000000000000000000000000;;				glog.V(4).Infof("Attempting to update Ingress: %v", ingress)
0000000000000000000000000000000000000000;;				_, err := client.Extensions().Ingresses(ingress.Namespace).Update(ingress)
0000000000000000000000000000000000000000;;				if err != nil {
0000000000000000000000000000000000000000;;					glog.V(4).Infof("Failed to update Ingress: %v", err)
0000000000000000000000000000000000000000;;				} else {
0000000000000000000000000000000000000000;;					glog.V(4).Infof("Successfully updated Ingress: %q", types.NamespacedName{Name: ingress.Name, Namespace: ingress.Namespace})
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				return err
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			func(client kubeclientset.Interface, obj pkgruntime.Object) error {
0000000000000000000000000000000000000000;;				ingress := obj.(*extensionsv1beta1.Ingress)
0000000000000000000000000000000000000000;;				glog.V(4).Infof("Attempting to delete Ingress: %v", ingress)
0000000000000000000000000000000000000000;;				orphanDependents := false
0000000000000000000000000000000000000000;;				err := client.Extensions().Ingresses(ingress.Namespace).Delete(ingress.Name, &metav1.DeleteOptions{OrphanDependents: &orphanDependents})
0000000000000000000000000000000000000000;;				return err
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Federated configmap updater along with Create/Update/Delete operations.  Only Update should ever be called.
0000000000000000000000000000000000000000;;		ic.federatedConfigMapUpdater = util.NewFederatedUpdater(ic.configMapFederatedInformer, "configmap", ic.updateTimeout, ic.eventRecorder,
0000000000000000000000000000000000000000;;			func(client kubeclientset.Interface, obj pkgruntime.Object) error {
0000000000000000000000000000000000000000;;				configMap := obj.(*v1.ConfigMap)
0000000000000000000000000000000000000000;;				configMapName := types.NamespacedName{Name: configMap.Name, Namespace: configMap.Namespace}
0000000000000000000000000000000000000000;;				glog.Errorf("Internal error: Incorrectly attempting to create ConfigMap: %q", configMapName)
0000000000000000000000000000000000000000;;				_, err := client.Core().ConfigMaps(configMap.Namespace).Create(configMap)
0000000000000000000000000000000000000000;;				return err
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			func(client kubeclientset.Interface, obj pkgruntime.Object) error {
0000000000000000000000000000000000000000;;				configMap := obj.(*v1.ConfigMap)
0000000000000000000000000000000000000000;;				configMapName := types.NamespacedName{Name: configMap.Name, Namespace: configMap.Namespace}
0000000000000000000000000000000000000000;;				glog.V(4).Infof("Attempting to update ConfigMap: %v", configMap)
0000000000000000000000000000000000000000;;				_, err := client.Core().ConfigMaps(configMap.Namespace).Update(configMap)
0000000000000000000000000000000000000000;;				if err == nil {
0000000000000000000000000000000000000000;;					glog.V(4).Infof("Successfully updated ConfigMap %q %v", configMapName, configMap)
0000000000000000000000000000000000000000;;				} else {
0000000000000000000000000000000000000000;;					glog.V(4).Infof("Failed to update ConfigMap %q: %v", configMapName, err)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				return err
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			func(client kubeclientset.Interface, obj pkgruntime.Object) error {
0000000000000000000000000000000000000000;;				configMap := obj.(*v1.ConfigMap)
0000000000000000000000000000000000000000;;				configMapName := types.NamespacedName{Name: configMap.Name, Namespace: configMap.Namespace}
0000000000000000000000000000000000000000;;				glog.Errorf("Internal error: Incorrectly attempting to delete ConfigMap: %q", configMapName)
0000000000000000000000000000000000000000;;				err := client.Core().ConfigMaps(configMap.Namespace).Delete(configMap.Name, &metav1.DeleteOptions{})
0000000000000000000000000000000000000000;;				return err
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		ic.deletionHelper = deletionhelper.NewDeletionHelper(
0000000000000000000000000000000000000000;;			ic.updateIngress,
0000000000000000000000000000000000000000;;			// objNameFunc
0000000000000000000000000000000000000000;;			func(obj pkgruntime.Object) string {
0000000000000000000000000000000000000000;;				ingress := obj.(*extensionsv1beta1.Ingress)
0000000000000000000000000000000000000000;;				return fmt.Sprintf("%s/%s", ingress.Namespace, ingress.Name)
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			ic.ingressFederatedInformer,
0000000000000000000000000000000000000000;;			ic.federatedIngressUpdater,
0000000000000000000000000000000000000000;;		)
0000000000000000000000000000000000000000;;		return ic
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Sends the given updated object to apiserver.
0000000000000000000000000000000000000000;;	// Assumes that the given object is an ingress.
0000000000000000000000000000000000000000;;	func (ic *IngressController) updateIngress(obj pkgruntime.Object) (pkgruntime.Object, error) {
0000000000000000000000000000000000000000;;		ingress := obj.(*extensionsv1beta1.Ingress)
0000000000000000000000000000000000000000;;		return ic.federatedApiClient.Extensions().Ingresses(ingress.Namespace).Update(ingress)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (ic *IngressController) Run(stopChan <-chan struct{}) {
0000000000000000000000000000000000000000;;		glog.Infof("Starting Ingress Controller")
0000000000000000000000000000000000000000;;		go ic.ingressInformerController.Run(stopChan)
0000000000000000000000000000000000000000;;		glog.Infof("... Starting Ingress Federated Informer")
0000000000000000000000000000000000000000;;		ic.ingressFederatedInformer.Start()
0000000000000000000000000000000000000000;;		glog.Infof("... Starting ConfigMap Federated Informer")
0000000000000000000000000000000000000000;;		ic.configMapFederatedInformer.Start()
0000000000000000000000000000000000000000;;		go func() {
0000000000000000000000000000000000000000;;			<-stopChan
0000000000000000000000000000000000000000;;			glog.Infof("Stopping Ingress Federated Informer")
0000000000000000000000000000000000000000;;			ic.ingressFederatedInformer.Stop()
0000000000000000000000000000000000000000;;			glog.Infof("Stopping ConfigMap Federated Informer")
0000000000000000000000000000000000000000;;			ic.configMapFederatedInformer.Stop()
0000000000000000000000000000000000000000;;			glog.Infof("Stopping ingress deliverer")
0000000000000000000000000000000000000000;;			ic.ingressDeliverer.Stop()
0000000000000000000000000000000000000000;;			glog.Infof("Stopping configmap deliverer")
0000000000000000000000000000000000000000;;			ic.configMapDeliverer.Stop()
0000000000000000000000000000000000000000;;			glog.Infof("Stopping cluster deliverer")
0000000000000000000000000000000000000000;;			ic.clusterDeliverer.Stop()
0000000000000000000000000000000000000000;;		}()
0000000000000000000000000000000000000000;;		ic.ingressDeliverer.StartWithHandler(func(item *util.DelayingDelivererItem) {
0000000000000000000000000000000000000000;;			ingress := item.Value.(types.NamespacedName)
0000000000000000000000000000000000000000;;			glog.V(4).Infof("Ingress change delivered, reconciling: %v", ingress)
0000000000000000000000000000000000000000;;			ic.reconcileIngress(ingress)
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;		ic.clusterDeliverer.StartWithHandler(func(item *util.DelayingDelivererItem) {
0000000000000000000000000000000000000000;;			clusterName := item.Key
0000000000000000000000000000000000000000;;			if clusterName != allClustersKey {
0000000000000000000000000000000000000000;;				glog.V(4).Infof("Cluster change delivered for cluster %q, reconciling configmap and ingress for that cluster", clusterName)
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				glog.V(4).Infof("Cluster change delivered for all clusters, reconciling configmaps and ingresses for all clusters")
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			ic.reconcileIngressesOnClusterChange(clusterName)
0000000000000000000000000000000000000000;;			ic.reconcileConfigMapForCluster(clusterName)
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;		ic.configMapDeliverer.StartWithHandler(func(item *util.DelayingDelivererItem) {
0000000000000000000000000000000000000000;;			clusterName := item.Key
0000000000000000000000000000000000000000;;			if clusterName != allClustersKey {
0000000000000000000000000000000000000000;;				glog.V(4).Infof("ConfigMap change delivered for cluster %q, reconciling configmap for that cluster", clusterName)
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				glog.V(4).Infof("ConfigMap change delivered for all clusters, reconciling configmaps for all clusters")
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			ic.reconcileConfigMapForCluster(clusterName)
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		util.StartBackoffGC(ic.ingressBackoff, stopChan)
0000000000000000000000000000000000000000;;		util.StartBackoffGC(ic.configMapBackoff, stopChan)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (ic *IngressController) deliverIngressObj(obj interface{}, delay time.Duration, failed bool) {
0000000000000000000000000000000000000000;;		ingress := obj.(*extensionsv1beta1.Ingress)
0000000000000000000000000000000000000000;;		ic.deliverIngress(types.NamespacedName{Namespace: ingress.Namespace, Name: ingress.Name}, delay, failed)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (ic *IngressController) deliverIngress(ingress types.NamespacedName, delay time.Duration, failed bool) {
0000000000000000000000000000000000000000;;		glog.V(4).Infof("Delivering ingress: %s with delay: %v error: %v", ingress, delay, failed)
0000000000000000000000000000000000000000;;		key := ingress.String()
0000000000000000000000000000000000000000;;		if failed {
0000000000000000000000000000000000000000;;			ic.ingressBackoff.Next(key, time.Now())
0000000000000000000000000000000000000000;;			delay = delay + ic.ingressBackoff.Get(key)
0000000000000000000000000000000000000000;;		} else {
0000000000000000000000000000000000000000;;			ic.ingressBackoff.Reset(key)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		ic.ingressDeliverer.DeliverAfter(key, ingress, delay)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (ic *IngressController) deliverConfigMapObj(clusterName string, obj interface{}, delay time.Duration, failed bool) {
0000000000000000000000000000000000000000;;		configMap := obj.(*v1.ConfigMap)
0000000000000000000000000000000000000000;;		ic.deliverConfigMap(clusterName, types.NamespacedName{Namespace: configMap.Namespace, Name: configMap.Name}, delay, failed)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (ic *IngressController) deliverConfigMap(cluster string, configMap types.NamespacedName, delay time.Duration, failed bool) {
0000000000000000000000000000000000000000;;		key := cluster
0000000000000000000000000000000000000000;;		if failed {
0000000000000000000000000000000000000000;;			ic.configMapBackoff.Next(key, time.Now())
0000000000000000000000000000000000000000;;			delay = delay + ic.configMapBackoff.Get(key)
0000000000000000000000000000000000000000;;		} else {
0000000000000000000000000000000000000000;;			ic.configMapBackoff.Reset(key)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		glog.V(4).Infof("Delivering ConfigMap for cluster %q (delay %q): %s", cluster, delay, configMap)
0000000000000000000000000000000000000000;;		ic.configMapDeliverer.DeliverAfter(key, configMap, delay)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Check whether all data stores are in sync. False is returned if any of the informer/stores is not yet
0000000000000000000000000000000000000000;;	// synced with the corresponding api server.
0000000000000000000000000000000000000000;;	func (ic *IngressController) isSynced() bool {
0000000000000000000000000000000000000000;;		if !ic.ingressFederatedInformer.ClustersSynced() {
0000000000000000000000000000000000000000;;			glog.V(2).Infof("Cluster list not synced for ingress federated informer")
0000000000000000000000000000000000000000;;			return false
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		clusters, err := ic.ingressFederatedInformer.GetReadyClusters()
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			glog.Errorf("Failed to get ready clusters for ingress federated informer: %v", err)
0000000000000000000000000000000000000000;;			return false
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if !ic.ingressFederatedInformer.GetTargetStore().ClustersSynced(clusters) {
0000000000000000000000000000000000000000;;			glog.V(2).Infof("Target store not synced for ingress federated informer")
0000000000000000000000000000000000000000;;			return false
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if !ic.configMapFederatedInformer.ClustersSynced() {
0000000000000000000000000000000000000000;;			glog.V(2).Infof("Cluster list not synced for config map federated informer")
0000000000000000000000000000000000000000;;			return false
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		clusters, err = ic.configMapFederatedInformer.GetReadyClusters()
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			glog.Errorf("Failed to get ready clusters for configmap federated informer: %v", err)
0000000000000000000000000000000000000000;;			return false
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if !ic.configMapFederatedInformer.GetTargetStore().ClustersSynced(clusters) {
0000000000000000000000000000000000000000;;			glog.V(2).Infof("Target store not synced for configmap federated informer")
0000000000000000000000000000000000000000;;			return false
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		glog.V(4).Infof("Cluster list is synced")
0000000000000000000000000000000000000000;;		return true
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// The function triggers reconciliation of all federated ingresses.  clusterName is the name of the cluster that changed
0000000000000000000000000000000000000000;;	// but all ingresses in all clusters are reconciled
0000000000000000000000000000000000000000;;	func (ic *IngressController) reconcileIngressesOnClusterChange(clusterName string) {
0000000000000000000000000000000000000000;;		glog.V(4).Infof("Reconciling ingresses on cluster change for cluster %q", clusterName)
0000000000000000000000000000000000000000;;		if !ic.isSynced() {
0000000000000000000000000000000000000000;;			glog.V(4).Infof("Not synced, will try again later to reconcile ingresses.")
0000000000000000000000000000000000000000;;			ic.clusterDeliverer.DeliverAfter(clusterName, nil, ic.clusterAvailableDelay)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		ingressList := ic.ingressInformerStore.List()
0000000000000000000000000000000000000000;;		if len(ingressList) <= 0 {
0000000000000000000000000000000000000000;;			glog.V(4).Infof("No federated ingresses to reconcile.")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		for _, obj := range ingressList {
0000000000000000000000000000000000000000;;			ingress := obj.(*extensionsv1beta1.Ingress)
0000000000000000000000000000000000000000;;			nsName := types.NamespacedName{Name: ingress.Name, Namespace: ingress.Namespace}
0000000000000000000000000000000000000000;;			glog.V(4).Infof("Delivering federated ingress %q for cluster %q", nsName, clusterName)
0000000000000000000000000000000000000000;;			ic.deliverIngress(nsName, ic.smallDelay, false)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	/*
0000000000000000000000000000000000000000;;	  reconcileConfigMapForCluster ensures that the configmap for the ingress controller in the cluster has objectmeta.data.UID
0000000000000000000000000000000000000000;;	  consistent with all the other clusters in the federation. If clusterName == allClustersKey, then all available clusters
0000000000000000000000000000000000000000;;	  configmaps are reconciled.
0000000000000000000000000000000000000000;;	*/
0000000000000000000000000000000000000000;;	func (ic *IngressController) reconcileConfigMapForCluster(clusterName string) {
0000000000000000000000000000000000000000;;		glog.V(4).Infof("Reconciling ConfigMap for cluster(s) %q", clusterName)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if !ic.isSynced() {
0000000000000000000000000000000000000000;;			ic.configMapDeliverer.DeliverAfter(clusterName, nil, ic.clusterAvailableDelay)
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if clusterName == allClustersKey {
0000000000000000000000000000000000000000;;			clusters, err := ic.configMapFederatedInformer.GetReadyClusters()
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				glog.Errorf("Failed to get ready clusters.  redelivering %q: %v", clusterName, err)
0000000000000000000000000000000000000000;;				ic.configMapDeliverer.DeliverAfter(clusterName, nil, ic.clusterAvailableDelay)
0000000000000000000000000000000000000000;;				return
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			for _, cluster := range clusters {
0000000000000000000000000000000000000000;;				glog.V(4).Infof("Delivering ConfigMap for cluster(s) %q", clusterName)
0000000000000000000000000000000000000000;;				ic.configMapDeliverer.DeliverAt(cluster.Name, nil, time.Now())
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		} else {
0000000000000000000000000000000000000000;;			cluster, found, err := ic.configMapFederatedInformer.GetReadyCluster(clusterName)
0000000000000000000000000000000000000000;;			if err != nil || !found {
0000000000000000000000000000000000000000;;				glog.Errorf("Internal error: Cluster %q queued for configmap reconciliation, but not found.  Will try again later: error = %v", clusterName, err)
0000000000000000000000000000000000000000;;				ic.configMapDeliverer.DeliverAfter(clusterName, nil, ic.clusterAvailableDelay)
0000000000000000000000000000000000000000;;				return
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			uidConfigMapNamespacedName := types.NamespacedName{Name: uidConfigMapName, Namespace: uidConfigMapNamespace}
0000000000000000000000000000000000000000;;			configMapObj, found, err := ic.configMapFederatedInformer.GetTargetStore().GetByKey(cluster.Name, uidConfigMapNamespacedName.String())
0000000000000000000000000000000000000000;;			if !found || err != nil {
0000000000000000000000000000000000000000;;				logmsg := fmt.Sprintf("Failed to get ConfigMap %q for cluster %q.  Will try again later", uidConfigMapNamespacedName, cluster.Name)
0000000000000000000000000000000000000000;;				if err != nil {
0000000000000000000000000000000000000000;;					logmsg = fmt.Sprintf("%v: %v", logmsg, err)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				if len(ic.ingressInformerStore.List()) > 0 { // Error-level if ingresses are active, Info-level otherwise.
0000000000000000000000000000000000000000;;					glog.Errorf(logmsg)
0000000000000000000000000000000000000000;;				} else {
0000000000000000000000000000000000000000;;					glog.V(4).Infof(logmsg)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				ic.configMapDeliverer.DeliverAfter(clusterName, nil, ic.configMapReviewDelay)
0000000000000000000000000000000000000000;;				return
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			glog.V(4).Infof("Successfully got ConfigMap %q for cluster %q.", uidConfigMapNamespacedName, clusterName)
0000000000000000000000000000000000000000;;			configMap, ok := configMapObj.(*v1.ConfigMap)
0000000000000000000000000000000000000000;;			if !ok {
0000000000000000000000000000000000000000;;				glog.Errorf("Internal error: The object in the ConfigMap cache for cluster %q configmap %q is not a *ConfigMap", cluster.Name, uidConfigMapNamespacedName)
0000000000000000000000000000000000000000;;				return
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			ic.reconcileConfigMap(cluster, configMap)
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// getProviderUid returns a provider ID based on the provided clusterName.
0000000000000000000000000000000000000000;;	func getProviderUid(clusterName string) string {
0000000000000000000000000000000000000000;;		hashedName := md5.Sum([]byte(clusterName))
0000000000000000000000000000000000000000;;		return fmt.Sprintf("%x", hashedName[:8])
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	/*
0000000000000000000000000000000000000000;;	  reconcileConfigMap ensures that the configmap in the cluster has a UID
0000000000000000000000000000000000000000;;	  consistent with the federation cluster's associated annotation.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  1. If the UID in the configmap differs from the UID stored in the cluster's annotation, the configmap is updated.
0000000000000000000000000000000000000000;;	  2. If the UID annotation is missing from the cluster, the cluster's UID annotation is updated to be consistent
0000000000000000000000000000000000000000;;	  with the master cluster.
0000000000000000000000000000000000000000;;	  3. If there is no elected master cluster, this cluster attempts to elect itself as the master cluster.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  In cases 2 and 3, the configmaps will be updated in the next cycle, triggered by the federation cluster update(s)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	*/
0000000000000000000000000000000000000000;;	func (ic *IngressController) reconcileConfigMap(cluster *federationapi.Cluster, configMap *v1.ConfigMap) {
0000000000000000000000000000000000000000;;		ic.Lock() // TODO: Reduce the scope of this master election lock.
0000000000000000000000000000000000000000;;		defer ic.Unlock()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		configMapNsName := types.NamespacedName{Name: configMap.Name, Namespace: configMap.Namespace}
0000000000000000000000000000000000000000;;		glog.V(4).Infof("Reconciling ConfigMap %q in cluster %q", configMapNsName, cluster.Name)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		clusterIngressUID, clusterIngressUIDExists := cluster.ObjectMeta.Annotations[uidAnnotationKey]
0000000000000000000000000000000000000000;;		configMapUID, ok := configMap.Data[uidKey]
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if !ok {
0000000000000000000000000000000000000000;;			glog.Errorf("Warning: ConfigMap %q in cluster %q does not contain data key %q.  Therefore it cannot become the master.", configMapNsName, cluster.Name, uidKey)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if !clusterIngressUIDExists || clusterIngressUID == "" {
0000000000000000000000000000000000000000;;			glog.V(4).Infof("Cluster %q is the only master", cluster.Name)
0000000000000000000000000000000000000000;;			// Second argument is the fallback, in case this is the only cluster, in which case it becomes the master
0000000000000000000000000000000000000000;;			var err error
0000000000000000000000000000000000000000;;			if clusterIngressUID, err = ic.updateClusterIngressUIDToMasters(cluster, configMapUID); err != nil {
0000000000000000000000000000000000000000;;				return
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			// If we successfully update the Cluster Object, fallthrough and update the configMap.
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Figure out providerUid.
0000000000000000000000000000000000000000;;		providerUid := getProviderUid(cluster.Name)
0000000000000000000000000000000000000000;;		configMapProviderUid := configMap.Data[providerUidKey]
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if configMapUID == clusterIngressUID && configMapProviderUid == providerUid {
0000000000000000000000000000000000000000;;			glog.V(4).Infof("Ingress configMap update is not required: UID %q and ProviderUid %q are equal", configMapUID, providerUid)
0000000000000000000000000000000000000000;;		} else {
0000000000000000000000000000000000000000;;			if configMapUID != clusterIngressUID {
0000000000000000000000000000000000000000;;				glog.V(4).Infof("Ingress configMap update is required for UID: configMapUID %q not equal to clusterIngressUID %q", configMapUID, clusterIngressUID)
0000000000000000000000000000000000000000;;			} else if configMapProviderUid != providerUid {
0000000000000000000000000000000000000000;;				glog.V(4).Infof("Ingress configMap update is required: configMapProviderUid %q not equal to providerUid %q", configMapProviderUid, providerUid)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			configMap.Data[uidKey] = clusterIngressUID
0000000000000000000000000000000000000000;;			configMap.Data[providerUidKey] = providerUid
0000000000000000000000000000000000000000;;			operations := []util.FederatedOperation{{
0000000000000000000000000000000000000000;;				Type:        util.OperationTypeUpdate,
0000000000000000000000000000000000000000;;				Obj:         configMap,
0000000000000000000000000000000000000000;;				ClusterName: cluster.Name,
0000000000000000000000000000000000000000;;				Key:         configMapNsName.String(),
0000000000000000000000000000000000000000;;			}}
0000000000000000000000000000000000000000;;			glog.V(4).Infof("Calling federatedConfigMapUpdater.Update() - operations: %v", operations)
0000000000000000000000000000000000000000;;			err := ic.federatedConfigMapUpdater.Update(operations)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				glog.Errorf("Failed to execute update of ConfigMap %q on cluster %q: %v", configMapNsName, cluster.Name, err)
0000000000000000000000000000000000000000;;				ic.configMapDeliverer.DeliverAfter(cluster.Name, nil, ic.configMapReviewDelay)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	/*
0000000000000000000000000000000000000000;;	  getMasterCluster returns the cluster which is the elected master w.r.t. ingress UID, and it's ingress UID.
0000000000000000000000000000000000000000;;	  If there is no elected master cluster, an error is returned.
0000000000000000000000000000000000000000;;	  All other clusters must use the ingress UID of the elected master.
0000000000000000000000000000000000000000;;	*/
0000000000000000000000000000000000000000;;	func (ic *IngressController) getMasterCluster() (master *federationapi.Cluster, ingressUID string, err error) {
0000000000000000000000000000000000000000;;		clusters, err := ic.configMapFederatedInformer.GetReadyClusters()
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			glog.Errorf("Failed to get cluster list: %v", err)
0000000000000000000000000000000000000000;;			return nil, "", err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		for _, c := range clusters {
0000000000000000000000000000000000000000;;			UID, exists := c.ObjectMeta.Annotations[uidAnnotationKey]
0000000000000000000000000000000000000000;;			if exists && UID != "" { // Found the master cluster
0000000000000000000000000000000000000000;;				glog.V(4).Infof("Found master cluster %q with annotation %q=%q", c.Name, uidAnnotationKey, UID)
0000000000000000000000000000000000000000;;				return c, UID, nil
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return nil, "", fmt.Errorf("Failed to find master cluster with annotation %q", uidAnnotationKey)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	/*
0000000000000000000000000000000000000000;;	  updateClusterIngressUIDToMasters takes the ingress UID annotation on the master cluster and applies it to cluster.
0000000000000000000000000000000000000000;;	  If there is no master cluster, then fallbackUID is used (and hence this cluster becomes the master).
0000000000000000000000000000000000000000;;	*/
0000000000000000000000000000000000000000;;	func (ic *IngressController) updateClusterIngressUIDToMasters(cluster *federationapi.Cluster, fallbackUID string) (string, error) {
0000000000000000000000000000000000000000;;		masterCluster, masterUID, err := ic.getMasterCluster()
0000000000000000000000000000000000000000;;		clusterObj, clusterErr := api.Scheme.DeepCopy(cluster) // Make a clone so that we don't clobber our input param
0000000000000000000000000000000000000000;;		cluster, ok := clusterObj.(*federationapi.Cluster)
0000000000000000000000000000000000000000;;		if clusterErr != nil || !ok {
0000000000000000000000000000000000000000;;			glog.Errorf("Internal error: Failed clone cluster resource while attempting to add master ingress UID annotation (%q = %q) from master cluster %q to cluster %q, will try again later: %v", uidAnnotationKey, masterUID, masterCluster.Name, cluster.Name, clusterErr)
0000000000000000000000000000000000000000;;			return "", clusterErr
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if err == nil {
0000000000000000000000000000000000000000;;			if masterCluster.Name != cluster.Name { // We're not the master, need to get in sync
0000000000000000000000000000000000000000;;				if cluster.ObjectMeta.Annotations == nil {
0000000000000000000000000000000000000000;;					cluster.ObjectMeta.Annotations = map[string]string{}
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				cluster.ObjectMeta.Annotations[uidAnnotationKey] = masterUID
0000000000000000000000000000000000000000;;				if _, err = ic.federatedApiClient.Federation().Clusters().Update(cluster); err != nil {
0000000000000000000000000000000000000000;;					glog.Errorf("Failed to add master ingress UID annotation (%q = %q) from master cluster %q to cluster %q, will try again later: %v", uidAnnotationKey, masterUID, masterCluster.Name, cluster.Name, err)
0000000000000000000000000000000000000000;;					return "", err
0000000000000000000000000000000000000000;;				} else {
0000000000000000000000000000000000000000;;					glog.V(4).Infof("Successfully added master ingress UID annotation (%q = %q) from master cluster %q to cluster %q.", uidAnnotationKey, masterUID, masterCluster.Name, cluster.Name)
0000000000000000000000000000000000000000;;					return masterUID, nil
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				glog.V(4).Infof("Cluster %q with ingress UID is already the master with annotation (%q = %q), no need to update.", cluster.Name, uidAnnotationKey, cluster.ObjectMeta.Annotations[uidAnnotationKey])
0000000000000000000000000000000000000000;;				return cluster.ObjectMeta.Annotations[uidAnnotationKey], nil
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		} else {
0000000000000000000000000000000000000000;;			glog.V(2).Infof("No master cluster found to source an ingress UID from for cluster %q.", cluster.Name)
0000000000000000000000000000000000000000;;			if fallbackUID != "" {
0000000000000000000000000000000000000000;;				glog.V(2).Infof("Attempting to elect new master cluster %q with ingress UID %q = %q", cluster.Name, uidAnnotationKey, fallbackUID)
0000000000000000000000000000000000000000;;				if cluster.ObjectMeta.Annotations == nil {
0000000000000000000000000000000000000000;;					cluster.ObjectMeta.Annotations = map[string]string{}
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				cluster.ObjectMeta.Annotations[uidAnnotationKey] = fallbackUID
0000000000000000000000000000000000000000;;				if _, err = ic.federatedApiClient.Federation().Clusters().Update(cluster); err != nil {
0000000000000000000000000000000000000000;;					glog.Errorf("Failed to add ingress UID annotation (%q = %q) to cluster %q. No master elected. Will try again later: %v", uidAnnotationKey, fallbackUID, cluster.Name, err)
0000000000000000000000000000000000000000;;					return "", err
0000000000000000000000000000000000000000;;				} else {
0000000000000000000000000000000000000000;;					glog.V(4).Infof("Successfully added ingress UID annotation (%q = %q) to cluster %q.", uidAnnotationKey, fallbackUID, cluster.Name)
0000000000000000000000000000000000000000;;					return fallbackUID, nil
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				glog.Errorf("No master cluster exists, and fallbackUID for cluster %q is nil.  This probably means that no clusters have an ingress controller configmap with key %q.  Federated Ingress currently supports clusters running Google Loadbalancer Controller (\"GLBC\")", cluster.Name, uidKey)
0000000000000000000000000000000000000000;;				return "", err
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (ic *IngressController) isClusterReady(clusterName string) bool {
0000000000000000000000000000000000000000;;		cluster, isReady, err := ic.ingressFederatedInformer.GetReadyCluster(clusterName)
0000000000000000000000000000000000000000;;		return isReady && err == nil && cluster != nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// updateAnnotationOnIngress updates the annotation with the given key on the given federated ingress.
0000000000000000000000000000000000000000;;	// Queues the ingress for resync when done.
0000000000000000000000000000000000000000;;	func (ic *IngressController) updateAnnotationOnIngress(ingress *extensionsv1beta1.Ingress, key, value string) {
0000000000000000000000000000000000000000;;		if ingress.ObjectMeta.Annotations == nil {
0000000000000000000000000000000000000000;;			ingress.ObjectMeta.Annotations = make(map[string]string)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		ingress.ObjectMeta.Annotations[key] = value
0000000000000000000000000000000000000000;;		ingressName := types.NamespacedName{Name: ingress.Name, Namespace: ingress.Namespace}
0000000000000000000000000000000000000000;;		glog.V(4).Infof("Attempting to update annotation %s:%s on base federated ingress: %v", key, value, ingressName)
0000000000000000000000000000000000000000;;		if updatedFedIngress, err := ic.federatedApiClient.Extensions().Ingresses(ingress.Namespace).Update(ingress); err != nil {
0000000000000000000000000000000000000000;;			glog.Errorf("Failed to update annotation %s:%s on federated ingress %q, will try again later: %v", key, value, ingressName, err)
0000000000000000000000000000000000000000;;			ic.deliverIngress(ingressName, ic.ingressReviewDelay, true)
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		} else {
0000000000000000000000000000000000000000;;			glog.V(4).Infof("Successfully updated annotation %s:%s on federated ingress %q, after update: %q", key, value, ingress, updatedFedIngress)
0000000000000000000000000000000000000000;;			ic.deliverIngress(ingressName, ic.smallDelay, false)
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (ic *IngressController) reconcileIngress(ingress types.NamespacedName) {
0000000000000000000000000000000000000000;;		glog.V(4).Infof("Reconciling ingress %q for all clusters", ingress)
0000000000000000000000000000000000000000;;		if !ic.isSynced() {
0000000000000000000000000000000000000000;;			ic.deliverIngress(ingress, ic.clusterAvailableDelay, false)
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		key := ingress.String()
0000000000000000000000000000000000000000;;		baseIngressObjFromStore, exist, err := ic.ingressInformerStore.GetByKey(key)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			glog.Errorf("Failed to query main ingress store for %v: %v", ingress, err)
0000000000000000000000000000000000000000;;			ic.deliverIngress(ingress, 0, true)
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if !exist {
0000000000000000000000000000000000000000;;			// Not federated ingress, ignoring.
0000000000000000000000000000000000000000;;			glog.V(4).Infof("Ingress %q is not federated.  Ignoring.", ingress)
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		baseIngressObj, err := api.Scheme.DeepCopy(baseIngressObjFromStore)
0000000000000000000000000000000000000000;;		baseIngress, ok := baseIngressObj.(*extensionsv1beta1.Ingress)
0000000000000000000000000000000000000000;;		if err != nil || !ok {
0000000000000000000000000000000000000000;;			glog.Errorf("Internal Error %v : Object retrieved from ingressInformerStore with key %q is not of correct type *extensionsv1beta1.Ingress: %v", err, key, baseIngressObj)
0000000000000000000000000000000000000000;;		} else {
0000000000000000000000000000000000000000;;			glog.V(4).Infof("Base (federated) ingress: %v", baseIngress)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if baseIngress.DeletionTimestamp != nil {
0000000000000000000000000000000000000000;;			if err := ic.delete(baseIngress); err != nil {
0000000000000000000000000000000000000000;;				glog.Errorf("Failed to delete %s: %v", ingress, err)
0000000000000000000000000000000000000000;;				ic.eventRecorder.Eventf(baseIngress, api.EventTypeWarning, "DeleteFailed",
0000000000000000000000000000000000000000;;					"Ingress delete failed: %v", err)
0000000000000000000000000000000000000000;;				ic.deliverIngress(ingress, 0, true)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		glog.V(3).Infof("Ensuring delete object from underlying clusters finalizer for ingress: %s",
0000000000000000000000000000000000000000;;			baseIngress.Name)
0000000000000000000000000000000000000000;;		// Add the required finalizers before creating a ingress in underlying clusters.
0000000000000000000000000000000000000000;;		updatedIngressObj, err := ic.deletionHelper.EnsureFinalizers(baseIngress)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			glog.Errorf("Failed to ensure delete object from underlying clusters finalizer in ingress %s: %v",
0000000000000000000000000000000000000000;;				baseIngress.Name, err)
0000000000000000000000000000000000000000;;			ic.deliverIngress(ingress, 0, true)
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		baseIngress = updatedIngressObj.(*extensionsv1beta1.Ingress)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		glog.V(3).Infof("Syncing ingress %s in underlying clusters", baseIngress.Name)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		clusters, err := ic.ingressFederatedInformer.GetReadyClusters()
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			glog.Errorf("Failed to get cluster list: %v", err)
0000000000000000000000000000000000000000;;			ic.deliverIngress(ingress, ic.clusterAvailableDelay, false)
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		} else {
0000000000000000000000000000000000000000;;			glog.V(4).Infof("Found %d ready clusters across which to reconcile ingress %q", len(clusters), ingress)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		operations := make([]util.FederatedOperation, 0)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		for _, cluster := range clusters {
0000000000000000000000000000000000000000;;			baseIPName, baseIPAnnotationExists := baseIngress.ObjectMeta.Annotations[staticIPNameKeyWritable]
0000000000000000000000000000000000000000;;			firstClusterName, firstClusterExists := baseIngress.ObjectMeta.Annotations[firstClusterAnnotation]
0000000000000000000000000000000000000000;;			clusterIngressObj, clusterIngressFound, err := ic.ingressFederatedInformer.GetTargetStore().GetByKey(cluster.Name, key)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				glog.Errorf("Failed to get cached ingress %s for cluster %s, will retry: %v", ingress, cluster.Name, err)
0000000000000000000000000000000000000000;;				ic.deliverIngress(ingress, 0, true)
0000000000000000000000000000000000000000;;				return
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			desiredIngress := &extensionsv1beta1.Ingress{}
0000000000000000000000000000000000000000;;			objMeta, err := api.Scheme.DeepCopy(&baseIngress.ObjectMeta)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				glog.Errorf("Error deep copying ObjectMeta: %v", err)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			objSpec, err := api.Scheme.DeepCopy(&baseIngress.Spec)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				glog.Errorf("Error deep copying Spec: %v", err)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			objMetaCopy, ok := objMeta.(*metav1.ObjectMeta)
0000000000000000000000000000000000000000;;			if !ok {
0000000000000000000000000000000000000000;;				glog.Errorf("Internal error: Failed to cast to *metav1.ObjectMeta: %v", objMeta)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			desiredIngress.ObjectMeta = *objMetaCopy
0000000000000000000000000000000000000000;;			objSpecCopy, ok := objSpec.(*extensionsv1beta1.IngressSpec)
0000000000000000000000000000000000000000;;			if !ok {
0000000000000000000000000000000000000000;;				glog.Errorf("Internal error: Failed to cast to extensionsv1beta1.Ingressespec: %v", objSpec)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			desiredIngress.Spec = *objSpecCopy
0000000000000000000000000000000000000000;;			glog.V(4).Infof("Desired Ingress: %v", desiredIngress)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			send, err := clusterselector.SendToCluster(cluster.Labels, desiredIngress.ObjectMeta.Annotations)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				glog.Errorf("Error processing ClusterSelector cluster: %s for Ingress map: %s error: %s", cluster.Name, key, err.Error())
0000000000000000000000000000000000000000;;				return
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			switch {
0000000000000000000000000000000000000000;;			case !clusterIngressFound && send:
0000000000000000000000000000000000000000;;				glog.V(4).Infof("No existing Ingress %s in cluster %s - checking if appropriate to queue a create operation", ingress, cluster.Name)
0000000000000000000000000000000000000000;;				// We can't supply server-created fields when creating a new object.
0000000000000000000000000000000000000000;;				desiredIngress.ObjectMeta = util.DeepCopyRelevantObjectMeta(baseIngress.ObjectMeta)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				// We always first create an ingress in the first available cluster. Once that ingress
0000000000000000000000000000000000000000;;				// has been created and allocated a global IP (visible via an annotation),
0000000000000000000000000000000000000000;;				// we record that annotation on the federated ingress, and create all other cluster
0000000000000000000000000000000000000000;;				// ingresses with that same global IP.
0000000000000000000000000000000000000000;;				// Note: If the first cluster becomes (e.g. temporarily) unavailable, the
0000000000000000000000000000000000000000;;				// second cluster will become the first cluster, but eventually all ingresses
0000000000000000000000000000000000000000;;				// will share the single global IP recorded in the annotation of the
0000000000000000000000000000000000000000;;				// federated ingress.
0000000000000000000000000000000000000000;;				haveFirstCluster := firstClusterExists && firstClusterName != "" && ic.isClusterReady(firstClusterName)
0000000000000000000000000000000000000000;;				if !haveFirstCluster {
0000000000000000000000000000000000000000;;					glog.V(4).Infof("No cluster has been chosen as the first cluster. Electing cluster %s as the first cluster to create ingress in", cluster.Name)
0000000000000000000000000000000000000000;;					ic.updateAnnotationOnIngress(baseIngress, firstClusterAnnotation, cluster.Name)
0000000000000000000000000000000000000000;;					return
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				if baseIPAnnotationExists || firstClusterName == cluster.Name {
0000000000000000000000000000000000000000;;					if baseIPAnnotationExists {
0000000000000000000000000000000000000000;;						glog.V(4).Infof("No existing Ingress %s in cluster %s and static IP annotation (%q) exists on base ingress - queuing a create operation", ingress, cluster.Name, staticIPNameKeyWritable)
0000000000000000000000000000000000000000;;					} else {
0000000000000000000000000000000000000000;;						glog.V(4).Infof("No existing Ingress %s in cluster %s and no static IP annotation (%q) on base ingress - queuing a create operation in first cluster", ingress, cluster.Name, staticIPNameKeyWritable)
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					operations = append(operations, util.FederatedOperation{
0000000000000000000000000000000000000000;;						Type:        util.OperationTypeAdd,
0000000000000000000000000000000000000000;;						Obj:         desiredIngress,
0000000000000000000000000000000000000000;;						ClusterName: cluster.Name,
0000000000000000000000000000000000000000;;						Key:         key,
0000000000000000000000000000000000000000;;					})
0000000000000000000000000000000000000000;;				} else {
0000000000000000000000000000000000000000;;					glog.V(4).Infof("No annotation %q exists on ingress %q in federation and waiting for ingress in cluster %s. Not queueing create operation for ingress until annotation exists", staticIPNameKeyWritable, ingress, firstClusterName)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			case clusterIngressFound && !send:
0000000000000000000000000000000000000000;;				glog.V(5).Infof("Removing Ingress: %s from cluster: %s reason: cluster selectors do not match: %-v %-v", key, cluster.Name, cluster.ObjectMeta.Labels, desiredIngress.ObjectMeta.Annotations[federationapi.FederationClusterSelectorAnnotation])
0000000000000000000000000000000000000000;;				operations = append(operations, util.FederatedOperation{
0000000000000000000000000000000000000000;;					Type:        util.OperationTypeDelete,
0000000000000000000000000000000000000000;;					Obj:         desiredIngress,
0000000000000000000000000000000000000000;;					ClusterName: cluster.Name,
0000000000000000000000000000000000000000;;					Key:         key,
0000000000000000000000000000000000000000;;				})
0000000000000000000000000000000000000000;;			case clusterIngressFound && send:
0000000000000000000000000000000000000000;;				clusterIngress := clusterIngressObj.(*extensionsv1beta1.Ingress)
0000000000000000000000000000000000000000;;				glog.V(4).Infof("Found existing Ingress %s in cluster %s - checking if update is required (in either direction)", ingress, cluster.Name)
0000000000000000000000000000000000000000;;				clusterIPName, clusterIPNameExists := clusterIngress.ObjectMeta.Annotations[staticIPNameKeyReadonly]
0000000000000000000000000000000000000000;;				baseLBStatusExists := len(baseIngress.Status.LoadBalancer.Ingress) > 0
0000000000000000000000000000000000000000;;				clusterLBStatusExists := len(clusterIngress.Status.LoadBalancer.Ingress) > 0
0000000000000000000000000000000000000000;;				logStr := fmt.Sprintf("Cluster ingress %q has annotation %q=%q, loadbalancer status exists? [%v], federated ingress has annotation %q=%q, loadbalancer status exists? [%v].  %%s annotation and/or loadbalancer status from cluster ingress to federated ingress.", ingress, staticIPNameKeyReadonly, clusterIPName, clusterLBStatusExists, staticIPNameKeyWritable, baseIPName, baseLBStatusExists)
0000000000000000000000000000000000000000;;				if (!baseIPAnnotationExists && clusterIPNameExists) || (!baseLBStatusExists && clusterLBStatusExists) { // copy the IP name from the readonly annotation on the cluster ingress, to the writable annotation on the federated ingress
0000000000000000000000000000000000000000;;					glog.V(4).Infof(logStr, "Transferring")
0000000000000000000000000000000000000000;;					if !baseIPAnnotationExists && clusterIPNameExists {
0000000000000000000000000000000000000000;;						ic.updateAnnotationOnIngress(baseIngress, staticIPNameKeyWritable, clusterIPName)
0000000000000000000000000000000000000000;;						return
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					if !baseLBStatusExists && clusterLBStatusExists {
0000000000000000000000000000000000000000;;						lbstatusObj, lbErr := api.Scheme.DeepCopy(&clusterIngress.Status.LoadBalancer)
0000000000000000000000000000000000000000;;						lbstatus, ok := lbstatusObj.(*v1.LoadBalancerStatus)
0000000000000000000000000000000000000000;;						if lbErr != nil || !ok {
0000000000000000000000000000000000000000;;							glog.Errorf("Internal error: Failed to clone LoadBalancerStatus of %q in cluster %q while attempting to update master loadbalancer ingress status, will try again later. error: %v, Object to be cloned: %v", ingress, cluster.Name, lbErr, lbstatusObj)
0000000000000000000000000000000000000000;;							ic.deliverIngress(ingress, ic.ingressReviewDelay, true)
0000000000000000000000000000000000000000;;							return
0000000000000000000000000000000000000000;;						}
0000000000000000000000000000000000000000;;						baseIngress.Status.LoadBalancer = *lbstatus
0000000000000000000000000000000000000000;;						glog.V(4).Infof("Attempting to update base federated ingress status: %v", baseIngress)
0000000000000000000000000000000000000000;;						if updatedFedIngress, err := ic.federatedApiClient.Extensions().Ingresses(baseIngress.Namespace).UpdateStatus(baseIngress); err != nil {
0000000000000000000000000000000000000000;;							glog.Errorf("Failed to update federated ingress status of %q (loadbalancer status), will try again later: %v", ingress, err)
0000000000000000000000000000000000000000;;							ic.deliverIngress(ingress, ic.ingressReviewDelay, true)
0000000000000000000000000000000000000000;;							return
0000000000000000000000000000000000000000;;						} else {
0000000000000000000000000000000000000000;;							glog.V(4).Infof("Successfully updated federated ingress status of %q (added loadbalancer status), after update: %q", ingress, updatedFedIngress)
0000000000000000000000000000000000000000;;							ic.deliverIngress(ingress, ic.smallDelay, false)
0000000000000000000000000000000000000000;;							return
0000000000000000000000000000000000000000;;						}
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;				} else {
0000000000000000000000000000000000000000;;					glog.V(4).Infof(logStr, "Not transferring")
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				// Update existing cluster ingress, if needed.
0000000000000000000000000000000000000000;;				if util.ObjectMetaAndSpecEquivalent(baseIngress, clusterIngress) {
0000000000000000000000000000000000000000;;					glog.V(4).Infof("Ingress %q in cluster %q does not need an update: cluster ingress is equivalent to federated ingress", ingress, cluster.Name)
0000000000000000000000000000000000000000;;				} else {
0000000000000000000000000000000000000000;;					glog.V(4).Infof("Ingress %s in cluster %s needs an update: cluster ingress %v is not equivalent to federated ingress %v", ingress, cluster.Name, clusterIngress, desiredIngress)
0000000000000000000000000000000000000000;;					objMeta, err := api.Scheme.DeepCopy(&clusterIngress.ObjectMeta)
0000000000000000000000000000000000000000;;					if err != nil {
0000000000000000000000000000000000000000;;						glog.Errorf("Error deep copying ObjectMeta: %v", err)
0000000000000000000000000000000000000000;;						ic.deliverIngress(ingress, ic.ingressReviewDelay, true)
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					objMetaCopy, ok := objMeta.(*metav1.ObjectMeta)
0000000000000000000000000000000000000000;;					if !ok {
0000000000000000000000000000000000000000;;						glog.Errorf("Internal error: Failed to cast to metav1.ObjectMeta: %v", objMeta)
0000000000000000000000000000000000000000;;						ic.deliverIngress(ingress, ic.ingressReviewDelay, true)
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					desiredIngress.ObjectMeta = *objMetaCopy
0000000000000000000000000000000000000000;;					// Merge any annotations and labels on the federated ingress onto the underlying cluster ingress,
0000000000000000000000000000000000000000;;					// overwriting duplicates.
0000000000000000000000000000000000000000;;					if desiredIngress.ObjectMeta.Annotations == nil {
0000000000000000000000000000000000000000;;						desiredIngress.ObjectMeta.Annotations = make(map[string]string)
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					for key, val := range baseIngress.ObjectMeta.Annotations {
0000000000000000000000000000000000000000;;						desiredIngress.ObjectMeta.Annotations[key] = val
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					if desiredIngress.ObjectMeta.Labels == nil {
0000000000000000000000000000000000000000;;						desiredIngress.ObjectMeta.Labels = make(map[string]string)
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					for key, val := range baseIngress.ObjectMeta.Labels {
0000000000000000000000000000000000000000;;						desiredIngress.ObjectMeta.Labels[key] = val
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;					operations = append(operations, util.FederatedOperation{
0000000000000000000000000000000000000000;;						Type:        util.OperationTypeUpdate,
0000000000000000000000000000000000000000;;						Obj:         desiredIngress,
0000000000000000000000000000000000000000;;						ClusterName: cluster.Name,
0000000000000000000000000000000000000000;;						Key:         key,
0000000000000000000000000000000000000000;;					})
0000000000000000000000000000000000000000;;					// TODO: Transfer any readonly (target-proxy, url-map etc) annotations from the master cluster to the federation, if this is the master cluster.
0000000000000000000000000000000000000000;;					// This is only for consistency, so that the federation ingress metadata matches the underlying clusters.  It's not actually required				}
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if len(operations) == 0 {
0000000000000000000000000000000000000000;;			// Everything is in order
0000000000000000000000000000000000000000;;			glog.V(4).Infof("Ingress %q is up-to-date in all clusters - no propagation to clusters required.", ingress)
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		glog.V(4).Infof("Calling federatedUpdater.Update() - operations: %v", operations)
0000000000000000000000000000000000000000;;		err = ic.federatedIngressUpdater.Update(operations)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			glog.Errorf("Failed to execute updates for %s: %v", ingress, err)
0000000000000000000000000000000000000000;;			ic.deliverIngress(ingress, ic.ingressReviewDelay, true)
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		// Schedule another periodic reconciliation, only to account for possible bugs in watch processing.
0000000000000000000000000000000000000000;;		ic.deliverIngress(ingress, ic.ingressReviewDelay, false)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// delete deletes the given ingress or returns error if the deletion was not complete.
0000000000000000000000000000000000000000;;	func (ic *IngressController) delete(ingress *extensionsv1beta1.Ingress) error {
0000000000000000000000000000000000000000;;		glog.V(3).Infof("Handling deletion of ingress: %v", *ingress)
0000000000000000000000000000000000000000;;		_, err := ic.deletionHelper.HandleObjectInUnderlyingClusters(ingress)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		err = ic.federatedApiClient.Extensions().Ingresses(ingress.Namespace).Delete(ingress.Name, nil)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			// Its all good if the error is not found error. That means it is deleted already and we do not have to do anything.
0000000000000000000000000000000000000000;;			// This is expected when we are processing an update as a result of ingress finalizer deletion.
0000000000000000000000000000000000000000;;			// The process that deleted the last finalizer is also going to delete the ingress and we do not have to do anything.
0000000000000000000000000000000000000000;;			if !errors.IsNotFound(err) {
0000000000000000000000000000000000000000;;				return fmt.Errorf("failed to delete ingress: %v", err)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return nil
0000000000000000000000000000000000000000;;	}
