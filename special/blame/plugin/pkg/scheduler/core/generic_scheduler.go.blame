0000000000000000000000000000000000000000;;	/*
0000000000000000000000000000000000000000;;	Copyright 2014 The Kubernetes Authors.
15cb1f713ffa0a0d4a81f56e9845d133f87e1375;pkg/scheduler/generic_scheduler.go[pkg/scheduler/generic_scheduler.go][plugin/pkg/scheduler/core/generic_scheduler.go];	
0000000000000000000000000000000000000000;;	Licensed under the Apache License, Version 2.0 (the "License");
0000000000000000000000000000000000000000;;	you may not use this file except in compliance with the License.
0000000000000000000000000000000000000000;;	You may obtain a copy of the License at
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	    http://www.apache.org/licenses/LICENSE-2.0
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	Unless required by applicable law or agreed to in writing, software
0000000000000000000000000000000000000000;;	distributed under the License is distributed on an "AS IS" BASIS,
0000000000000000000000000000000000000000;;	WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
0000000000000000000000000000000000000000;;	See the License for the specific language governing permissions and
0000000000000000000000000000000000000000;;	limitations under the License.
0000000000000000000000000000000000000000;;	*/
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	package core
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	import (
0000000000000000000000000000000000000000;;		"fmt"
0000000000000000000000000000000000000000;;		"sort"
0000000000000000000000000000000000000000;;		"strings"
0000000000000000000000000000000000000000;;		"sync"
0000000000000000000000000000000000000000;;		"sync/atomic"
0000000000000000000000000000000000000000;;		"time"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		"github.com/golang/glog"
0000000000000000000000000000000000000000;;		"k8s.io/api/core/v1"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/util/errors"
0000000000000000000000000000000000000000;;		utiltrace "k8s.io/apiserver/pkg/util/trace"
0000000000000000000000000000000000000000;;		"k8s.io/client-go/util/workqueue"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/plugin/pkg/scheduler/algorithm"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/plugin/pkg/scheduler/algorithm/predicates"
0000000000000000000000000000000000000000;;		schedulerapi "k8s.io/kubernetes/plugin/pkg/scheduler/api"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/plugin/pkg/scheduler/schedulercache"
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type FailedPredicateMap map[string][]algorithm.PredicateFailureReason
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type FitError struct {
0000000000000000000000000000000000000000;;		Pod              *v1.Pod
0000000000000000000000000000000000000000;;		FailedPredicates FailedPredicateMap
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	var ErrNoNodesAvailable = fmt.Errorf("no nodes available to schedule pods")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	const NoNodeAvailableMsg = "No nodes are available that match all of the following predicates"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Error returns detailed information of why the pod failed to fit on each node
0000000000000000000000000000000000000000;;	func (f *FitError) Error() string {
0000000000000000000000000000000000000000;;		reasons := make(map[string]int)
0000000000000000000000000000000000000000;;		for _, predicates := range f.FailedPredicates {
0000000000000000000000000000000000000000;;			for _, pred := range predicates {
0000000000000000000000000000000000000000;;				reasons[pred.GetReason()] += 1
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		sortReasonsHistogram := func() []string {
0000000000000000000000000000000000000000;;			reasonStrings := []string{}
0000000000000000000000000000000000000000;;			for k, v := range reasons {
0000000000000000000000000000000000000000;;				reasonStrings = append(reasonStrings, fmt.Sprintf("%v (%v)", k, v))
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			sort.Strings(reasonStrings)
0000000000000000000000000000000000000000;;			return reasonStrings
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		reasonMsg := fmt.Sprintf(NoNodeAvailableMsg+": %v.", strings.Join(sortReasonsHistogram(), ", "))
0000000000000000000000000000000000000000;;		return reasonMsg
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type genericScheduler struct {
0000000000000000000000000000000000000000;;		cache                 schedulercache.Cache
0000000000000000000000000000000000000000;;		equivalenceCache      *EquivalenceCache
0000000000000000000000000000000000000000;;		predicates            map[string]algorithm.FitPredicate
0000000000000000000000000000000000000000;;		priorityMetaProducer  algorithm.MetadataProducer
0000000000000000000000000000000000000000;;		predicateMetaProducer algorithm.MetadataProducer
0000000000000000000000000000000000000000;;		prioritizers          []algorithm.PriorityConfig
0000000000000000000000000000000000000000;;		extenders             []algorithm.SchedulerExtender
0000000000000000000000000000000000000000;;		pods                  algorithm.PodLister
0000000000000000000000000000000000000000;;		lastNodeIndexLock     sync.Mutex
0000000000000000000000000000000000000000;;		lastNodeIndex         uint64
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		cachedNodeInfoMap map[string]*schedulercache.NodeInfo
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Schedule tries to schedule the given pod to one of node in the node list.
0000000000000000000000000000000000000000;;	// If it succeeds, it will return the name of the node.
0000000000000000000000000000000000000000;;	// If it fails, it will return a Fiterror error with reasons.
0000000000000000000000000000000000000000;;	func (g *genericScheduler) Schedule(pod *v1.Pod, nodeLister algorithm.NodeLister) (string, error) {
0000000000000000000000000000000000000000;;		trace := utiltrace.New(fmt.Sprintf("Scheduling %s/%s", pod.Namespace, pod.Name))
0000000000000000000000000000000000000000;;		defer trace.LogIfLong(100 * time.Millisecond)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		nodes, err := nodeLister.List()
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return "", err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if len(nodes) == 0 {
0000000000000000000000000000000000000000;;			return "", ErrNoNodesAvailable
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Used for all fit and priority funcs.
0000000000000000000000000000000000000000;;		err = g.cache.UpdateNodeNameToInfoMap(g.cachedNodeInfoMap)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return "", err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		trace.Step("Computing predicates")
0000000000000000000000000000000000000000;;		filteredNodes, failedPredicateMap, err := findNodesThatFit(pod, g.cachedNodeInfoMap, nodes, g.predicates, g.extenders, g.predicateMetaProducer, g.equivalenceCache)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return "", err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if len(filteredNodes) == 0 {
0000000000000000000000000000000000000000;;			return "", &FitError{
0000000000000000000000000000000000000000;;				Pod:              pod,
0000000000000000000000000000000000000000;;				FailedPredicates: failedPredicateMap,
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		trace.Step("Prioritizing")
0000000000000000000000000000000000000000;;		metaPrioritiesInterface := g.priorityMetaProducer(pod, g.cachedNodeInfoMap)
0000000000000000000000000000000000000000;;		priorityList, err := PrioritizeNodes(pod, g.cachedNodeInfoMap, metaPrioritiesInterface, g.prioritizers, filteredNodes, g.extenders)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return "", err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		trace.Step("Selecting host")
0000000000000000000000000000000000000000;;		return g.selectHost(priorityList)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Prioritizers returns a slice containing all the scheduler's priority
0000000000000000000000000000000000000000;;	// functions and their config. It is exposed for testing only.
0000000000000000000000000000000000000000;;	func (g *genericScheduler) Prioritizers() []algorithm.PriorityConfig {
0000000000000000000000000000000000000000;;		return g.prioritizers
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Predicates returns a map containing all the scheduler's predicate
0000000000000000000000000000000000000000;;	// functions. It is exposed for testing only.
0000000000000000000000000000000000000000;;	func (g *genericScheduler) Predicates() map[string]algorithm.FitPredicate {
0000000000000000000000000000000000000000;;		return g.predicates
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// selectHost takes a prioritized list of nodes and then picks one
0000000000000000000000000000000000000000;;	// in a round-robin manner from the nodes that had the highest score.
0000000000000000000000000000000000000000;;	func (g *genericScheduler) selectHost(priorityList schedulerapi.HostPriorityList) (string, error) {
0000000000000000000000000000000000000000;;		if len(priorityList) == 0 {
0000000000000000000000000000000000000000;;			return "", fmt.Errorf("empty priorityList")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		sort.Sort(sort.Reverse(priorityList))
0000000000000000000000000000000000000000;;		maxScore := priorityList[0].Score
0000000000000000000000000000000000000000;;		firstAfterMaxScore := sort.Search(len(priorityList), func(i int) bool { return priorityList[i].Score < maxScore })
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		g.lastNodeIndexLock.Lock()
0000000000000000000000000000000000000000;;		ix := int(g.lastNodeIndex % uint64(firstAfterMaxScore))
0000000000000000000000000000000000000000;;		g.lastNodeIndex++
0000000000000000000000000000000000000000;;		g.lastNodeIndexLock.Unlock()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return priorityList[ix].Host, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Filters the nodes to find the ones that fit based on the given predicate functions
0000000000000000000000000000000000000000;;	// Each node is passed through the predicate functions to determine if it is a fit
0000000000000000000000000000000000000000;;	func findNodesThatFit(
0000000000000000000000000000000000000000;;		pod *v1.Pod,
0000000000000000000000000000000000000000;;		nodeNameToInfo map[string]*schedulercache.NodeInfo,
0000000000000000000000000000000000000000;;		nodes []*v1.Node,
0000000000000000000000000000000000000000;;		predicateFuncs map[string]algorithm.FitPredicate,
0000000000000000000000000000000000000000;;		extenders []algorithm.SchedulerExtender,
0000000000000000000000000000000000000000;;		metadataProducer algorithm.MetadataProducer,
0000000000000000000000000000000000000000;;		ecache *EquivalenceCache,
0000000000000000000000000000000000000000;;	) ([]*v1.Node, FailedPredicateMap, error) {
0000000000000000000000000000000000000000;;		var filtered []*v1.Node
0000000000000000000000000000000000000000;;		failedPredicateMap := FailedPredicateMap{}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if len(predicateFuncs) == 0 {
0000000000000000000000000000000000000000;;			filtered = nodes
0000000000000000000000000000000000000000;;		} else {
0000000000000000000000000000000000000000;;			// Create filtered list with enough space to avoid growing it
0000000000000000000000000000000000000000;;			// and allow assigning.
0000000000000000000000000000000000000000;;			filtered = make([]*v1.Node, len(nodes))
0000000000000000000000000000000000000000;;			errs := errors.MessageCountMap{}
0000000000000000000000000000000000000000;;			var predicateResultLock sync.Mutex
0000000000000000000000000000000000000000;;			var filteredLen int32
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// We can use the same metadata producer for all nodes.
0000000000000000000000000000000000000000;;			meta := metadataProducer(pod, nodeNameToInfo)
0000000000000000000000000000000000000000;;			checkNode := func(i int) {
0000000000000000000000000000000000000000;;				nodeName := nodes[i].Name
0000000000000000000000000000000000000000;;				fits, failedPredicates, err := podFitsOnNode(pod, meta, nodeNameToInfo[nodeName], predicateFuncs, ecache)
0000000000000000000000000000000000000000;;				if err != nil {
0000000000000000000000000000000000000000;;					predicateResultLock.Lock()
0000000000000000000000000000000000000000;;					errs[err.Error()]++
0000000000000000000000000000000000000000;;					predicateResultLock.Unlock()
0000000000000000000000000000000000000000;;					return
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				if fits {
0000000000000000000000000000000000000000;;					filtered[atomic.AddInt32(&filteredLen, 1)-1] = nodes[i]
0000000000000000000000000000000000000000;;				} else {
0000000000000000000000000000000000000000;;					predicateResultLock.Lock()
0000000000000000000000000000000000000000;;					failedPredicateMap[nodeName] = failedPredicates
0000000000000000000000000000000000000000;;					predicateResultLock.Unlock()
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			workqueue.Parallelize(16, len(nodes), checkNode)
0000000000000000000000000000000000000000;;			filtered = filtered[:filteredLen]
0000000000000000000000000000000000000000;;			if len(errs) > 0 {
0000000000000000000000000000000000000000;;				return []*v1.Node{}, FailedPredicateMap{}, errors.CreateAggregateFromMessageCountMap(errs)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if len(filtered) > 0 && len(extenders) != 0 {
0000000000000000000000000000000000000000;;			for _, extender := range extenders {
0000000000000000000000000000000000000000;;				filteredList, failedMap, err := extender.Filter(pod, filtered, nodeNameToInfo)
0000000000000000000000000000000000000000;;				if err != nil {
0000000000000000000000000000000000000000;;					return []*v1.Node{}, FailedPredicateMap{}, err
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				for failedNodeName, failedMsg := range failedMap {
0000000000000000000000000000000000000000;;					if _, found := failedPredicateMap[failedNodeName]; !found {
0000000000000000000000000000000000000000;;						failedPredicateMap[failedNodeName] = []algorithm.PredicateFailureReason{}
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					failedPredicateMap[failedNodeName] = append(failedPredicateMap[failedNodeName], predicates.NewFailureReason(failedMsg))
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				filtered = filteredList
0000000000000000000000000000000000000000;;				if len(filtered) == 0 {
0000000000000000000000000000000000000000;;					break
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return filtered, failedPredicateMap, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Checks whether node with a given name and NodeInfo satisfies all predicateFuncs.
0000000000000000000000000000000000000000;;	func podFitsOnNode(pod *v1.Pod, meta interface{}, info *schedulercache.NodeInfo, predicateFuncs map[string]algorithm.FitPredicate,
0000000000000000000000000000000000000000;;		ecache *EquivalenceCache) (bool, []algorithm.PredicateFailureReason, error) {
0000000000000000000000000000000000000000;;		var (
0000000000000000000000000000000000000000;;			equivalenceHash  uint64
0000000000000000000000000000000000000000;;			failedPredicates []algorithm.PredicateFailureReason
0000000000000000000000000000000000000000;;			eCacheAvailable  bool
0000000000000000000000000000000000000000;;			invalid          bool
0000000000000000000000000000000000000000;;			fit              bool
0000000000000000000000000000000000000000;;			reasons          []algorithm.PredicateFailureReason
0000000000000000000000000000000000000000;;			err              error
0000000000000000000000000000000000000000;;		)
0000000000000000000000000000000000000000;;		if ecache != nil {
0000000000000000000000000000000000000000;;			// getHashEquivalencePod will return immediately if no equivalence pod found
0000000000000000000000000000000000000000;;			equivalenceHash = ecache.getHashEquivalencePod(pod)
0000000000000000000000000000000000000000;;			eCacheAvailable = (equivalenceHash != 0)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		for predicateKey, predicate := range predicateFuncs {
0000000000000000000000000000000000000000;;			// If equivalenceCache is available
0000000000000000000000000000000000000000;;			if eCacheAvailable {
0000000000000000000000000000000000000000;;				// PredicateWithECache will returns it's cached predicate results
0000000000000000000000000000000000000000;;				fit, reasons, invalid = ecache.PredicateWithECache(pod, info.Node().GetName(), predicateKey, equivalenceHash)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			if !eCacheAvailable || invalid {
0000000000000000000000000000000000000000;;				// we need to execute predicate functions since equivalence cache does not work
0000000000000000000000000000000000000000;;				fit, reasons, err = predicate(pod, meta, info)
0000000000000000000000000000000000000000;;				if err != nil {
0000000000000000000000000000000000000000;;					return false, []algorithm.PredicateFailureReason{}, err
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				if eCacheAvailable {
0000000000000000000000000000000000000000;;					// update equivalence cache with newly computed fit & reasons
0000000000000000000000000000000000000000;;					// TODO(resouer) should we do this in another thread? any race?
0000000000000000000000000000000000000000;;					ecache.UpdateCachedPredicateItem(pod, info.Node().GetName(), predicateKey, fit, reasons, equivalenceHash)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			if !fit {
0000000000000000000000000000000000000000;;				// eCache is available and valid, and predicates result is unfit, record the fail reasons
0000000000000000000000000000000000000000;;				failedPredicates = append(failedPredicates, reasons...)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return len(failedPredicates) == 0, failedPredicates, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Prioritizes the nodes by running the individual priority functions in parallel.
0000000000000000000000000000000000000000;;	// Each priority function is expected to set a score of 0-10
0000000000000000000000000000000000000000;;	// 0 is the lowest priority score (least preferred node) and 10 is the highest
0000000000000000000000000000000000000000;;	// Each priority function can also have its own weight
0000000000000000000000000000000000000000;;	// The node scores returned by the priority function are multiplied by the weights to get weighted scores
0000000000000000000000000000000000000000;;	// All scores are finally combined (added) to get the total weighted scores of all nodes
0000000000000000000000000000000000000000;;	func PrioritizeNodes(
0000000000000000000000000000000000000000;;		pod *v1.Pod,
0000000000000000000000000000000000000000;;		nodeNameToInfo map[string]*schedulercache.NodeInfo,
0000000000000000000000000000000000000000;;		meta interface{},
0000000000000000000000000000000000000000;;		priorityConfigs []algorithm.PriorityConfig,
0000000000000000000000000000000000000000;;		nodes []*v1.Node,
0000000000000000000000000000000000000000;;		extenders []algorithm.SchedulerExtender,
0000000000000000000000000000000000000000;;	) (schedulerapi.HostPriorityList, error) {
0000000000000000000000000000000000000000;;		// If no priority configs are provided, then the EqualPriority function is applied
0000000000000000000000000000000000000000;;		// This is required to generate the priority list in the required format
0000000000000000000000000000000000000000;;		if len(priorityConfigs) == 0 && len(extenders) == 0 {
0000000000000000000000000000000000000000;;			result := make(schedulerapi.HostPriorityList, 0, len(nodes))
0000000000000000000000000000000000000000;;			for i := range nodes {
0000000000000000000000000000000000000000;;				hostPriority, err := EqualPriorityMap(pod, meta, nodeNameToInfo[nodes[i].Name])
0000000000000000000000000000000000000000;;				if err != nil {
0000000000000000000000000000000000000000;;					return nil, err
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				result = append(result, hostPriority)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			return result, nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		var (
0000000000000000000000000000000000000000;;			mu   = sync.Mutex{}
0000000000000000000000000000000000000000;;			wg   = sync.WaitGroup{}
0000000000000000000000000000000000000000;;			errs []error
0000000000000000000000000000000000000000;;		)
0000000000000000000000000000000000000000;;		appendError := func(err error) {
0000000000000000000000000000000000000000;;			mu.Lock()
0000000000000000000000000000000000000000;;			defer mu.Unlock()
0000000000000000000000000000000000000000;;			errs = append(errs, err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		results := make([]schedulerapi.HostPriorityList, 0, len(priorityConfigs))
0000000000000000000000000000000000000000;;		for range priorityConfigs {
0000000000000000000000000000000000000000;;			results = append(results, nil)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		for i, priorityConfig := range priorityConfigs {
0000000000000000000000000000000000000000;;			if priorityConfig.Function != nil {
0000000000000000000000000000000000000000;;				// DEPRECATED
0000000000000000000000000000000000000000;;				wg.Add(1)
0000000000000000000000000000000000000000;;				go func(index int, config algorithm.PriorityConfig) {
0000000000000000000000000000000000000000;;					defer wg.Done()
0000000000000000000000000000000000000000;;					var err error
0000000000000000000000000000000000000000;;					results[index], err = config.Function(pod, nodeNameToInfo, nodes)
0000000000000000000000000000000000000000;;					if err != nil {
0000000000000000000000000000000000000000;;						appendError(err)
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;				}(i, priorityConfig)
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				results[i] = make(schedulerapi.HostPriorityList, len(nodes))
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		processNode := func(index int) {
0000000000000000000000000000000000000000;;			nodeInfo := nodeNameToInfo[nodes[index].Name]
0000000000000000000000000000000000000000;;			var err error
0000000000000000000000000000000000000000;;			for i := range priorityConfigs {
0000000000000000000000000000000000000000;;				if priorityConfigs[i].Function != nil {
0000000000000000000000000000000000000000;;					continue
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				results[i][index], err = priorityConfigs[i].Map(pod, meta, nodeInfo)
0000000000000000000000000000000000000000;;				if err != nil {
0000000000000000000000000000000000000000;;					appendError(err)
0000000000000000000000000000000000000000;;					return
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		workqueue.Parallelize(16, len(nodes), processNode)
0000000000000000000000000000000000000000;;		for i, priorityConfig := range priorityConfigs {
0000000000000000000000000000000000000000;;			if priorityConfig.Reduce == nil {
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			wg.Add(1)
0000000000000000000000000000000000000000;;			go func(index int, config algorithm.PriorityConfig) {
0000000000000000000000000000000000000000;;				defer wg.Done()
0000000000000000000000000000000000000000;;				if err := config.Reduce(pod, meta, nodeNameToInfo, results[index]); err != nil {
0000000000000000000000000000000000000000;;					appendError(err)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}(i, priorityConfig)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		// Wait for all computations to be finished.
0000000000000000000000000000000000000000;;		wg.Wait()
0000000000000000000000000000000000000000;;		if len(errs) != 0 {
0000000000000000000000000000000000000000;;			return schedulerapi.HostPriorityList{}, errors.NewAggregate(errs)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Summarize all scores.
0000000000000000000000000000000000000000;;		result := make(schedulerapi.HostPriorityList, 0, len(nodes))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		for i := range nodes {
0000000000000000000000000000000000000000;;			result = append(result, schedulerapi.HostPriority{Host: nodes[i].Name, Score: 0})
0000000000000000000000000000000000000000;;			for j := range priorityConfigs {
0000000000000000000000000000000000000000;;				result[i].Score += results[j][i].Score * priorityConfigs[j].Weight
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if len(extenders) != 0 && nodes != nil {
0000000000000000000000000000000000000000;;			combinedScores := make(map[string]int, len(nodeNameToInfo))
0000000000000000000000000000000000000000;;			for _, extender := range extenders {
0000000000000000000000000000000000000000;;				wg.Add(1)
0000000000000000000000000000000000000000;;				go func(ext algorithm.SchedulerExtender) {
0000000000000000000000000000000000000000;;					defer wg.Done()
0000000000000000000000000000000000000000;;					prioritizedList, weight, err := ext.Prioritize(pod, nodes)
0000000000000000000000000000000000000000;;					if err != nil {
0000000000000000000000000000000000000000;;						// Prioritization errors from extender can be ignored, let k8s/other extenders determine the priorities
0000000000000000000000000000000000000000;;						return
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					mu.Lock()
0000000000000000000000000000000000000000;;					for i := range *prioritizedList {
0000000000000000000000000000000000000000;;						host, score := (*prioritizedList)[i].Host, (*prioritizedList)[i].Score
0000000000000000000000000000000000000000;;						combinedScores[host] += score * weight
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					mu.Unlock()
0000000000000000000000000000000000000000;;				}(extender)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			// wait for all go routines to finish
0000000000000000000000000000000000000000;;			wg.Wait()
0000000000000000000000000000000000000000;;			for i := range result {
0000000000000000000000000000000000000000;;				result[i].Score += combinedScores[result[i].Host]
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if glog.V(10) {
0000000000000000000000000000000000000000;;			for i := range result {
0000000000000000000000000000000000000000;;				glog.V(10).Infof("Host %s => Score %d", result[i].Host, result[i].Score)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return result, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// EqualPriority is a prioritizer function that gives an equal weight of one to all nodes
0000000000000000000000000000000000000000;;	func EqualPriorityMap(_ *v1.Pod, _ interface{}, nodeInfo *schedulercache.NodeInfo) (schedulerapi.HostPriority, error) {
0000000000000000000000000000000000000000;;		node := nodeInfo.Node()
0000000000000000000000000000000000000000;;		if node == nil {
0000000000000000000000000000000000000000;;			return schedulerapi.HostPriority{}, fmt.Errorf("node not found")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return schedulerapi.HostPriority{
0000000000000000000000000000000000000000;;			Host:  node.Name,
0000000000000000000000000000000000000000;;			Score: 1,
0000000000000000000000000000000000000000;;		}, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func NewGenericScheduler(
0000000000000000000000000000000000000000;;		cache schedulercache.Cache,
0000000000000000000000000000000000000000;;		eCache *EquivalenceCache,
0000000000000000000000000000000000000000;;		predicates map[string]algorithm.FitPredicate,
0000000000000000000000000000000000000000;;		predicateMetaProducer algorithm.MetadataProducer,
0000000000000000000000000000000000000000;;		prioritizers []algorithm.PriorityConfig,
0000000000000000000000000000000000000000;;		priorityMetaProducer algorithm.MetadataProducer,
0000000000000000000000000000000000000000;;		extenders []algorithm.SchedulerExtender) algorithm.ScheduleAlgorithm {
0000000000000000000000000000000000000000;;		return &genericScheduler{
0000000000000000000000000000000000000000;;			cache:                 cache,
0000000000000000000000000000000000000000;;			equivalenceCache:      eCache,
0000000000000000000000000000000000000000;;			predicates:            predicates,
0000000000000000000000000000000000000000;;			predicateMetaProducer: predicateMetaProducer,
0000000000000000000000000000000000000000;;			prioritizers:          prioritizers,
0000000000000000000000000000000000000000;;			priorityMetaProducer:  priorityMetaProducer,
0000000000000000000000000000000000000000;;			extenders:             extenders,
0000000000000000000000000000000000000000;;			cachedNodeInfoMap:     make(map[string]*schedulercache.NodeInfo),
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
