0000000000000000000000000000000000000000;;	/*
0000000000000000000000000000000000000000;;	Copyright 2016 The Kubernetes Authors.
6500db57949cbd8df90efbdff3251d221998769c;;	
0000000000000000000000000000000000000000;;	Licensed under the Apache License, Version 2.0 (the "License");
0000000000000000000000000000000000000000;;	you may not use this file except in compliance with the License.
0000000000000000000000000000000000000000;;	You may obtain a copy of the License at
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	    http://www.apache.org/licenses/LICENSE-2.0
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	Unless required by applicable law or agreed to in writing, software
0000000000000000000000000000000000000000;;	distributed under the License is distributed on an "AS IS" BASIS,
0000000000000000000000000000000000000000;;	WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
0000000000000000000000000000000000000000;;	See the License for the specific language governing permissions and
0000000000000000000000000000000000000000;;	limitations under the License.
0000000000000000000000000000000000000000;;	*/
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	package core
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	import (
0000000000000000000000000000000000000000;;		"fmt"
0000000000000000000000000000000000000000;;		"strings"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		"k8s.io/api/core/v1"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/api/resource"
0000000000000000000000000000000000000000;;		metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/runtime"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/runtime/schema"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/util/sets"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/util/validation/field"
0000000000000000000000000000000000000000;;		"k8s.io/apiserver/pkg/admission"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/api"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/api/helper/qos"
0000000000000000000000000000000000000000;;		k8s_api_v1 "k8s.io/kubernetes/pkg/api/v1"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/api/validation"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/client/clientset_generated/clientset"
0000000000000000000000000000000000000000;;		informers "k8s.io/kubernetes/pkg/client/informers/informers_generated/externalversions"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/quota"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/quota/generic"
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// podResources are the set of resources managed by quota associated with pods.
0000000000000000000000000000000000000000;;	var podResources = []api.ResourceName{
0000000000000000000000000000000000000000;;		api.ResourceCPU,
0000000000000000000000000000000000000000;;		api.ResourceMemory,
0000000000000000000000000000000000000000;;		api.ResourceRequestsCPU,
0000000000000000000000000000000000000000;;		api.ResourceRequestsMemory,
0000000000000000000000000000000000000000;;		api.ResourceLimitsCPU,
0000000000000000000000000000000000000000;;		api.ResourceLimitsMemory,
0000000000000000000000000000000000000000;;		api.ResourcePods,
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// listPodsByNamespaceFuncUsingClient returns a pod listing function based on the provided client.
0000000000000000000000000000000000000000;;	func listPodsByNamespaceFuncUsingClient(kubeClient clientset.Interface) generic.ListFuncByNamespace {
0000000000000000000000000000000000000000;;		// TODO: ideally, we could pass dynamic client pool down into this code, and have one way of doing this.
0000000000000000000000000000000000000000;;		// unfortunately, dynamic client works with Unstructured objects, and when we calculate Usage, we require
0000000000000000000000000000000000000000;;		// structured objects.
0000000000000000000000000000000000000000;;		return func(namespace string, options metav1.ListOptions) ([]runtime.Object, error) {
0000000000000000000000000000000000000000;;			itemList, err := kubeClient.Core().Pods(namespace).List(options)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				return nil, err
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			results := make([]runtime.Object, 0, len(itemList.Items))
0000000000000000000000000000000000000000;;			for i := range itemList.Items {
0000000000000000000000000000000000000000;;				results = append(results, &itemList.Items[i])
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			return results, nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// NewPodEvaluator returns an evaluator that can evaluate pods
0000000000000000000000000000000000000000;;	// if the specified shared informer factory is not nil, evaluator may use it to support listing functions.
0000000000000000000000000000000000000000;;	func NewPodEvaluator(kubeClient clientset.Interface, f informers.SharedInformerFactory) quota.Evaluator {
0000000000000000000000000000000000000000;;		listFuncByNamespace := listPodsByNamespaceFuncUsingClient(kubeClient)
0000000000000000000000000000000000000000;;		if f != nil {
0000000000000000000000000000000000000000;;			listFuncByNamespace = generic.ListResourceUsingInformerFunc(f, v1.SchemeGroupVersion.WithResource("pods"))
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return &podEvaluator{
0000000000000000000000000000000000000000;;			listFuncByNamespace: listFuncByNamespace,
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// podEvaluator knows how to measure usage of pods.
0000000000000000000000000000000000000000;;	type podEvaluator struct {
0000000000000000000000000000000000000000;;		// knows how to list pods
0000000000000000000000000000000000000000;;		listFuncByNamespace generic.ListFuncByNamespace
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Constraints verifies that all required resources are present on the pod
0000000000000000000000000000000000000000;;	// In addition, it validates that the resources are valid (i.e. requests < limits)
0000000000000000000000000000000000000000;;	func (p *podEvaluator) Constraints(required []api.ResourceName, item runtime.Object) error {
0000000000000000000000000000000000000000;;		pod, ok := item.(*api.Pod)
0000000000000000000000000000000000000000;;		if !ok {
0000000000000000000000000000000000000000;;			return fmt.Errorf("Unexpected input object %v", item)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Pod level resources are often set during admission control
0000000000000000000000000000000000000000;;		// As a consequence, we want to verify that resources are valid prior
0000000000000000000000000000000000000000;;		// to ever charging quota prematurely in case they are not.
0000000000000000000000000000000000000000;;		allErrs := field.ErrorList{}
0000000000000000000000000000000000000000;;		fldPath := field.NewPath("spec").Child("containers")
0000000000000000000000000000000000000000;;		for i, ctr := range pod.Spec.Containers {
0000000000000000000000000000000000000000;;			allErrs = append(allErrs, validation.ValidateResourceRequirements(&ctr.Resources, fldPath.Index(i).Child("resources"))...)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		fldPath = field.NewPath("spec").Child("initContainers")
0000000000000000000000000000000000000000;;		for i, ctr := range pod.Spec.InitContainers {
0000000000000000000000000000000000000000;;			allErrs = append(allErrs, validation.ValidateResourceRequirements(&ctr.Resources, fldPath.Index(i).Child("resources"))...)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if len(allErrs) > 0 {
0000000000000000000000000000000000000000;;			return allErrs.ToAggregate()
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// TODO: fix this when we have pod level resource requirements
0000000000000000000000000000000000000000;;		// since we do not yet pod level requests/limits, we need to ensure each
0000000000000000000000000000000000000000;;		// container makes an explict request or limit for a quota tracked resource
0000000000000000000000000000000000000000;;		requiredSet := quota.ToSet(required)
0000000000000000000000000000000000000000;;		missingSet := sets.NewString()
0000000000000000000000000000000000000000;;		for i := range pod.Spec.Containers {
0000000000000000000000000000000000000000;;			enforcePodContainerConstraints(&pod.Spec.Containers[i], requiredSet, missingSet)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		for i := range pod.Spec.InitContainers {
0000000000000000000000000000000000000000;;			enforcePodContainerConstraints(&pod.Spec.InitContainers[i], requiredSet, missingSet)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if len(missingSet) == 0 {
0000000000000000000000000000000000000000;;			return nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return fmt.Errorf("must specify %s", strings.Join(missingSet.List(), ","))
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// GroupKind that this evaluator tracks
0000000000000000000000000000000000000000;;	func (p *podEvaluator) GroupKind() schema.GroupKind {
0000000000000000000000000000000000000000;;		return api.Kind("Pod")
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Handles returns true of the evaluator should handle the specified operation.
0000000000000000000000000000000000000000;;	func (p *podEvaluator) Handles(operation admission.Operation) bool {
0000000000000000000000000000000000000000;;		// TODO: update this if/when pods support resizing resource requirements.
0000000000000000000000000000000000000000;;		return admission.Create == operation
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Matches returns true if the evaluator matches the specified quota with the provided input item
0000000000000000000000000000000000000000;;	func (p *podEvaluator) Matches(resourceQuota *api.ResourceQuota, item runtime.Object) (bool, error) {
0000000000000000000000000000000000000000;;		return generic.Matches(resourceQuota, item, p.MatchingResources, podMatchesScopeFunc)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// MatchingResources takes the input specified list of resources and returns the set of resources it matches.
0000000000000000000000000000000000000000;;	func (p *podEvaluator) MatchingResources(input []api.ResourceName) []api.ResourceName {
0000000000000000000000000000000000000000;;		return quota.Intersection(input, podResources)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Usage knows how to measure usage associated with pods
0000000000000000000000000000000000000000;;	func (p *podEvaluator) Usage(item runtime.Object) (api.ResourceList, error) {
0000000000000000000000000000000000000000;;		return PodUsageFunc(item)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// UsageStats calculates aggregate usage for the object.
0000000000000000000000000000000000000000;;	func (p *podEvaluator) UsageStats(options quota.UsageStatsOptions) (quota.UsageStats, error) {
0000000000000000000000000000000000000000;;		return generic.CalculateUsageStats(options, p.listFuncByNamespace, podMatchesScopeFunc, p.Usage)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// verifies we implement the required interface.
0000000000000000000000000000000000000000;;	var _ quota.Evaluator = &podEvaluator{}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// enforcePodContainerConstraints checks for required resources that are not set on this container and
0000000000000000000000000000000000000000;;	// adds them to missingSet.
0000000000000000000000000000000000000000;;	func enforcePodContainerConstraints(container *api.Container, requiredSet, missingSet sets.String) {
0000000000000000000000000000000000000000;;		requests := container.Resources.Requests
0000000000000000000000000000000000000000;;		limits := container.Resources.Limits
0000000000000000000000000000000000000000;;		containerUsage := podUsageHelper(requests, limits)
0000000000000000000000000000000000000000;;		containerSet := quota.ToSet(quota.ResourceNames(containerUsage))
0000000000000000000000000000000000000000;;		if !containerSet.Equal(requiredSet) {
0000000000000000000000000000000000000000;;			difference := requiredSet.Difference(containerSet)
0000000000000000000000000000000000000000;;			missingSet.Insert(difference.List()...)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// podUsageHelper can summarize the pod quota usage based on requests and limits
0000000000000000000000000000000000000000;;	func podUsageHelper(requests api.ResourceList, limits api.ResourceList) api.ResourceList {
0000000000000000000000000000000000000000;;		result := api.ResourceList{}
0000000000000000000000000000000000000000;;		result[api.ResourcePods] = resource.MustParse("1")
0000000000000000000000000000000000000000;;		if request, found := requests[api.ResourceCPU]; found {
0000000000000000000000000000000000000000;;			result[api.ResourceCPU] = request
0000000000000000000000000000000000000000;;			result[api.ResourceRequestsCPU] = request
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if limit, found := limits[api.ResourceCPU]; found {
0000000000000000000000000000000000000000;;			result[api.ResourceLimitsCPU] = limit
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if request, found := requests[api.ResourceMemory]; found {
0000000000000000000000000000000000000000;;			result[api.ResourceMemory] = request
0000000000000000000000000000000000000000;;			result[api.ResourceRequestsMemory] = request
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if limit, found := limits[api.ResourceMemory]; found {
0000000000000000000000000000000000000000;;			result[api.ResourceLimitsMemory] = limit
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return result
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func toInternalPodOrError(obj runtime.Object) (*api.Pod, error) {
0000000000000000000000000000000000000000;;		pod := &api.Pod{}
0000000000000000000000000000000000000000;;		switch t := obj.(type) {
0000000000000000000000000000000000000000;;		case *v1.Pod:
0000000000000000000000000000000000000000;;			if err := k8s_api_v1.Convert_v1_Pod_To_api_Pod(t, pod, nil); err != nil {
0000000000000000000000000000000000000000;;				return nil, err
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		case *api.Pod:
0000000000000000000000000000000000000000;;			pod = t
0000000000000000000000000000000000000000;;		default:
0000000000000000000000000000000000000000;;			return nil, fmt.Errorf("expect *api.Pod or *v1.Pod, got %v", t)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return pod, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// podMatchesScopeFunc is a function that knows how to evaluate if a pod matches a scope
0000000000000000000000000000000000000000;;	func podMatchesScopeFunc(scope api.ResourceQuotaScope, object runtime.Object) (bool, error) {
0000000000000000000000000000000000000000;;		pod, err := toInternalPodOrError(object)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return false, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		switch scope {
0000000000000000000000000000000000000000;;		case api.ResourceQuotaScopeTerminating:
0000000000000000000000000000000000000000;;			return isTerminating(pod), nil
0000000000000000000000000000000000000000;;		case api.ResourceQuotaScopeNotTerminating:
0000000000000000000000000000000000000000;;			return !isTerminating(pod), nil
0000000000000000000000000000000000000000;;		case api.ResourceQuotaScopeBestEffort:
0000000000000000000000000000000000000000;;			return isBestEffort(pod), nil
0000000000000000000000000000000000000000;;		case api.ResourceQuotaScopeNotBestEffort:
0000000000000000000000000000000000000000;;			return !isBestEffort(pod), nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return false, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// PodUsageFunc knows how to measure usage associated with pods
0000000000000000000000000000000000000000;;	func PodUsageFunc(obj runtime.Object) (api.ResourceList, error) {
0000000000000000000000000000000000000000;;		pod, err := toInternalPodOrError(obj)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return api.ResourceList{}, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		// by convention, we do not quota pods that have reached an end-of-life state
0000000000000000000000000000000000000000;;		if !QuotaPod(pod) {
0000000000000000000000000000000000000000;;			return api.ResourceList{}, nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		requests := api.ResourceList{}
0000000000000000000000000000000000000000;;		limits := api.ResourceList{}
0000000000000000000000000000000000000000;;		// TODO: fix this when we have pod level cgroups
0000000000000000000000000000000000000000;;		// when we have pod level cgroups, we can just read pod level requests/limits
0000000000000000000000000000000000000000;;		for i := range pod.Spec.Containers {
0000000000000000000000000000000000000000;;			requests = quota.Add(requests, pod.Spec.Containers[i].Resources.Requests)
0000000000000000000000000000000000000000;;			limits = quota.Add(limits, pod.Spec.Containers[i].Resources.Limits)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		// InitContainers are run sequentially before other containers start, so the highest
0000000000000000000000000000000000000000;;		// init container resource is compared against the sum of app containers to determine
0000000000000000000000000000000000000000;;		// the effective usage for both requests and limits.
0000000000000000000000000000000000000000;;		for i := range pod.Spec.InitContainers {
0000000000000000000000000000000000000000;;			requests = quota.Max(requests, pod.Spec.InitContainers[i].Resources.Requests)
0000000000000000000000000000000000000000;;			limits = quota.Max(limits, pod.Spec.InitContainers[i].Resources.Limits)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return podUsageHelper(requests, limits), nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func isBestEffort(pod *api.Pod) bool {
0000000000000000000000000000000000000000;;		return qos.GetPodQOS(pod) == api.PodQOSBestEffort
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func isTerminating(pod *api.Pod) bool {
0000000000000000000000000000000000000000;;		if pod.Spec.ActiveDeadlineSeconds != nil && *pod.Spec.ActiveDeadlineSeconds >= int64(0) {
0000000000000000000000000000000000000000;;			return true
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return false
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// QuotaPod returns true if the pod is eligible to track against a quota
0000000000000000000000000000000000000000;;	func QuotaPod(pod *api.Pod) bool {
0000000000000000000000000000000000000000;;		return !(api.PodFailed == pod.Status.Phase || api.PodSucceeded == pod.Status.Phase)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// QuotaV1Pod returns true if the pod is eligible to track against a quota
0000000000000000000000000000000000000000;;	// if it's not in a terminal state according to its phase.
0000000000000000000000000000000000000000;;	func QuotaV1Pod(pod *v1.Pod) bool {
0000000000000000000000000000000000000000;;		return !(v1.PodFailed == pod.Status.Phase || v1.PodSucceeded == pod.Status.Phase)
0000000000000000000000000000000000000000;;	}
