0000000000000000000000000000000000000000;;	/*
0000000000000000000000000000000000000000;;	Copyright 2016 The Kubernetes Authors.
4bb8edea185476a33845e7f8ccbfba179d4728f1;;	
0000000000000000000000000000000000000000;;	Licensed under the Apache License, Version 2.0 (the "License");
0000000000000000000000000000000000000000;;	you may not use this file except in compliance with the License.
0000000000000000000000000000000000000000;;	You may obtain a copy of the License at
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	    http://www.apache.org/licenses/LICENSE-2.0
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	Unless required by applicable law or agreed to in writing, software
0000000000000000000000000000000000000000;;	distributed under the License is distributed on an "AS IS" BASIS,
0000000000000000000000000000000000000000;;	WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
0000000000000000000000000000000000000000;;	See the License for the specific language governing permissions and
0000000000000000000000000000000000000000;;	limitations under the License.
0000000000000000000000000000000000000000;;	*/
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	package cinder
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	import (
0000000000000000000000000000000000000000;;		"fmt"
0000000000000000000000000000000000000000;;		"os"
0000000000000000000000000000000000000000;;		"path"
0000000000000000000000000000000000000000;;		"strings"
0000000000000000000000000000000000000000;;		"time"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		"github.com/golang/glog"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/types"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/util/wait"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/util/exec"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/util/mount"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/volume"
0000000000000000000000000000000000000000;;		volumeutil "k8s.io/kubernetes/pkg/volume/util"
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type cinderDiskAttacher struct {
0000000000000000000000000000000000000000;;		host           volume.VolumeHost
0000000000000000000000000000000000000000;;		cinderProvider CinderProvider
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	var _ volume.Attacher = &cinderDiskAttacher{}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	var _ volume.AttachableVolumePlugin = &cinderPlugin{}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	const (
0000000000000000000000000000000000000000;;		checkSleepDuration       = 1 * time.Second
0000000000000000000000000000000000000000;;		operationFinishInitDealy = 1 * time.Second
0000000000000000000000000000000000000000;;		operationFinishFactor    = 1.1
0000000000000000000000000000000000000000;;		operationFinishSteps     = 10
0000000000000000000000000000000000000000;;		diskAttachInitDealy      = 1 * time.Second
0000000000000000000000000000000000000000;;		diskAttachFactor         = 1.2
0000000000000000000000000000000000000000;;		diskAttachSteps          = 15
0000000000000000000000000000000000000000;;		diskDetachInitDealy      = 1 * time.Second
0000000000000000000000000000000000000000;;		diskDetachFactor         = 1.2
0000000000000000000000000000000000000000;;		diskDetachSteps          = 13
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (plugin *cinderPlugin) NewAttacher() (volume.Attacher, error) {
0000000000000000000000000000000000000000;;		cinder, err := getCloudProvider(plugin.host.GetCloudProvider())
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return nil, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return &cinderDiskAttacher{
0000000000000000000000000000000000000000;;			host:           plugin.host,
0000000000000000000000000000000000000000;;			cinderProvider: cinder,
0000000000000000000000000000000000000000;;		}, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (plugin *cinderPlugin) GetDeviceMountRefs(deviceMountPath string) ([]string, error) {
0000000000000000000000000000000000000000;;		mounter := plugin.host.GetMounter()
0000000000000000000000000000000000000000;;		return mount.GetMountRefs(mounter, deviceMountPath)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (attacher *cinderDiskAttacher) waitOperationFinished(volumeID string) error {
0000000000000000000000000000000000000000;;		backoff := wait.Backoff{
0000000000000000000000000000000000000000;;			Duration: operationFinishInitDealy,
0000000000000000000000000000000000000000;;			Factor:   operationFinishFactor,
0000000000000000000000000000000000000000;;			Steps:    operationFinishSteps,
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		var volumeStatus string
0000000000000000000000000000000000000000;;		err := wait.ExponentialBackoff(backoff, func() (bool, error) {
0000000000000000000000000000000000000000;;			var pending bool
0000000000000000000000000000000000000000;;			var err error
0000000000000000000000000000000000000000;;			pending, volumeStatus, err = attacher.cinderProvider.OperationPending(volumeID)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				return false, err
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			return !pending, nil
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if err == wait.ErrWaitTimeout {
0000000000000000000000000000000000000000;;			err = fmt.Errorf("Volume %q is %s, can't finish within the alloted time", volumeID, volumeStatus)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return err
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (attacher *cinderDiskAttacher) waitDiskAttached(instanceID, volumeID string) error {
0000000000000000000000000000000000000000;;		backoff := wait.Backoff{
0000000000000000000000000000000000000000;;			Duration: diskAttachInitDealy,
0000000000000000000000000000000000000000;;			Factor:   diskAttachFactor,
0000000000000000000000000000000000000000;;			Steps:    diskAttachSteps,
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		err := wait.ExponentialBackoff(backoff, func() (bool, error) {
0000000000000000000000000000000000000000;;			attached, err := attacher.cinderProvider.DiskIsAttached(instanceID, volumeID)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				return false, err
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			return attached, nil
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if err == wait.ErrWaitTimeout {
0000000000000000000000000000000000000000;;			err = fmt.Errorf("Volume %q failed to be attached within the alloted time", volumeID)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return err
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (attacher *cinderDiskAttacher) Attach(spec *volume.Spec, nodeName types.NodeName) (string, error) {
0000000000000000000000000000000000000000;;		volumeSource, _, err := getVolumeSource(spec)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return "", err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		volumeID := volumeSource.VolumeID
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		instanceID, err := attacher.nodeInstanceID(nodeName)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return "", err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if err := attacher.waitOperationFinished(volumeID); err != nil {
0000000000000000000000000000000000000000;;			return "", err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		attached, err := attacher.cinderProvider.DiskIsAttached(instanceID, volumeID)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			// Log error and continue with attach
0000000000000000000000000000000000000000;;			glog.Warningf(
0000000000000000000000000000000000000000;;				"Error checking if volume (%q) is already attached to current instance (%q). Will continue and try attach anyway. err=%v",
0000000000000000000000000000000000000000;;				volumeID, instanceID, err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if err == nil && attached {
0000000000000000000000000000000000000000;;			// Volume is already attached to instance.
0000000000000000000000000000000000000000;;			glog.Infof("Attach operation is successful. volume %q is already attached to instance %q.", volumeID, instanceID)
0000000000000000000000000000000000000000;;		} else {
0000000000000000000000000000000000000000;;			_, err = attacher.cinderProvider.AttachDisk(instanceID, volumeID)
0000000000000000000000000000000000000000;;			if err == nil {
0000000000000000000000000000000000000000;;				if err = attacher.waitDiskAttached(instanceID, volumeID); err != nil {
0000000000000000000000000000000000000000;;					glog.Errorf("Error waiting for volume %q to be attached from node %q: %v", volumeID, nodeName, err)
0000000000000000000000000000000000000000;;					return "", err
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				glog.Infof("Attach operation successful: volume %q attached to instance %q.", volumeID, instanceID)
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				glog.Infof("Attach volume %q to instance %q failed with: %v", volumeID, instanceID, err)
0000000000000000000000000000000000000000;;				return "", err
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		devicePath, err := attacher.cinderProvider.GetAttachmentDiskPath(instanceID, volumeID)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			glog.Infof("Can not get device path of volume %q which be attached to instance %q, failed with: %v", volumeID, instanceID, err)
0000000000000000000000000000000000000000;;			return "", err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return devicePath, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (attacher *cinderDiskAttacher) VolumesAreAttached(specs []*volume.Spec, nodeName types.NodeName) (map[*volume.Spec]bool, error) {
0000000000000000000000000000000000000000;;		volumesAttachedCheck := make(map[*volume.Spec]bool)
0000000000000000000000000000000000000000;;		volumeSpecMap := make(map[string]*volume.Spec)
0000000000000000000000000000000000000000;;		volumeIDList := []string{}
0000000000000000000000000000000000000000;;		for _, spec := range specs {
0000000000000000000000000000000000000000;;			volumeSource, _, err := getVolumeSource(spec)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				glog.Errorf("Error getting volume (%q) source : %v", spec.Name(), err)
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			volumeIDList = append(volumeIDList, volumeSource.VolumeID)
0000000000000000000000000000000000000000;;			volumesAttachedCheck[spec] = true
0000000000000000000000000000000000000000;;			volumeSpecMap[volumeSource.VolumeID] = spec
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		instanceID, err := attacher.nodeInstanceID(nodeName)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return volumesAttachedCheck, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		attachedResult, err := attacher.cinderProvider.DisksAreAttached(instanceID, volumeIDList)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			// Log error and continue with attach
0000000000000000000000000000000000000000;;			glog.Errorf(
0000000000000000000000000000000000000000;;				"Error checking if Volumes (%v) are already attached to current node (%q). Will continue and try attach anyway. err=%v",
0000000000000000000000000000000000000000;;				volumeIDList, nodeName, err)
0000000000000000000000000000000000000000;;			return volumesAttachedCheck, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		for volumeID, attached := range attachedResult {
0000000000000000000000000000000000000000;;			if !attached {
0000000000000000000000000000000000000000;;				spec := volumeSpecMap[volumeID]
0000000000000000000000000000000000000000;;				volumesAttachedCheck[spec] = false
0000000000000000000000000000000000000000;;				glog.V(2).Infof("VolumesAreAttached: check volume %q (specName: %q) is no longer attached", volumeID, spec.Name())
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return volumesAttachedCheck, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (attacher *cinderDiskAttacher) WaitForAttach(spec *volume.Spec, devicePath string, timeout time.Duration) (string, error) {
0000000000000000000000000000000000000000;;		// NOTE: devicePath is is path as reported by Cinder, which may be incorrect and should not be used. See Issue #33128
0000000000000000000000000000000000000000;;		volumeSource, _, err := getVolumeSource(spec)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return "", err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		volumeID := volumeSource.VolumeID
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if devicePath == "" {
0000000000000000000000000000000000000000;;			return "", fmt.Errorf("WaitForAttach failed for Cinder disk %q: devicePath is empty.", volumeID)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		ticker := time.NewTicker(checkSleepDuration)
0000000000000000000000000000000000000000;;		defer ticker.Stop()
0000000000000000000000000000000000000000;;		timer := time.NewTimer(timeout)
0000000000000000000000000000000000000000;;		defer timer.Stop()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		for {
0000000000000000000000000000000000000000;;			probeAttachedVolume()
0000000000000000000000000000000000000000;;			select {
0000000000000000000000000000000000000000;;			case <-ticker.C:
0000000000000000000000000000000000000000;;				glog.V(5).Infof("Checking Cinder disk %q is attached.", volumeID)
0000000000000000000000000000000000000000;;				probeAttachedVolume()
0000000000000000000000000000000000000000;;				if !attacher.cinderProvider.ShouldTrustDevicePath() {
0000000000000000000000000000000000000000;;					// Using the Cinder volume ID, find the real device path (See Issue #33128)
0000000000000000000000000000000000000000;;					devicePath = attacher.cinderProvider.GetDevicePath(volumeID)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				exists, err := volumeutil.PathExists(devicePath)
0000000000000000000000000000000000000000;;				if exists && err == nil {
0000000000000000000000000000000000000000;;					glog.Infof("Successfully found attached Cinder disk %q at %v.", volumeID, devicePath)
0000000000000000000000000000000000000000;;					return devicePath, nil
0000000000000000000000000000000000000000;;				} else {
0000000000000000000000000000000000000000;;					// Log an error, and continue checking periodically
0000000000000000000000000000000000000000;;					glog.Errorf("Error: could not find attached Cinder disk %q (path: %q): %v", volumeID, devicePath, err)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			case <-timer.C:
0000000000000000000000000000000000000000;;				return "", fmt.Errorf("Could not find attached Cinder disk %q. Timeout waiting for mount paths to be created.", volumeID)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (attacher *cinderDiskAttacher) GetDeviceMountPath(
0000000000000000000000000000000000000000;;		spec *volume.Spec) (string, error) {
0000000000000000000000000000000000000000;;		volumeSource, _, err := getVolumeSource(spec)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return "", err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return makeGlobalPDName(attacher.host, volumeSource.VolumeID), nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// FIXME: this method can be further pruned.
0000000000000000000000000000000000000000;;	func (attacher *cinderDiskAttacher) MountDevice(spec *volume.Spec, devicePath string, deviceMountPath string) error {
0000000000000000000000000000000000000000;;		mounter := attacher.host.GetMounter()
0000000000000000000000000000000000000000;;		notMnt, err := mounter.IsLikelyNotMountPoint(deviceMountPath)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			if os.IsNotExist(err) {
0000000000000000000000000000000000000000;;				if err := os.MkdirAll(deviceMountPath, 0750); err != nil {
0000000000000000000000000000000000000000;;					return err
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				notMnt = true
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				return err
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		volumeSource, readOnly, err := getVolumeSource(spec)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		options := []string{}
0000000000000000000000000000000000000000;;		if readOnly {
0000000000000000000000000000000000000000;;			options = append(options, "ro")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if notMnt {
0000000000000000000000000000000000000000;;			diskMounter := &mount.SafeFormatAndMount{Interface: mounter, Runner: exec.New()}
0000000000000000000000000000000000000000;;			mountOptions := volume.MountOptionFromSpec(spec, options...)
0000000000000000000000000000000000000000;;			err = diskMounter.FormatAndMount(devicePath, deviceMountPath, volumeSource.FSType, mountOptions)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				os.Remove(deviceMountPath)
0000000000000000000000000000000000000000;;				return err
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type cinderDiskDetacher struct {
0000000000000000000000000000000000000000;;		mounter        mount.Interface
0000000000000000000000000000000000000000;;		cinderProvider CinderProvider
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	var _ volume.Detacher = &cinderDiskDetacher{}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (plugin *cinderPlugin) NewDetacher() (volume.Detacher, error) {
0000000000000000000000000000000000000000;;		cinder, err := getCloudProvider(plugin.host.GetCloudProvider())
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return nil, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return &cinderDiskDetacher{
0000000000000000000000000000000000000000;;			mounter:        plugin.host.GetMounter(),
0000000000000000000000000000000000000000;;			cinderProvider: cinder,
0000000000000000000000000000000000000000;;		}, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (detacher *cinderDiskDetacher) waitOperationFinished(volumeID string) error {
0000000000000000000000000000000000000000;;		backoff := wait.Backoff{
0000000000000000000000000000000000000000;;			Duration: operationFinishInitDealy,
0000000000000000000000000000000000000000;;			Factor:   operationFinishFactor,
0000000000000000000000000000000000000000;;			Steps:    operationFinishSteps,
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		var volumeStatus string
0000000000000000000000000000000000000000;;		err := wait.ExponentialBackoff(backoff, func() (bool, error) {
0000000000000000000000000000000000000000;;			var pending bool
0000000000000000000000000000000000000000;;			var err error
0000000000000000000000000000000000000000;;			pending, volumeStatus, err = detacher.cinderProvider.OperationPending(volumeID)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				return false, err
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			return !pending, nil
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if err == wait.ErrWaitTimeout {
0000000000000000000000000000000000000000;;			err = fmt.Errorf("Volume %q is %s, can't finish within the alloted time", volumeID, volumeStatus)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return err
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (detacher *cinderDiskDetacher) waitDiskDetached(instanceID, volumeID string) error {
0000000000000000000000000000000000000000;;		backoff := wait.Backoff{
0000000000000000000000000000000000000000;;			Duration: diskDetachInitDealy,
0000000000000000000000000000000000000000;;			Factor:   diskDetachFactor,
0000000000000000000000000000000000000000;;			Steps:    diskDetachSteps,
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		err := wait.ExponentialBackoff(backoff, func() (bool, error) {
0000000000000000000000000000000000000000;;			attached, err := detacher.cinderProvider.DiskIsAttached(instanceID, volumeID)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				return false, err
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			return !attached, nil
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if err == wait.ErrWaitTimeout {
0000000000000000000000000000000000000000;;			err = fmt.Errorf("Volume %q failed to detach within the alloted time", volumeID)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return err
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (detacher *cinderDiskDetacher) Detach(deviceMountPath string, nodeName types.NodeName) error {
0000000000000000000000000000000000000000;;		volumeID := path.Base(deviceMountPath)
0000000000000000000000000000000000000000;;		instances, res := detacher.cinderProvider.Instances()
0000000000000000000000000000000000000000;;		if !res {
0000000000000000000000000000000000000000;;			return fmt.Errorf("failed to list openstack instances")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		instanceID, err := instances.InstanceID(nodeName)
0000000000000000000000000000000000000000;;		if ind := strings.LastIndex(instanceID, "/"); ind >= 0 {
0000000000000000000000000000000000000000;;			instanceID = instanceID[(ind + 1):]
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if err := detacher.waitOperationFinished(volumeID); err != nil {
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		attached, err := detacher.cinderProvider.DiskIsAttached(instanceID, volumeID)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			// Log error and continue with detach
0000000000000000000000000000000000000000;;			glog.Errorf(
0000000000000000000000000000000000000000;;				"Error checking if volume (%q) is already attached to current node (%q). Will continue and try detach anyway. err=%v",
0000000000000000000000000000000000000000;;				volumeID, nodeName, err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if err == nil && !attached {
0000000000000000000000000000000000000000;;			// Volume is already detached from node.
0000000000000000000000000000000000000000;;			glog.Infof("detach operation was successful. volume %q is already detached from node %q.", volumeID, nodeName)
0000000000000000000000000000000000000000;;			return nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if err = detacher.cinderProvider.DetachDisk(instanceID, volumeID); err != nil {
0000000000000000000000000000000000000000;;			glog.Errorf("Error detaching volume %q from node %q: %v", volumeID, nodeName, err)
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if err = detacher.waitDiskDetached(instanceID, volumeID); err != nil {
0000000000000000000000000000000000000000;;			glog.Errorf("Error waiting for volume %q to detach from node %q: %v", volumeID, nodeName, err)
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		glog.Infof("detached volume %q from node %q", volumeID, nodeName)
0000000000000000000000000000000000000000;;		return nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (detacher *cinderDiskDetacher) UnmountDevice(deviceMountPath string) error {
0000000000000000000000000000000000000000;;		return volumeutil.UnmountPath(deviceMountPath, detacher.mounter)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (attacher *cinderDiskAttacher) nodeInstanceID(nodeName types.NodeName) (string, error) {
0000000000000000000000000000000000000000;;		instances, res := attacher.cinderProvider.Instances()
0000000000000000000000000000000000000000;;		if !res {
0000000000000000000000000000000000000000;;			return "", fmt.Errorf("failed to list openstack instances")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		instanceID, err := instances.InstanceID(nodeName)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return "", err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if ind := strings.LastIndex(instanceID, "/"); ind >= 0 {
0000000000000000000000000000000000000000;;			instanceID = instanceID[(ind + 1):]
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return instanceID, nil
0000000000000000000000000000000000000000;;	}
