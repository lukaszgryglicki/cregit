0000000000000000000000000000000000000000;;	/*
0000000000000000000000000000000000000000;;	Copyright 2015 The Kubernetes Authors.
ebd560ae040ae6b34c24b27d4eed543ec7595f30;;	
0000000000000000000000000000000000000000;;	Licensed under the Apache License, Version 2.0 (the "License");
0000000000000000000000000000000000000000;;	you may not use this file except in compliance with the License.
0000000000000000000000000000000000000000;;	You may obtain a copy of the License at
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	    http://www.apache.org/licenses/LICENSE-2.0
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	Unless required by applicable law or agreed to in writing, software
0000000000000000000000000000000000000000;;	distributed under the License is distributed on an "AS IS" BASIS,
0000000000000000000000000000000000000000;;	WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
0000000000000000000000000000000000000000;;	See the License for the specific language governing permissions and
0000000000000000000000000000000000000000;;	limitations under the License.
0000000000000000000000000000000000000000;;	*/
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	package glusterfs
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	import (
0000000000000000000000000000000000000000;;		"fmt"
0000000000000000000000000000000000000000;;		"math"
0000000000000000000000000000000000000000;;		"os"
0000000000000000000000000000000000000000;;		"path"
0000000000000000000000000000000000000000;;		"runtime"
0000000000000000000000000000000000000000;;		"strconv"
0000000000000000000000000000000000000000;;		dstrings "strings"
0000000000000000000000000000000000000000;;		"sync"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		"github.com/golang/glog"
0000000000000000000000000000000000000000;;		gcli "github.com/heketi/heketi/client/api/go-client"
0000000000000000000000000000000000000000;;		gapi "github.com/heketi/heketi/pkg/glusterfs/api"
0000000000000000000000000000000000000000;;		"k8s.io/api/core/v1"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/api/errors"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/api/resource"
0000000000000000000000000000000000000000;;		metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/labels"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/types"
0000000000000000000000000000000000000000;;		v1helper "k8s.io/kubernetes/pkg/api/v1/helper"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/client/clientset_generated/clientset"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/util/exec"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/util/mount"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/util/strings"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/volume"
0000000000000000000000000000000000000000;;		volutil "k8s.io/kubernetes/pkg/volume/util"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/volume/util/volumehelper"
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// ProbeVolumePlugins is the primary entrypoint for volume plugins.
0000000000000000000000000000000000000000;;	func ProbeVolumePlugins() []volume.VolumePlugin {
0000000000000000000000000000000000000000;;		return []volume.VolumePlugin{&glusterfsPlugin{host: nil, exe: exec.New(), gidTable: make(map[string]*MinMaxAllocator)}}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type glusterfsPlugin struct {
0000000000000000000000000000000000000000;;		host         volume.VolumeHost
0000000000000000000000000000000000000000;;		exe          exec.Interface
0000000000000000000000000000000000000000;;		gidTable     map[string]*MinMaxAllocator
0000000000000000000000000000000000000000;;		gidTableLock sync.Mutex
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	var _ volume.VolumePlugin = &glusterfsPlugin{}
0000000000000000000000000000000000000000;;	var _ volume.PersistentVolumePlugin = &glusterfsPlugin{}
0000000000000000000000000000000000000000;;	var _ volume.DeletableVolumePlugin = &glusterfsPlugin{}
0000000000000000000000000000000000000000;;	var _ volume.ProvisionableVolumePlugin = &glusterfsPlugin{}
0000000000000000000000000000000000000000;;	var _ volume.Provisioner = &glusterfsVolumeProvisioner{}
0000000000000000000000000000000000000000;;	var _ volume.Deleter = &glusterfsVolumeDeleter{}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	const (
0000000000000000000000000000000000000000;;		glusterfsPluginName            = "kubernetes.io/glusterfs"
0000000000000000000000000000000000000000;;		volPrefix                      = "vol_"
0000000000000000000000000000000000000000;;		dynamicEpSvcPrefix             = "glusterfs-dynamic-"
0000000000000000000000000000000000000000;;		replicaCount                   = 3
0000000000000000000000000000000000000000;;		durabilityType                 = "replicate"
0000000000000000000000000000000000000000;;		secretKeyName                  = "key" // key name used in secret
0000000000000000000000000000000000000000;;		gciLinuxGlusterMountBinaryPath = "/sbin/mount.glusterfs"
0000000000000000000000000000000000000000;;		defaultGidMin                  = 2000
0000000000000000000000000000000000000000;;		defaultGidMax                  = math.MaxInt32
0000000000000000000000000000000000000000;;		// absoluteGidMin/Max are currently the same as the
0000000000000000000000000000000000000000;;		// default values, but they play a different role and
0000000000000000000000000000000000000000;;		// could take a different value. Only thing we need is:
0000000000000000000000000000000000000000;;		// absGidMin <= defGidMin <= defGidMax <= absGidMax
0000000000000000000000000000000000000000;;		absoluteGidMin          = 2000
0000000000000000000000000000000000000000;;		absoluteGidMax          = math.MaxInt32
0000000000000000000000000000000000000000;;		linuxGlusterMountBinary = "mount.glusterfs"
0000000000000000000000000000000000000000;;		heketiAnn               = "heketi-dynamic-provisioner"
0000000000000000000000000000000000000000;;		glusterTypeAnn          = "gluster.org/type"
0000000000000000000000000000000000000000;;		glusterDescAnn          = "Gluster-Internal: Dynamically provisioned PV"
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (plugin *glusterfsPlugin) Init(host volume.VolumeHost) error {
0000000000000000000000000000000000000000;;		plugin.host = host
0000000000000000000000000000000000000000;;		return nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (plugin *glusterfsPlugin) GetPluginName() string {
0000000000000000000000000000000000000000;;		return glusterfsPluginName
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (plugin *glusterfsPlugin) GetVolumeName(spec *volume.Spec) (string, error) {
0000000000000000000000000000000000000000;;		volumeSource, _, err := getVolumeSource(spec)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return "", err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return fmt.Sprintf(
0000000000000000000000000000000000000000;;			"%v:%v",
0000000000000000000000000000000000000000;;			volumeSource.EndpointsName,
0000000000000000000000000000000000000000;;			volumeSource.Path), nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (plugin *glusterfsPlugin) CanSupport(spec *volume.Spec) bool {
0000000000000000000000000000000000000000;;		if (spec.PersistentVolume != nil && spec.PersistentVolume.Spec.Glusterfs == nil) ||
0000000000000000000000000000000000000000;;			(spec.Volume != nil && spec.Volume.Glusterfs == nil) {
0000000000000000000000000000000000000000;;			return false
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return true
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (plugin *glusterfsPlugin) RequiresRemount() bool {
0000000000000000000000000000000000000000;;		return false
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (plugin *glusterfsPlugin) SupportsMountOption() bool {
0000000000000000000000000000000000000000;;		return true
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (plugin *glusterfsPlugin) SupportsBulkVolumeVerification() bool {
0000000000000000000000000000000000000000;;		return false
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (plugin *glusterfsPlugin) GetAccessModes() []v1.PersistentVolumeAccessMode {
0000000000000000000000000000000000000000;;		return []v1.PersistentVolumeAccessMode{
0000000000000000000000000000000000000000;;			v1.ReadWriteOnce,
0000000000000000000000000000000000000000;;			v1.ReadOnlyMany,
0000000000000000000000000000000000000000;;			v1.ReadWriteMany,
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (plugin *glusterfsPlugin) NewMounter(spec *volume.Spec, pod *v1.Pod, _ volume.VolumeOptions) (volume.Mounter, error) {
0000000000000000000000000000000000000000;;		source, _ := plugin.getGlusterVolumeSource(spec)
0000000000000000000000000000000000000000;;		epName := source.EndpointsName
0000000000000000000000000000000000000000;;		// PVC/POD is in same ns.
0000000000000000000000000000000000000000;;		podNs := pod.Namespace
0000000000000000000000000000000000000000;;		kubeClient := plugin.host.GetKubeClient()
0000000000000000000000000000000000000000;;		if kubeClient == nil {
0000000000000000000000000000000000000000;;			return nil, fmt.Errorf("glusterfs: failed to get kube client to initialize mounter")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		ep, err := kubeClient.Core().Endpoints(podNs).Get(epName, metav1.GetOptions{})
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			glog.Errorf("glusterfs: failed to get endpoints %s[%v]", epName, err)
0000000000000000000000000000000000000000;;			return nil, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		glog.V(1).Infof("glusterfs: endpoints %v", ep)
0000000000000000000000000000000000000000;;		return plugin.newMounterInternal(spec, ep, pod, plugin.host.GetMounter(), exec.New())
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (plugin *glusterfsPlugin) getGlusterVolumeSource(spec *volume.Spec) (*v1.GlusterfsVolumeSource, bool) {
0000000000000000000000000000000000000000;;		// Glusterfs volumes used directly in a pod have a ReadOnly flag set by the pod author.
0000000000000000000000000000000000000000;;		// Glusterfs volumes used as a PersistentVolume gets the ReadOnly flag indirectly through the persistent-claim volume used to mount the PV
0000000000000000000000000000000000000000;;		if spec.Volume != nil && spec.Volume.Glusterfs != nil {
0000000000000000000000000000000000000000;;			return spec.Volume.Glusterfs, spec.Volume.Glusterfs.ReadOnly
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return spec.PersistentVolume.Spec.Glusterfs, spec.ReadOnly
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (plugin *glusterfsPlugin) newMounterInternal(spec *volume.Spec, ep *v1.Endpoints, pod *v1.Pod, mounter mount.Interface, exe exec.Interface) (volume.Mounter, error) {
0000000000000000000000000000000000000000;;		source, readOnly := plugin.getGlusterVolumeSource(spec)
0000000000000000000000000000000000000000;;		return &glusterfsMounter{
0000000000000000000000000000000000000000;;			glusterfs: &glusterfs{
0000000000000000000000000000000000000000;;				volName: spec.Name(),
0000000000000000000000000000000000000000;;				mounter: mounter,
0000000000000000000000000000000000000000;;				pod:     pod,
0000000000000000000000000000000000000000;;				plugin:  plugin,
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			hosts:        ep,
0000000000000000000000000000000000000000;;			path:         source.Path,
0000000000000000000000000000000000000000;;			readOnly:     readOnly,
0000000000000000000000000000000000000000;;			exe:          exe,
0000000000000000000000000000000000000000;;			mountOptions: volume.MountOptionFromSpec(spec),
0000000000000000000000000000000000000000;;		}, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (plugin *glusterfsPlugin) NewUnmounter(volName string, podUID types.UID) (volume.Unmounter, error) {
0000000000000000000000000000000000000000;;		return plugin.newUnmounterInternal(volName, podUID, plugin.host.GetMounter())
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (plugin *glusterfsPlugin) newUnmounterInternal(volName string, podUID types.UID, mounter mount.Interface) (volume.Unmounter, error) {
0000000000000000000000000000000000000000;;		return &glusterfsUnmounter{&glusterfs{
0000000000000000000000000000000000000000;;			volName: volName,
0000000000000000000000000000000000000000;;			mounter: mounter,
0000000000000000000000000000000000000000;;			pod:     &v1.Pod{ObjectMeta: metav1.ObjectMeta{UID: podUID}},
0000000000000000000000000000000000000000;;			plugin:  plugin,
0000000000000000000000000000000000000000;;		}}, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (plugin *glusterfsPlugin) execCommand(command string, args []string) ([]byte, error) {
0000000000000000000000000000000000000000;;		cmd := plugin.exe.Command(command, args...)
0000000000000000000000000000000000000000;;		return cmd.CombinedOutput()
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (plugin *glusterfsPlugin) ConstructVolumeSpec(volumeName, mountPath string) (*volume.Spec, error) {
0000000000000000000000000000000000000000;;		glusterfsVolume := &v1.Volume{
0000000000000000000000000000000000000000;;			Name: volumeName,
0000000000000000000000000000000000000000;;			VolumeSource: v1.VolumeSource{
0000000000000000000000000000000000000000;;				Glusterfs: &v1.GlusterfsVolumeSource{
0000000000000000000000000000000000000000;;					EndpointsName: volumeName,
0000000000000000000000000000000000000000;;					Path:          volumeName,
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return volume.NewSpecFromVolume(glusterfsVolume), nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Glusterfs volumes represent a bare host file or directory mount of an Glusterfs export.
0000000000000000000000000000000000000000;;	type glusterfs struct {
0000000000000000000000000000000000000000;;		volName string
0000000000000000000000000000000000000000;;		pod     *v1.Pod
0000000000000000000000000000000000000000;;		mounter mount.Interface
0000000000000000000000000000000000000000;;		plugin  *glusterfsPlugin
0000000000000000000000000000000000000000;;		volume.MetricsNil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type glusterfsMounter struct {
0000000000000000000000000000000000000000;;		*glusterfs
0000000000000000000000000000000000000000;;		hosts        *v1.Endpoints
0000000000000000000000000000000000000000;;		path         string
0000000000000000000000000000000000000000;;		readOnly     bool
0000000000000000000000000000000000000000;;		exe          exec.Interface
0000000000000000000000000000000000000000;;		mountOptions []string
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	var _ volume.Mounter = &glusterfsMounter{}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (b *glusterfsMounter) GetAttributes() volume.Attributes {
0000000000000000000000000000000000000000;;		return volume.Attributes{
0000000000000000000000000000000000000000;;			ReadOnly:        b.readOnly,
0000000000000000000000000000000000000000;;			Managed:         false,
0000000000000000000000000000000000000000;;			SupportsSELinux: false,
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Checks prior to mount operations to verify that the required components (binaries, etc.)
0000000000000000000000000000000000000000;;	// to mount the volume are available on the underlying node.
0000000000000000000000000000000000000000;;	// If not, it returns an error
0000000000000000000000000000000000000000;;	func (b *glusterfsMounter) CanMount() error {
0000000000000000000000000000000000000000;;		exe := exec.New()
0000000000000000000000000000000000000000;;		switch runtime.GOOS {
0000000000000000000000000000000000000000;;		case "linux":
0000000000000000000000000000000000000000;;			if _, err := exe.Command("/bin/ls", gciLinuxGlusterMountBinaryPath).CombinedOutput(); err != nil {
0000000000000000000000000000000000000000;;				return fmt.Errorf("Required binary %s is missing", gciLinuxGlusterMountBinaryPath)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// SetUp attaches the disk and bind mounts to the volume path.
0000000000000000000000000000000000000000;;	func (b *glusterfsMounter) SetUp(fsGroup *int64) error {
0000000000000000000000000000000000000000;;		return b.SetUpAt(b.GetPath(), fsGroup)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (b *glusterfsMounter) SetUpAt(dir string, fsGroup *int64) error {
0000000000000000000000000000000000000000;;		notMnt, err := b.mounter.IsLikelyNotMountPoint(dir)
0000000000000000000000000000000000000000;;		glog.V(4).Infof("glusterfs: mount set up: %s %v %v", dir, !notMnt, err)
0000000000000000000000000000000000000000;;		if err != nil && !os.IsNotExist(err) {
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if !notMnt {
0000000000000000000000000000000000000000;;			return nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		os.MkdirAll(dir, 0750)
0000000000000000000000000000000000000000;;		err = b.setUpAtInternal(dir)
0000000000000000000000000000000000000000;;		if err == nil {
0000000000000000000000000000000000000000;;			return nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Cleanup upon failure.
0000000000000000000000000000000000000000;;		volutil.UnmountPath(dir, b.mounter)
0000000000000000000000000000000000000000;;		return err
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (glusterfsVolume *glusterfs) GetPath() string {
0000000000000000000000000000000000000000;;		name := glusterfsPluginName
0000000000000000000000000000000000000000;;		return glusterfsVolume.plugin.host.GetPodVolumeDir(glusterfsVolume.pod.UID, strings.EscapeQualifiedNameForDisk(name), glusterfsVolume.volName)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type glusterfsUnmounter struct {
0000000000000000000000000000000000000000;;		*glusterfs
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	var _ volume.Unmounter = &glusterfsUnmounter{}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (c *glusterfsUnmounter) TearDown() error {
0000000000000000000000000000000000000000;;		return c.TearDownAt(c.GetPath())
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (c *glusterfsUnmounter) TearDownAt(dir string) error {
0000000000000000000000000000000000000000;;		return volutil.UnmountPath(dir, c.mounter)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (b *glusterfsMounter) setUpAtInternal(dir string) error {
0000000000000000000000000000000000000000;;		var errs error
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		options := []string{}
0000000000000000000000000000000000000000;;		if b.readOnly {
0000000000000000000000000000000000000000;;			options = append(options, "ro")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		p := path.Join(b.glusterfs.plugin.host.GetPluginDir(glusterfsPluginName), b.glusterfs.volName)
0000000000000000000000000000000000000000;;		if err := os.MkdirAll(p, 0750); err != nil {
0000000000000000000000000000000000000000;;			return fmt.Errorf("glusterfs: mkdir failed: %v", err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// adding log-level ERROR to remove noise
0000000000000000000000000000000000000000;;		// and more specific log path so each pod has
0000000000000000000000000000000000000000;;		// its own log based on PV + Pod
0000000000000000000000000000000000000000;;		log := path.Join(p, b.pod.Name+"-glusterfs.log")
0000000000000000000000000000000000000000;;		options = append(options, "log-level=ERROR")
0000000000000000000000000000000000000000;;		options = append(options, "log-file="+log)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		var addrlist []string
0000000000000000000000000000000000000000;;		if b.hosts == nil {
0000000000000000000000000000000000000000;;			return fmt.Errorf("glusterfs: endpoint is nil")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		addr := make(map[string]struct{})
0000000000000000000000000000000000000000;;		if b.hosts.Subsets != nil {
0000000000000000000000000000000000000000;;			for _, s := range b.hosts.Subsets {
0000000000000000000000000000000000000000;;				for _, a := range s.Addresses {
0000000000000000000000000000000000000000;;					addr[a.IP] = struct{}{}
0000000000000000000000000000000000000000;;					addrlist = append(addrlist, a.IP)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		options = append(options, "backup-volfile-servers="+dstrings.Join(addrlist[:], ":"))
0000000000000000000000000000000000000000;;		mountOptions := volume.JoinMountOptions(b.mountOptions, options)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Avoid mount storm, pick a host randomly.
0000000000000000000000000000000000000000;;		// Iterate all hosts until mount succeeds.
0000000000000000000000000000000000000000;;		for _, ip := range addrlist {
0000000000000000000000000000000000000000;;			errs = b.mounter.Mount(ip+":"+b.path, dir, "glusterfs", mountOptions)
0000000000000000000000000000000000000000;;			if errs == nil {
0000000000000000000000000000000000000000;;				glog.Infof("glusterfs: successfully mounted %s", dir)
0000000000000000000000000000000000000000;;				return nil
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			const invalidOption = "Invalid option auto_unmount"
0000000000000000000000000000000000000000;;			if dstrings.Contains(errs.Error(), invalidOption) {
0000000000000000000000000000000000000000;;				// Give a try without `auto_unmount` mount option, because
0000000000000000000000000000000000000000;;				// it could be that gluster fuse client is older version and
0000000000000000000000000000000000000000;;				// mount.glusterfs is unaware of `auto_unmount`.
0000000000000000000000000000000000000000;;				noAutoMountOptions := make([]string, len(mountOptions))
0000000000000000000000000000000000000000;;				for _, opt := range mountOptions {
0000000000000000000000000000000000000000;;					if opt != "auto_unmount" {
0000000000000000000000000000000000000000;;						noAutoMountOptions = append(noAutoMountOptions, opt)
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				errs = b.mounter.Mount(ip+":"+b.path, dir, "glusterfs", noAutoMountOptions)
0000000000000000000000000000000000000000;;				if errs == nil {
0000000000000000000000000000000000000000;;					glog.Infof("glusterfs: successfully mounted %s", dir)
0000000000000000000000000000000000000000;;					return nil
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Failed mount scenario.
0000000000000000000000000000000000000000;;		// Since glusterfs does not return error text
0000000000000000000000000000000000000000;;		// it all goes in a log file, we will read the log file
0000000000000000000000000000000000000000;;		logErr := readGlusterLog(log, b.pod.Name)
0000000000000000000000000000000000000000;;		if logErr != nil {
0000000000000000000000000000000000000000;;			// return fmt.Errorf("glusterfs: mount failed: %v", logErr)
0000000000000000000000000000000000000000;;			return fmt.Errorf("glusterfs: mount failed: %v the following error information was pulled from the glusterfs log to help diagnose this issue: %v", errs, logErr)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return fmt.Errorf("glusterfs: mount failed: %v", errs)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func getVolumeSource(
0000000000000000000000000000000000000000;;		spec *volume.Spec) (*v1.GlusterfsVolumeSource, bool, error) {
0000000000000000000000000000000000000000;;		if spec.Volume != nil && spec.Volume.Glusterfs != nil {
0000000000000000000000000000000000000000;;			return spec.Volume.Glusterfs, spec.Volume.Glusterfs.ReadOnly, nil
0000000000000000000000000000000000000000;;		} else if spec.PersistentVolume != nil &&
0000000000000000000000000000000000000000;;			spec.PersistentVolume.Spec.Glusterfs != nil {
0000000000000000000000000000000000000000;;			return spec.PersistentVolume.Spec.Glusterfs, spec.ReadOnly, nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return nil, false, fmt.Errorf("Spec does not reference a GlusterFS volume type")
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (plugin *glusterfsPlugin) NewProvisioner(options volume.VolumeOptions) (volume.Provisioner, error) {
0000000000000000000000000000000000000000;;		return plugin.newProvisionerInternal(options)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (plugin *glusterfsPlugin) newProvisionerInternal(options volume.VolumeOptions) (volume.Provisioner, error) {
0000000000000000000000000000000000000000;;		return &glusterfsVolumeProvisioner{
0000000000000000000000000000000000000000;;			glusterfsMounter: &glusterfsMounter{
0000000000000000000000000000000000000000;;				glusterfs: &glusterfs{
0000000000000000000000000000000000000000;;					plugin: plugin,
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			options: options,
0000000000000000000000000000000000000000;;		}, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type provisionerConfig struct {
0000000000000000000000000000000000000000;;		url             string
0000000000000000000000000000000000000000;;		user            string
0000000000000000000000000000000000000000;;		userKey         string
0000000000000000000000000000000000000000;;		secretNamespace string
0000000000000000000000000000000000000000;;		secretName      string
0000000000000000000000000000000000000000;;		secretValue     string
0000000000000000000000000000000000000000;;		clusterID       string
0000000000000000000000000000000000000000;;		gidMin          int
0000000000000000000000000000000000000000;;		gidMax          int
0000000000000000000000000000000000000000;;		volumeType      gapi.VolumeDurabilityInfo
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type glusterfsVolumeProvisioner struct {
0000000000000000000000000000000000000000;;		*glusterfsMounter
0000000000000000000000000000000000000000;;		provisionerConfig
0000000000000000000000000000000000000000;;		options volume.VolumeOptions
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func convertGid(gidString string) (int, error) {
0000000000000000000000000000000000000000;;		gid64, err := strconv.ParseInt(gidString, 10, 32)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return 0, fmt.Errorf("glusterfs: failed to parse gid %v ", gidString)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if gid64 < 0 {
0000000000000000000000000000000000000000;;			return 0, fmt.Errorf("glusterfs: negative GIDs are not allowed: %v", gidString)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// ParseInt returns a int64, but since we parsed only
0000000000000000000000000000000000000000;;		// for 32 bit, we can cast to int without loss:
0000000000000000000000000000000000000000;;		gid := int(gid64)
0000000000000000000000000000000000000000;;		return gid, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func convertVolumeParam(volumeString string) (int, error) {
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		count, err := strconv.Atoi(volumeString)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return 0, fmt.Errorf("failed to parse %q", volumeString)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if count < 0 {
0000000000000000000000000000000000000000;;			return 0, fmt.Errorf("negative values are not allowed")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return count, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (plugin *glusterfsPlugin) NewDeleter(spec *volume.Spec) (volume.Deleter, error) {
0000000000000000000000000000000000000000;;		return plugin.newDeleterInternal(spec)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (plugin *glusterfsPlugin) newDeleterInternal(spec *volume.Spec) (volume.Deleter, error) {
0000000000000000000000000000000000000000;;		if spec.PersistentVolume != nil && spec.PersistentVolume.Spec.Glusterfs == nil {
0000000000000000000000000000000000000000;;			return nil, fmt.Errorf("spec.PersistentVolumeSource.Spec.Glusterfs is nil")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return &glusterfsVolumeDeleter{
0000000000000000000000000000000000000000;;			glusterfsMounter: &glusterfsMounter{
0000000000000000000000000000000000000000;;				glusterfs: &glusterfs{
0000000000000000000000000000000000000000;;					volName: spec.Name(),
0000000000000000000000000000000000000000;;					plugin:  plugin,
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;				path: spec.PersistentVolume.Spec.Glusterfs.Path,
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			spec: spec.PersistentVolume,
0000000000000000000000000000000000000000;;		}, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type glusterfsVolumeDeleter struct {
0000000000000000000000000000000000000000;;		*glusterfsMounter
0000000000000000000000000000000000000000;;		provisionerConfig
0000000000000000000000000000000000000000;;		spec *v1.PersistentVolume
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (d *glusterfsVolumeDeleter) GetPath() string {
0000000000000000000000000000000000000000;;		name := glusterfsPluginName
0000000000000000000000000000000000000000;;		return d.plugin.host.GetPodVolumeDir(d.glusterfsMounter.glusterfs.pod.UID, strings.EscapeQualifiedNameForDisk(name), d.glusterfsMounter.glusterfs.volName)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	//
0000000000000000000000000000000000000000;;	// Traverse the PVs, fetching all the GIDs from those
0000000000000000000000000000000000000000;;	// in a given storage class, and mark them in the table.
0000000000000000000000000000000000000000;;	//
0000000000000000000000000000000000000000;;	func (plugin *glusterfsPlugin) collectGids(className string, gidTable *MinMaxAllocator) error {
0000000000000000000000000000000000000000;;		kubeClient := plugin.host.GetKubeClient()
0000000000000000000000000000000000000000;;		if kubeClient == nil {
0000000000000000000000000000000000000000;;			return fmt.Errorf("glusterfs: failed to get kube client when collecting gids")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		pvList, err := kubeClient.Core().PersistentVolumes().List(metav1.ListOptions{LabelSelector: labels.Everything().String()})
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			glog.Errorf("glusterfs: failed to get existing persistent volumes")
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		for _, pv := range pvList.Items {
0000000000000000000000000000000000000000;;			if v1helper.GetPersistentVolumeClass(&pv) != className {
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			pvName := pv.ObjectMeta.Name
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			gidStr, ok := pv.Annotations[volumehelper.VolumeGidAnnotationKey]
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			if !ok {
0000000000000000000000000000000000000000;;				glog.Warningf("glusterfs: no gid found in pv '%v'", pvName)
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			gid, err := convertGid(gidStr)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				glog.Error(err)
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			_, err = gidTable.Allocate(gid)
0000000000000000000000000000000000000000;;			if err == ErrConflict {
0000000000000000000000000000000000000000;;				glog.Warningf("glusterfs: gid %v found in pv %v was already allocated", gid)
0000000000000000000000000000000000000000;;			} else if err != nil {
0000000000000000000000000000000000000000;;				glog.Errorf("glusterfs: failed to store gid %v found in pv '%v': %v", gid, pvName, err)
0000000000000000000000000000000000000000;;				return err
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	//
0000000000000000000000000000000000000000;;	// Return the gid table for a storage class.
0000000000000000000000000000000000000000;;	// - If this is the first time, fill it with all the gids
0000000000000000000000000000000000000000;;	//   used in PVs of this storage class by traversing the PVs.
0000000000000000000000000000000000000000;;	// - Adapt the range of the table to the current range of the SC.
0000000000000000000000000000000000000000;;	//
0000000000000000000000000000000000000000;;	func (plugin *glusterfsPlugin) getGidTable(className string, min int, max int) (*MinMaxAllocator, error) {
0000000000000000000000000000000000000000;;		var err error
0000000000000000000000000000000000000000;;		plugin.gidTableLock.Lock()
0000000000000000000000000000000000000000;;		gidTable, ok := plugin.gidTable[className]
0000000000000000000000000000000000000000;;		plugin.gidTableLock.Unlock()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if ok {
0000000000000000000000000000000000000000;;			err = gidTable.SetRange(min, max)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				return nil, err
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			return gidTable, nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// create a new table and fill it
0000000000000000000000000000000000000000;;		newGidTable, err := NewMinMaxAllocator(0, absoluteGidMax)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return nil, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// collect gids with the full range
0000000000000000000000000000000000000000;;		err = plugin.collectGids(className, newGidTable)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return nil, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// and only reduce the range afterwards
0000000000000000000000000000000000000000;;		err = newGidTable.SetRange(min, max)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return nil, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// if in the meantime a table appeared, use it
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		plugin.gidTableLock.Lock()
0000000000000000000000000000000000000000;;		defer plugin.gidTableLock.Unlock()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		gidTable, ok = plugin.gidTable[className]
0000000000000000000000000000000000000000;;		if ok {
0000000000000000000000000000000000000000;;			err = gidTable.SetRange(min, max)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				return nil, err
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			return gidTable, nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		plugin.gidTable[className] = newGidTable
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return newGidTable, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (d *glusterfsVolumeDeleter) getGid() (int, bool, error) {
0000000000000000000000000000000000000000;;		gidStr, ok := d.spec.Annotations[volumehelper.VolumeGidAnnotationKey]
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if !ok {
0000000000000000000000000000000000000000;;			return 0, false, nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		gid, err := convertGid(gidStr)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return gid, true, err
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (d *glusterfsVolumeDeleter) Delete() error {
0000000000000000000000000000000000000000;;		var err error
0000000000000000000000000000000000000000;;		glog.V(2).Infof("glusterfs: delete volume: %s ", d.glusterfsMounter.path)
0000000000000000000000000000000000000000;;		volumeName := d.glusterfsMounter.path
0000000000000000000000000000000000000000;;		volumeID := dstrings.TrimPrefix(volumeName, volPrefix)
0000000000000000000000000000000000000000;;		class, err := volutil.GetClassForVolume(d.plugin.host.GetKubeClient(), d.spec)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		cfg, err := parseClassParameters(class.Parameters, d.plugin.host.GetKubeClient())
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		d.provisionerConfig = *cfg
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		glog.V(4).Infof("glusterfs: deleting volume %q with configuration %+v", volumeID, d.provisionerConfig)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		gid, exists, err := d.getGid()
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			glog.Error(err)
0000000000000000000000000000000000000000;;		} else if exists {
0000000000000000000000000000000000000000;;			gidTable, err := d.plugin.getGidTable(class.Name, cfg.gidMin, cfg.gidMax)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				return fmt.Errorf("glusterfs: failed to get gidTable: %v", err)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			err = gidTable.Release(gid)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				return fmt.Errorf("glusterfs: failed to release gid %v: %v", gid, err)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		cli := gcli.NewClient(d.url, d.user, d.secretValue)
0000000000000000000000000000000000000000;;		if cli == nil {
0000000000000000000000000000000000000000;;			glog.Errorf("glusterfs: failed to create glusterfs rest client")
0000000000000000000000000000000000000000;;			return fmt.Errorf("glusterfs: failed to create glusterfs rest client, REST server authentication failed")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		err = cli.VolumeDelete(volumeID)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			glog.Errorf("glusterfs: error when deleting the volume :%v", err)
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		glog.V(2).Infof("glusterfs: volume %s deleted successfully", volumeName)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		//Deleter takes endpoint and endpointnamespace from pv spec.
0000000000000000000000000000000000000000;;		pvSpec := d.spec.Spec
0000000000000000000000000000000000000000;;		var dynamicEndpoint, dynamicNamespace string
0000000000000000000000000000000000000000;;		if pvSpec.ClaimRef == nil {
0000000000000000000000000000000000000000;;			glog.Errorf("glusterfs: ClaimRef is nil")
0000000000000000000000000000000000000000;;			return fmt.Errorf("glusterfs: ClaimRef is nil")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if pvSpec.ClaimRef.Namespace == "" {
0000000000000000000000000000000000000000;;			glog.Errorf("glusterfs: namespace is nil")
0000000000000000000000000000000000000000;;			return fmt.Errorf("glusterfs: namespace is nil")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		dynamicNamespace = pvSpec.ClaimRef.Namespace
0000000000000000000000000000000000000000;;		if pvSpec.Glusterfs.EndpointsName != "" {
0000000000000000000000000000000000000000;;			dynamicEndpoint = pvSpec.Glusterfs.EndpointsName
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		glog.V(3).Infof("glusterfs: dynamic namespace and endpoint : [%v/%v]", dynamicNamespace, dynamicEndpoint)
0000000000000000000000000000000000000000;;		err = d.deleteEndpointService(dynamicNamespace, dynamicEndpoint)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			glog.Errorf("glusterfs: error when deleting endpoint/service :%v", err)
0000000000000000000000000000000000000000;;		} else {
0000000000000000000000000000000000000000;;			glog.V(1).Infof("glusterfs: [%v/%v] deleted successfully ", dynamicNamespace, dynamicEndpoint)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (p *glusterfsVolumeProvisioner) Provision() (*v1.PersistentVolume, error) {
0000000000000000000000000000000000000000;;		if !volume.AccessModesContainedInAll(p.plugin.GetAccessModes(), p.options.PVC.Spec.AccessModes) {
0000000000000000000000000000000000000000;;			return nil, fmt.Errorf("invalid AccessModes %v: only AccessModes %v are supported", p.options.PVC.Spec.AccessModes, p.plugin.GetAccessModes())
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		var err error
0000000000000000000000000000000000000000;;		if p.options.PVC.Spec.Selector != nil {
0000000000000000000000000000000000000000;;			glog.V(4).Infof("glusterfs: not able to parse your claim Selector")
0000000000000000000000000000000000000000;;			return nil, fmt.Errorf("glusterfs: not able to parse your claim Selector")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		glog.V(4).Infof("glusterfs: Provison VolumeOptions %v", p.options)
0000000000000000000000000000000000000000;;		scName := v1helper.GetPersistentVolumeClaimClass(p.options.PVC)
0000000000000000000000000000000000000000;;		cfg, err := parseClassParameters(p.options.Parameters, p.plugin.host.GetKubeClient())
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return nil, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		p.provisionerConfig = *cfg
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		glog.V(4).Infof("glusterfs: creating volume with configuration %+v", p.provisionerConfig)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		gidTable, err := p.plugin.getGidTable(scName, cfg.gidMin, cfg.gidMax)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return nil, fmt.Errorf("glusterfs: failed to get gidTable: %v", err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		gid, _, err := gidTable.AllocateNext()
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			glog.Errorf("glusterfs: failed to reserve gid from table: %v", err)
0000000000000000000000000000000000000000;;			return nil, fmt.Errorf("glusterfs: failed to reserve gid from table: %v", err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		glog.V(2).Infof("glusterfs: got gid [%d] for PVC %s", gid, p.options.PVC.Name)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		glusterfs, sizeGB, err := p.CreateVolume(gid)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			if releaseErr := gidTable.Release(gid); releaseErr != nil {
0000000000000000000000000000000000000000;;				glog.Errorf("glusterfs:  error when releasing gid in storageclass: %s", scName)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			glog.Errorf("glusterfs: create volume err: %v.", err)
0000000000000000000000000000000000000000;;			return nil, fmt.Errorf("glusterfs: create volume err: %v", err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		pv := new(v1.PersistentVolume)
0000000000000000000000000000000000000000;;		pv.Spec.PersistentVolumeSource.Glusterfs = glusterfs
0000000000000000000000000000000000000000;;		pv.Spec.PersistentVolumeReclaimPolicy = p.options.PersistentVolumeReclaimPolicy
0000000000000000000000000000000000000000;;		pv.Spec.AccessModes = p.options.PVC.Spec.AccessModes
0000000000000000000000000000000000000000;;		if len(pv.Spec.AccessModes) == 0 {
0000000000000000000000000000000000000000;;			pv.Spec.AccessModes = p.plugin.GetAccessModes()
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		gidStr := strconv.FormatInt(int64(gid), 10)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		pv.Annotations = map[string]string{
0000000000000000000000000000000000000000;;			volumehelper.VolumeGidAnnotationKey:        gidStr,
0000000000000000000000000000000000000000;;			volumehelper.VolumeDynamicallyCreatedByKey: heketiAnn,
0000000000000000000000000000000000000000;;			glusterTypeAnn:                             "file",
0000000000000000000000000000000000000000;;			"Description":                              glusterDescAnn,
0000000000000000000000000000000000000000;;			v1.MountOptionAnnotation:                   "auto_unmount",
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		pv.Spec.Capacity = v1.ResourceList{
0000000000000000000000000000000000000000;;			v1.ResourceName(v1.ResourceStorage): resource.MustParse(fmt.Sprintf("%dGi", sizeGB)),
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return pv, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (p *glusterfsVolumeProvisioner) CreateVolume(gid int) (r *v1.GlusterfsVolumeSource, size int, err error) {
0000000000000000000000000000000000000000;;		var clusterIDs []string
0000000000000000000000000000000000000000;;		capacity := p.options.PVC.Spec.Resources.Requests[v1.ResourceName(v1.ResourceStorage)]
0000000000000000000000000000000000000000;;		volSizeBytes := capacity.Value()
0000000000000000000000000000000000000000;;		sz := int(volume.RoundUpSize(volSizeBytes, 1024*1024*1024))
0000000000000000000000000000000000000000;;		glog.V(2).Infof("glusterfs: create volume of size: %d bytes and configuration %+v", volSizeBytes, p.provisionerConfig)
0000000000000000000000000000000000000000;;		if p.url == "" {
0000000000000000000000000000000000000000;;			glog.Errorf("glusterfs : rest server endpoint is empty")
0000000000000000000000000000000000000000;;			return nil, 0, fmt.Errorf("failed to create glusterfs REST client, REST URL is empty")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		cli := gcli.NewClient(p.url, p.user, p.secretValue)
0000000000000000000000000000000000000000;;		if cli == nil {
0000000000000000000000000000000000000000;;			glog.Errorf("glusterfs: failed to create glusterfs rest client")
0000000000000000000000000000000000000000;;			return nil, 0, fmt.Errorf("failed to create glusterfs REST client, REST server authentication failed")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if p.provisionerConfig.clusterID != "" {
0000000000000000000000000000000000000000;;			clusterIDs = dstrings.Split(p.clusterID, ",")
0000000000000000000000000000000000000000;;			glog.V(4).Infof("glusterfs: provided clusterIDs: %v", clusterIDs)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		gid64 := int64(gid)
0000000000000000000000000000000000000000;;		volumeReq := &gapi.VolumeCreateRequest{Size: sz, Clusters: clusterIDs, Gid: gid64, Durability: p.volumeType}
0000000000000000000000000000000000000000;;		volume, err := cli.VolumeCreate(volumeReq)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			glog.Errorf("glusterfs: error creating volume %v ", err)
0000000000000000000000000000000000000000;;			return nil, 0, fmt.Errorf("error creating volume %v", err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		glog.V(1).Infof("glusterfs: volume with size: %d and name: %s created", volume.Size, volume.Name)
0000000000000000000000000000000000000000;;		dynamicHostIps, err := getClusterNodes(cli, volume.Cluster)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			glog.Errorf("glusterfs: error [%v] when getting cluster nodes for volume %s", err, volume)
0000000000000000000000000000000000000000;;			return nil, 0, fmt.Errorf("error [%v] when getting cluster nodes for volume %s", err, volume)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// The 'endpointname' is created in form of 'gluster-dynamic-<claimname>'.
0000000000000000000000000000000000000000;;		// createEndpointService() checks for this 'endpoint' existence in PVC's namespace and
0000000000000000000000000000000000000000;;		// If not found, it create an endpoint and svc using the IPs we dynamically picked at time
0000000000000000000000000000000000000000;;		// of volume creation.
0000000000000000000000000000000000000000;;		epServiceName := dynamicEpSvcPrefix + p.options.PVC.Name
0000000000000000000000000000000000000000;;		epNamespace := p.options.PVC.Namespace
0000000000000000000000000000000000000000;;		endpoint, service, err := p.createEndpointService(epNamespace, epServiceName, dynamicHostIps, p.options.PVC.Name)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			glog.Errorf("glusterfs: failed to create endpoint/service: %v", err)
0000000000000000000000000000000000000000;;			deleteErr := cli.VolumeDelete(volume.Id)
0000000000000000000000000000000000000000;;			if deleteErr != nil {
0000000000000000000000000000000000000000;;				glog.Errorf("glusterfs: error when deleting the volume :%v , manual deletion required", deleteErr)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			return nil, 0, fmt.Errorf("failed to create endpoint/service %v", err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		glog.V(3).Infof("glusterfs: dynamic ep %v and svc : %v ", endpoint, service)
0000000000000000000000000000000000000000;;		return &v1.GlusterfsVolumeSource{
0000000000000000000000000000000000000000;;			EndpointsName: endpoint.Name,
0000000000000000000000000000000000000000;;			Path:          volume.Name,
0000000000000000000000000000000000000000;;			ReadOnly:      false,
0000000000000000000000000000000000000000;;		}, sz, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (p *glusterfsVolumeProvisioner) createEndpointService(namespace string, epServiceName string, hostips []string, pvcname string) (endpoint *v1.Endpoints, service *v1.Service, err error) {
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		addrlist := make([]v1.EndpointAddress, len(hostips))
0000000000000000000000000000000000000000;;		for i, v := range hostips {
0000000000000000000000000000000000000000;;			addrlist[i].IP = v
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		endpoint = &v1.Endpoints{
0000000000000000000000000000000000000000;;			ObjectMeta: metav1.ObjectMeta{
0000000000000000000000000000000000000000;;				Namespace: namespace,
0000000000000000000000000000000000000000;;				Name:      epServiceName,
0000000000000000000000000000000000000000;;				Labels: map[string]string{
0000000000000000000000000000000000000000;;					"gluster.kubernetes.io/provisioned-for-pvc": pvcname,
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			Subsets: []v1.EndpointSubset{{
0000000000000000000000000000000000000000;;				Addresses: addrlist,
0000000000000000000000000000000000000000;;				Ports:     []v1.EndpointPort{{Port: 1, Protocol: "TCP"}},
0000000000000000000000000000000000000000;;			}},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		kubeClient := p.plugin.host.GetKubeClient()
0000000000000000000000000000000000000000;;		if kubeClient == nil {
0000000000000000000000000000000000000000;;			return nil, nil, fmt.Errorf("glusterfs: failed to get kube client when creating endpoint service")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		_, err = kubeClient.Core().Endpoints(namespace).Create(endpoint)
0000000000000000000000000000000000000000;;		if err != nil && errors.IsAlreadyExists(err) {
0000000000000000000000000000000000000000;;			glog.V(1).Infof("glusterfs: endpoint [%s] already exist in namespace [%s]", endpoint, namespace)
0000000000000000000000000000000000000000;;			err = nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			glog.Errorf("glusterfs: failed to create endpoint: %v", err)
0000000000000000000000000000000000000000;;			return nil, nil, fmt.Errorf("error creating endpoint: %v", err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		service = &v1.Service{
0000000000000000000000000000000000000000;;			ObjectMeta: metav1.ObjectMeta{
0000000000000000000000000000000000000000;;				Name:      epServiceName,
0000000000000000000000000000000000000000;;				Namespace: namespace,
0000000000000000000000000000000000000000;;				Labels: map[string]string{
0000000000000000000000000000000000000000;;					"gluster.kubernetes.io/provisioned-for-pvc": pvcname,
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			Spec: v1.ServiceSpec{
0000000000000000000000000000000000000000;;				Ports: []v1.ServicePort{
0000000000000000000000000000000000000000;;					{Protocol: "TCP", Port: 1}}}}
0000000000000000000000000000000000000000;;		_, err = kubeClient.Core().Services(namespace).Create(service)
0000000000000000000000000000000000000000;;		if err != nil && errors.IsAlreadyExists(err) {
0000000000000000000000000000000000000000;;			glog.V(1).Infof("glusterfs: service [%s] already exist in namespace [%s]", service, namespace)
0000000000000000000000000000000000000000;;			err = nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			glog.Errorf("glusterfs: failed to create service: %v", err)
0000000000000000000000000000000000000000;;			return nil, nil, fmt.Errorf("error creating service: %v", err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return endpoint, service, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (d *glusterfsVolumeDeleter) deleteEndpointService(namespace string, epServiceName string) (err error) {
0000000000000000000000000000000000000000;;		kubeClient := d.plugin.host.GetKubeClient()
0000000000000000000000000000000000000000;;		if kubeClient == nil {
0000000000000000000000000000000000000000;;			return fmt.Errorf("glusterfs: failed to get kube client when deleting endpoint service")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		err = kubeClient.Core().Services(namespace).Delete(epServiceName, nil)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			glog.Errorf("glusterfs: error deleting service %s/%s: %v", namespace, epServiceName, err)
0000000000000000000000000000000000000000;;			return fmt.Errorf("error deleting service %s/%s: %v", namespace, epServiceName, err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		glog.V(1).Infof("glusterfs: service/endpoint %s/%s deleted successfully", namespace, epServiceName)
0000000000000000000000000000000000000000;;		return nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// parseSecret finds a given Secret instance and reads user password from it.
0000000000000000000000000000000000000000;;	func parseSecret(namespace, secretName string, kubeClient clientset.Interface) (string, error) {
0000000000000000000000000000000000000000;;		secretMap, err := volutil.GetSecretForPV(namespace, secretName, glusterfsPluginName, kubeClient)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			glog.Errorf("failed to get secret %s/%s: %v", namespace, secretName, err)
0000000000000000000000000000000000000000;;			return "", fmt.Errorf("failed to get secret %s/%s: %v", namespace, secretName, err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if len(secretMap) == 0 {
0000000000000000000000000000000000000000;;			return "", fmt.Errorf("empty secret map")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		secret := ""
0000000000000000000000000000000000000000;;		for k, v := range secretMap {
0000000000000000000000000000000000000000;;			if k == secretKeyName {
0000000000000000000000000000000000000000;;				return v, nil
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			secret = v
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		// If not found, the last secret in the map wins as done before
0000000000000000000000000000000000000000;;		return secret, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// getClusterNodes() returns the cluster nodes of a given cluster
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func getClusterNodes(cli *gcli.Client, cluster string) (dynamicHostIps []string, err error) {
0000000000000000000000000000000000000000;;		clusterinfo, err := cli.ClusterInfo(cluster)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			glog.Errorf("glusterfs: failed to get cluster details: %v", err)
0000000000000000000000000000000000000000;;			return nil, fmt.Errorf("failed to get cluster details: %v", err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// For the dynamically provisioned volume, we gather the list of node IPs
0000000000000000000000000000000000000000;;		// of the cluster on which provisioned volume belongs to, as there can be multiple
0000000000000000000000000000000000000000;;		// clusters.
0000000000000000000000000000000000000000;;		for _, node := range clusterinfo.Nodes {
0000000000000000000000000000000000000000;;			nodei, err := cli.NodeInfo(string(node))
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				glog.Errorf("glusterfs: failed to get hostip: %v", err)
0000000000000000000000000000000000000000;;				return nil, fmt.Errorf("failed to get hostip: %v", err)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			ipaddr := dstrings.Join(nodei.NodeAddRequest.Hostnames.Storage, "")
0000000000000000000000000000000000000000;;			dynamicHostIps = append(dynamicHostIps, ipaddr)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		glog.V(3).Infof("glusterfs: hostlist :%v", dynamicHostIps)
0000000000000000000000000000000000000000;;		if len(dynamicHostIps) == 0 {
0000000000000000000000000000000000000000;;			glog.Errorf("glusterfs: no hosts found: %v", err)
0000000000000000000000000000000000000000;;			return nil, fmt.Errorf("no hosts found: %v", err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return dynamicHostIps, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// parseClassParameters parses StorageClass.Parameters
0000000000000000000000000000000000000000;;	func parseClassParameters(params map[string]string, kubeClient clientset.Interface) (*provisionerConfig, error) {
0000000000000000000000000000000000000000;;		var cfg provisionerConfig
0000000000000000000000000000000000000000;;		var err error
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		cfg.gidMin = defaultGidMin
0000000000000000000000000000000000000000;;		cfg.gidMax = defaultGidMax
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		authEnabled := true
0000000000000000000000000000000000000000;;		parseVolumeType := ""
0000000000000000000000000000000000000000;;		for k, v := range params {
0000000000000000000000000000000000000000;;			switch dstrings.ToLower(k) {
0000000000000000000000000000000000000000;;			case "resturl":
0000000000000000000000000000000000000000;;				cfg.url = v
0000000000000000000000000000000000000000;;			case "restuser":
0000000000000000000000000000000000000000;;				cfg.user = v
0000000000000000000000000000000000000000;;			case "restuserkey":
0000000000000000000000000000000000000000;;				cfg.userKey = v
0000000000000000000000000000000000000000;;			case "secretname":
0000000000000000000000000000000000000000;;				cfg.secretName = v
0000000000000000000000000000000000000000;;			case "secretnamespace":
0000000000000000000000000000000000000000;;				cfg.secretNamespace = v
0000000000000000000000000000000000000000;;			case "clusterid":
0000000000000000000000000000000000000000;;				if len(v) != 0 {
0000000000000000000000000000000000000000;;					cfg.clusterID = v
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			case "restauthenabled":
0000000000000000000000000000000000000000;;				authEnabled = dstrings.ToLower(v) == "true"
0000000000000000000000000000000000000000;;			case "gidmin":
0000000000000000000000000000000000000000;;				parseGidMin, err := convertGid(v)
0000000000000000000000000000000000000000;;				if err != nil {
0000000000000000000000000000000000000000;;					return nil, fmt.Errorf("glusterfs: invalid value %q for volume plugin %s", k, glusterfsPluginName)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				if parseGidMin < absoluteGidMin {
0000000000000000000000000000000000000000;;					return nil, fmt.Errorf("glusterfs: gidMin must be >= %v", absoluteGidMin)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				if parseGidMin > absoluteGidMax {
0000000000000000000000000000000000000000;;					return nil, fmt.Errorf("glusterfs: gidMin must be <= %v", absoluteGidMax)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				cfg.gidMin = parseGidMin
0000000000000000000000000000000000000000;;			case "gidmax":
0000000000000000000000000000000000000000;;				parseGidMax, err := convertGid(v)
0000000000000000000000000000000000000000;;				if err != nil {
0000000000000000000000000000000000000000;;					return nil, fmt.Errorf("glusterfs: invalid value %q for volume plugin %s", k, glusterfsPluginName)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				if parseGidMax < absoluteGidMin {
0000000000000000000000000000000000000000;;					return nil, fmt.Errorf("glusterfs: gidMax must be >= %v", absoluteGidMin)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				if parseGidMax > absoluteGidMax {
0000000000000000000000000000000000000000;;					return nil, fmt.Errorf("glusterfs: gidMax must be <= %v", absoluteGidMax)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				cfg.gidMax = parseGidMax
0000000000000000000000000000000000000000;;			case "volumetype":
0000000000000000000000000000000000000000;;				parseVolumeType = v
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			default:
0000000000000000000000000000000000000000;;				return nil, fmt.Errorf("glusterfs: invalid option %q for volume plugin %s", k, glusterfsPluginName)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if len(cfg.url) == 0 {
0000000000000000000000000000000000000000;;			return nil, fmt.Errorf("StorageClass for provisioner %s must contain 'resturl' parameter", glusterfsPluginName)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if len(parseVolumeType) == 0 {
0000000000000000000000000000000000000000;;			cfg.volumeType = gapi.VolumeDurabilityInfo{Type: gapi.DurabilityReplicate, Replicate: gapi.ReplicaDurability{Replica: replicaCount}}
0000000000000000000000000000000000000000;;		} else {
0000000000000000000000000000000000000000;;			parseVolumeTypeInfo := dstrings.Split(parseVolumeType, ":")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			switch parseVolumeTypeInfo[0] {
0000000000000000000000000000000000000000;;			case "replicate":
0000000000000000000000000000000000000000;;				if len(parseVolumeTypeInfo) >= 2 {
0000000000000000000000000000000000000000;;					newReplicaCount, err := convertVolumeParam(parseVolumeTypeInfo[1])
0000000000000000000000000000000000000000;;					if err != nil {
0000000000000000000000000000000000000000;;						return nil, fmt.Errorf("error [%v] when parsing value %q of option '%s' for volume plugin %s", err, parseVolumeTypeInfo[1], "volumetype", glusterfsPluginName)
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					cfg.volumeType = gapi.VolumeDurabilityInfo{Type: gapi.DurabilityReplicate, Replicate: gapi.ReplicaDurability{Replica: newReplicaCount}}
0000000000000000000000000000000000000000;;				} else {
0000000000000000000000000000000000000000;;					cfg.volumeType = gapi.VolumeDurabilityInfo{Type: gapi.DurabilityReplicate, Replicate: gapi.ReplicaDurability{Replica: replicaCount}}
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			case "disperse":
0000000000000000000000000000000000000000;;				if len(parseVolumeTypeInfo) >= 3 {
0000000000000000000000000000000000000000;;					newDisperseData, err := convertVolumeParam(parseVolumeTypeInfo[1])
0000000000000000000000000000000000000000;;					if err != nil {
0000000000000000000000000000000000000000;;						return nil, fmt.Errorf("error [%v] when parsing value %q of option '%s' for volume plugin %s", parseVolumeTypeInfo[1], err, "volumetype", glusterfsPluginName)
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					newDisperseRedundancy, err := convertVolumeParam(parseVolumeTypeInfo[2])
0000000000000000000000000000000000000000;;					if err != nil {
0000000000000000000000000000000000000000;;						return nil, fmt.Errorf("error [%v] when parsing value %q of option '%s' for volume plugin %s", err, parseVolumeTypeInfo[2], "volumetype", glusterfsPluginName)
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					cfg.volumeType = gapi.VolumeDurabilityInfo{Type: gapi.DurabilityEC, Disperse: gapi.DisperseDurability{Data: newDisperseData, Redundancy: newDisperseRedundancy}}
0000000000000000000000000000000000000000;;				} else {
0000000000000000000000000000000000000000;;					return nil, fmt.Errorf("StorageClass for provisioner %q must have data:redundancy count set for disperse volumes in storage class option '%s'", glusterfsPluginName, "volumetype")
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			case "none":
0000000000000000000000000000000000000000;;				cfg.volumeType = gapi.VolumeDurabilityInfo{Type: gapi.DurabilityDistributeOnly}
0000000000000000000000000000000000000000;;			default:
0000000000000000000000000000000000000000;;				return nil, fmt.Errorf("error parsing value for option 'volumetype' for volume plugin %s", glusterfsPluginName)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if !authEnabled {
0000000000000000000000000000000000000000;;			cfg.user = ""
0000000000000000000000000000000000000000;;			cfg.secretName = ""
0000000000000000000000000000000000000000;;			cfg.secretNamespace = ""
0000000000000000000000000000000000000000;;			cfg.userKey = ""
0000000000000000000000000000000000000000;;			cfg.secretValue = ""
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if len(cfg.secretName) != 0 || len(cfg.secretNamespace) != 0 {
0000000000000000000000000000000000000000;;			// secretName + Namespace has precedence over userKey
0000000000000000000000000000000000000000;;			if len(cfg.secretName) != 0 && len(cfg.secretNamespace) != 0 {
0000000000000000000000000000000000000000;;				cfg.secretValue, err = parseSecret(cfg.secretNamespace, cfg.secretName, kubeClient)
0000000000000000000000000000000000000000;;				if err != nil {
0000000000000000000000000000000000000000;;					return nil, err
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				return nil, fmt.Errorf("StorageClass for provisioner %q must have secretNamespace and secretName either both set or both empty", glusterfsPluginName)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		} else {
0000000000000000000000000000000000000000;;			cfg.secretValue = cfg.userKey
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if cfg.gidMin > cfg.gidMax {
0000000000000000000000000000000000000000;;			return nil, fmt.Errorf("StorageClass for provisioner %q must have gidMax value >= gidMin", glusterfsPluginName)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return &cfg, nil
0000000000000000000000000000000000000000;;	}
