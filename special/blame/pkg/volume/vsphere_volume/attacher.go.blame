0000000000000000000000000000000000000000;;	/*
0000000000000000000000000000000000000000;;	Copyright 2016 The Kubernetes Authors.
9eb4d432b448d169e4f7ec0574876a0c4254faf2;;	
0000000000000000000000000000000000000000;;	Licensed under the Apache License, Version 2.0 (the "License");
0000000000000000000000000000000000000000;;	you may not use this file except in compliance with the License.
0000000000000000000000000000000000000000;;	You may obtain a copy of the License at
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	    http://www.apache.org/licenses/LICENSE-2.0
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	Unless required by applicable law or agreed to in writing, software
0000000000000000000000000000000000000000;;	distributed under the License is distributed on an "AS IS" BASIS,
0000000000000000000000000000000000000000;;	WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
0000000000000000000000000000000000000000;;	See the License for the specific language governing permissions and
0000000000000000000000000000000000000000;;	limitations under the License.
0000000000000000000000000000000000000000;;	*/
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	package vsphere_volume
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	import (
0000000000000000000000000000000000000000;;		"fmt"
0000000000000000000000000000000000000000;;		"os"
0000000000000000000000000000000000000000;;		"path"
0000000000000000000000000000000000000000;;		"time"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		"github.com/golang/glog"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/types"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/cloudprovider/providers/vsphere"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/util/exec"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/util/keymutex"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/util/mount"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/volume"
0000000000000000000000000000000000000000;;		volumeutil "k8s.io/kubernetes/pkg/volume/util"
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type vsphereVMDKAttacher struct {
0000000000000000000000000000000000000000;;		host           volume.VolumeHost
0000000000000000000000000000000000000000;;		vsphereVolumes vsphere.Volumes
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	var _ volume.Attacher = &vsphereVMDKAttacher{}
0000000000000000000000000000000000000000;;	var _ volume.AttachableVolumePlugin = &vsphereVolumePlugin{}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Singleton key mutex for keeping attach operations for the same host atomic
0000000000000000000000000000000000000000;;	var attachdetachMutex = keymutex.NewKeyMutex()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (plugin *vsphereVolumePlugin) NewAttacher() (volume.Attacher, error) {
0000000000000000000000000000000000000000;;		vsphereCloud, err := getCloudProvider(plugin.host.GetCloudProvider())
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return nil, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return &vsphereVMDKAttacher{
0000000000000000000000000000000000000000;;			host:           plugin.host,
0000000000000000000000000000000000000000;;			vsphereVolumes: vsphereCloud,
0000000000000000000000000000000000000000;;		}, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Attaches the volume specified by the given spec to the given host.
0000000000000000000000000000000000000000;;	// On success, returns the device path where the device was attached on the
0000000000000000000000000000000000000000;;	// node.
0000000000000000000000000000000000000000;;	// Callers are responsible for retryinging on failure.
0000000000000000000000000000000000000000;;	// Callers are responsible for thread safety between concurrent attach and
0000000000000000000000000000000000000000;;	// detach operations.
0000000000000000000000000000000000000000;;	func (attacher *vsphereVMDKAttacher) Attach(spec *volume.Spec, nodeName types.NodeName) (string, error) {
0000000000000000000000000000000000000000;;		volumeSource, _, err := getVolumeSource(spec)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return "", err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		glog.V(4).Infof("vSphere: Attach disk called for node %s", nodeName)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Keeps concurrent attach operations to same host atomic
0000000000000000000000000000000000000000;;		attachdetachMutex.LockKey(string(nodeName))
0000000000000000000000000000000000000000;;		defer attachdetachMutex.UnlockKey(string(nodeName))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// vsphereCloud.AttachDisk checks if disk is already attached to host and
0000000000000000000000000000000000000000;;		// succeeds in that case, so no need to do that separately.
0000000000000000000000000000000000000000;;		_, diskUUID, err := attacher.vsphereVolumes.AttachDisk(volumeSource.VolumePath, volumeSource.StoragePolicyID, nodeName)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			glog.Errorf("Error attaching volume %q to node %q: %+v", volumeSource.VolumePath, nodeName, err)
0000000000000000000000000000000000000000;;			return "", err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return path.Join(diskByIDPath, diskSCSIPrefix+diskUUID), nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (attacher *vsphereVMDKAttacher) VolumesAreAttached(specs []*volume.Spec, nodeName types.NodeName) (map[*volume.Spec]bool, error) {
0000000000000000000000000000000000000000;;		volumesAttachedCheck := make(map[*volume.Spec]bool)
0000000000000000000000000000000000000000;;		volumeSpecMap := make(map[string]*volume.Spec)
0000000000000000000000000000000000000000;;		volumePathList := []string{}
0000000000000000000000000000000000000000;;		for _, spec := range specs {
0000000000000000000000000000000000000000;;			volumeSource, _, err := getVolumeSource(spec)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				glog.Errorf("Error getting volume (%q) source : %v", spec.Name(), err)
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			volumePathList = append(volumePathList, volumeSource.VolumePath)
0000000000000000000000000000000000000000;;			volumeSpecMap[volumeSource.VolumePath] = spec
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		attachedResult, err := attacher.vsphereVolumes.DisksAreAttached(volumePathList, nodeName)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			glog.Errorf(
0000000000000000000000000000000000000000;;				"Error checking if volumes (%v) are attached to current node (%q). err=%v",
0000000000000000000000000000000000000000;;				volumePathList, nodeName, err)
0000000000000000000000000000000000000000;;			return nil, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		for volumePath, attached := range attachedResult {
0000000000000000000000000000000000000000;;			spec := volumeSpecMap[volumePath]
0000000000000000000000000000000000000000;;			if !attached {
0000000000000000000000000000000000000000;;				volumesAttachedCheck[spec] = false
0000000000000000000000000000000000000000;;				glog.V(2).Infof("VolumesAreAttached: volume %q (specName: %q) is no longer attached", volumePath, spec.Name())
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				volumesAttachedCheck[spec] = true
0000000000000000000000000000000000000000;;				glog.V(2).Infof("VolumesAreAttached: volume %q (specName: %q) is attached", volumePath, spec.Name())
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return volumesAttachedCheck, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (attacher *vsphereVMDKAttacher) WaitForAttach(spec *volume.Spec, devicePath string, timeout time.Duration) (string, error) {
0000000000000000000000000000000000000000;;		volumeSource, _, err := getVolumeSource(spec)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return "", err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if devicePath == "" {
0000000000000000000000000000000000000000;;			return "", fmt.Errorf("WaitForAttach failed for VMDK %q: devicePath is empty.", volumeSource.VolumePath)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		ticker := time.NewTicker(checkSleepDuration)
0000000000000000000000000000000000000000;;		defer ticker.Stop()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		timer := time.NewTimer(timeout)
0000000000000000000000000000000000000000;;		defer timer.Stop()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		for {
0000000000000000000000000000000000000000;;			select {
0000000000000000000000000000000000000000;;			case <-ticker.C:
0000000000000000000000000000000000000000;;				glog.V(5).Infof("Checking VMDK %q is attached", volumeSource.VolumePath)
0000000000000000000000000000000000000000;;				path, err := verifyDevicePath(devicePath)
0000000000000000000000000000000000000000;;				if err != nil {
0000000000000000000000000000000000000000;;					// Log error, if any, and continue checking periodically. See issue #11321
0000000000000000000000000000000000000000;;					glog.Warningf("Error verifying VMDK (%q) is attached: %v", volumeSource.VolumePath, err)
0000000000000000000000000000000000000000;;				} else if path != "" {
0000000000000000000000000000000000000000;;					// A device path has successfully been created for the VMDK
0000000000000000000000000000000000000000;;					glog.Infof("Successfully found attached VMDK %q.", volumeSource.VolumePath)
0000000000000000000000000000000000000000;;					return path, nil
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			case <-timer.C:
0000000000000000000000000000000000000000;;				return "", fmt.Errorf("Could not find attached VMDK %q. Timeout waiting for mount paths to be created.", volumeSource.VolumePath)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// GetDeviceMountPath returns a path where the device should
0000000000000000000000000000000000000000;;	// point which should be bind mounted for individual volumes.
0000000000000000000000000000000000000000;;	func (attacher *vsphereVMDKAttacher) GetDeviceMountPath(spec *volume.Spec) (string, error) {
0000000000000000000000000000000000000000;;		volumeSource, _, err := getVolumeSource(spec)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return "", err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return makeGlobalPDPath(attacher.host, volumeSource.VolumePath), nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// GetMountDeviceRefs finds all other references to the device referenced
0000000000000000000000000000000000000000;;	// by deviceMountPath; returns a list of paths.
0000000000000000000000000000000000000000;;	func (plugin *vsphereVolumePlugin) GetDeviceMountRefs(deviceMountPath string) ([]string, error) {
0000000000000000000000000000000000000000;;		mounter := plugin.host.GetMounter()
0000000000000000000000000000000000000000;;		return mount.GetMountRefs(mounter, deviceMountPath)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// MountDevice mounts device to global mount point.
0000000000000000000000000000000000000000;;	func (attacher *vsphereVMDKAttacher) MountDevice(spec *volume.Spec, devicePath string, deviceMountPath string) error {
0000000000000000000000000000000000000000;;		mounter := attacher.host.GetMounter()
0000000000000000000000000000000000000000;;		notMnt, err := mounter.IsLikelyNotMountPoint(deviceMountPath)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			if os.IsNotExist(err) {
0000000000000000000000000000000000000000;;				if err := os.MkdirAll(deviceMountPath, 0750); err != nil {
0000000000000000000000000000000000000000;;					glog.Errorf("Failed to create directory at %#v. err: %s", deviceMountPath, err)
0000000000000000000000000000000000000000;;					return err
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				notMnt = true
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				return err
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		volumeSource, _, err := getVolumeSource(spec)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		options := []string{}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if notMnt {
0000000000000000000000000000000000000000;;			diskMounter := &mount.SafeFormatAndMount{Interface: mounter, Runner: exec.New()}
0000000000000000000000000000000000000000;;			mountOptions := volume.MountOptionFromSpec(spec, options...)
0000000000000000000000000000000000000000;;			err = diskMounter.FormatAndMount(devicePath, deviceMountPath, volumeSource.FSType, mountOptions)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				os.Remove(deviceMountPath)
0000000000000000000000000000000000000000;;				return err
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			glog.V(4).Infof("formatting spec %v devicePath %v deviceMountPath %v fs %v with options %+v", spec.Name(), devicePath, deviceMountPath, volumeSource.FSType, options)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type vsphereVMDKDetacher struct {
0000000000000000000000000000000000000000;;		mounter        mount.Interface
0000000000000000000000000000000000000000;;		vsphereVolumes vsphere.Volumes
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	var _ volume.Detacher = &vsphereVMDKDetacher{}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (plugin *vsphereVolumePlugin) NewDetacher() (volume.Detacher, error) {
0000000000000000000000000000000000000000;;		vsphereCloud, err := getCloudProvider(plugin.host.GetCloudProvider())
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return nil, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return &vsphereVMDKDetacher{
0000000000000000000000000000000000000000;;			mounter:        plugin.host.GetMounter(),
0000000000000000000000000000000000000000;;			vsphereVolumes: vsphereCloud,
0000000000000000000000000000000000000000;;		}, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Detach the given device from the given node.
0000000000000000000000000000000000000000;;	func (detacher *vsphereVMDKDetacher) Detach(deviceMountPath string, nodeName types.NodeName) error {
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		volPath := getVolPathfromDeviceMountPath(deviceMountPath)
0000000000000000000000000000000000000000;;		attached, err := detacher.vsphereVolumes.DiskIsAttached(volPath, nodeName)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			// Log error and continue with detach
0000000000000000000000000000000000000000;;			glog.Errorf(
0000000000000000000000000000000000000000;;				"Error checking if volume (%q) is already attached to current node (%q). Will continue and try detach anyway. err=%v",
0000000000000000000000000000000000000000;;				volPath, nodeName, err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if err == nil && !attached {
0000000000000000000000000000000000000000;;			// Volume is already detached from node.
0000000000000000000000000000000000000000;;			glog.Infof("detach operation was successful. volume %q is already detached from node %q.", volPath, nodeName)
0000000000000000000000000000000000000000;;			return nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		attachdetachMutex.LockKey(string(nodeName))
0000000000000000000000000000000000000000;;		defer attachdetachMutex.UnlockKey(string(nodeName))
0000000000000000000000000000000000000000;;		if err := detacher.vsphereVolumes.DetachDisk(volPath, nodeName); err != nil {
0000000000000000000000000000000000000000;;			glog.Errorf("Error detaching volume %q: %v", volPath, err)
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (detacher *vsphereVMDKDetacher) UnmountDevice(deviceMountPath string) error {
0000000000000000000000000000000000000000;;		return volumeutil.UnmountPath(deviceMountPath, detacher.mounter)
0000000000000000000000000000000000000000;;	}
