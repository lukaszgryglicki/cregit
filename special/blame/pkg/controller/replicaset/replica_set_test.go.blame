0000000000000000000000000000000000000000;;	/*
0000000000000000000000000000000000000000;;	Copyright 2016 The Kubernetes Authors.
dfb305c976fde56d31af6eebe20e295c36d5d9de;;	
0000000000000000000000000000000000000000;;	Licensed under the Apache License, Version 2.0 (the "License");
0000000000000000000000000000000000000000;;	you may not use this file except in compliance with the License.
0000000000000000000000000000000000000000;;	You may obtain a copy of the License at
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	    http://www.apache.org/licenses/LICENSE-2.0
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	Unless required by applicable law or agreed to in writing, software
0000000000000000000000000000000000000000;;	distributed under the License is distributed on an "AS IS" BASIS,
0000000000000000000000000000000000000000;;	WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
0000000000000000000000000000000000000000;;	See the License for the specific language governing permissions and
0000000000000000000000000000000000000000;;	limitations under the License.
0000000000000000000000000000000000000000;;	*/
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// If you make changes to this file, you should also make the corresponding change in ReplicationController.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	package replicaset
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	import (
0000000000000000000000000000000000000000;;		"errors"
0000000000000000000000000000000000000000;;		"fmt"
0000000000000000000000000000000000000000;;		"math/rand"
0000000000000000000000000000000000000000;;		"net/http/httptest"
0000000000000000000000000000000000000000;;		"net/url"
0000000000000000000000000000000000000000;;		"reflect"
0000000000000000000000000000000000000000;;		"strings"
0000000000000000000000000000000000000000;;		"testing"
0000000000000000000000000000000000000000;;		"time"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		"k8s.io/api/core/v1"
0000000000000000000000000000000000000000;;		extensions "k8s.io/api/extensions/v1beta1"
0000000000000000000000000000000000000000;;		apiequality "k8s.io/apimachinery/pkg/api/equality"
0000000000000000000000000000000000000000;;		metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/runtime"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/util/sets"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/util/uuid"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/util/wait"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/watch"
0000000000000000000000000000000000000000;;		restclient "k8s.io/client-go/rest"
0000000000000000000000000000000000000000;;		core "k8s.io/client-go/testing"
0000000000000000000000000000000000000000;;		"k8s.io/client-go/tools/cache"
0000000000000000000000000000000000000000;;		utiltesting "k8s.io/client-go/util/testing"
0000000000000000000000000000000000000000;;		"k8s.io/client-go/util/workqueue"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/api"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/api/testapi"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/client/clientset_generated/clientset"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/client/clientset_generated/clientset/fake"
0000000000000000000000000000000000000000;;		fakeclientset "k8s.io/kubernetes/pkg/client/clientset_generated/clientset/fake"
0000000000000000000000000000000000000000;;		informers "k8s.io/kubernetes/pkg/client/informers/informers_generated/externalversions"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/controller"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/securitycontext"
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func testNewReplicaSetControllerFromClient(client clientset.Interface, stopCh chan struct{}, burstReplicas int) (*ReplicaSetController, informers.SharedInformerFactory) {
0000000000000000000000000000000000000000;;		informers := informers.NewSharedInformerFactory(client, controller.NoResyncPeriodFunc())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		ret := NewReplicaSetController(
0000000000000000000000000000000000000000;;			informers.Extensions().V1beta1().ReplicaSets(),
0000000000000000000000000000000000000000;;			informers.Core().V1().Pods(),
0000000000000000000000000000000000000000;;			client,
0000000000000000000000000000000000000000;;			burstReplicas,
0000000000000000000000000000000000000000;;		)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		ret.podListerSynced = alwaysReady
0000000000000000000000000000000000000000;;		ret.rsListerSynced = alwaysReady
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return ret, informers
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func filterInformerActions(actions []core.Action) []core.Action {
0000000000000000000000000000000000000000;;		ret := []core.Action{}
0000000000000000000000000000000000000000;;		for _, action := range actions {
0000000000000000000000000000000000000000;;			if len(action.GetNamespace()) == 0 &&
0000000000000000000000000000000000000000;;				(action.Matches("list", "pods") ||
0000000000000000000000000000000000000000;;					action.Matches("list", "replicasets") ||
0000000000000000000000000000000000000000;;					action.Matches("watch", "pods") ||
0000000000000000000000000000000000000000;;					action.Matches("watch", "replicasets")) {
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			ret = append(ret, action)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return ret
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func skipListerFunc(verb string, url url.URL) bool {
0000000000000000000000000000000000000000;;		if verb != "GET" {
0000000000000000000000000000000000000000;;			return false
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if strings.HasSuffix(url.Path, "/pods") || strings.Contains(url.Path, "/replicasets") {
0000000000000000000000000000000000000000;;			return true
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return false
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	var alwaysReady = func() bool { return true }
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func getKey(rs *extensions.ReplicaSet, t *testing.T) string {
0000000000000000000000000000000000000000;;		if key, err := controller.KeyFunc(rs); err != nil {
0000000000000000000000000000000000000000;;			t.Errorf("Unexpected error getting key for ReplicaSet %v: %v", rs.Name, err)
0000000000000000000000000000000000000000;;			return ""
0000000000000000000000000000000000000000;;		} else {
0000000000000000000000000000000000000000;;			return key
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func newReplicaSet(replicas int, selectorMap map[string]string) *extensions.ReplicaSet {
0000000000000000000000000000000000000000;;		rs := &extensions.ReplicaSet{
0000000000000000000000000000000000000000;;			TypeMeta: metav1.TypeMeta{APIVersion: api.Registry.GroupOrDie(v1.GroupName).GroupVersion.String()},
0000000000000000000000000000000000000000;;			ObjectMeta: metav1.ObjectMeta{
0000000000000000000000000000000000000000;;				UID:             uuid.NewUUID(),
0000000000000000000000000000000000000000;;				Name:            "foobar",
0000000000000000000000000000000000000000;;				Namespace:       metav1.NamespaceDefault,
0000000000000000000000000000000000000000;;				ResourceVersion: "18",
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			Spec: extensions.ReplicaSetSpec{
0000000000000000000000000000000000000000;;				Replicas: func() *int32 { i := int32(replicas); return &i }(),
0000000000000000000000000000000000000000;;				Selector: &metav1.LabelSelector{MatchLabels: selectorMap},
0000000000000000000000000000000000000000;;				Template: v1.PodTemplateSpec{
0000000000000000000000000000000000000000;;					ObjectMeta: metav1.ObjectMeta{
0000000000000000000000000000000000000000;;						Labels: map[string]string{
0000000000000000000000000000000000000000;;							"name": "foo",
0000000000000000000000000000000000000000;;							"type": "production",
0000000000000000000000000000000000000000;;						},
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;					Spec: v1.PodSpec{
0000000000000000000000000000000000000000;;						Containers: []v1.Container{
0000000000000000000000000000000000000000;;							{
0000000000000000000000000000000000000000;;								Image: "foo/bar",
0000000000000000000000000000000000000000;;								TerminationMessagePath: v1.TerminationMessagePathDefault,
0000000000000000000000000000000000000000;;								ImagePullPolicy:        v1.PullIfNotPresent,
0000000000000000000000000000000000000000;;								SecurityContext:        securitycontext.ValidSecurityContextWithContainerDefaults(),
0000000000000000000000000000000000000000;;							},
0000000000000000000000000000000000000000;;						},
0000000000000000000000000000000000000000;;						RestartPolicy: v1.RestartPolicyAlways,
0000000000000000000000000000000000000000;;						DNSPolicy:     v1.DNSDefault,
0000000000000000000000000000000000000000;;						NodeSelector: map[string]string{
0000000000000000000000000000000000000000;;							"baz": "blah",
0000000000000000000000000000000000000000;;						},
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return rs
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// create a pod with the given phase for the given rs (same selectors and namespace)
0000000000000000000000000000000000000000;;	func newPod(name string, rs *extensions.ReplicaSet, status v1.PodPhase, lastTransitionTime *metav1.Time, properlyOwned bool) *v1.Pod {
0000000000000000000000000000000000000000;;		var conditions []v1.PodCondition
0000000000000000000000000000000000000000;;		if status == v1.PodRunning {
0000000000000000000000000000000000000000;;			condition := v1.PodCondition{Type: v1.PodReady, Status: v1.ConditionTrue}
0000000000000000000000000000000000000000;;			if lastTransitionTime != nil {
0000000000000000000000000000000000000000;;				condition.LastTransitionTime = *lastTransitionTime
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			conditions = append(conditions, condition)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		var controllerReference metav1.OwnerReference
0000000000000000000000000000000000000000;;		if properlyOwned {
0000000000000000000000000000000000000000;;			var trueVar = true
0000000000000000000000000000000000000000;;			controllerReference = metav1.OwnerReference{UID: rs.UID, APIVersion: "v1beta1", Kind: "ReplicaSet", Name: rs.Name, Controller: &trueVar}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return &v1.Pod{
0000000000000000000000000000000000000000;;			ObjectMeta: metav1.ObjectMeta{
0000000000000000000000000000000000000000;;				Name:            name,
0000000000000000000000000000000000000000;;				Namespace:       rs.Namespace,
0000000000000000000000000000000000000000;;				Labels:          rs.Spec.Selector.MatchLabels,
0000000000000000000000000000000000000000;;				OwnerReferences: []metav1.OwnerReference{controllerReference},
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			Status: v1.PodStatus{Phase: status, Conditions: conditions},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// create count pods with the given phase for the given ReplicaSet (same selectors and namespace), and add them to the store.
0000000000000000000000000000000000000000;;	func newPodList(store cache.Store, count int, status v1.PodPhase, labelMap map[string]string, rs *extensions.ReplicaSet, name string) *v1.PodList {
0000000000000000000000000000000000000000;;		pods := []v1.Pod{}
0000000000000000000000000000000000000000;;		var trueVar = true
0000000000000000000000000000000000000000;;		controllerReference := metav1.OwnerReference{UID: rs.UID, APIVersion: "v1beta1", Kind: "ReplicaSet", Name: rs.Name, Controller: &trueVar}
0000000000000000000000000000000000000000;;		for i := 0; i < count; i++ {
0000000000000000000000000000000000000000;;			pod := newPod(fmt.Sprintf("%s%d", name, i), rs, status, nil, false)
0000000000000000000000000000000000000000;;			pod.ObjectMeta.Labels = labelMap
0000000000000000000000000000000000000000;;			pod.OwnerReferences = []metav1.OwnerReference{controllerReference}
0000000000000000000000000000000000000000;;			if store != nil {
0000000000000000000000000000000000000000;;				store.Add(pod)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			pods = append(pods, *pod)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return &v1.PodList{
0000000000000000000000000000000000000000;;			Items: pods,
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// processSync initiates a sync via processNextWorkItem() to test behavior that
0000000000000000000000000000000000000000;;	// depends on both functions (such as re-queueing on sync error).
0000000000000000000000000000000000000000;;	func processSync(rsc *ReplicaSetController, key string) error {
0000000000000000000000000000000000000000;;		// Save old syncHandler and replace with one that captures the error.
0000000000000000000000000000000000000000;;		oldSyncHandler := rsc.syncHandler
0000000000000000000000000000000000000000;;		defer func() {
0000000000000000000000000000000000000000;;			rsc.syncHandler = oldSyncHandler
0000000000000000000000000000000000000000;;		}()
0000000000000000000000000000000000000000;;		var syncErr error
0000000000000000000000000000000000000000;;		rsc.syncHandler = func(key string) error {
0000000000000000000000000000000000000000;;			syncErr = oldSyncHandler(key)
0000000000000000000000000000000000000000;;			return syncErr
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		rsc.queue.Add(key)
0000000000000000000000000000000000000000;;		rsc.processNextWorkItem()
0000000000000000000000000000000000000000;;		return syncErr
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func validateSyncReplicaSet(t *testing.T, fakePodControl *controller.FakePodControl, expectedCreates, expectedDeletes, expectedPatches int) {
0000000000000000000000000000000000000000;;		if e, a := expectedCreates, len(fakePodControl.Templates); e != a {
0000000000000000000000000000000000000000;;			t.Errorf("Unexpected number of creates.  Expected %d, saw %d\n", e, a)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if e, a := expectedDeletes, len(fakePodControl.DeletePodName); e != a {
0000000000000000000000000000000000000000;;			t.Errorf("Unexpected number of deletes.  Expected %d, saw %d\n", e, a)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if e, a := expectedPatches, len(fakePodControl.Patches); e != a {
0000000000000000000000000000000000000000;;			t.Errorf("Unexpected number of patches.  Expected %d, saw %d\n", e, a)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func replicaSetResourceName() string {
0000000000000000000000000000000000000000;;		return "replicasets"
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type serverResponse struct {
0000000000000000000000000000000000000000;;		statusCode int
0000000000000000000000000000000000000000;;		obj        interface{}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestSyncReplicaSetDoesNothing(t *testing.T) {
0000000000000000000000000000000000000000;;		client := clientset.NewForConfigOrDie(&restclient.Config{Host: "", ContentConfig: restclient.ContentConfig{GroupVersion: &api.Registry.GroupOrDie(v1.GroupName).GroupVersion}})
0000000000000000000000000000000000000000;;		fakePodControl := controller.FakePodControl{}
0000000000000000000000000000000000000000;;		stopCh := make(chan struct{})
0000000000000000000000000000000000000000;;		defer close(stopCh)
0000000000000000000000000000000000000000;;		manager, informers := testNewReplicaSetControllerFromClient(client, stopCh, BurstReplicas)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// 2 running pods, a controller with 2 replicas, sync is a no-op
0000000000000000000000000000000000000000;;		labelMap := map[string]string{"foo": "bar"}
0000000000000000000000000000000000000000;;		rsSpec := newReplicaSet(2, labelMap)
0000000000000000000000000000000000000000;;		informers.Extensions().V1beta1().ReplicaSets().Informer().GetIndexer().Add(rsSpec)
0000000000000000000000000000000000000000;;		newPodList(informers.Core().V1().Pods().Informer().GetIndexer(), 2, v1.PodRunning, labelMap, rsSpec, "pod")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		manager.podControl = &fakePodControl
0000000000000000000000000000000000000000;;		manager.syncReplicaSet(getKey(rsSpec, t))
0000000000000000000000000000000000000000;;		validateSyncReplicaSet(t, &fakePodControl, 0, 0, 0)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestSyncReplicaSetDeletes(t *testing.T) {
0000000000000000000000000000000000000000;;		labelMap := map[string]string{"foo": "bar"}
0000000000000000000000000000000000000000;;		rsSpec := newReplicaSet(1, labelMap)
0000000000000000000000000000000000000000;;		client := fake.NewSimpleClientset(rsSpec)
0000000000000000000000000000000000000000;;		fakePodControl := controller.FakePodControl{}
0000000000000000000000000000000000000000;;		stopCh := make(chan struct{})
0000000000000000000000000000000000000000;;		defer close(stopCh)
0000000000000000000000000000000000000000;;		manager, informers := testNewReplicaSetControllerFromClient(client, stopCh, BurstReplicas)
0000000000000000000000000000000000000000;;		manager.podControl = &fakePodControl
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// 2 running pods and a controller with 1 replica, one pod delete expected
0000000000000000000000000000000000000000;;		informers.Extensions().V1beta1().ReplicaSets().Informer().GetIndexer().Add(rsSpec)
0000000000000000000000000000000000000000;;		newPodList(informers.Core().V1().Pods().Informer().GetIndexer(), 2, v1.PodRunning, labelMap, rsSpec, "pod")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		manager.syncReplicaSet(getKey(rsSpec, t))
0000000000000000000000000000000000000000;;		validateSyncReplicaSet(t, &fakePodControl, 0, 1, 0)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestDeleteFinalStateUnknown(t *testing.T) {
0000000000000000000000000000000000000000;;		client := clientset.NewForConfigOrDie(&restclient.Config{Host: "", ContentConfig: restclient.ContentConfig{GroupVersion: &api.Registry.GroupOrDie(v1.GroupName).GroupVersion}})
0000000000000000000000000000000000000000;;		fakePodControl := controller.FakePodControl{}
0000000000000000000000000000000000000000;;		stopCh := make(chan struct{})
0000000000000000000000000000000000000000;;		defer close(stopCh)
0000000000000000000000000000000000000000;;		manager, informers := testNewReplicaSetControllerFromClient(client, stopCh, BurstReplicas)
0000000000000000000000000000000000000000;;		manager.podControl = &fakePodControl
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		received := make(chan string)
0000000000000000000000000000000000000000;;		manager.syncHandler = func(key string) error {
0000000000000000000000000000000000000000;;			received <- key
0000000000000000000000000000000000000000;;			return nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// The DeletedFinalStateUnknown object should cause the ReplicaSet manager to insert
0000000000000000000000000000000000000000;;		// the controller matching the selectors of the deleted pod into the work queue.
0000000000000000000000000000000000000000;;		labelMap := map[string]string{"foo": "bar"}
0000000000000000000000000000000000000000;;		rsSpec := newReplicaSet(1, labelMap)
0000000000000000000000000000000000000000;;		informers.Extensions().V1beta1().ReplicaSets().Informer().GetIndexer().Add(rsSpec)
0000000000000000000000000000000000000000;;		pods := newPodList(nil, 1, v1.PodRunning, labelMap, rsSpec, "pod")
0000000000000000000000000000000000000000;;		manager.deletePod(cache.DeletedFinalStateUnknown{Key: "foo", Obj: &pods.Items[0]})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		go manager.worker()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		expected := getKey(rsSpec, t)
0000000000000000000000000000000000000000;;		select {
0000000000000000000000000000000000000000;;		case key := <-received:
0000000000000000000000000000000000000000;;			if key != expected {
0000000000000000000000000000000000000000;;				t.Errorf("Unexpected sync all for ReplicaSet %v, expected %v", key, expected)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		case <-time.After(wait.ForeverTestTimeout):
0000000000000000000000000000000000000000;;			t.Errorf("Processing DeleteFinalStateUnknown took longer than expected")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestSyncReplicaSetCreates(t *testing.T) {
0000000000000000000000000000000000000000;;		labelMap := map[string]string{"foo": "bar"}
0000000000000000000000000000000000000000;;		rs := newReplicaSet(2, labelMap)
0000000000000000000000000000000000000000;;		client := fake.NewSimpleClientset(rs)
0000000000000000000000000000000000000000;;		stopCh := make(chan struct{})
0000000000000000000000000000000000000000;;		defer close(stopCh)
0000000000000000000000000000000000000000;;		manager, informers := testNewReplicaSetControllerFromClient(client, stopCh, BurstReplicas)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// A controller with 2 replicas and no active pods in the store.
0000000000000000000000000000000000000000;;		// Inactive pods should be ignored. 2 creates expected.
0000000000000000000000000000000000000000;;		informers.Extensions().V1beta1().ReplicaSets().Informer().GetIndexer().Add(rs)
0000000000000000000000000000000000000000;;		failedPod := newPod("failed-pod", rs, v1.PodFailed, nil, true)
0000000000000000000000000000000000000000;;		deletedPod := newPod("deleted-pod", rs, v1.PodRunning, nil, true)
0000000000000000000000000000000000000000;;		deletedPod.DeletionTimestamp = &metav1.Time{Time: time.Now()}
0000000000000000000000000000000000000000;;		informers.Core().V1().Pods().Informer().GetIndexer().Add(failedPod)
0000000000000000000000000000000000000000;;		informers.Core().V1().Pods().Informer().GetIndexer().Add(deletedPod)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		fakePodControl := controller.FakePodControl{}
0000000000000000000000000000000000000000;;		manager.podControl = &fakePodControl
0000000000000000000000000000000000000000;;		manager.syncReplicaSet(getKey(rs, t))
0000000000000000000000000000000000000000;;		validateSyncReplicaSet(t, &fakePodControl, 2, 0, 0)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestStatusUpdatesWithoutReplicasChange(t *testing.T) {
0000000000000000000000000000000000000000;;		// Setup a fake server to listen for requests, and run the ReplicaSet controller in steady state
0000000000000000000000000000000000000000;;		fakeHandler := utiltesting.FakeHandler{
0000000000000000000000000000000000000000;;			StatusCode:    200,
0000000000000000000000000000000000000000;;			ResponseBody:  "{}",
0000000000000000000000000000000000000000;;			SkipRequestFn: skipListerFunc,
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		testServer := httptest.NewServer(&fakeHandler)
0000000000000000000000000000000000000000;;		defer testServer.Close()
0000000000000000000000000000000000000000;;		client := clientset.NewForConfigOrDie(&restclient.Config{Host: testServer.URL, ContentConfig: restclient.ContentConfig{GroupVersion: &api.Registry.GroupOrDie(v1.GroupName).GroupVersion}})
0000000000000000000000000000000000000000;;		stopCh := make(chan struct{})
0000000000000000000000000000000000000000;;		defer close(stopCh)
0000000000000000000000000000000000000000;;		manager, informers := testNewReplicaSetControllerFromClient(client, stopCh, BurstReplicas)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Steady state for the ReplicaSet, no Status.Replicas updates expected
0000000000000000000000000000000000000000;;		activePods := 5
0000000000000000000000000000000000000000;;		labelMap := map[string]string{"foo": "bar"}
0000000000000000000000000000000000000000;;		rs := newReplicaSet(activePods, labelMap)
0000000000000000000000000000000000000000;;		informers.Extensions().V1beta1().ReplicaSets().Informer().GetIndexer().Add(rs)
0000000000000000000000000000000000000000;;		rs.Status = extensions.ReplicaSetStatus{Replicas: int32(activePods), ReadyReplicas: int32(activePods), AvailableReplicas: int32(activePods)}
0000000000000000000000000000000000000000;;		newPodList(informers.Core().V1().Pods().Informer().GetIndexer(), activePods, v1.PodRunning, labelMap, rs, "pod")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		fakePodControl := controller.FakePodControl{}
0000000000000000000000000000000000000000;;		manager.podControl = &fakePodControl
0000000000000000000000000000000000000000;;		manager.syncReplicaSet(getKey(rs, t))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		validateSyncReplicaSet(t, &fakePodControl, 0, 0, 0)
0000000000000000000000000000000000000000;;		if fakeHandler.RequestReceived != nil {
0000000000000000000000000000000000000000;;			t.Errorf("Unexpected update when pods and ReplicaSets are in a steady state")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// This response body is just so we don't err out decoding the http response, all
0000000000000000000000000000000000000000;;		// we care about is the request body sent below.
0000000000000000000000000000000000000000;;		response := runtime.EncodeOrDie(testapi.Extensions.Codec(), &extensions.ReplicaSet{})
0000000000000000000000000000000000000000;;		fakeHandler.SetResponseBody(response)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		rs.Generation = rs.Generation + 1
0000000000000000000000000000000000000000;;		manager.syncReplicaSet(getKey(rs, t))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		rs.Status.ObservedGeneration = rs.Generation
0000000000000000000000000000000000000000;;		updatedRc := runtime.EncodeOrDie(testapi.Extensions.Codec(), rs)
0000000000000000000000000000000000000000;;		fakeHandler.ValidateRequest(t, testapi.Extensions.ResourcePath(replicaSetResourceName(), rs.Namespace, rs.Name)+"/status", "PUT", &updatedRc)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestControllerUpdateReplicas(t *testing.T) {
0000000000000000000000000000000000000000;;		// This is a happy server just to record the PUT request we expect for status.Replicas
0000000000000000000000000000000000000000;;		fakeHandler := utiltesting.FakeHandler{
0000000000000000000000000000000000000000;;			StatusCode:    200,
0000000000000000000000000000000000000000;;			ResponseBody:  "{}",
0000000000000000000000000000000000000000;;			SkipRequestFn: skipListerFunc,
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		testServer := httptest.NewServer(&fakeHandler)
0000000000000000000000000000000000000000;;		defer testServer.Close()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		client := clientset.NewForConfigOrDie(&restclient.Config{Host: testServer.URL, ContentConfig: restclient.ContentConfig{GroupVersion: &api.Registry.GroupOrDie(v1.GroupName).GroupVersion}})
0000000000000000000000000000000000000000;;		stopCh := make(chan struct{})
0000000000000000000000000000000000000000;;		defer close(stopCh)
0000000000000000000000000000000000000000;;		manager, informers := testNewReplicaSetControllerFromClient(client, stopCh, BurstReplicas)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Insufficient number of pods in the system, and Status.Replicas is wrong;
0000000000000000000000000000000000000000;;		// Status.Replica should update to match number of pods in system, 1 new pod should be created.
0000000000000000000000000000000000000000;;		labelMap := map[string]string{"foo": "bar"}
0000000000000000000000000000000000000000;;		extraLabelMap := map[string]string{"foo": "bar", "extraKey": "extraValue"}
0000000000000000000000000000000000000000;;		rs := newReplicaSet(5, labelMap)
0000000000000000000000000000000000000000;;		rs.Spec.Template.Labels = extraLabelMap
0000000000000000000000000000000000000000;;		informers.Extensions().V1beta1().ReplicaSets().Informer().GetIndexer().Add(rs)
0000000000000000000000000000000000000000;;		rs.Status = extensions.ReplicaSetStatus{Replicas: 2, FullyLabeledReplicas: 6, ReadyReplicas: 2, AvailableReplicas: 2, ObservedGeneration: 0}
0000000000000000000000000000000000000000;;		rs.Generation = 1
0000000000000000000000000000000000000000;;		newPodList(informers.Core().V1().Pods().Informer().GetIndexer(), 2, v1.PodRunning, labelMap, rs, "pod")
0000000000000000000000000000000000000000;;		newPodList(informers.Core().V1().Pods().Informer().GetIndexer(), 2, v1.PodRunning, extraLabelMap, rs, "podWithExtraLabel")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// This response body is just so we don't err out decoding the http response
0000000000000000000000000000000000000000;;		response := runtime.EncodeOrDie(testapi.Extensions.Codec(), &extensions.ReplicaSet{})
0000000000000000000000000000000000000000;;		fakeHandler.SetResponseBody(response)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		fakePodControl := controller.FakePodControl{}
0000000000000000000000000000000000000000;;		manager.podControl = &fakePodControl
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		manager.syncReplicaSet(getKey(rs, t))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// 1. Status.Replicas should go up from 2->4 even though we created 5-4=1 pod.
0000000000000000000000000000000000000000;;		// 2. Status.FullyLabeledReplicas should equal to the number of pods that
0000000000000000000000000000000000000000;;		// has the extra labels, i.e., 2.
0000000000000000000000000000000000000000;;		// 3. Every update to the status should include the Generation of the spec.
0000000000000000000000000000000000000000;;		rs.Status = extensions.ReplicaSetStatus{Replicas: 4, FullyLabeledReplicas: 2, ReadyReplicas: 4, AvailableReplicas: 4, ObservedGeneration: 1}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		decRc := runtime.EncodeOrDie(testapi.Extensions.Codec(), rs)
0000000000000000000000000000000000000000;;		fakeHandler.ValidateRequest(t, testapi.Extensions.ResourcePath(replicaSetResourceName(), rs.Namespace, rs.Name)+"/status", "PUT", &decRc)
0000000000000000000000000000000000000000;;		validateSyncReplicaSet(t, &fakePodControl, 1, 0, 0)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestSyncReplicaSetDormancy(t *testing.T) {
0000000000000000000000000000000000000000;;		// Setup a test server so we can lie about the current state of pods
0000000000000000000000000000000000000000;;		fakeHandler := utiltesting.FakeHandler{
0000000000000000000000000000000000000000;;			StatusCode:    200,
0000000000000000000000000000000000000000;;			ResponseBody:  "{}",
0000000000000000000000000000000000000000;;			SkipRequestFn: skipListerFunc,
0000000000000000000000000000000000000000;;			T:             t,
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		testServer := httptest.NewServer(&fakeHandler)
0000000000000000000000000000000000000000;;		defer testServer.Close()
0000000000000000000000000000000000000000;;		client := clientset.NewForConfigOrDie(&restclient.Config{Host: testServer.URL, ContentConfig: restclient.ContentConfig{GroupVersion: &api.Registry.GroupOrDie(v1.GroupName).GroupVersion}})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		fakePodControl := controller.FakePodControl{}
0000000000000000000000000000000000000000;;		stopCh := make(chan struct{})
0000000000000000000000000000000000000000;;		defer close(stopCh)
0000000000000000000000000000000000000000;;		manager, informers := testNewReplicaSetControllerFromClient(client, stopCh, BurstReplicas)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		manager.podControl = &fakePodControl
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		labelMap := map[string]string{"foo": "bar"}
0000000000000000000000000000000000000000;;		rsSpec := newReplicaSet(2, labelMap)
0000000000000000000000000000000000000000;;		informers.Extensions().V1beta1().ReplicaSets().Informer().GetIndexer().Add(rsSpec)
0000000000000000000000000000000000000000;;		newPodList(informers.Core().V1().Pods().Informer().GetIndexer(), 1, v1.PodRunning, labelMap, rsSpec, "pod")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Creates a replica and sets expectations
0000000000000000000000000000000000000000;;		rsSpec.Status.Replicas = 1
0000000000000000000000000000000000000000;;		rsSpec.Status.ReadyReplicas = 1
0000000000000000000000000000000000000000;;		rsSpec.Status.AvailableReplicas = 1
0000000000000000000000000000000000000000;;		manager.syncReplicaSet(getKey(rsSpec, t))
0000000000000000000000000000000000000000;;		validateSyncReplicaSet(t, &fakePodControl, 1, 0, 0)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Expectations prevents replicas but not an update on status
0000000000000000000000000000000000000000;;		rsSpec.Status.Replicas = 0
0000000000000000000000000000000000000000;;		rsSpec.Status.ReadyReplicas = 0
0000000000000000000000000000000000000000;;		rsSpec.Status.AvailableReplicas = 0
0000000000000000000000000000000000000000;;		fakePodControl.Clear()
0000000000000000000000000000000000000000;;		manager.syncReplicaSet(getKey(rsSpec, t))
0000000000000000000000000000000000000000;;		validateSyncReplicaSet(t, &fakePodControl, 0, 0, 0)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Get the key for the controller
0000000000000000000000000000000000000000;;		rsKey, err := controller.KeyFunc(rsSpec)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			t.Errorf("Couldn't get key for object %#v: %v", rsSpec, err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Lowering expectations should lead to a sync that creates a replica, however the
0000000000000000000000000000000000000000;;		// fakePodControl error will prevent this, leaving expectations at 0, 0
0000000000000000000000000000000000000000;;		manager.expectations.CreationObserved(rsKey)
0000000000000000000000000000000000000000;;		rsSpec.Status.Replicas = 1
0000000000000000000000000000000000000000;;		rsSpec.Status.ReadyReplicas = 1
0000000000000000000000000000000000000000;;		rsSpec.Status.AvailableReplicas = 1
0000000000000000000000000000000000000000;;		fakePodControl.Clear()
0000000000000000000000000000000000000000;;		fakePodControl.Err = fmt.Errorf("Fake Error")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		manager.syncReplicaSet(getKey(rsSpec, t))
0000000000000000000000000000000000000000;;		validateSyncReplicaSet(t, &fakePodControl, 1, 0, 0)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// This replica should not need a Lowering of expectations, since the previous create failed
0000000000000000000000000000000000000000;;		fakePodControl.Clear()
0000000000000000000000000000000000000000;;		fakePodControl.Err = nil
0000000000000000000000000000000000000000;;		manager.syncReplicaSet(getKey(rsSpec, t))
0000000000000000000000000000000000000000;;		validateSyncReplicaSet(t, &fakePodControl, 1, 0, 0)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// 2 PUT for the ReplicaSet status during dormancy window.
0000000000000000000000000000000000000000;;		// Note that the pod creates go through pod control so they're not recorded.
0000000000000000000000000000000000000000;;		fakeHandler.ValidateRequestCount(t, 2)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestPodControllerLookup(t *testing.T) {
0000000000000000000000000000000000000000;;		stopCh := make(chan struct{})
0000000000000000000000000000000000000000;;		defer close(stopCh)
0000000000000000000000000000000000000000;;		manager, informers := testNewReplicaSetControllerFromClient(clientset.NewForConfigOrDie(&restclient.Config{Host: "", ContentConfig: restclient.ContentConfig{GroupVersion: &api.Registry.GroupOrDie(v1.GroupName).GroupVersion}}), stopCh, BurstReplicas)
0000000000000000000000000000000000000000;;		testCases := []struct {
0000000000000000000000000000000000000000;;			inRSs     []*extensions.ReplicaSet
0000000000000000000000000000000000000000;;			pod       *v1.Pod
0000000000000000000000000000000000000000;;			outRSName string
0000000000000000000000000000000000000000;;		}{
0000000000000000000000000000000000000000;;			// pods without labels don't match any ReplicaSets
0000000000000000000000000000000000000000;;			{
0000000000000000000000000000000000000000;;				inRSs: []*extensions.ReplicaSet{
0000000000000000000000000000000000000000;;					{ObjectMeta: metav1.ObjectMeta{Name: "basic"}}},
0000000000000000000000000000000000000000;;				pod:       &v1.Pod{ObjectMeta: metav1.ObjectMeta{Name: "foo1", Namespace: metav1.NamespaceAll}},
0000000000000000000000000000000000000000;;				outRSName: "",
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			// Matching labels, not namespace
0000000000000000000000000000000000000000;;			{
0000000000000000000000000000000000000000;;				inRSs: []*extensions.ReplicaSet{
0000000000000000000000000000000000000000;;					{
0000000000000000000000000000000000000000;;						ObjectMeta: metav1.ObjectMeta{Name: "foo"},
0000000000000000000000000000000000000000;;						Spec: extensions.ReplicaSetSpec{
0000000000000000000000000000000000000000;;							Selector: &metav1.LabelSelector{MatchLabels: map[string]string{"foo": "bar"}},
0000000000000000000000000000000000000000;;						},
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;				pod: &v1.Pod{
0000000000000000000000000000000000000000;;					ObjectMeta: metav1.ObjectMeta{
0000000000000000000000000000000000000000;;						Name: "foo2", Namespace: "ns", Labels: map[string]string{"foo": "bar"}}},
0000000000000000000000000000000000000000;;				outRSName: "",
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			// Matching ns and labels returns the key to the ReplicaSet, not the ReplicaSet name
0000000000000000000000000000000000000000;;			{
0000000000000000000000000000000000000000;;				inRSs: []*extensions.ReplicaSet{
0000000000000000000000000000000000000000;;					{
0000000000000000000000000000000000000000;;						ObjectMeta: metav1.ObjectMeta{Name: "bar", Namespace: "ns"},
0000000000000000000000000000000000000000;;						Spec: extensions.ReplicaSetSpec{
0000000000000000000000000000000000000000;;							Selector: &metav1.LabelSelector{MatchLabels: map[string]string{"foo": "bar"}},
0000000000000000000000000000000000000000;;						},
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;				pod: &v1.Pod{
0000000000000000000000000000000000000000;;					ObjectMeta: metav1.ObjectMeta{
0000000000000000000000000000000000000000;;						Name: "foo3", Namespace: "ns", Labels: map[string]string{"foo": "bar"}}},
0000000000000000000000000000000000000000;;				outRSName: "bar",
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		for _, c := range testCases {
0000000000000000000000000000000000000000;;			for _, r := range c.inRSs {
0000000000000000000000000000000000000000;;				informers.Extensions().V1beta1().ReplicaSets().Informer().GetIndexer().Add(r)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if rss := manager.getPodReplicaSets(c.pod); rss != nil {
0000000000000000000000000000000000000000;;				if len(rss) != 1 {
0000000000000000000000000000000000000000;;					t.Errorf("len(rss) = %v, want %v", len(rss), 1)
0000000000000000000000000000000000000000;;					continue
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				rs := rss[0]
0000000000000000000000000000000000000000;;				if c.outRSName != rs.Name {
0000000000000000000000000000000000000000;;					t.Errorf("Got replica set %+v expected %+v", rs.Name, c.outRSName)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			} else if c.outRSName != "" {
0000000000000000000000000000000000000000;;				t.Errorf("Expected a replica set %v pod %v, found none", c.outRSName, c.pod.Name)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type FakeWatcher struct {
0000000000000000000000000000000000000000;;		w *watch.FakeWatcher
0000000000000000000000000000000000000000;;		*fake.Clientset
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestWatchControllers(t *testing.T) {
0000000000000000000000000000000000000000;;		fakeWatch := watch.NewFake()
0000000000000000000000000000000000000000;;		client := fake.NewSimpleClientset()
0000000000000000000000000000000000000000;;		client.PrependWatchReactor("replicasets", core.DefaultWatchReactor(fakeWatch, nil))
0000000000000000000000000000000000000000;;		stopCh := make(chan struct{})
0000000000000000000000000000000000000000;;		defer close(stopCh)
0000000000000000000000000000000000000000;;		informers := informers.NewSharedInformerFactory(client, controller.NoResyncPeriodFunc())
0000000000000000000000000000000000000000;;		manager := NewReplicaSetController(
0000000000000000000000000000000000000000;;			informers.Extensions().V1beta1().ReplicaSets(),
0000000000000000000000000000000000000000;;			informers.Core().V1().Pods(),
0000000000000000000000000000000000000000;;			client,
0000000000000000000000000000000000000000;;			BurstReplicas,
0000000000000000000000000000000000000000;;		)
0000000000000000000000000000000000000000;;		informers.Start(stopCh)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		var testRSSpec extensions.ReplicaSet
0000000000000000000000000000000000000000;;		received := make(chan string)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// The update sent through the fakeWatcher should make its way into the workqueue,
0000000000000000000000000000000000000000;;		// and eventually into the syncHandler. The handler validates the received controller
0000000000000000000000000000000000000000;;		// and closes the received channel to indicate that the test can finish.
0000000000000000000000000000000000000000;;		manager.syncHandler = func(key string) error {
0000000000000000000000000000000000000000;;			obj, exists, err := informers.Extensions().V1beta1().ReplicaSets().Informer().GetIndexer().GetByKey(key)
0000000000000000000000000000000000000000;;			if !exists || err != nil {
0000000000000000000000000000000000000000;;				t.Errorf("Expected to find replica set under key %v", key)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			rsSpec := *obj.(*extensions.ReplicaSet)
0000000000000000000000000000000000000000;;			if !apiequality.Semantic.DeepDerivative(rsSpec, testRSSpec) {
0000000000000000000000000000000000000000;;				t.Errorf("Expected %#v, but got %#v", testRSSpec, rsSpec)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			close(received)
0000000000000000000000000000000000000000;;			return nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		// Start only the ReplicaSet watcher and the workqueue, send a watch event,
0000000000000000000000000000000000000000;;		// and make sure it hits the sync method.
0000000000000000000000000000000000000000;;		go wait.Until(manager.worker, 10*time.Millisecond, stopCh)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		testRSSpec.Name = "foo"
0000000000000000000000000000000000000000;;		fakeWatch.Add(&testRSSpec)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		select {
0000000000000000000000000000000000000000;;		case <-received:
0000000000000000000000000000000000000000;;		case <-time.After(wait.ForeverTestTimeout):
0000000000000000000000000000000000000000;;			t.Errorf("unexpected timeout from result channel")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestWatchPods(t *testing.T) {
0000000000000000000000000000000000000000;;		client := fake.NewSimpleClientset()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		fakeWatch := watch.NewFake()
0000000000000000000000000000000000000000;;		client.PrependWatchReactor("pods", core.DefaultWatchReactor(fakeWatch, nil))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		stopCh := make(chan struct{})
0000000000000000000000000000000000000000;;		defer close(stopCh)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		manager, informers := testNewReplicaSetControllerFromClient(client, stopCh, BurstReplicas)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Put one ReplicaSet into the shared informer
0000000000000000000000000000000000000000;;		labelMap := map[string]string{"foo": "bar"}
0000000000000000000000000000000000000000;;		testRSSpec := newReplicaSet(1, labelMap)
0000000000000000000000000000000000000000;;		informers.Extensions().V1beta1().ReplicaSets().Informer().GetIndexer().Add(testRSSpec)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		received := make(chan string)
0000000000000000000000000000000000000000;;		// The pod update sent through the fakeWatcher should figure out the managing ReplicaSet and
0000000000000000000000000000000000000000;;		// send it into the syncHandler.
0000000000000000000000000000000000000000;;		manager.syncHandler = func(key string) error {
0000000000000000000000000000000000000000;;			namespace, name, err := cache.SplitMetaNamespaceKey(key)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				t.Errorf("Error splitting key: %v", err)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			rsSpec, err := manager.rsLister.ReplicaSets(namespace).Get(name)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				t.Errorf("Expected to find replica set under key %v: %v", key, err)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if !apiequality.Semantic.DeepDerivative(rsSpec, testRSSpec) {
0000000000000000000000000000000000000000;;				t.Errorf("\nExpected %#v,\nbut got %#v", testRSSpec, rsSpec)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			close(received)
0000000000000000000000000000000000000000;;			return nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Start only the pod watcher and the workqueue, send a watch event,
0000000000000000000000000000000000000000;;		// and make sure it hits the sync method for the right ReplicaSet.
0000000000000000000000000000000000000000;;		go informers.Core().V1().Pods().Informer().Run(stopCh)
0000000000000000000000000000000000000000;;		go manager.Run(1, stopCh)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		pods := newPodList(nil, 1, v1.PodRunning, labelMap, testRSSpec, "pod")
0000000000000000000000000000000000000000;;		testPod := pods.Items[0]
0000000000000000000000000000000000000000;;		testPod.Status.Phase = v1.PodFailed
0000000000000000000000000000000000000000;;		fakeWatch.Add(&testPod)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		select {
0000000000000000000000000000000000000000;;		case <-received:
0000000000000000000000000000000000000000;;		case <-time.After(wait.ForeverTestTimeout):
0000000000000000000000000000000000000000;;			t.Errorf("unexpected timeout from result channel")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestUpdatePods(t *testing.T) {
0000000000000000000000000000000000000000;;		stopCh := make(chan struct{})
0000000000000000000000000000000000000000;;		defer close(stopCh)
0000000000000000000000000000000000000000;;		manager, informers := testNewReplicaSetControllerFromClient(fake.NewSimpleClientset(), stopCh, BurstReplicas)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		received := make(chan string)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		manager.syncHandler = func(key string) error {
0000000000000000000000000000000000000000;;			namespace, name, err := cache.SplitMetaNamespaceKey(key)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				t.Errorf("Error splitting key: %v", err)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			rsSpec, err := manager.rsLister.ReplicaSets(namespace).Get(name)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				t.Errorf("Expected to find replica set under key %v: %v", key, err)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			received <- rsSpec.Name
0000000000000000000000000000000000000000;;			return nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		go wait.Until(manager.worker, 10*time.Millisecond, stopCh)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Put 2 ReplicaSets and one pod into the informers
0000000000000000000000000000000000000000;;		labelMap1 := map[string]string{"foo": "bar"}
0000000000000000000000000000000000000000;;		testRSSpec1 := newReplicaSet(1, labelMap1)
0000000000000000000000000000000000000000;;		informers.Extensions().V1beta1().ReplicaSets().Informer().GetIndexer().Add(testRSSpec1)
0000000000000000000000000000000000000000;;		testRSSpec2 := *testRSSpec1
0000000000000000000000000000000000000000;;		labelMap2 := map[string]string{"bar": "foo"}
0000000000000000000000000000000000000000;;		testRSSpec2.Spec.Selector = &metav1.LabelSelector{MatchLabels: labelMap2}
0000000000000000000000000000000000000000;;		testRSSpec2.Name = "barfoo"
0000000000000000000000000000000000000000;;		informers.Extensions().V1beta1().ReplicaSets().Informer().GetIndexer().Add(&testRSSpec2)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		isController := true
0000000000000000000000000000000000000000;;		controllerRef1 := metav1.OwnerReference{UID: testRSSpec1.UID, APIVersion: "v1", Kind: "ReplicaSet", Name: testRSSpec1.Name, Controller: &isController}
0000000000000000000000000000000000000000;;		controllerRef2 := metav1.OwnerReference{UID: testRSSpec2.UID, APIVersion: "v1", Kind: "ReplicaSet", Name: testRSSpec2.Name, Controller: &isController}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// case 1: Pod with a ControllerRef
0000000000000000000000000000000000000000;;		pod1 := newPodList(informers.Core().V1().Pods().Informer().GetIndexer(), 1, v1.PodRunning, labelMap1, testRSSpec1, "pod").Items[0]
0000000000000000000000000000000000000000;;		pod1.OwnerReferences = []metav1.OwnerReference{controllerRef1}
0000000000000000000000000000000000000000;;		pod1.ResourceVersion = "1"
0000000000000000000000000000000000000000;;		pod2 := pod1
0000000000000000000000000000000000000000;;		pod2.Labels = labelMap2
0000000000000000000000000000000000000000;;		pod2.ResourceVersion = "2"
0000000000000000000000000000000000000000;;		manager.updatePod(&pod1, &pod2)
0000000000000000000000000000000000000000;;		expected := sets.NewString(testRSSpec1.Name)
0000000000000000000000000000000000000000;;		for _, name := range expected.List() {
0000000000000000000000000000000000000000;;			t.Logf("Expecting update for %+v", name)
0000000000000000000000000000000000000000;;			select {
0000000000000000000000000000000000000000;;			case got := <-received:
0000000000000000000000000000000000000000;;				if !expected.Has(got) {
0000000000000000000000000000000000000000;;					t.Errorf("Expected keys %#v got %v", expected, got)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			case <-time.After(wait.ForeverTestTimeout):
0000000000000000000000000000000000000000;;				t.Errorf("Expected update notifications for replica sets")
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// case 2: Remove ControllerRef (orphan). Expect to sync label-matching RS.
0000000000000000000000000000000000000000;;		pod1 = newPodList(informers.Core().V1().Pods().Informer().GetIndexer(), 1, v1.PodRunning, labelMap1, testRSSpec1, "pod").Items[0]
0000000000000000000000000000000000000000;;		pod1.ResourceVersion = "1"
0000000000000000000000000000000000000000;;		pod1.Labels = labelMap2
0000000000000000000000000000000000000000;;		pod1.OwnerReferences = []metav1.OwnerReference{controllerRef2}
0000000000000000000000000000000000000000;;		pod2 = pod1
0000000000000000000000000000000000000000;;		pod2.OwnerReferences = nil
0000000000000000000000000000000000000000;;		pod2.ResourceVersion = "2"
0000000000000000000000000000000000000000;;		manager.updatePod(&pod1, &pod2)
0000000000000000000000000000000000000000;;		expected = sets.NewString(testRSSpec2.Name)
0000000000000000000000000000000000000000;;		for _, name := range expected.List() {
0000000000000000000000000000000000000000;;			t.Logf("Expecting update for %+v", name)
0000000000000000000000000000000000000000;;			select {
0000000000000000000000000000000000000000;;			case got := <-received:
0000000000000000000000000000000000000000;;				if !expected.Has(got) {
0000000000000000000000000000000000000000;;					t.Errorf("Expected keys %#v got %v", expected, got)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			case <-time.After(wait.ForeverTestTimeout):
0000000000000000000000000000000000000000;;				t.Errorf("Expected update notifications for replica sets")
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// case 2: Remove ControllerRef (orphan). Expect to sync both former owner and
0000000000000000000000000000000000000000;;		// any label-matching RS.
0000000000000000000000000000000000000000;;		pod1 = newPodList(informers.Core().V1().Pods().Informer().GetIndexer(), 1, v1.PodRunning, labelMap1, testRSSpec1, "pod").Items[0]
0000000000000000000000000000000000000000;;		pod1.ResourceVersion = "1"
0000000000000000000000000000000000000000;;		pod1.Labels = labelMap2
0000000000000000000000000000000000000000;;		pod1.OwnerReferences = []metav1.OwnerReference{controllerRef1}
0000000000000000000000000000000000000000;;		pod2 = pod1
0000000000000000000000000000000000000000;;		pod2.OwnerReferences = nil
0000000000000000000000000000000000000000;;		pod2.ResourceVersion = "2"
0000000000000000000000000000000000000000;;		manager.updatePod(&pod1, &pod2)
0000000000000000000000000000000000000000;;		expected = sets.NewString(testRSSpec1.Name, testRSSpec2.Name)
0000000000000000000000000000000000000000;;		for _, name := range expected.List() {
0000000000000000000000000000000000000000;;			t.Logf("Expecting update for %+v", name)
0000000000000000000000000000000000000000;;			select {
0000000000000000000000000000000000000000;;			case got := <-received:
0000000000000000000000000000000000000000;;				if !expected.Has(got) {
0000000000000000000000000000000000000000;;					t.Errorf("Expected keys %#v got %v", expected, got)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			case <-time.After(wait.ForeverTestTimeout):
0000000000000000000000000000000000000000;;				t.Errorf("Expected update notifications for replica sets")
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// case 4: Keep ControllerRef, change labels. Expect to sync owning RS.
0000000000000000000000000000000000000000;;		pod1 = newPodList(informers.Core().V1().Pods().Informer().GetIndexer(), 1, v1.PodRunning, labelMap1, testRSSpec1, "pod").Items[0]
0000000000000000000000000000000000000000;;		pod1.ResourceVersion = "1"
0000000000000000000000000000000000000000;;		pod1.Labels = labelMap1
0000000000000000000000000000000000000000;;		pod1.OwnerReferences = []metav1.OwnerReference{controllerRef2}
0000000000000000000000000000000000000000;;		pod2 = pod1
0000000000000000000000000000000000000000;;		pod2.Labels = labelMap2
0000000000000000000000000000000000000000;;		pod2.ResourceVersion = "2"
0000000000000000000000000000000000000000;;		manager.updatePod(&pod1, &pod2)
0000000000000000000000000000000000000000;;		expected = sets.NewString(testRSSpec2.Name)
0000000000000000000000000000000000000000;;		for _, name := range expected.List() {
0000000000000000000000000000000000000000;;			t.Logf("Expecting update for %+v", name)
0000000000000000000000000000000000000000;;			select {
0000000000000000000000000000000000000000;;			case got := <-received:
0000000000000000000000000000000000000000;;				if !expected.Has(got) {
0000000000000000000000000000000000000000;;					t.Errorf("Expected keys %#v got %v", expected, got)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			case <-time.After(wait.ForeverTestTimeout):
0000000000000000000000000000000000000000;;				t.Errorf("Expected update notifications for replica sets")
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestControllerUpdateRequeue(t *testing.T) {
0000000000000000000000000000000000000000;;		// This server should force a requeue of the controller because it fails to update status.Replicas.
0000000000000000000000000000000000000000;;		labelMap := map[string]string{"foo": "bar"}
0000000000000000000000000000000000000000;;		rs := newReplicaSet(1, labelMap)
0000000000000000000000000000000000000000;;		client := fake.NewSimpleClientset(rs)
0000000000000000000000000000000000000000;;		client.PrependReactor("update", "replicasets",
0000000000000000000000000000000000000000;;			func(action core.Action) (bool, runtime.Object, error) {
0000000000000000000000000000000000000000;;				if action.GetSubresource() != "status" {
0000000000000000000000000000000000000000;;					return false, nil, nil
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				return true, nil, errors.New("failed to update status")
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;		stopCh := make(chan struct{})
0000000000000000000000000000000000000000;;		defer close(stopCh)
0000000000000000000000000000000000000000;;		manager, informers := testNewReplicaSetControllerFromClient(client, stopCh, BurstReplicas)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		informers.Extensions().V1beta1().ReplicaSets().Informer().GetIndexer().Add(rs)
0000000000000000000000000000000000000000;;		rs.Status = extensions.ReplicaSetStatus{Replicas: 2}
0000000000000000000000000000000000000000;;		newPodList(informers.Core().V1().Pods().Informer().GetIndexer(), 1, v1.PodRunning, labelMap, rs, "pod")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		fakePodControl := controller.FakePodControl{}
0000000000000000000000000000000000000000;;		manager.podControl = &fakePodControl
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Enqueue once. Then process it. Disable rate-limiting for this.
0000000000000000000000000000000000000000;;		manager.queue = workqueue.NewRateLimitingQueue(workqueue.NewMaxOfRateLimiter())
0000000000000000000000000000000000000000;;		manager.enqueueReplicaSet(rs)
0000000000000000000000000000000000000000;;		manager.processNextWorkItem()
0000000000000000000000000000000000000000;;		// It should have been requeued.
0000000000000000000000000000000000000000;;		if got, want := manager.queue.Len(), 1; got != want {
0000000000000000000000000000000000000000;;			t.Errorf("queue.Len() = %v, want %v", got, want)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestControllerUpdateStatusWithFailure(t *testing.T) {
0000000000000000000000000000000000000000;;		rs := newReplicaSet(1, map[string]string{"foo": "bar"})
0000000000000000000000000000000000000000;;		fakeClient := &fake.Clientset{}
0000000000000000000000000000000000000000;;		fakeClient.AddReactor("get", "replicasets", func(action core.Action) (bool, runtime.Object, error) { return true, rs, nil })
0000000000000000000000000000000000000000;;		fakeClient.AddReactor("*", "*", func(action core.Action) (bool, runtime.Object, error) {
0000000000000000000000000000000000000000;;			return true, &extensions.ReplicaSet{}, fmt.Errorf("Fake error")
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;		fakeRSClient := fakeClient.Extensions().ReplicaSets("default")
0000000000000000000000000000000000000000;;		numReplicas := int32(10)
0000000000000000000000000000000000000000;;		newStatus := extensions.ReplicaSetStatus{Replicas: numReplicas}
0000000000000000000000000000000000000000;;		updateReplicaSetStatus(fakeRSClient, rs, newStatus)
0000000000000000000000000000000000000000;;		updates, gets := 0, 0
0000000000000000000000000000000000000000;;		for _, a := range fakeClient.Actions() {
0000000000000000000000000000000000000000;;			if a.GetResource().Resource != "replicasets" {
0000000000000000000000000000000000000000;;				t.Errorf("Unexpected action %+v", a)
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			switch action := a.(type) {
0000000000000000000000000000000000000000;;			case core.GetAction:
0000000000000000000000000000000000000000;;				gets++
0000000000000000000000000000000000000000;;				// Make sure the get is for the right ReplicaSet even though the update failed.
0000000000000000000000000000000000000000;;				if action.GetName() != rs.Name {
0000000000000000000000000000000000000000;;					t.Errorf("Expected get for ReplicaSet %v, got %+v instead", rs.Name, action.GetName())
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			case core.UpdateAction:
0000000000000000000000000000000000000000;;				updates++
0000000000000000000000000000000000000000;;				// Confirm that the update has the right status.Replicas even though the Get
0000000000000000000000000000000000000000;;				// returned a ReplicaSet with replicas=1.
0000000000000000000000000000000000000000;;				if c, ok := action.GetObject().(*extensions.ReplicaSet); !ok {
0000000000000000000000000000000000000000;;					t.Errorf("Expected a ReplicaSet as the argument to update, got %T", c)
0000000000000000000000000000000000000000;;				} else if c.Status.Replicas != numReplicas {
0000000000000000000000000000000000000000;;					t.Errorf("Expected update for ReplicaSet to contain replicas %v, got %v instead",
0000000000000000000000000000000000000000;;						numReplicas, c.Status.Replicas)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			default:
0000000000000000000000000000000000000000;;				t.Errorf("Unexpected action %+v", a)
0000000000000000000000000000000000000000;;				break
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if gets != 1 || updates != 2 {
0000000000000000000000000000000000000000;;			t.Errorf("Expected 1 get and 2 updates, got %d gets %d updates", gets, updates)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// TODO: This test is too hairy for a unittest. It should be moved to an E2E suite.
0000000000000000000000000000000000000000;;	func doTestControllerBurstReplicas(t *testing.T, burstReplicas, numReplicas int) {
0000000000000000000000000000000000000000;;		labelMap := map[string]string{"foo": "bar"}
0000000000000000000000000000000000000000;;		rsSpec := newReplicaSet(numReplicas, labelMap)
0000000000000000000000000000000000000000;;		client := fake.NewSimpleClientset(rsSpec)
0000000000000000000000000000000000000000;;		fakePodControl := controller.FakePodControl{}
0000000000000000000000000000000000000000;;		stopCh := make(chan struct{})
0000000000000000000000000000000000000000;;		defer close(stopCh)
0000000000000000000000000000000000000000;;		manager, informers := testNewReplicaSetControllerFromClient(client, stopCh, burstReplicas)
0000000000000000000000000000000000000000;;		manager.podControl = &fakePodControl
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		informers.Extensions().V1beta1().ReplicaSets().Informer().GetIndexer().Add(rsSpec)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		expectedPods := int32(0)
0000000000000000000000000000000000000000;;		pods := newPodList(nil, numReplicas, v1.PodPending, labelMap, rsSpec, "pod")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		rsKey, err := controller.KeyFunc(rsSpec)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			t.Errorf("Couldn't get key for object %#v: %v", rsSpec, err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Size up the controller, then size it down, and confirm the expected create/delete pattern
0000000000000000000000000000000000000000;;		for _, replicas := range []int32{int32(numReplicas), 0} {
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			*(rsSpec.Spec.Replicas) = replicas
0000000000000000000000000000000000000000;;			informers.Extensions().V1beta1().ReplicaSets().Informer().GetIndexer().Add(rsSpec)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			for i := 0; i < numReplicas; i += burstReplicas {
0000000000000000000000000000000000000000;;				manager.syncReplicaSet(getKey(rsSpec, t))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				// The store accrues active pods. It's also used by the ReplicaSet to determine how many
0000000000000000000000000000000000000000;;				// replicas to create.
0000000000000000000000000000000000000000;;				activePods := int32(len(informers.Core().V1().Pods().Informer().GetIndexer().List()))
0000000000000000000000000000000000000000;;				if replicas != 0 {
0000000000000000000000000000000000000000;;					// This is the number of pods currently "in flight". They were created by the
0000000000000000000000000000000000000000;;					// ReplicaSet controller above, which then puts the ReplicaSet to sleep till
0000000000000000000000000000000000000000;;					// all of them have been observed.
0000000000000000000000000000000000000000;;					expectedPods = replicas - activePods
0000000000000000000000000000000000000000;;					if expectedPods > int32(burstReplicas) {
0000000000000000000000000000000000000000;;						expectedPods = int32(burstReplicas)
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					// This validates the ReplicaSet manager sync actually created pods
0000000000000000000000000000000000000000;;					validateSyncReplicaSet(t, &fakePodControl, int(expectedPods), 0, 0)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;					// This simulates the watch events for all but 1 of the expected pods.
0000000000000000000000000000000000000000;;					// None of these should wake the controller because it has expectations==BurstReplicas.
0000000000000000000000000000000000000000;;					for i := int32(0); i < expectedPods-1; i++ {
0000000000000000000000000000000000000000;;						informers.Core().V1().Pods().Informer().GetIndexer().Add(&pods.Items[i])
0000000000000000000000000000000000000000;;						manager.addPod(&pods.Items[i])
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;					podExp, exists, err := manager.expectations.GetExpectations(rsKey)
0000000000000000000000000000000000000000;;					if !exists || err != nil {
0000000000000000000000000000000000000000;;						t.Fatalf("Did not find expectations for rs.")
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					if add, _ := podExp.GetExpectations(); add != 1 {
0000000000000000000000000000000000000000;;						t.Fatalf("Expectations are wrong %v", podExp)
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;				} else {
0000000000000000000000000000000000000000;;					expectedPods = (replicas - activePods) * -1
0000000000000000000000000000000000000000;;					if expectedPods > int32(burstReplicas) {
0000000000000000000000000000000000000000;;						expectedPods = int32(burstReplicas)
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					validateSyncReplicaSet(t, &fakePodControl, 0, int(expectedPods), 0)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;					// To accurately simulate a watch we must delete the exact pods
0000000000000000000000000000000000000000;;					// the rs is waiting for.
0000000000000000000000000000000000000000;;					expectedDels := manager.expectations.GetUIDs(getKey(rsSpec, t))
0000000000000000000000000000000000000000;;					podsToDelete := []*v1.Pod{}
0000000000000000000000000000000000000000;;					isController := true
0000000000000000000000000000000000000000;;					for _, key := range expectedDels.List() {
0000000000000000000000000000000000000000;;						nsName := strings.Split(key, "/")
0000000000000000000000000000000000000000;;						podsToDelete = append(podsToDelete, &v1.Pod{
0000000000000000000000000000000000000000;;							ObjectMeta: metav1.ObjectMeta{
0000000000000000000000000000000000000000;;								Name:      nsName[1],
0000000000000000000000000000000000000000;;								Namespace: nsName[0],
0000000000000000000000000000000000000000;;								Labels:    rsSpec.Spec.Selector.MatchLabels,
0000000000000000000000000000000000000000;;								OwnerReferences: []metav1.OwnerReference{
0000000000000000000000000000000000000000;;									{UID: rsSpec.UID, APIVersion: "v1", Kind: "ReplicaSet", Name: rsSpec.Name, Controller: &isController},
0000000000000000000000000000000000000000;;								},
0000000000000000000000000000000000000000;;							},
0000000000000000000000000000000000000000;;						})
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					// Don't delete all pods because we confirm that the last pod
0000000000000000000000000000000000000000;;					// has exactly one expectation at the end, to verify that we
0000000000000000000000000000000000000000;;					// don't double delete.
0000000000000000000000000000000000000000;;					for i := range podsToDelete[1:] {
0000000000000000000000000000000000000000;;						informers.Core().V1().Pods().Informer().GetIndexer().Delete(podsToDelete[i])
0000000000000000000000000000000000000000;;						manager.deletePod(podsToDelete[i])
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					podExp, exists, err := manager.expectations.GetExpectations(rsKey)
0000000000000000000000000000000000000000;;					if !exists || err != nil {
0000000000000000000000000000000000000000;;						t.Fatalf("Did not find expectations for ReplicaSet.")
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					if _, del := podExp.GetExpectations(); del != 1 {
0000000000000000000000000000000000000000;;						t.Fatalf("Expectations are wrong %v", podExp)
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				// Check that the ReplicaSet didn't take any action for all the above pods
0000000000000000000000000000000000000000;;				fakePodControl.Clear()
0000000000000000000000000000000000000000;;				manager.syncReplicaSet(getKey(rsSpec, t))
0000000000000000000000000000000000000000;;				validateSyncReplicaSet(t, &fakePodControl, 0, 0, 0)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				// Create/Delete the last pod
0000000000000000000000000000000000000000;;				// The last add pod will decrease the expectation of the ReplicaSet to 0,
0000000000000000000000000000000000000000;;				// which will cause it to create/delete the remaining replicas up to burstReplicas.
0000000000000000000000000000000000000000;;				if replicas != 0 {
0000000000000000000000000000000000000000;;					informers.Core().V1().Pods().Informer().GetIndexer().Add(&pods.Items[expectedPods-1])
0000000000000000000000000000000000000000;;					manager.addPod(&pods.Items[expectedPods-1])
0000000000000000000000000000000000000000;;				} else {
0000000000000000000000000000000000000000;;					expectedDel := manager.expectations.GetUIDs(getKey(rsSpec, t))
0000000000000000000000000000000000000000;;					if expectedDel.Len() != 1 {
0000000000000000000000000000000000000000;;						t.Fatalf("Waiting on unexpected number of deletes.")
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					nsName := strings.Split(expectedDel.List()[0], "/")
0000000000000000000000000000000000000000;;					isController := true
0000000000000000000000000000000000000000;;					lastPod := &v1.Pod{
0000000000000000000000000000000000000000;;						ObjectMeta: metav1.ObjectMeta{
0000000000000000000000000000000000000000;;							Name:      nsName[1],
0000000000000000000000000000000000000000;;							Namespace: nsName[0],
0000000000000000000000000000000000000000;;							Labels:    rsSpec.Spec.Selector.MatchLabels,
0000000000000000000000000000000000000000;;							OwnerReferences: []metav1.OwnerReference{
0000000000000000000000000000000000000000;;								{UID: rsSpec.UID, APIVersion: "v1", Kind: "ReplicaSet", Name: rsSpec.Name, Controller: &isController},
0000000000000000000000000000000000000000;;							},
0000000000000000000000000000000000000000;;						},
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					informers.Core().V1().Pods().Informer().GetIndexer().Delete(lastPod)
0000000000000000000000000000000000000000;;					manager.deletePod(lastPod)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				pods.Items = pods.Items[expectedPods:]
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Confirm that we've created the right number of replicas
0000000000000000000000000000000000000000;;			activePods := int32(len(informers.Core().V1().Pods().Informer().GetIndexer().List()))
0000000000000000000000000000000000000000;;			if activePods != *(rsSpec.Spec.Replicas) {
0000000000000000000000000000000000000000;;				t.Fatalf("Unexpected number of active pods, expected %d, got %d", *(rsSpec.Spec.Replicas), activePods)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			// Replenish the pod list, since we cut it down sizing up
0000000000000000000000000000000000000000;;			pods = newPodList(nil, int(replicas), v1.PodRunning, labelMap, rsSpec, "pod")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestControllerBurstReplicas(t *testing.T) {
0000000000000000000000000000000000000000;;		doTestControllerBurstReplicas(t, 5, 30)
0000000000000000000000000000000000000000;;		doTestControllerBurstReplicas(t, 5, 12)
0000000000000000000000000000000000000000;;		doTestControllerBurstReplicas(t, 3, 2)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type FakeRSExpectations struct {
0000000000000000000000000000000000000000;;		*controller.ControllerExpectations
0000000000000000000000000000000000000000;;		satisfied    bool
0000000000000000000000000000000000000000;;		expSatisfied func()
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (fe FakeRSExpectations) SatisfiedExpectations(controllerKey string) bool {
0000000000000000000000000000000000000000;;		fe.expSatisfied()
0000000000000000000000000000000000000000;;		return fe.satisfied
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// TestRSSyncExpectations tests that a pod cannot sneak in between counting active pods
0000000000000000000000000000000000000000;;	// and checking expectations.
0000000000000000000000000000000000000000;;	func TestRSSyncExpectations(t *testing.T) {
0000000000000000000000000000000000000000;;		client := clientset.NewForConfigOrDie(&restclient.Config{Host: "", ContentConfig: restclient.ContentConfig{GroupVersion: &api.Registry.GroupOrDie(v1.GroupName).GroupVersion}})
0000000000000000000000000000000000000000;;		fakePodControl := controller.FakePodControl{}
0000000000000000000000000000000000000000;;		stopCh := make(chan struct{})
0000000000000000000000000000000000000000;;		defer close(stopCh)
0000000000000000000000000000000000000000;;		manager, informers := testNewReplicaSetControllerFromClient(client, stopCh, 2)
0000000000000000000000000000000000000000;;		manager.podControl = &fakePodControl
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		labelMap := map[string]string{"foo": "bar"}
0000000000000000000000000000000000000000;;		rsSpec := newReplicaSet(2, labelMap)
0000000000000000000000000000000000000000;;		informers.Extensions().V1beta1().ReplicaSets().Informer().GetIndexer().Add(rsSpec)
0000000000000000000000000000000000000000;;		pods := newPodList(nil, 2, v1.PodPending, labelMap, rsSpec, "pod")
0000000000000000000000000000000000000000;;		informers.Core().V1().Pods().Informer().GetIndexer().Add(&pods.Items[0])
0000000000000000000000000000000000000000;;		postExpectationsPod := pods.Items[1]
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		manager.expectations = controller.NewUIDTrackingControllerExpectations(FakeRSExpectations{
0000000000000000000000000000000000000000;;			controller.NewControllerExpectations(), true, func() {
0000000000000000000000000000000000000000;;				// If we check active pods before checking expectataions, the
0000000000000000000000000000000000000000;;				// ReplicaSet will create a new replica because it doesn't see
0000000000000000000000000000000000000000;;				// this pod, but has fulfilled its expectations.
0000000000000000000000000000000000000000;;				informers.Core().V1().Pods().Informer().GetIndexer().Add(&postExpectationsPod)
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;		manager.syncReplicaSet(getKey(rsSpec, t))
0000000000000000000000000000000000000000;;		validateSyncReplicaSet(t, &fakePodControl, 0, 0, 0)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestDeleteControllerAndExpectations(t *testing.T) {
0000000000000000000000000000000000000000;;		rs := newReplicaSet(1, map[string]string{"foo": "bar"})
0000000000000000000000000000000000000000;;		client := fake.NewSimpleClientset(rs)
0000000000000000000000000000000000000000;;		stopCh := make(chan struct{})
0000000000000000000000000000000000000000;;		defer close(stopCh)
0000000000000000000000000000000000000000;;		manager, informers := testNewReplicaSetControllerFromClient(client, stopCh, 10)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		informers.Extensions().V1beta1().ReplicaSets().Informer().GetIndexer().Add(rs)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		fakePodControl := controller.FakePodControl{}
0000000000000000000000000000000000000000;;		manager.podControl = &fakePodControl
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// This should set expectations for the ReplicaSet
0000000000000000000000000000000000000000;;		manager.syncReplicaSet(getKey(rs, t))
0000000000000000000000000000000000000000;;		validateSyncReplicaSet(t, &fakePodControl, 1, 0, 0)
0000000000000000000000000000000000000000;;		fakePodControl.Clear()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Get the ReplicaSet key
0000000000000000000000000000000000000000;;		rsKey, err := controller.KeyFunc(rs)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			t.Errorf("Couldn't get key for object %#v: %v", rs, err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// This is to simulate a concurrent addPod, that has a handle on the expectations
0000000000000000000000000000000000000000;;		// as the controller deletes it.
0000000000000000000000000000000000000000;;		podExp, exists, err := manager.expectations.GetExpectations(rsKey)
0000000000000000000000000000000000000000;;		if !exists || err != nil {
0000000000000000000000000000000000000000;;			t.Errorf("No expectations found for ReplicaSet")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		informers.Extensions().V1beta1().ReplicaSets().Informer().GetIndexer().Delete(rs)
0000000000000000000000000000000000000000;;		manager.syncReplicaSet(getKey(rs, t))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if _, exists, err = manager.expectations.GetExpectations(rsKey); exists {
0000000000000000000000000000000000000000;;			t.Errorf("Found expectaions, expected none since the ReplicaSet has been deleted.")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// This should have no effect, since we've deleted the ReplicaSet.
0000000000000000000000000000000000000000;;		podExp.Add(-1, 0)
0000000000000000000000000000000000000000;;		informers.Core().V1().Pods().Informer().GetIndexer().Replace(make([]interface{}, 0), "0")
0000000000000000000000000000000000000000;;		manager.syncReplicaSet(getKey(rs, t))
0000000000000000000000000000000000000000;;		validateSyncReplicaSet(t, &fakePodControl, 0, 0, 0)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// shuffle returns a new shuffled list of container controllers.
0000000000000000000000000000000000000000;;	func shuffle(controllers []*extensions.ReplicaSet) []*extensions.ReplicaSet {
0000000000000000000000000000000000000000;;		numControllers := len(controllers)
0000000000000000000000000000000000000000;;		randIndexes := rand.Perm(numControllers)
0000000000000000000000000000000000000000;;		shuffled := make([]*extensions.ReplicaSet, numControllers)
0000000000000000000000000000000000000000;;		for i := 0; i < numControllers; i++ {
0000000000000000000000000000000000000000;;			shuffled[i] = controllers[randIndexes[i]]
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return shuffled
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestOverlappingRSs(t *testing.T) {
0000000000000000000000000000000000000000;;		client := clientset.NewForConfigOrDie(&restclient.Config{Host: "", ContentConfig: restclient.ContentConfig{GroupVersion: &api.Registry.GroupOrDie(v1.GroupName).GroupVersion}})
0000000000000000000000000000000000000000;;		labelMap := map[string]string{"foo": "bar"}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		stopCh := make(chan struct{})
0000000000000000000000000000000000000000;;		defer close(stopCh)
0000000000000000000000000000000000000000;;		manager, informers := testNewReplicaSetControllerFromClient(client, stopCh, 10)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Create 10 ReplicaSets, shuffled them randomly and insert them into the
0000000000000000000000000000000000000000;;		// ReplicaSet controller's store.
0000000000000000000000000000000000000000;;		// All use the same CreationTimestamp since ControllerRef should be able
0000000000000000000000000000000000000000;;		// to handle that.
0000000000000000000000000000000000000000;;		timestamp := metav1.Date(2014, time.December, 0, 0, 0, 0, 0, time.Local)
0000000000000000000000000000000000000000;;		var controllers []*extensions.ReplicaSet
0000000000000000000000000000000000000000;;		for j := 1; j < 10; j++ {
0000000000000000000000000000000000000000;;			rsSpec := newReplicaSet(1, labelMap)
0000000000000000000000000000000000000000;;			rsSpec.CreationTimestamp = timestamp
0000000000000000000000000000000000000000;;			rsSpec.Name = fmt.Sprintf("rs%d", j)
0000000000000000000000000000000000000000;;			controllers = append(controllers, rsSpec)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		shuffledControllers := shuffle(controllers)
0000000000000000000000000000000000000000;;		for j := range shuffledControllers {
0000000000000000000000000000000000000000;;			informers.Extensions().V1beta1().ReplicaSets().Informer().GetIndexer().Add(shuffledControllers[j])
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		// Add a pod with a ControllerRef and make sure only the corresponding
0000000000000000000000000000000000000000;;		// ReplicaSet is synced. Pick a RS in the middle since the old code used to
0000000000000000000000000000000000000000;;		// sort by name if all timestamps were equal.
0000000000000000000000000000000000000000;;		rs := controllers[3]
0000000000000000000000000000000000000000;;		pods := newPodList(nil, 1, v1.PodPending, labelMap, rs, "pod")
0000000000000000000000000000000000000000;;		pod := &pods.Items[0]
0000000000000000000000000000000000000000;;		isController := true
0000000000000000000000000000000000000000;;		pod.OwnerReferences = []metav1.OwnerReference{
0000000000000000000000000000000000000000;;			{UID: rs.UID, APIVersion: "v1", Kind: "ReplicaSet", Name: rs.Name, Controller: &isController},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		rsKey := getKey(rs, t)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		manager.addPod(pod)
0000000000000000000000000000000000000000;;		queueRS, _ := manager.queue.Get()
0000000000000000000000000000000000000000;;		if queueRS != rsKey {
0000000000000000000000000000000000000000;;			t.Fatalf("Expected to find key %v in queue, found %v", rsKey, queueRS)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestDeletionTimestamp(t *testing.T) {
0000000000000000000000000000000000000000;;		c := clientset.NewForConfigOrDie(&restclient.Config{Host: "", ContentConfig: restclient.ContentConfig{GroupVersion: &api.Registry.GroupOrDie(v1.GroupName).GroupVersion}})
0000000000000000000000000000000000000000;;		labelMap := map[string]string{"foo": "bar"}
0000000000000000000000000000000000000000;;		stopCh := make(chan struct{})
0000000000000000000000000000000000000000;;		defer close(stopCh)
0000000000000000000000000000000000000000;;		manager, informers := testNewReplicaSetControllerFromClient(c, stopCh, 10)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		rs := newReplicaSet(1, labelMap)
0000000000000000000000000000000000000000;;		informers.Extensions().V1beta1().ReplicaSets().Informer().GetIndexer().Add(rs)
0000000000000000000000000000000000000000;;		rsKey, err := controller.KeyFunc(rs)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			t.Errorf("Couldn't get key for object %#v: %v", rs, err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		pod := newPodList(nil, 1, v1.PodPending, labelMap, rs, "pod").Items[0]
0000000000000000000000000000000000000000;;		pod.DeletionTimestamp = &metav1.Time{Time: time.Now()}
0000000000000000000000000000000000000000;;		pod.ResourceVersion = "1"
0000000000000000000000000000000000000000;;		manager.expectations.ExpectDeletions(rsKey, []string{controller.PodKey(&pod)})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// A pod added with a deletion timestamp should decrement deletions, not creations.
0000000000000000000000000000000000000000;;		manager.addPod(&pod)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		queueRS, _ := manager.queue.Get()
0000000000000000000000000000000000000000;;		if queueRS != rsKey {
0000000000000000000000000000000000000000;;			t.Fatalf("Expected to find key %v in queue, found %v", rsKey, queueRS)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		manager.queue.Done(rsKey)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		podExp, exists, err := manager.expectations.GetExpectations(rsKey)
0000000000000000000000000000000000000000;;		if !exists || err != nil || !podExp.Fulfilled() {
0000000000000000000000000000000000000000;;			t.Fatalf("Wrong expectations %#v", podExp)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// An update from no deletion timestamp to having one should be treated
0000000000000000000000000000000000000000;;		// as a deletion.
0000000000000000000000000000000000000000;;		oldPod := newPodList(nil, 1, v1.PodPending, labelMap, rs, "pod").Items[0]
0000000000000000000000000000000000000000;;		oldPod.ResourceVersion = "2"
0000000000000000000000000000000000000000;;		manager.expectations.ExpectDeletions(rsKey, []string{controller.PodKey(&pod)})
0000000000000000000000000000000000000000;;		manager.updatePod(&oldPod, &pod)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		queueRS, _ = manager.queue.Get()
0000000000000000000000000000000000000000;;		if queueRS != rsKey {
0000000000000000000000000000000000000000;;			t.Fatalf("Expected to find key %v in queue, found %v", rsKey, queueRS)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		manager.queue.Done(rsKey)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		podExp, exists, err = manager.expectations.GetExpectations(rsKey)
0000000000000000000000000000000000000000;;		if !exists || err != nil || !podExp.Fulfilled() {
0000000000000000000000000000000000000000;;			t.Fatalf("Wrong expectations %#v", podExp)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// An update to the pod (including an update to the deletion timestamp)
0000000000000000000000000000000000000000;;		// should not be counted as a second delete.
0000000000000000000000000000000000000000;;		isController := true
0000000000000000000000000000000000000000;;		secondPod := &v1.Pod{
0000000000000000000000000000000000000000;;			ObjectMeta: metav1.ObjectMeta{
0000000000000000000000000000000000000000;;				Namespace: pod.Namespace,
0000000000000000000000000000000000000000;;				Name:      "secondPod",
0000000000000000000000000000000000000000;;				Labels:    pod.Labels,
0000000000000000000000000000000000000000;;				OwnerReferences: []metav1.OwnerReference{
0000000000000000000000000000000000000000;;					{UID: rs.UID, APIVersion: "v1", Kind: "ReplicaSet", Name: rs.Name, Controller: &isController},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		manager.expectations.ExpectDeletions(rsKey, []string{controller.PodKey(secondPod)})
0000000000000000000000000000000000000000;;		oldPod.DeletionTimestamp = &metav1.Time{Time: time.Now()}
0000000000000000000000000000000000000000;;		oldPod.ResourceVersion = "2"
0000000000000000000000000000000000000000;;		manager.updatePod(&oldPod, &pod)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		podExp, exists, err = manager.expectations.GetExpectations(rsKey)
0000000000000000000000000000000000000000;;		if !exists || err != nil || podExp.Fulfilled() {
0000000000000000000000000000000000000000;;			t.Fatalf("Wrong expectations %#v", podExp)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// A pod with a non-nil deletion timestamp should also be ignored by the
0000000000000000000000000000000000000000;;		// delete handler, because it's already been counted in the update.
0000000000000000000000000000000000000000;;		manager.deletePod(&pod)
0000000000000000000000000000000000000000;;		podExp, exists, err = manager.expectations.GetExpectations(rsKey)
0000000000000000000000000000000000000000;;		if !exists || err != nil || podExp.Fulfilled() {
0000000000000000000000000000000000000000;;			t.Fatalf("Wrong expectations %#v", podExp)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Deleting the second pod should clear expectations.
0000000000000000000000000000000000000000;;		manager.deletePod(secondPod)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		queueRS, _ = manager.queue.Get()
0000000000000000000000000000000000000000;;		if queueRS != rsKey {
0000000000000000000000000000000000000000;;			t.Fatalf("Expected to find key %v in queue, found %v", rsKey, queueRS)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		manager.queue.Done(rsKey)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		podExp, exists, err = manager.expectations.GetExpectations(rsKey)
0000000000000000000000000000000000000000;;		if !exists || err != nil || !podExp.Fulfilled() {
0000000000000000000000000000000000000000;;			t.Fatalf("Wrong expectations %#v", podExp)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// setupManagerWithGCEnabled creates a RS manager with a fakePodControl
0000000000000000000000000000000000000000;;	func setupManagerWithGCEnabled(stopCh chan struct{}, objs ...runtime.Object) (manager *ReplicaSetController, fakePodControl *controller.FakePodControl, informers informers.SharedInformerFactory) {
0000000000000000000000000000000000000000;;		c := fakeclientset.NewSimpleClientset(objs...)
0000000000000000000000000000000000000000;;		fakePodControl = &controller.FakePodControl{}
0000000000000000000000000000000000000000;;		manager, informers = testNewReplicaSetControllerFromClient(c, stopCh, BurstReplicas)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		manager.podControl = fakePodControl
0000000000000000000000000000000000000000;;		return manager, fakePodControl, informers
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestDoNotPatchPodWithOtherControlRef(t *testing.T) {
0000000000000000000000000000000000000000;;		labelMap := map[string]string{"foo": "bar"}
0000000000000000000000000000000000000000;;		rs := newReplicaSet(2, labelMap)
0000000000000000000000000000000000000000;;		stopCh := make(chan struct{})
0000000000000000000000000000000000000000;;		defer close(stopCh)
0000000000000000000000000000000000000000;;		manager, fakePodControl, informers := setupManagerWithGCEnabled(stopCh, rs)
0000000000000000000000000000000000000000;;		informers.Extensions().V1beta1().ReplicaSets().Informer().GetIndexer().Add(rs)
0000000000000000000000000000000000000000;;		var trueVar = true
0000000000000000000000000000000000000000;;		otherControllerReference := metav1.OwnerReference{UID: uuid.NewUUID(), APIVersion: "v1beta1", Kind: "ReplicaSet", Name: "AnotherRS", Controller: &trueVar}
0000000000000000000000000000000000000000;;		// add to podLister a matching Pod controlled by another controller. Expect no patch.
0000000000000000000000000000000000000000;;		pod := newPod("pod", rs, v1.PodRunning, nil, true)
0000000000000000000000000000000000000000;;		pod.OwnerReferences = []metav1.OwnerReference{otherControllerReference}
0000000000000000000000000000000000000000;;		informers.Core().V1().Pods().Informer().GetIndexer().Add(pod)
0000000000000000000000000000000000000000;;		err := manager.syncReplicaSet(getKey(rs, t))
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			t.Fatal(err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		// because the matching pod already has a controller, so 2 pods should be created.
0000000000000000000000000000000000000000;;		validateSyncReplicaSet(t, fakePodControl, 2, 0, 0)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestPatchPodWithOtherOwnerRef(t *testing.T) {
0000000000000000000000000000000000000000;;		labelMap := map[string]string{"foo": "bar"}
0000000000000000000000000000000000000000;;		rs := newReplicaSet(2, labelMap)
0000000000000000000000000000000000000000;;		stopCh := make(chan struct{})
0000000000000000000000000000000000000000;;		defer close(stopCh)
0000000000000000000000000000000000000000;;		manager, fakePodControl, informers := setupManagerWithGCEnabled(stopCh, rs)
0000000000000000000000000000000000000000;;		informers.Extensions().V1beta1().ReplicaSets().Informer().GetIndexer().Add(rs)
0000000000000000000000000000000000000000;;		// add to podLister one more matching pod that doesn't have a controller
0000000000000000000000000000000000000000;;		// ref, but has an owner ref pointing to other object. Expect a patch to
0000000000000000000000000000000000000000;;		// take control of it.
0000000000000000000000000000000000000000;;		unrelatedOwnerReference := metav1.OwnerReference{UID: uuid.NewUUID(), APIVersion: "batch/v1", Kind: "Job", Name: "Job"}
0000000000000000000000000000000000000000;;		pod := newPod("pod", rs, v1.PodRunning, nil, false)
0000000000000000000000000000000000000000;;		pod.OwnerReferences = []metav1.OwnerReference{unrelatedOwnerReference}
0000000000000000000000000000000000000000;;		informers.Core().V1().Pods().Informer().GetIndexer().Add(pod)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		err := manager.syncReplicaSet(getKey(rs, t))
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			t.Fatal(err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		// 1 patch to take control of pod, and 1 create of new pod.
0000000000000000000000000000000000000000;;		validateSyncReplicaSet(t, fakePodControl, 1, 0, 1)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestPatchPodWithCorrectOwnerRef(t *testing.T) {
0000000000000000000000000000000000000000;;		labelMap := map[string]string{"foo": "bar"}
0000000000000000000000000000000000000000;;		rs := newReplicaSet(2, labelMap)
0000000000000000000000000000000000000000;;		stopCh := make(chan struct{})
0000000000000000000000000000000000000000;;		defer close(stopCh)
0000000000000000000000000000000000000000;;		manager, fakePodControl, informers := setupManagerWithGCEnabled(stopCh, rs)
0000000000000000000000000000000000000000;;		informers.Extensions().V1beta1().ReplicaSets().Informer().GetIndexer().Add(rs)
0000000000000000000000000000000000000000;;		// add to podLister a matching pod that has an ownerRef pointing to the rs,
0000000000000000000000000000000000000000;;		// but ownerRef.Controller is false. Expect a patch to take control it.
0000000000000000000000000000000000000000;;		rsOwnerReference := metav1.OwnerReference{UID: rs.UID, APIVersion: "v1", Kind: "ReplicaSet", Name: rs.Name}
0000000000000000000000000000000000000000;;		pod := newPod("pod", rs, v1.PodRunning, nil, false)
0000000000000000000000000000000000000000;;		pod.OwnerReferences = []metav1.OwnerReference{rsOwnerReference}
0000000000000000000000000000000000000000;;		informers.Core().V1().Pods().Informer().GetIndexer().Add(pod)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		err := manager.syncReplicaSet(getKey(rs, t))
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			t.Fatal(err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		// 1 patch to take control of pod, and 1 create of new pod.
0000000000000000000000000000000000000000;;		validateSyncReplicaSet(t, fakePodControl, 1, 0, 1)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestPatchPodFails(t *testing.T) {
0000000000000000000000000000000000000000;;		labelMap := map[string]string{"foo": "bar"}
0000000000000000000000000000000000000000;;		rs := newReplicaSet(2, labelMap)
0000000000000000000000000000000000000000;;		stopCh := make(chan struct{})
0000000000000000000000000000000000000000;;		defer close(stopCh)
0000000000000000000000000000000000000000;;		manager, fakePodControl, informers := setupManagerWithGCEnabled(stopCh, rs)
0000000000000000000000000000000000000000;;		informers.Extensions().V1beta1().ReplicaSets().Informer().GetIndexer().Add(rs)
0000000000000000000000000000000000000000;;		// add to podLister two matching pods. Expect two patches to take control
0000000000000000000000000000000000000000;;		// them.
0000000000000000000000000000000000000000;;		informers.Core().V1().Pods().Informer().GetIndexer().Add(newPod("pod1", rs, v1.PodRunning, nil, false))
0000000000000000000000000000000000000000;;		informers.Core().V1().Pods().Informer().GetIndexer().Add(newPod("pod2", rs, v1.PodRunning, nil, false))
0000000000000000000000000000000000000000;;		// let both patches fail. The rs controller will assume it fails to take
0000000000000000000000000000000000000000;;		// control of the pods and requeue to try again.
0000000000000000000000000000000000000000;;		fakePodControl.Err = fmt.Errorf("Fake Error")
0000000000000000000000000000000000000000;;		rsKey := getKey(rs, t)
0000000000000000000000000000000000000000;;		err := processSync(manager, rsKey)
0000000000000000000000000000000000000000;;		if err == nil || !strings.Contains(err.Error(), "Fake Error") {
0000000000000000000000000000000000000000;;			t.Errorf("expected Fake Error, got %+v", err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		// 2 patches to take control of pod1 and pod2 (both fail).
0000000000000000000000000000000000000000;;		validateSyncReplicaSet(t, fakePodControl, 0, 0, 2)
0000000000000000000000000000000000000000;;		// RS should requeue itself.
0000000000000000000000000000000000000000;;		queueRS, _ := manager.queue.Get()
0000000000000000000000000000000000000000;;		if queueRS != rsKey {
0000000000000000000000000000000000000000;;			t.Fatalf("Expected to find key %v in queue, found %v", rsKey, queueRS)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestPatchExtraPodsThenDelete(t *testing.T) {
0000000000000000000000000000000000000000;;		labelMap := map[string]string{"foo": "bar"}
0000000000000000000000000000000000000000;;		rs := newReplicaSet(2, labelMap)
0000000000000000000000000000000000000000;;		stopCh := make(chan struct{})
0000000000000000000000000000000000000000;;		defer close(stopCh)
0000000000000000000000000000000000000000;;		manager, fakePodControl, informers := setupManagerWithGCEnabled(stopCh, rs)
0000000000000000000000000000000000000000;;		informers.Extensions().V1beta1().ReplicaSets().Informer().GetIndexer().Add(rs)
0000000000000000000000000000000000000000;;		// add to podLister three matching pods. Expect three patches to take control
0000000000000000000000000000000000000000;;		// them, and later delete one of them.
0000000000000000000000000000000000000000;;		informers.Core().V1().Pods().Informer().GetIndexer().Add(newPod("pod1", rs, v1.PodRunning, nil, false))
0000000000000000000000000000000000000000;;		informers.Core().V1().Pods().Informer().GetIndexer().Add(newPod("pod2", rs, v1.PodRunning, nil, false))
0000000000000000000000000000000000000000;;		informers.Core().V1().Pods().Informer().GetIndexer().Add(newPod("pod3", rs, v1.PodRunning, nil, false))
0000000000000000000000000000000000000000;;		err := manager.syncReplicaSet(getKey(rs, t))
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			t.Fatal(err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		// 3 patches to take control of the pods, and 1 deletion because there is an extra pod.
0000000000000000000000000000000000000000;;		validateSyncReplicaSet(t, fakePodControl, 0, 1, 3)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestUpdateLabelsRemoveControllerRef(t *testing.T) {
0000000000000000000000000000000000000000;;		labelMap := map[string]string{"foo": "bar"}
0000000000000000000000000000000000000000;;		rs := newReplicaSet(2, labelMap)
0000000000000000000000000000000000000000;;		stopCh := make(chan struct{})
0000000000000000000000000000000000000000;;		defer close(stopCh)
0000000000000000000000000000000000000000;;		manager, fakePodControl, informers := setupManagerWithGCEnabled(stopCh, rs)
0000000000000000000000000000000000000000;;		informers.Extensions().V1beta1().ReplicaSets().Informer().GetIndexer().Add(rs)
0000000000000000000000000000000000000000;;		// put one pod in the podLister
0000000000000000000000000000000000000000;;		pod := newPod("pod", rs, v1.PodRunning, nil, false)
0000000000000000000000000000000000000000;;		pod.ResourceVersion = "1"
0000000000000000000000000000000000000000;;		var trueVar = true
0000000000000000000000000000000000000000;;		rsOwnerReference := metav1.OwnerReference{UID: rs.UID, APIVersion: "v1beta1", Kind: "ReplicaSet", Name: rs.Name, Controller: &trueVar}
0000000000000000000000000000000000000000;;		pod.OwnerReferences = []metav1.OwnerReference{rsOwnerReference}
0000000000000000000000000000000000000000;;		updatedPod := *pod
0000000000000000000000000000000000000000;;		// reset the labels
0000000000000000000000000000000000000000;;		updatedPod.Labels = make(map[string]string)
0000000000000000000000000000000000000000;;		updatedPod.ResourceVersion = "2"
0000000000000000000000000000000000000000;;		// add the updatedPod to the store. This is consistent with the behavior of
0000000000000000000000000000000000000000;;		// the Informer: Informer updates the store before call the handler
0000000000000000000000000000000000000000;;		// (updatePod() in this case).
0000000000000000000000000000000000000000;;		informers.Core().V1().Pods().Informer().GetIndexer().Add(&updatedPod)
0000000000000000000000000000000000000000;;		// send a update of the same pod with modified labels
0000000000000000000000000000000000000000;;		manager.updatePod(pod, &updatedPod)
0000000000000000000000000000000000000000;;		// verifies that rs is added to the queue
0000000000000000000000000000000000000000;;		rsKey := getKey(rs, t)
0000000000000000000000000000000000000000;;		queueRS, _ := manager.queue.Get()
0000000000000000000000000000000000000000;;		if queueRS != rsKey {
0000000000000000000000000000000000000000;;			t.Fatalf("Expected to find key %v in queue, found %v", rsKey, queueRS)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		manager.queue.Done(queueRS)
0000000000000000000000000000000000000000;;		err := manager.syncReplicaSet(rsKey)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			t.Fatal(err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		// expect 1 patch to be sent to remove the controllerRef for the pod.
0000000000000000000000000000000000000000;;		// expect 2 creates because the *(rs.Spec.Replicas)=2 and there exists no
0000000000000000000000000000000000000000;;		// matching pod.
0000000000000000000000000000000000000000;;		validateSyncReplicaSet(t, fakePodControl, 2, 0, 1)
0000000000000000000000000000000000000000;;		fakePodControl.Clear()
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestUpdateSelectorControllerRef(t *testing.T) {
0000000000000000000000000000000000000000;;		labelMap := map[string]string{"foo": "bar"}
0000000000000000000000000000000000000000;;		rs := newReplicaSet(2, labelMap)
0000000000000000000000000000000000000000;;		stopCh := make(chan struct{})
0000000000000000000000000000000000000000;;		defer close(stopCh)
0000000000000000000000000000000000000000;;		manager, fakePodControl, informers := setupManagerWithGCEnabled(stopCh, rs)
0000000000000000000000000000000000000000;;		// put 2 pods in the podLister
0000000000000000000000000000000000000000;;		newPodList(informers.Core().V1().Pods().Informer().GetIndexer(), 2, v1.PodRunning, labelMap, rs, "pod")
0000000000000000000000000000000000000000;;		// update the RS so that its selector no longer matches the pods
0000000000000000000000000000000000000000;;		updatedRS := *rs
0000000000000000000000000000000000000000;;		updatedRS.Spec.Selector.MatchLabels = map[string]string{"foo": "baz"}
0000000000000000000000000000000000000000;;		// put the updatedRS into the store. This is consistent with the behavior of
0000000000000000000000000000000000000000;;		// the Informer: Informer updates the store before call the handler
0000000000000000000000000000000000000000;;		// (updateRS() in this case).
0000000000000000000000000000000000000000;;		informers.Extensions().V1beta1().ReplicaSets().Informer().GetIndexer().Add(&updatedRS)
0000000000000000000000000000000000000000;;		manager.updateRS(rs, &updatedRS)
0000000000000000000000000000000000000000;;		// verifies that the rs is added to the queue
0000000000000000000000000000000000000000;;		rsKey := getKey(rs, t)
0000000000000000000000000000000000000000;;		queueRS, _ := manager.queue.Get()
0000000000000000000000000000000000000000;;		if queueRS != rsKey {
0000000000000000000000000000000000000000;;			t.Fatalf("Expected to find key %v in queue, found %v", rsKey, queueRS)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		manager.queue.Done(queueRS)
0000000000000000000000000000000000000000;;		err := manager.syncReplicaSet(rsKey)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			t.Fatal(err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		// expect 2 patches to be sent to remove the controllerRef for the pods.
0000000000000000000000000000000000000000;;		// expect 2 creates because the *(rc.Spec.Replicas)=2 and there exists no
0000000000000000000000000000000000000000;;		// matching pod.
0000000000000000000000000000000000000000;;		validateSyncReplicaSet(t, fakePodControl, 2, 0, 2)
0000000000000000000000000000000000000000;;		fakePodControl.Clear()
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// RS controller shouldn't adopt or create more pods if the rc is about to be
0000000000000000000000000000000000000000;;	// deleted.
0000000000000000000000000000000000000000;;	func TestDoNotAdoptOrCreateIfBeingDeleted(t *testing.T) {
0000000000000000000000000000000000000000;;		labelMap := map[string]string{"foo": "bar"}
0000000000000000000000000000000000000000;;		rs := newReplicaSet(2, labelMap)
0000000000000000000000000000000000000000;;		now := metav1.Now()
0000000000000000000000000000000000000000;;		rs.DeletionTimestamp = &now
0000000000000000000000000000000000000000;;		stopCh := make(chan struct{})
0000000000000000000000000000000000000000;;		defer close(stopCh)
0000000000000000000000000000000000000000;;		manager, fakePodControl, informers := setupManagerWithGCEnabled(stopCh, rs)
0000000000000000000000000000000000000000;;		informers.Extensions().V1beta1().ReplicaSets().Informer().GetIndexer().Add(rs)
0000000000000000000000000000000000000000;;		pod1 := newPod("pod1", rs, v1.PodRunning, nil, false)
0000000000000000000000000000000000000000;;		informers.Core().V1().Pods().Informer().GetIndexer().Add(pod1)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// no patch, no create
0000000000000000000000000000000000000000;;		err := manager.syncReplicaSet(getKey(rs, t))
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			t.Fatal(err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		validateSyncReplicaSet(t, fakePodControl, 0, 0, 0)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestDoNotAdoptOrCreateIfBeingDeletedRace(t *testing.T) {
0000000000000000000000000000000000000000;;		labelMap := map[string]string{"foo": "bar"}
0000000000000000000000000000000000000000;;		// Bare client says it IS deleted.
0000000000000000000000000000000000000000;;		rs := newReplicaSet(2, labelMap)
0000000000000000000000000000000000000000;;		now := metav1.Now()
0000000000000000000000000000000000000000;;		rs.DeletionTimestamp = &now
0000000000000000000000000000000000000000;;		stopCh := make(chan struct{})
0000000000000000000000000000000000000000;;		defer close(stopCh)
0000000000000000000000000000000000000000;;		manager, fakePodControl, informers := setupManagerWithGCEnabled(stopCh, rs)
0000000000000000000000000000000000000000;;		// Lister (cache) says it's NOT deleted.
0000000000000000000000000000000000000000;;		rs2 := *rs
0000000000000000000000000000000000000000;;		rs2.DeletionTimestamp = nil
0000000000000000000000000000000000000000;;		informers.Extensions().V1beta1().ReplicaSets().Informer().GetIndexer().Add(&rs2)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Recheck occurs if a matching orphan is present.
0000000000000000000000000000000000000000;;		pod1 := newPod("pod1", rs, v1.PodRunning, nil, false)
0000000000000000000000000000000000000000;;		informers.Core().V1().Pods().Informer().GetIndexer().Add(pod1)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// sync should abort.
0000000000000000000000000000000000000000;;		err := manager.syncReplicaSet(getKey(rs, t))
0000000000000000000000000000000000000000;;		if err == nil {
0000000000000000000000000000000000000000;;			t.Error("syncReplicaSet() err = nil, expected non-nil")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		// no patch, no create.
0000000000000000000000000000000000000000;;		validateSyncReplicaSet(t, fakePodControl, 0, 0, 0)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestReadyReplicas(t *testing.T) {
0000000000000000000000000000000000000000;;		// This is a happy server just to record the PUT request we expect for status.Replicas
0000000000000000000000000000000000000000;;		fakeHandler := utiltesting.FakeHandler{
0000000000000000000000000000000000000000;;			StatusCode:    200,
0000000000000000000000000000000000000000;;			ResponseBody:  "{}",
0000000000000000000000000000000000000000;;			SkipRequestFn: skipListerFunc,
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		testServer := httptest.NewServer(&fakeHandler)
0000000000000000000000000000000000000000;;		defer testServer.Close()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		client := clientset.NewForConfigOrDie(&restclient.Config{Host: testServer.URL, ContentConfig: restclient.ContentConfig{GroupVersion: &api.Registry.GroupOrDie(v1.GroupName).GroupVersion}})
0000000000000000000000000000000000000000;;		stopCh := make(chan struct{})
0000000000000000000000000000000000000000;;		defer close(stopCh)
0000000000000000000000000000000000000000;;		manager, informers := testNewReplicaSetControllerFromClient(client, stopCh, BurstReplicas)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Status.Replica should update to match number of pods in system, 1 new pod should be created.
0000000000000000000000000000000000000000;;		labelMap := map[string]string{"foo": "bar"}
0000000000000000000000000000000000000000;;		rs := newReplicaSet(2, labelMap)
0000000000000000000000000000000000000000;;		rs.Status = extensions.ReplicaSetStatus{Replicas: 2, ReadyReplicas: 0, AvailableReplicas: 0, ObservedGeneration: 1}
0000000000000000000000000000000000000000;;		rs.Generation = 1
0000000000000000000000000000000000000000;;		informers.Extensions().V1beta1().ReplicaSets().Informer().GetIndexer().Add(rs)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		newPodList(informers.Core().V1().Pods().Informer().GetIndexer(), 2, v1.PodPending, labelMap, rs, "pod")
0000000000000000000000000000000000000000;;		newPodList(informers.Core().V1().Pods().Informer().GetIndexer(), 2, v1.PodRunning, labelMap, rs, "pod")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// This response body is just so we don't err out decoding the http response
0000000000000000000000000000000000000000;;		response := runtime.EncodeOrDie(testapi.Extensions.Codec(), &extensions.ReplicaSet{})
0000000000000000000000000000000000000000;;		fakeHandler.SetResponseBody(response)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		fakePodControl := controller.FakePodControl{}
0000000000000000000000000000000000000000;;		manager.podControl = &fakePodControl
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		manager.syncReplicaSet(getKey(rs, t))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// ReadyReplicas should go from 0 to 2.
0000000000000000000000000000000000000000;;		rs.Status = extensions.ReplicaSetStatus{Replicas: 2, ReadyReplicas: 2, AvailableReplicas: 2, ObservedGeneration: 1}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		decRs := runtime.EncodeOrDie(testapi.Extensions.Codec(), rs)
0000000000000000000000000000000000000000;;		fakeHandler.ValidateRequest(t, testapi.Extensions.ResourcePath(replicaSetResourceName(), rs.Namespace, rs.Name)+"/status", "PUT", &decRs)
0000000000000000000000000000000000000000;;		validateSyncReplicaSet(t, &fakePodControl, 0, 0, 0)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestAvailableReplicas(t *testing.T) {
0000000000000000000000000000000000000000;;		// This is a happy server just to record the PUT request we expect for status.Replicas
0000000000000000000000000000000000000000;;		fakeHandler := utiltesting.FakeHandler{
0000000000000000000000000000000000000000;;			StatusCode:    200,
0000000000000000000000000000000000000000;;			ResponseBody:  "{}",
0000000000000000000000000000000000000000;;			SkipRequestFn: skipListerFunc,
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		testServer := httptest.NewServer(&fakeHandler)
0000000000000000000000000000000000000000;;		defer testServer.Close()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		client := clientset.NewForConfigOrDie(&restclient.Config{Host: testServer.URL, ContentConfig: restclient.ContentConfig{GroupVersion: &api.Registry.GroupOrDie(v1.GroupName).GroupVersion}})
0000000000000000000000000000000000000000;;		stopCh := make(chan struct{})
0000000000000000000000000000000000000000;;		defer close(stopCh)
0000000000000000000000000000000000000000;;		manager, informers := testNewReplicaSetControllerFromClient(client, stopCh, BurstReplicas)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Status.Replica should update to match number of pods in system, 1 new pod should be created.
0000000000000000000000000000000000000000;;		labelMap := map[string]string{"foo": "bar"}
0000000000000000000000000000000000000000;;		rs := newReplicaSet(2, labelMap)
0000000000000000000000000000000000000000;;		rs.Status = extensions.ReplicaSetStatus{Replicas: 2, ReadyReplicas: 0, AvailableReplicas: 0, ObservedGeneration: 1}
0000000000000000000000000000000000000000;;		rs.Generation = 1
0000000000000000000000000000000000000000;;		// minReadySeconds set to 15s
0000000000000000000000000000000000000000;;		rs.Spec.MinReadySeconds = 15
0000000000000000000000000000000000000000;;		informers.Extensions().V1beta1().ReplicaSets().Informer().GetIndexer().Add(rs)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// First pod becomes ready 20s ago
0000000000000000000000000000000000000000;;		moment := metav1.Time{Time: time.Now().Add(-2e10)}
0000000000000000000000000000000000000000;;		pod := newPod("pod", rs, v1.PodRunning, &moment, true)
0000000000000000000000000000000000000000;;		informers.Core().V1().Pods().Informer().GetIndexer().Add(pod)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Second pod becomes ready now
0000000000000000000000000000000000000000;;		otherMoment := metav1.Now()
0000000000000000000000000000000000000000;;		otherPod := newPod("otherPod", rs, v1.PodRunning, &otherMoment, true)
0000000000000000000000000000000000000000;;		informers.Core().V1().Pods().Informer().GetIndexer().Add(otherPod)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// This response body is just so we don't err out decoding the http response
0000000000000000000000000000000000000000;;		response := runtime.EncodeOrDie(testapi.Extensions.Codec(), &extensions.ReplicaSet{})
0000000000000000000000000000000000000000;;		fakeHandler.SetResponseBody(response)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		fakePodControl := controller.FakePodControl{}
0000000000000000000000000000000000000000;;		manager.podControl = &fakePodControl
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// The controller should see only one available pod.
0000000000000000000000000000000000000000;;		manager.syncReplicaSet(getKey(rs, t))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		rs.Status = extensions.ReplicaSetStatus{Replicas: 2, ReadyReplicas: 2, AvailableReplicas: 1, ObservedGeneration: 1}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		decRs := runtime.EncodeOrDie(testapi.Extensions.Codec(), rs)
0000000000000000000000000000000000000000;;		fakeHandler.ValidateRequest(t, testapi.Extensions.ResourcePath(replicaSetResourceName(), rs.Namespace, rs.Name)+"/status", "PUT", &decRs)
0000000000000000000000000000000000000000;;		validateSyncReplicaSet(t, &fakePodControl, 0, 0, 0)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	var (
0000000000000000000000000000000000000000;;		imagePullBackOff extensions.ReplicaSetConditionType = "ImagePullBackOff"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		condImagePullBackOff = func() extensions.ReplicaSetCondition {
0000000000000000000000000000000000000000;;			return extensions.ReplicaSetCondition{
0000000000000000000000000000000000000000;;				Type:   imagePullBackOff,
0000000000000000000000000000000000000000;;				Status: v1.ConditionTrue,
0000000000000000000000000000000000000000;;				Reason: "NonExistentImage",
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		condReplicaFailure = func() extensions.ReplicaSetCondition {
0000000000000000000000000000000000000000;;			return extensions.ReplicaSetCondition{
0000000000000000000000000000000000000000;;				Type:   extensions.ReplicaSetReplicaFailure,
0000000000000000000000000000000000000000;;				Status: v1.ConditionTrue,
0000000000000000000000000000000000000000;;				Reason: "OtherFailure",
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		condReplicaFailure2 = func() extensions.ReplicaSetCondition {
0000000000000000000000000000000000000000;;			return extensions.ReplicaSetCondition{
0000000000000000000000000000000000000000;;				Type:   extensions.ReplicaSetReplicaFailure,
0000000000000000000000000000000000000000;;				Status: v1.ConditionTrue,
0000000000000000000000000000000000000000;;				Reason: "AnotherFailure",
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		status = func() *extensions.ReplicaSetStatus {
0000000000000000000000000000000000000000;;			return &extensions.ReplicaSetStatus{
0000000000000000000000000000000000000000;;				Conditions: []extensions.ReplicaSetCondition{condReplicaFailure()},
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestGetCondition(t *testing.T) {
0000000000000000000000000000000000000000;;		exampleStatus := status()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		tests := []struct {
0000000000000000000000000000000000000000;;			name string
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			status     extensions.ReplicaSetStatus
0000000000000000000000000000000000000000;;			condType   extensions.ReplicaSetConditionType
0000000000000000000000000000000000000000;;			condStatus v1.ConditionStatus
0000000000000000000000000000000000000000;;			condReason string
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			expected bool
0000000000000000000000000000000000000000;;		}{
0000000000000000000000000000000000000000;;			{
0000000000000000000000000000000000000000;;				name: "condition exists",
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				status:   *exampleStatus,
0000000000000000000000000000000000000000;;				condType: extensions.ReplicaSetReplicaFailure,
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				expected: true,
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			{
0000000000000000000000000000000000000000;;				name: "condition does not exist",
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				status:   *exampleStatus,
0000000000000000000000000000000000000000;;				condType: imagePullBackOff,
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				expected: false,
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		for _, test := range tests {
0000000000000000000000000000000000000000;;			cond := GetCondition(test.status, test.condType)
0000000000000000000000000000000000000000;;			exists := cond != nil
0000000000000000000000000000000000000000;;			if exists != test.expected {
0000000000000000000000000000000000000000;;				t.Errorf("%s: expected condition to exist: %t, got: %t", test.name, test.expected, exists)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestSetCondition(t *testing.T) {
0000000000000000000000000000000000000000;;		tests := []struct {
0000000000000000000000000000000000000000;;			name string
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			status *extensions.ReplicaSetStatus
0000000000000000000000000000000000000000;;			cond   extensions.ReplicaSetCondition
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			expectedStatus *extensions.ReplicaSetStatus
0000000000000000000000000000000000000000;;		}{
0000000000000000000000000000000000000000;;			{
0000000000000000000000000000000000000000;;				name: "set for the first time",
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				status: &extensions.ReplicaSetStatus{},
0000000000000000000000000000000000000000;;				cond:   condReplicaFailure(),
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				expectedStatus: &extensions.ReplicaSetStatus{Conditions: []extensions.ReplicaSetCondition{condReplicaFailure()}},
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			{
0000000000000000000000000000000000000000;;				name: "simple set",
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				status: &extensions.ReplicaSetStatus{Conditions: []extensions.ReplicaSetCondition{condImagePullBackOff()}},
0000000000000000000000000000000000000000;;				cond:   condReplicaFailure(),
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				expectedStatus: &extensions.ReplicaSetStatus{Conditions: []extensions.ReplicaSetCondition{condImagePullBackOff(), condReplicaFailure()}},
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			{
0000000000000000000000000000000000000000;;				name: "overwrite",
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				status: &extensions.ReplicaSetStatus{Conditions: []extensions.ReplicaSetCondition{condReplicaFailure()}},
0000000000000000000000000000000000000000;;				cond:   condReplicaFailure2(),
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				expectedStatus: &extensions.ReplicaSetStatus{Conditions: []extensions.ReplicaSetCondition{condReplicaFailure2()}},
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		for _, test := range tests {
0000000000000000000000000000000000000000;;			SetCondition(test.status, test.cond)
0000000000000000000000000000000000000000;;			if !reflect.DeepEqual(test.status, test.expectedStatus) {
0000000000000000000000000000000000000000;;				t.Errorf("%s: expected status: %v, got: %v", test.name, test.expectedStatus, test.status)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestRemoveCondition(t *testing.T) {
0000000000000000000000000000000000000000;;		tests := []struct {
0000000000000000000000000000000000000000;;			name string
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			status   *extensions.ReplicaSetStatus
0000000000000000000000000000000000000000;;			condType extensions.ReplicaSetConditionType
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			expectedStatus *extensions.ReplicaSetStatus
0000000000000000000000000000000000000000;;		}{
0000000000000000000000000000000000000000;;			{
0000000000000000000000000000000000000000;;				name: "remove from empty status",
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				status:   &extensions.ReplicaSetStatus{},
0000000000000000000000000000000000000000;;				condType: extensions.ReplicaSetReplicaFailure,
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				expectedStatus: &extensions.ReplicaSetStatus{},
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			{
0000000000000000000000000000000000000000;;				name: "simple remove",
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				status:   &extensions.ReplicaSetStatus{Conditions: []extensions.ReplicaSetCondition{condReplicaFailure()}},
0000000000000000000000000000000000000000;;				condType: extensions.ReplicaSetReplicaFailure,
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				expectedStatus: &extensions.ReplicaSetStatus{},
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			{
0000000000000000000000000000000000000000;;				name: "doesn't remove anything",
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				status:   status(),
0000000000000000000000000000000000000000;;				condType: imagePullBackOff,
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				expectedStatus: status(),
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		for _, test := range tests {
0000000000000000000000000000000000000000;;			RemoveCondition(test.status, test.condType)
0000000000000000000000000000000000000000;;			if !reflect.DeepEqual(test.status, test.expectedStatus) {
0000000000000000000000000000000000000000;;				t.Errorf("%s: expected status: %v, got: %v", test.name, test.expectedStatus, test.status)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
