0000000000000000000000000000000000000000;;	/*
0000000000000000000000000000000000000000;;	Copyright 2014 The Kubernetes Authors.
9fbdd758c00a160e902805405146a779d3acf5d8;pkg/registry/endpoints.go[pkg/registry/endpoints.go][pkg/controller/endpoint/endpoints_controller.go];	
0000000000000000000000000000000000000000;;	Licensed under the Apache License, Version 2.0 (the "License");
0000000000000000000000000000000000000000;;	you may not use this file except in compliance with the License.
0000000000000000000000000000000000000000;;	You may obtain a copy of the License at
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	    http://www.apache.org/licenses/LICENSE-2.0
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	Unless required by applicable law or agreed to in writing, software
0000000000000000000000000000000000000000;;	distributed under the License is distributed on an "AS IS" BASIS,
0000000000000000000000000000000000000000;;	WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
0000000000000000000000000000000000000000;;	See the License for the specific language governing permissions and
0000000000000000000000000000000000000000;;	limitations under the License.
0000000000000000000000000000000000000000;;	*/
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	package endpoint
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	import (
0000000000000000000000000000000000000000;;		"fmt"
0000000000000000000000000000000000000000;;		"reflect"
0000000000000000000000000000000000000000;;		"strconv"
0000000000000000000000000000000000000000;;		"time"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		"k8s.io/api/core/v1"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/api/errors"
0000000000000000000000000000000000000000;;		metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/labels"
0000000000000000000000000000000000000000;;		utilruntime "k8s.io/apimachinery/pkg/util/runtime"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/util/sets"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/util/wait"
0000000000000000000000000000000000000000;;		"k8s.io/client-go/tools/cache"
0000000000000000000000000000000000000000;;		"k8s.io/client-go/tools/leaderelection/resourcelock"
0000000000000000000000000000000000000000;;		"k8s.io/client-go/util/workqueue"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/api"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/api/v1/endpoints"
0000000000000000000000000000000000000000;;		podutil "k8s.io/kubernetes/pkg/api/v1/pod"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/client/clientset_generated/clientset"
0000000000000000000000000000000000000000;;		coreinformers "k8s.io/kubernetes/pkg/client/informers/informers_generated/externalversions/core/v1"
0000000000000000000000000000000000000000;;		corelisters "k8s.io/kubernetes/pkg/client/listers/core/v1"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/controller"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/util/metrics"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		"github.com/golang/glog"
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	const (
0000000000000000000000000000000000000000;;		// maxRetries is the number of times a service will be retried before it is dropped out of the queue.
0000000000000000000000000000000000000000;;		// With the current rate-limiter in use (5ms*2^(maxRetries-1)) the following numbers represent the
0000000000000000000000000000000000000000;;		// sequence of delays between successive queuings of a service.
0000000000000000000000000000000000000000;;		//
0000000000000000000000000000000000000000;;		// 5ms, 10ms, 20ms, 40ms, 80ms, 160ms, 320ms, 640ms, 1.3s, 2.6s, 5.1s, 10.2s, 20.4s, 41s, 82s
0000000000000000000000000000000000000000;;		maxRetries = 15
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// An annotation on the Service denoting if the endpoints controller should
0000000000000000000000000000000000000000;;		// go ahead and create endpoints for unready pods. This annotation is
0000000000000000000000000000000000000000;;		// currently only used by StatefulSets, where we need the pod to be DNS
0000000000000000000000000000000000000000;;		// resolvable during initialization and termination. In this situation we
0000000000000000000000000000000000000000;;		// create a headless Service just for the StatefulSet, and clients shouldn't
0000000000000000000000000000000000000000;;		// be using this Service for anything so unready endpoints don't matter.
0000000000000000000000000000000000000000;;		// Endpoints of these Services retain their DNS records and continue
0000000000000000000000000000000000000000;;		// receiving traffic for the Service from the moment the kubelet starts all
0000000000000000000000000000000000000000;;		// containers in the pod and marks it "Running", till the kubelet stops all
0000000000000000000000000000000000000000;;		// containers and deletes the pod from the apiserver.
0000000000000000000000000000000000000000;;		TolerateUnreadyEndpointsAnnotation = "service.alpha.kubernetes.io/tolerate-unready-endpoints"
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	var (
0000000000000000000000000000000000000000;;		keyFunc = cache.DeletionHandlingMetaNamespaceKeyFunc
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// NewEndpointController returns a new *EndpointController.
0000000000000000000000000000000000000000;;	func NewEndpointController(podInformer coreinformers.PodInformer, serviceInformer coreinformers.ServiceInformer,
0000000000000000000000000000000000000000;;		endpointsInformer coreinformers.EndpointsInformer, client clientset.Interface) *EndpointController {
0000000000000000000000000000000000000000;;		if client != nil && client.Core().RESTClient().GetRateLimiter() != nil {
0000000000000000000000000000000000000000;;			metrics.RegisterMetricAndTrackRateLimiterUsage("endpoint_controller", client.Core().RESTClient().GetRateLimiter())
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		e := &EndpointController{
0000000000000000000000000000000000000000;;			client:           client,
0000000000000000000000000000000000000000;;			queue:            workqueue.NewNamedRateLimitingQueue(workqueue.DefaultControllerRateLimiter(), "endpoint"),
0000000000000000000000000000000000000000;;			workerLoopPeriod: time.Second,
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		serviceInformer.Informer().AddEventHandler(cache.ResourceEventHandlerFuncs{
0000000000000000000000000000000000000000;;			AddFunc: e.enqueueService,
0000000000000000000000000000000000000000;;			UpdateFunc: func(old, cur interface{}) {
0000000000000000000000000000000000000000;;				e.enqueueService(cur)
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			DeleteFunc: e.enqueueService,
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;		e.serviceLister = serviceInformer.Lister()
0000000000000000000000000000000000000000;;		e.servicesSynced = serviceInformer.Informer().HasSynced
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		podInformer.Informer().AddEventHandler(cache.ResourceEventHandlerFuncs{
0000000000000000000000000000000000000000;;			AddFunc:    e.addPod,
0000000000000000000000000000000000000000;;			UpdateFunc: e.updatePod,
0000000000000000000000000000000000000000;;			DeleteFunc: e.deletePod,
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;		e.podLister = podInformer.Lister()
0000000000000000000000000000000000000000;;		e.podsSynced = podInformer.Informer().HasSynced
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		e.endpointsLister = endpointsInformer.Lister()
0000000000000000000000000000000000000000;;		e.endpointsSynced = endpointsInformer.Informer().HasSynced
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return e
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// EndpointController manages selector-based service endpoints.
0000000000000000000000000000000000000000;;	type EndpointController struct {
0000000000000000000000000000000000000000;;		client clientset.Interface
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// serviceLister is able to list/get services and is populated by the shared informer passed to
0000000000000000000000000000000000000000;;		// NewEndpointController.
0000000000000000000000000000000000000000;;		serviceLister corelisters.ServiceLister
0000000000000000000000000000000000000000;;		// servicesSynced returns true if the service shared informer has been synced at least once.
0000000000000000000000000000000000000000;;		// Added as a member to the struct to allow injection for testing.
0000000000000000000000000000000000000000;;		servicesSynced cache.InformerSynced
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// podLister is able to list/get pods and is populated by the shared informer passed to
0000000000000000000000000000000000000000;;		// NewEndpointController.
0000000000000000000000000000000000000000;;		podLister corelisters.PodLister
0000000000000000000000000000000000000000;;		// podsSynced returns true if the pod shared informer has been synced at least once.
0000000000000000000000000000000000000000;;		// Added as a member to the struct to allow injection for testing.
0000000000000000000000000000000000000000;;		podsSynced cache.InformerSynced
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// endpointsLister is able to list/get endpoints and is populated by the shared informer passed to
0000000000000000000000000000000000000000;;		// NewEndpointController.
0000000000000000000000000000000000000000;;		endpointsLister corelisters.EndpointsLister
0000000000000000000000000000000000000000;;		// endpointsSynced returns true if the endpoints shared informer has been synced at least once.
0000000000000000000000000000000000000000;;		// Added as a member to the struct to allow injection for testing.
0000000000000000000000000000000000000000;;		endpointsSynced cache.InformerSynced
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Services that need to be updated. A channel is inappropriate here,
0000000000000000000000000000000000000000;;		// because it allows services with lots of pods to be serviced much
0000000000000000000000000000000000000000;;		// more often than services with few pods; it also would cause a
0000000000000000000000000000000000000000;;		// service that's inserted multiple times to be processed more than
0000000000000000000000000000000000000000;;		// necessary.
0000000000000000000000000000000000000000;;		queue workqueue.RateLimitingInterface
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// workerLoopPeriod is the time between worker runs. The workers process the queue of service and pod changes.
0000000000000000000000000000000000000000;;		workerLoopPeriod time.Duration
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Runs e; will not return until stopCh is closed. workers determines how many
0000000000000000000000000000000000000000;;	// endpoints will be handled in parallel.
0000000000000000000000000000000000000000;;	func (e *EndpointController) Run(workers int, stopCh <-chan struct{}) {
0000000000000000000000000000000000000000;;		defer utilruntime.HandleCrash()
0000000000000000000000000000000000000000;;		defer e.queue.ShutDown()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		glog.Infof("Starting endpoint controller")
0000000000000000000000000000000000000000;;		defer glog.Infof("Shutting down endpoint controller")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if !controller.WaitForCacheSync("endpoint", stopCh, e.podsSynced, e.servicesSynced, e.endpointsSynced) {
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		for i := 0; i < workers; i++ {
0000000000000000000000000000000000000000;;			go wait.Until(e.worker, e.workerLoopPeriod, stopCh)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		go func() {
0000000000000000000000000000000000000000;;			defer utilruntime.HandleCrash()
0000000000000000000000000000000000000000;;			e.checkLeftoverEndpoints()
0000000000000000000000000000000000000000;;		}()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		<-stopCh
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (e *EndpointController) getPodServiceMemberships(pod *v1.Pod) (sets.String, error) {
0000000000000000000000000000000000000000;;		set := sets.String{}
0000000000000000000000000000000000000000;;		services, err := e.serviceLister.GetPodServices(pod)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			// don't log this error because this function makes pointless
0000000000000000000000000000000000000000;;			// errors when no services match.
0000000000000000000000000000000000000000;;			return set, nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		for i := range services {
0000000000000000000000000000000000000000;;			key, err := keyFunc(services[i])
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				return nil, err
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			set.Insert(key)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return set, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// When a pod is added, figure out what services it will be a member of and
0000000000000000000000000000000000000000;;	// enqueue them. obj must have *v1.Pod type.
0000000000000000000000000000000000000000;;	func (e *EndpointController) addPod(obj interface{}) {
0000000000000000000000000000000000000000;;		pod := obj.(*v1.Pod)
0000000000000000000000000000000000000000;;		services, err := e.getPodServiceMemberships(pod)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			utilruntime.HandleError(fmt.Errorf("Unable to get pod %v/%v's service memberships: %v", pod.Namespace, pod.Name, err))
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		for key := range services {
0000000000000000000000000000000000000000;;			e.queue.Add(key)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// When a pod is updated, figure out what services it used to be a member of
0000000000000000000000000000000000000000;;	// and what services it will be a member of, and enqueue the union of these.
0000000000000000000000000000000000000000;;	// old and cur must be *v1.Pod types.
0000000000000000000000000000000000000000;;	func (e *EndpointController) updatePod(old, cur interface{}) {
0000000000000000000000000000000000000000;;		newPod := cur.(*v1.Pod)
0000000000000000000000000000000000000000;;		oldPod := old.(*v1.Pod)
0000000000000000000000000000000000000000;;		if newPod.ResourceVersion == oldPod.ResourceVersion {
0000000000000000000000000000000000000000;;			// Periodic resync will send update events for all known pods.
0000000000000000000000000000000000000000;;			// Two different versions of the same pod will always have different RVs.
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		services, err := e.getPodServiceMemberships(newPod)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			utilruntime.HandleError(fmt.Errorf("Unable to get pod %v/%v's service memberships: %v", newPod.Namespace, newPod.Name, err))
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Only need to get the old services if the labels changed.
0000000000000000000000000000000000000000;;		if !reflect.DeepEqual(newPod.Labels, oldPod.Labels) ||
0000000000000000000000000000000000000000;;			!hostNameAndDomainAreEqual(newPod, oldPod) {
0000000000000000000000000000000000000000;;			oldServices, err := e.getPodServiceMemberships(oldPod)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				utilruntime.HandleError(fmt.Errorf("Unable to get pod %v/%v's service memberships: %v", oldPod.Namespace, oldPod.Name, err))
0000000000000000000000000000000000000000;;				return
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			services = services.Union(oldServices)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		for key := range services {
0000000000000000000000000000000000000000;;			e.queue.Add(key)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func hostNameAndDomainAreEqual(pod1, pod2 *v1.Pod) bool {
0000000000000000000000000000000000000000;;		return pod1.Spec.Hostname == pod2.Spec.Hostname &&
0000000000000000000000000000000000000000;;			pod1.Spec.Subdomain == pod2.Spec.Subdomain
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// When a pod is deleted, enqueue the services the pod used to be a member of.
0000000000000000000000000000000000000000;;	// obj could be an *v1.Pod, or a DeletionFinalStateUnknown marker item.
0000000000000000000000000000000000000000;;	func (e *EndpointController) deletePod(obj interface{}) {
0000000000000000000000000000000000000000;;		if _, ok := obj.(*v1.Pod); ok {
0000000000000000000000000000000000000000;;			// Enqueue all the services that the pod used to be a member
0000000000000000000000000000000000000000;;			// of. This happens to be exactly the same thing we do when a
0000000000000000000000000000000000000000;;			// pod is added.
0000000000000000000000000000000000000000;;			e.addPod(obj)
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		// If we reached here it means the pod was deleted but its final state is unrecorded.
0000000000000000000000000000000000000000;;		tombstone, ok := obj.(cache.DeletedFinalStateUnknown)
0000000000000000000000000000000000000000;;		if !ok {
0000000000000000000000000000000000000000;;			utilruntime.HandleError(fmt.Errorf("Couldn't get object from tombstone %#v", obj))
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		pod, ok := tombstone.Obj.(*v1.Pod)
0000000000000000000000000000000000000000;;		if !ok {
0000000000000000000000000000000000000000;;			utilruntime.HandleError(fmt.Errorf("Tombstone contained object that is not a Pod: %#v", obj))
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		glog.V(4).Infof("Enqueuing services of deleted pod %s having final state unrecorded", pod.Name)
0000000000000000000000000000000000000000;;		e.addPod(pod)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// obj could be an *v1.Service, or a DeletionFinalStateUnknown marker item.
0000000000000000000000000000000000000000;;	func (e *EndpointController) enqueueService(obj interface{}) {
0000000000000000000000000000000000000000;;		key, err := keyFunc(obj)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			utilruntime.HandleError(fmt.Errorf("Couldn't get key for object %+v: %v", obj, err))
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		e.queue.Add(key)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// worker runs a worker thread that just dequeues items, processes them, and
0000000000000000000000000000000000000000;;	// marks them done. You may run as many of these in parallel as you wish; the
0000000000000000000000000000000000000000;;	// workqueue guarantees that they will not end up processing the same service
0000000000000000000000000000000000000000;;	// at the same time.
0000000000000000000000000000000000000000;;	func (e *EndpointController) worker() {
0000000000000000000000000000000000000000;;		for e.processNextWorkItem() {
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (e *EndpointController) processNextWorkItem() bool {
0000000000000000000000000000000000000000;;		eKey, quit := e.queue.Get()
0000000000000000000000000000000000000000;;		if quit {
0000000000000000000000000000000000000000;;			return false
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		defer e.queue.Done(eKey)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		err := e.syncService(eKey.(string))
0000000000000000000000000000000000000000;;		e.handleErr(err, eKey)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return true
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (e *EndpointController) handleErr(err error, key interface{}) {
0000000000000000000000000000000000000000;;		if err == nil {
0000000000000000000000000000000000000000;;			e.queue.Forget(key)
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if e.queue.NumRequeues(key) < maxRetries {
0000000000000000000000000000000000000000;;			glog.V(2).Infof("Error syncing endpoints for service %q: %v", key, err)
0000000000000000000000000000000000000000;;			e.queue.AddRateLimited(key)
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		glog.Warningf("Dropping service %q out of the queue: %v", key, err)
0000000000000000000000000000000000000000;;		e.queue.Forget(key)
0000000000000000000000000000000000000000;;		utilruntime.HandleError(err)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (e *EndpointController) syncService(key string) error {
0000000000000000000000000000000000000000;;		startTime := time.Now()
0000000000000000000000000000000000000000;;		defer func() {
0000000000000000000000000000000000000000;;			glog.V(4).Infof("Finished syncing service %q endpoints. (%v)", key, time.Now().Sub(startTime))
0000000000000000000000000000000000000000;;		}()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		namespace, name, err := cache.SplitMetaNamespaceKey(key)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		service, err := e.serviceLister.Services(namespace).Get(name)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			// Delete the corresponding endpoint, as the service has been deleted.
0000000000000000000000000000000000000000;;			// TODO: Please note that this will delete an endpoint when a
0000000000000000000000000000000000000000;;			// service is deleted. However, if we're down at the time when
0000000000000000000000000000000000000000;;			// the service is deleted, we will miss that deletion, so this
0000000000000000000000000000000000000000;;			// doesn't completely solve the problem. See #6877.
0000000000000000000000000000000000000000;;			namespace, name, err := cache.SplitMetaNamespaceKey(key)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				utilruntime.HandleError(fmt.Errorf("Need to delete endpoint with key %q, but couldn't understand the key: %v", key, err))
0000000000000000000000000000000000000000;;				// Don't retry, as the key isn't going to magically become understandable.
0000000000000000000000000000000000000000;;				return nil
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			err = e.client.Core().Endpoints(namespace).Delete(name, nil)
0000000000000000000000000000000000000000;;			if err != nil && !errors.IsNotFound(err) {
0000000000000000000000000000000000000000;;				return err
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			return nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if service.Spec.Selector == nil {
0000000000000000000000000000000000000000;;			// services without a selector receive no endpoints from this controller;
0000000000000000000000000000000000000000;;			// these services will receive the endpoints that are created out-of-band via the REST API.
0000000000000000000000000000000000000000;;			return nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		glog.V(5).Infof("About to update endpoints for service %q", key)
0000000000000000000000000000000000000000;;		pods, err := e.podLister.Pods(service.Namespace).List(labels.Set(service.Spec.Selector).AsSelectorPreValidated())
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			// Since we're getting stuff from a local cache, it is
0000000000000000000000000000000000000000;;			// basically impossible to get this error.
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		var tolerateUnreadyEndpoints bool
0000000000000000000000000000000000000000;;		if v, ok := service.Annotations[TolerateUnreadyEndpointsAnnotation]; ok {
0000000000000000000000000000000000000000;;			b, err := strconv.ParseBool(v)
0000000000000000000000000000000000000000;;			if err == nil {
0000000000000000000000000000000000000000;;				tolerateUnreadyEndpoints = b
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				utilruntime.HandleError(fmt.Errorf("Failed to parse annotation %v: %v", TolerateUnreadyEndpointsAnnotation, err))
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		subsets := []v1.EndpointSubset{}
0000000000000000000000000000000000000000;;		var totalReadyEps int = 0
0000000000000000000000000000000000000000;;		var totalNotReadyEps int = 0
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		for _, pod := range pods {
0000000000000000000000000000000000000000;;			if len(pod.Status.PodIP) == 0 {
0000000000000000000000000000000000000000;;				glog.V(5).Infof("Failed to find an IP for pod %s/%s", pod.Namespace, pod.Name)
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if !tolerateUnreadyEndpoints && pod.DeletionTimestamp != nil {
0000000000000000000000000000000000000000;;				glog.V(5).Infof("Pod is being deleted %s/%s", pod.Namespace, pod.Name)
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			epa := v1.EndpointAddress{
0000000000000000000000000000000000000000;;				IP:       pod.Status.PodIP,
0000000000000000000000000000000000000000;;				NodeName: &pod.Spec.NodeName,
0000000000000000000000000000000000000000;;				TargetRef: &v1.ObjectReference{
0000000000000000000000000000000000000000;;					Kind:            "Pod",
0000000000000000000000000000000000000000;;					Namespace:       pod.ObjectMeta.Namespace,
0000000000000000000000000000000000000000;;					Name:            pod.ObjectMeta.Name,
0000000000000000000000000000000000000000;;					UID:             pod.ObjectMeta.UID,
0000000000000000000000000000000000000000;;					ResourceVersion: pod.ObjectMeta.ResourceVersion,
0000000000000000000000000000000000000000;;				}}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			hostname := pod.Spec.Hostname
0000000000000000000000000000000000000000;;			if len(hostname) > 0 && pod.Spec.Subdomain == service.Name && service.Namespace == pod.Namespace {
0000000000000000000000000000000000000000;;				epa.Hostname = hostname
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Allow headless service not to have ports.
0000000000000000000000000000000000000000;;			if len(service.Spec.Ports) == 0 {
0000000000000000000000000000000000000000;;				if service.Spec.ClusterIP == api.ClusterIPNone {
0000000000000000000000000000000000000000;;					epp := v1.EndpointPort{Port: 0, Protocol: v1.ProtocolTCP}
0000000000000000000000000000000000000000;;					subsets, totalReadyEps, totalNotReadyEps = addEndpointSubset(subsets, pod, epa, epp, tolerateUnreadyEndpoints)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				for i := range service.Spec.Ports {
0000000000000000000000000000000000000000;;					servicePort := &service.Spec.Ports[i]
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;					portName := servicePort.Name
0000000000000000000000000000000000000000;;					portProto := servicePort.Protocol
0000000000000000000000000000000000000000;;					portNum, err := podutil.FindPort(pod, servicePort)
0000000000000000000000000000000000000000;;					if err != nil {
0000000000000000000000000000000000000000;;						glog.V(4).Infof("Failed to find port for service %s/%s: %v", service.Namespace, service.Name, err)
0000000000000000000000000000000000000000;;						continue
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;					var readyEps, notReadyEps int
0000000000000000000000000000000000000000;;					epp := v1.EndpointPort{Name: portName, Port: int32(portNum), Protocol: portProto}
0000000000000000000000000000000000000000;;					subsets, readyEps, notReadyEps = addEndpointSubset(subsets, pod, epa, epp, tolerateUnreadyEndpoints)
0000000000000000000000000000000000000000;;					totalReadyEps = totalReadyEps + readyEps
0000000000000000000000000000000000000000;;					totalNotReadyEps = totalNotReadyEps + notReadyEps
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		subsets = endpoints.RepackSubsets(subsets)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// See if there's actually an update here.
0000000000000000000000000000000000000000;;		currentEndpoints, err := e.endpointsLister.Endpoints(service.Namespace).Get(service.Name)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			if errors.IsNotFound(err) {
0000000000000000000000000000000000000000;;				currentEndpoints = &v1.Endpoints{
0000000000000000000000000000000000000000;;					ObjectMeta: metav1.ObjectMeta{
0000000000000000000000000000000000000000;;						Name:   service.Name,
0000000000000000000000000000000000000000;;						Labels: service.Labels,
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				return err
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if reflect.DeepEqual(currentEndpoints.Subsets, subsets) &&
0000000000000000000000000000000000000000;;			reflect.DeepEqual(currentEndpoints.Labels, service.Labels) {
0000000000000000000000000000000000000000;;			glog.V(5).Infof("endpoints are equal for %s/%s, skipping update", service.Namespace, service.Name)
0000000000000000000000000000000000000000;;			return nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		copy, err := api.Scheme.DeepCopy(currentEndpoints)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		newEndpoints := copy.(*v1.Endpoints)
0000000000000000000000000000000000000000;;		newEndpoints.Subsets = subsets
0000000000000000000000000000000000000000;;		newEndpoints.Labels = service.Labels
0000000000000000000000000000000000000000;;		if newEndpoints.Annotations == nil {
0000000000000000000000000000000000000000;;			newEndpoints.Annotations = make(map[string]string)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		glog.V(4).Infof("Update endpoints for %v/%v, ready: %d not ready: %d", service.Namespace, service.Name, totalReadyEps, totalNotReadyEps)
0000000000000000000000000000000000000000;;		createEndpoints := len(currentEndpoints.ResourceVersion) == 0
0000000000000000000000000000000000000000;;		if createEndpoints {
0000000000000000000000000000000000000000;;			// No previous endpoints, create them
0000000000000000000000000000000000000000;;			_, err = e.client.Core().Endpoints(service.Namespace).Create(newEndpoints)
0000000000000000000000000000000000000000;;		} else {
0000000000000000000000000000000000000000;;			// Pre-existing
0000000000000000000000000000000000000000;;			_, err = e.client.Core().Endpoints(service.Namespace).Update(newEndpoints)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			if createEndpoints && errors.IsForbidden(err) {
0000000000000000000000000000000000000000;;				// A request is forbidden primarily for two reasons:
0000000000000000000000000000000000000000;;				// 1. namespace is terminating, endpoint creation is not allowed by default.
0000000000000000000000000000000000000000;;				// 2. policy is misconfigured, in which case no service would function anywhere.
0000000000000000000000000000000000000000;;				// Given the frequency of 1, we log at a lower level.
0000000000000000000000000000000000000000;;				glog.V(5).Infof("Forbidden from creating endpoints: %v", err)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// checkLeftoverEndpoints lists all currently existing endpoints and adds their
0000000000000000000000000000000000000000;;	// service to the queue. This will detect endpoints that exist with no
0000000000000000000000000000000000000000;;	// corresponding service; these endpoints need to be deleted. We only need to
0000000000000000000000000000000000000000;;	// do this once on startup, because in steady-state these are detected (but
0000000000000000000000000000000000000000;;	// some stragglers could have been left behind if the endpoint controller
0000000000000000000000000000000000000000;;	// reboots).
0000000000000000000000000000000000000000;;	func (e *EndpointController) checkLeftoverEndpoints() {
0000000000000000000000000000000000000000;;		list, err := e.endpointsLister.List(labels.Everything())
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			utilruntime.HandleError(fmt.Errorf("Unable to list endpoints (%v); orphaned endpoints will not be cleaned up. (They're pretty harmless, but you can restart this component if you want another attempt made.)", err))
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		for _, ep := range list {
0000000000000000000000000000000000000000;;			if _, ok := ep.Annotations[resourcelock.LeaderElectionRecordAnnotationKey]; ok {
0000000000000000000000000000000000000000;;				// when there are multiple controller-manager instances,
0000000000000000000000000000000000000000;;				// we observe that it will delete leader-election endpoints after 5min
0000000000000000000000000000000000000000;;				// and cause re-election
0000000000000000000000000000000000000000;;				// so skip the delete here
0000000000000000000000000000000000000000;;				// as leader-election only have endpoints without service
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			key, err := keyFunc(ep)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				utilruntime.HandleError(fmt.Errorf("Unable to get key for endpoint %#v", ep))
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			e.queue.Add(key)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func addEndpointSubset(subsets []v1.EndpointSubset, pod *v1.Pod, epa v1.EndpointAddress,
0000000000000000000000000000000000000000;;		epp v1.EndpointPort, tolerateUnreadyEndpoints bool) ([]v1.EndpointSubset, int, int) {
0000000000000000000000000000000000000000;;		var readyEps int = 0
0000000000000000000000000000000000000000;;		var notReadyEps int = 0
0000000000000000000000000000000000000000;;		if tolerateUnreadyEndpoints || podutil.IsPodReady(pod) {
0000000000000000000000000000000000000000;;			subsets = append(subsets, v1.EndpointSubset{
0000000000000000000000000000000000000000;;				Addresses: []v1.EndpointAddress{epa},
0000000000000000000000000000000000000000;;				Ports:     []v1.EndpointPort{epp},
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;			readyEps++
0000000000000000000000000000000000000000;;		} else if shouldPodBeInEndpoints(pod) {
0000000000000000000000000000000000000000;;			glog.V(5).Infof("Pod is out of service: %v/%v", pod.Namespace, pod.Name)
0000000000000000000000000000000000000000;;			subsets = append(subsets, v1.EndpointSubset{
0000000000000000000000000000000000000000;;				NotReadyAddresses: []v1.EndpointAddress{epa},
0000000000000000000000000000000000000000;;				Ports:             []v1.EndpointPort{epp},
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;			notReadyEps++
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return subsets, readyEps, notReadyEps
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func shouldPodBeInEndpoints(pod *v1.Pod) bool {
0000000000000000000000000000000000000000;;		switch pod.Spec.RestartPolicy {
0000000000000000000000000000000000000000;;		case v1.RestartPolicyNever:
0000000000000000000000000000000000000000;;			return pod.Status.Phase != v1.PodFailed && pod.Status.Phase != v1.PodSucceeded
0000000000000000000000000000000000000000;;		case v1.RestartPolicyOnFailure:
0000000000000000000000000000000000000000;;			return pod.Status.Phase != v1.PodSucceeded
0000000000000000000000000000000000000000;;		default:
0000000000000000000000000000000000000000;;			return true
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
