0000000000000000000000000000000000000000;;	/*
0000000000000000000000000000000000000000;;	Copyright 2015 The Kubernetes Authors.
2ee2838929787787c2140ccf65e6bc3959412998;pkg/cloudprovider/servicecontroller/servicecontroller.go[pkg/cloudprovider/servicecontroller/servicecontroller.go][pkg/controller/service/servicecontroller.go];	
0000000000000000000000000000000000000000;;	Licensed under the Apache License, Version 2.0 (the "License");
0000000000000000000000000000000000000000;;	you may not use this file except in compliance with the License.
0000000000000000000000000000000000000000;;	You may obtain a copy of the License at
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	    http://www.apache.org/licenses/LICENSE-2.0
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	Unless required by applicable law or agreed to in writing, software
0000000000000000000000000000000000000000;;	distributed under the License is distributed on an "AS IS" BASIS,
0000000000000000000000000000000000000000;;	WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
0000000000000000000000000000000000000000;;	See the License for the specific language governing permissions and
0000000000000000000000000000000000000000;;	limitations under the License.
0000000000000000000000000000000000000000;;	*/
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	package service
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	import (
0000000000000000000000000000000000000000;;		"fmt"
0000000000000000000000000000000000000000;;		"sort"
0000000000000000000000000000000000000000;;		"sync"
0000000000000000000000000000000000000000;;		"time"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		"reflect"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		"github.com/golang/glog"
0000000000000000000000000000000000000000;;		"k8s.io/api/core/v1"
0000000000000000000000000000000000000000;;		clientv1 "k8s.io/api/core/v1"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/api/errors"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/util/runtime"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/util/wait"
0000000000000000000000000000000000000000;;		v1core "k8s.io/client-go/kubernetes/typed/core/v1"
0000000000000000000000000000000000000000;;		"k8s.io/client-go/tools/cache"
0000000000000000000000000000000000000000;;		"k8s.io/client-go/tools/record"
0000000000000000000000000000000000000000;;		"k8s.io/client-go/util/workqueue"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/cmd/kubeadm/app/constants"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/api"
0000000000000000000000000000000000000000;;		v1helper "k8s.io/kubernetes/pkg/api/v1/helper"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/client/clientset_generated/clientset"
0000000000000000000000000000000000000000;;		coreinformers "k8s.io/kubernetes/pkg/client/informers/informers_generated/externalversions/core/v1"
0000000000000000000000000000000000000000;;		corelisters "k8s.io/kubernetes/pkg/client/listers/core/v1"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/cloudprovider"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/controller"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/util/metrics"
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	const (
0000000000000000000000000000000000000000;;		// Interval of synchronizing service status from apiserver
0000000000000000000000000000000000000000;;		serviceSyncPeriod = 30 * time.Second
0000000000000000000000000000000000000000;;		// Interval of synchronizing node status from apiserver
0000000000000000000000000000000000000000;;		nodeSyncPeriod = 100 * time.Second
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// How long to wait before retrying the processing of a service change.
0000000000000000000000000000000000000000;;		// If this changes, the sleep in hack/jenkins/e2e.sh before downing a cluster
0000000000000000000000000000000000000000;;		// should be changed appropriately.
0000000000000000000000000000000000000000;;		minRetryDelay = 5 * time.Second
0000000000000000000000000000000000000000;;		maxRetryDelay = 300 * time.Second
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		clientRetryCount    = 5
0000000000000000000000000000000000000000;;		clientRetryInterval = 5 * time.Second
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		retryable    = true
0000000000000000000000000000000000000000;;		notRetryable = false
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		doNotRetry = time.Duration(0)
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type cachedService struct {
0000000000000000000000000000000000000000;;		// The cached state of the service
0000000000000000000000000000000000000000;;		state *v1.Service
0000000000000000000000000000000000000000;;		// Controls error back-off
0000000000000000000000000000000000000000;;		lastRetryDelay time.Duration
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type serviceCache struct {
0000000000000000000000000000000000000000;;		mu         sync.Mutex // protects serviceMap
0000000000000000000000000000000000000000;;		serviceMap map[string]*cachedService
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type ServiceController struct {
0000000000000000000000000000000000000000;;		cloud               cloudprovider.Interface
0000000000000000000000000000000000000000;;		knownHosts          []*v1.Node
0000000000000000000000000000000000000000;;		servicesToUpdate    []*v1.Service
0000000000000000000000000000000000000000;;		kubeClient          clientset.Interface
0000000000000000000000000000000000000000;;		clusterName         string
0000000000000000000000000000000000000000;;		balancer            cloudprovider.LoadBalancer
0000000000000000000000000000000000000000;;		cache               *serviceCache
0000000000000000000000000000000000000000;;		serviceLister       corelisters.ServiceLister
0000000000000000000000000000000000000000;;		serviceListerSynced cache.InformerSynced
0000000000000000000000000000000000000000;;		eventBroadcaster    record.EventBroadcaster
0000000000000000000000000000000000000000;;		eventRecorder       record.EventRecorder
0000000000000000000000000000000000000000;;		nodeLister          corelisters.NodeLister
0000000000000000000000000000000000000000;;		nodeListerSynced    cache.InformerSynced
0000000000000000000000000000000000000000;;		// services that need to be synced
0000000000000000000000000000000000000000;;		workingQueue workqueue.DelayingInterface
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// New returns a new service controller to keep cloud provider service resources
0000000000000000000000000000000000000000;;	// (like load balancers) in sync with the registry.
0000000000000000000000000000000000000000;;	func New(
0000000000000000000000000000000000000000;;		cloud cloudprovider.Interface,
0000000000000000000000000000000000000000;;		kubeClient clientset.Interface,
0000000000000000000000000000000000000000;;		serviceInformer coreinformers.ServiceInformer,
0000000000000000000000000000000000000000;;		nodeInformer coreinformers.NodeInformer,
0000000000000000000000000000000000000000;;		clusterName string,
0000000000000000000000000000000000000000;;	) (*ServiceController, error) {
0000000000000000000000000000000000000000;;		broadcaster := record.NewBroadcaster()
0000000000000000000000000000000000000000;;		broadcaster.StartRecordingToSink(&v1core.EventSinkImpl{Interface: v1core.New(kubeClient.Core().RESTClient()).Events("")})
0000000000000000000000000000000000000000;;		recorder := broadcaster.NewRecorder(api.Scheme, clientv1.EventSource{Component: "service-controller"})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if kubeClient != nil && kubeClient.Core().RESTClient().GetRateLimiter() != nil {
0000000000000000000000000000000000000000;;			metrics.RegisterMetricAndTrackRateLimiterUsage("service_controller", kubeClient.Core().RESTClient().GetRateLimiter())
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		s := &ServiceController{
0000000000000000000000000000000000000000;;			cloud:            cloud,
0000000000000000000000000000000000000000;;			knownHosts:       []*v1.Node{},
0000000000000000000000000000000000000000;;			kubeClient:       kubeClient,
0000000000000000000000000000000000000000;;			clusterName:      clusterName,
0000000000000000000000000000000000000000;;			cache:            &serviceCache{serviceMap: make(map[string]*cachedService)},
0000000000000000000000000000000000000000;;			eventBroadcaster: broadcaster,
0000000000000000000000000000000000000000;;			eventRecorder:    recorder,
0000000000000000000000000000000000000000;;			nodeLister:       nodeInformer.Lister(),
0000000000000000000000000000000000000000;;			nodeListerSynced: nodeInformer.Informer().HasSynced,
0000000000000000000000000000000000000000;;			workingQueue:     workqueue.NewNamedDelayingQueue("service"),
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		serviceInformer.Informer().AddEventHandlerWithResyncPeriod(
0000000000000000000000000000000000000000;;			cache.ResourceEventHandlerFuncs{
0000000000000000000000000000000000000000;;				AddFunc: s.enqueueService,
0000000000000000000000000000000000000000;;				UpdateFunc: func(old, cur interface{}) {
0000000000000000000000000000000000000000;;					oldSvc, ok1 := old.(*v1.Service)
0000000000000000000000000000000000000000;;					curSvc, ok2 := cur.(*v1.Service)
0000000000000000000000000000000000000000;;					if ok1 && ok2 && s.needsUpdate(oldSvc, curSvc) {
0000000000000000000000000000000000000000;;						s.enqueueService(cur)
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;				DeleteFunc: s.enqueueService,
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			serviceSyncPeriod,
0000000000000000000000000000000000000000;;		)
0000000000000000000000000000000000000000;;		s.serviceLister = serviceInformer.Lister()
0000000000000000000000000000000000000000;;		s.serviceListerSynced = serviceInformer.Informer().HasSynced
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if err := s.init(); err != nil {
0000000000000000000000000000000000000000;;			return nil, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return s, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// obj could be an *v1.Service, or a DeletionFinalStateUnknown marker item.
0000000000000000000000000000000000000000;;	func (s *ServiceController) enqueueService(obj interface{}) {
0000000000000000000000000000000000000000;;		key, err := controller.KeyFunc(obj)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			glog.Errorf("Couldn't get key for object %#v: %v", obj, err)
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		s.workingQueue.Add(key)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Run starts a background goroutine that watches for changes to services that
0000000000000000000000000000000000000000;;	// have (or had) LoadBalancers=true and ensures that they have
0000000000000000000000000000000000000000;;	// load balancers created and deleted appropriately.
0000000000000000000000000000000000000000;;	// serviceSyncPeriod controls how often we check the cluster's services to
0000000000000000000000000000000000000000;;	// ensure that the correct load balancers exist.
0000000000000000000000000000000000000000;;	// nodeSyncPeriod controls how often we check the cluster's nodes to determine
0000000000000000000000000000000000000000;;	// if load balancers need to be updated to point to a new set.
0000000000000000000000000000000000000000;;	//
0000000000000000000000000000000000000000;;	// It's an error to call Run() more than once for a given ServiceController
0000000000000000000000000000000000000000;;	// object.
0000000000000000000000000000000000000000;;	func (s *ServiceController) Run(stopCh <-chan struct{}, workers int) {
0000000000000000000000000000000000000000;;		defer runtime.HandleCrash()
0000000000000000000000000000000000000000;;		defer s.workingQueue.ShutDown()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		glog.Info("Starting service controller")
0000000000000000000000000000000000000000;;		defer glog.Info("Shutting down service controller")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if !controller.WaitForCacheSync("service", stopCh, s.serviceListerSynced, s.nodeListerSynced) {
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		for i := 0; i < workers; i++ {
0000000000000000000000000000000000000000;;			go wait.Until(s.worker, time.Second, stopCh)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		go wait.Until(s.nodeSyncLoop, nodeSyncPeriod, stopCh)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		<-stopCh
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// worker runs a worker thread that just dequeues items, processes them, and marks them done.
0000000000000000000000000000000000000000;;	// It enforces that the syncHandler is never invoked concurrently with the same key.
0000000000000000000000000000000000000000;;	func (s *ServiceController) worker() {
0000000000000000000000000000000000000000;;		for {
0000000000000000000000000000000000000000;;			func() {
0000000000000000000000000000000000000000;;				key, quit := s.workingQueue.Get()
0000000000000000000000000000000000000000;;				if quit {
0000000000000000000000000000000000000000;;					return
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				defer s.workingQueue.Done(key)
0000000000000000000000000000000000000000;;				err := s.syncService(key.(string))
0000000000000000000000000000000000000000;;				if err != nil {
0000000000000000000000000000000000000000;;					glog.Errorf("Error syncing service: %v", err)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}()
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (s *ServiceController) init() error {
0000000000000000000000000000000000000000;;		if s.cloud == nil {
0000000000000000000000000000000000000000;;			return fmt.Errorf("WARNING: no cloud provider provided, services of type LoadBalancer will fail.")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		balancer, ok := s.cloud.LoadBalancer()
0000000000000000000000000000000000000000;;		if !ok {
0000000000000000000000000000000000000000;;			return fmt.Errorf("the cloud provider does not support external load balancers.")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		s.balancer = balancer
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Returns an error if processing the service update failed, along with a time.Duration
0000000000000000000000000000000000000000;;	// indicating whether processing should be retried; zero means no-retry; otherwise
0000000000000000000000000000000000000000;;	// we should retry in that Duration.
0000000000000000000000000000000000000000;;	func (s *ServiceController) processServiceUpdate(cachedService *cachedService, service *v1.Service, key string) (error, time.Duration) {
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// cache the service, we need the info for service deletion
0000000000000000000000000000000000000000;;		cachedService.state = service
0000000000000000000000000000000000000000;;		err, retry := s.createLoadBalancerIfNeeded(key, service)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			message := "Error creating load balancer"
0000000000000000000000000000000000000000;;			if retry {
0000000000000000000000000000000000000000;;				message += " (will retry): "
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				message += " (will not retry): "
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			message += err.Error()
0000000000000000000000000000000000000000;;			s.eventRecorder.Event(service, v1.EventTypeWarning, "CreatingLoadBalancerFailed", message)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			return err, cachedService.nextRetryDelay()
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		// Always update the cache upon success.
0000000000000000000000000000000000000000;;		// NOTE: Since we update the cached service if and only if we successfully
0000000000000000000000000000000000000000;;		// processed it, a cached service being nil implies that it hasn't yet
0000000000000000000000000000000000000000;;		// been successfully processed.
0000000000000000000000000000000000000000;;		s.cache.set(key, cachedService)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		cachedService.resetRetryDelay()
0000000000000000000000000000000000000000;;		return nil, doNotRetry
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Returns whatever error occurred along with a boolean indicator of whether it
0000000000000000000000000000000000000000;;	// should be retried.
0000000000000000000000000000000000000000;;	func (s *ServiceController) createLoadBalancerIfNeeded(key string, service *v1.Service) (error, bool) {
0000000000000000000000000000000000000000;;		// Note: It is safe to just call EnsureLoadBalancer.  But, on some clouds that requires a delete & create,
0000000000000000000000000000000000000000;;		// which may involve service interruption.  Also, we would like user-friendly events.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Save the state so we can avoid a write if it doesn't change
0000000000000000000000000000000000000000;;		previousState := v1helper.LoadBalancerStatusDeepCopy(&service.Status.LoadBalancer)
0000000000000000000000000000000000000000;;		var newState *v1.LoadBalancerStatus
0000000000000000000000000000000000000000;;		var err error
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if !wantsLoadBalancer(service) {
0000000000000000000000000000000000000000;;			needDelete := true
0000000000000000000000000000000000000000;;			_, exists, err := s.balancer.GetLoadBalancer(s.clusterName, service)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				return fmt.Errorf("Error getting LB for service %s: %v", key, err), retryable
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if !exists {
0000000000000000000000000000000000000000;;				needDelete = false
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			if needDelete {
0000000000000000000000000000000000000000;;				glog.Infof("Deleting existing load balancer for service %s that no longer needs a load balancer.", key)
0000000000000000000000000000000000000000;;				s.eventRecorder.Event(service, v1.EventTypeNormal, "DeletingLoadBalancer", "Deleting load balancer")
0000000000000000000000000000000000000000;;				if err := s.balancer.EnsureLoadBalancerDeleted(s.clusterName, service); err != nil {
0000000000000000000000000000000000000000;;					return err, retryable
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				s.eventRecorder.Event(service, v1.EventTypeNormal, "DeletedLoadBalancer", "Deleted load balancer")
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			newState = &v1.LoadBalancerStatus{}
0000000000000000000000000000000000000000;;		} else {
0000000000000000000000000000000000000000;;			glog.V(2).Infof("Ensuring LB for service %s", key)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// TODO: We could do a dry-run here if wanted to avoid the spurious cloud-calls & events when we restart
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// The load balancer doesn't exist yet, so create it.
0000000000000000000000000000000000000000;;			s.eventRecorder.Event(service, v1.EventTypeNormal, "CreatingLoadBalancer", "Creating load balancer")
0000000000000000000000000000000000000000;;			newState, err = s.createLoadBalancer(service)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				return fmt.Errorf("Failed to create load balancer for service %s: %v", key, err), retryable
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			s.eventRecorder.Event(service, v1.EventTypeNormal, "CreatedLoadBalancer", "Created load balancer")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Write the state if changed
0000000000000000000000000000000000000000;;		// TODO: Be careful here ... what if there were other changes to the service?
0000000000000000000000000000000000000000;;		if !v1helper.LoadBalancerStatusEqual(previousState, newState) {
0000000000000000000000000000000000000000;;			// Make a copy so we don't mutate the shared informer cache
0000000000000000000000000000000000000000;;			copy, err := api.Scheme.DeepCopy(service)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				return err, retryable
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			service = copy.(*v1.Service)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Update the status on the copy
0000000000000000000000000000000000000000;;			service.Status.LoadBalancer = *newState
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			if err := s.persistUpdate(service); err != nil {
0000000000000000000000000000000000000000;;				return fmt.Errorf("Failed to persist updated status to apiserver, even after retries. Giving up: %v", err), notRetryable
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		} else {
0000000000000000000000000000000000000000;;			glog.V(2).Infof("Not persisting unchanged LoadBalancerStatus for service %s to registry.", key)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return nil, notRetryable
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (s *ServiceController) persistUpdate(service *v1.Service) error {
0000000000000000000000000000000000000000;;		var err error
0000000000000000000000000000000000000000;;		for i := 0; i < clientRetryCount; i++ {
0000000000000000000000000000000000000000;;			_, err = s.kubeClient.Core().Services(service.Namespace).UpdateStatus(service)
0000000000000000000000000000000000000000;;			if err == nil {
0000000000000000000000000000000000000000;;				return nil
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			// If the object no longer exists, we don't want to recreate it. Just bail
0000000000000000000000000000000000000000;;			// out so that we can process the delete, which we should soon be receiving
0000000000000000000000000000000000000000;;			// if we haven't already.
0000000000000000000000000000000000000000;;			if errors.IsNotFound(err) {
0000000000000000000000000000000000000000;;				glog.Infof("Not persisting update to service '%s/%s' that no longer exists: %v",
0000000000000000000000000000000000000000;;					service.Namespace, service.Name, err)
0000000000000000000000000000000000000000;;				return nil
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			// TODO: Try to resolve the conflict if the change was unrelated to load
0000000000000000000000000000000000000000;;			// balancer status. For now, just pass it up the stack.
0000000000000000000000000000000000000000;;			if errors.IsConflict(err) {
0000000000000000000000000000000000000000;;				return fmt.Errorf("Not persisting update to service '%s/%s' that has been changed since we received it: %v",
0000000000000000000000000000000000000000;;					service.Namespace, service.Name, err)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			glog.Warningf("Failed to persist updated LoadBalancerStatus to service '%s/%s' after creating its load balancer: %v",
0000000000000000000000000000000000000000;;				service.Namespace, service.Name, err)
0000000000000000000000000000000000000000;;			time.Sleep(clientRetryInterval)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return err
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (s *ServiceController) createLoadBalancer(service *v1.Service) (*v1.LoadBalancerStatus, error) {
0000000000000000000000000000000000000000;;		nodes, err := s.nodeLister.ListWithPredicate(getNodeConditionPredicate())
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return nil, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// - Only one protocol supported per service
0000000000000000000000000000000000000000;;		// - Not all cloud providers support all protocols and the next step is expected to return
0000000000000000000000000000000000000000;;		//   an error for unsupported protocols
0000000000000000000000000000000000000000;;		return s.balancer.EnsureLoadBalancer(s.clusterName, service, nodes)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// ListKeys implements the interface required by DeltaFIFO to list the keys we
0000000000000000000000000000000000000000;;	// already know about.
0000000000000000000000000000000000000000;;	func (s *serviceCache) ListKeys() []string {
0000000000000000000000000000000000000000;;		s.mu.Lock()
0000000000000000000000000000000000000000;;		defer s.mu.Unlock()
0000000000000000000000000000000000000000;;		keys := make([]string, 0, len(s.serviceMap))
0000000000000000000000000000000000000000;;		for k := range s.serviceMap {
0000000000000000000000000000000000000000;;			keys = append(keys, k)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return keys
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// GetByKey returns the value stored in the serviceMap under the given key
0000000000000000000000000000000000000000;;	func (s *serviceCache) GetByKey(key string) (interface{}, bool, error) {
0000000000000000000000000000000000000000;;		s.mu.Lock()
0000000000000000000000000000000000000000;;		defer s.mu.Unlock()
0000000000000000000000000000000000000000;;		if v, ok := s.serviceMap[key]; ok {
0000000000000000000000000000000000000000;;			return v, true, nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return nil, false, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// ListKeys implements the interface required by DeltaFIFO to list the keys we
0000000000000000000000000000000000000000;;	// already know about.
0000000000000000000000000000000000000000;;	func (s *serviceCache) allServices() []*v1.Service {
0000000000000000000000000000000000000000;;		s.mu.Lock()
0000000000000000000000000000000000000000;;		defer s.mu.Unlock()
0000000000000000000000000000000000000000;;		services := make([]*v1.Service, 0, len(s.serviceMap))
0000000000000000000000000000000000000000;;		for _, v := range s.serviceMap {
0000000000000000000000000000000000000000;;			services = append(services, v.state)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return services
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (s *serviceCache) get(serviceName string) (*cachedService, bool) {
0000000000000000000000000000000000000000;;		s.mu.Lock()
0000000000000000000000000000000000000000;;		defer s.mu.Unlock()
0000000000000000000000000000000000000000;;		service, ok := s.serviceMap[serviceName]
0000000000000000000000000000000000000000;;		return service, ok
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (s *serviceCache) getOrCreate(serviceName string) *cachedService {
0000000000000000000000000000000000000000;;		s.mu.Lock()
0000000000000000000000000000000000000000;;		defer s.mu.Unlock()
0000000000000000000000000000000000000000;;		service, ok := s.serviceMap[serviceName]
0000000000000000000000000000000000000000;;		if !ok {
0000000000000000000000000000000000000000;;			service = &cachedService{}
0000000000000000000000000000000000000000;;			s.serviceMap[serviceName] = service
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return service
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (s *serviceCache) set(serviceName string, service *cachedService) {
0000000000000000000000000000000000000000;;		s.mu.Lock()
0000000000000000000000000000000000000000;;		defer s.mu.Unlock()
0000000000000000000000000000000000000000;;		s.serviceMap[serviceName] = service
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (s *serviceCache) delete(serviceName string) {
0000000000000000000000000000000000000000;;		s.mu.Lock()
0000000000000000000000000000000000000000;;		defer s.mu.Unlock()
0000000000000000000000000000000000000000;;		delete(s.serviceMap, serviceName)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (s *ServiceController) needsUpdate(oldService *v1.Service, newService *v1.Service) bool {
0000000000000000000000000000000000000000;;		if !wantsLoadBalancer(oldService) && !wantsLoadBalancer(newService) {
0000000000000000000000000000000000000000;;			return false
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if wantsLoadBalancer(oldService) != wantsLoadBalancer(newService) {
0000000000000000000000000000000000000000;;			s.eventRecorder.Eventf(newService, v1.EventTypeNormal, "Type", "%v -> %v",
0000000000000000000000000000000000000000;;				oldService.Spec.Type, newService.Spec.Type)
0000000000000000000000000000000000000000;;			return true
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if wantsLoadBalancer(newService) && !reflect.DeepEqual(oldService.Spec.LoadBalancerSourceRanges, newService.Spec.LoadBalancerSourceRanges) {
0000000000000000000000000000000000000000;;			s.eventRecorder.Eventf(newService, v1.EventTypeNormal, "LoadBalancerSourceRanges", "%v -> %v",
0000000000000000000000000000000000000000;;				oldService.Spec.LoadBalancerSourceRanges, newService.Spec.LoadBalancerSourceRanges)
0000000000000000000000000000000000000000;;			return true
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if !portsEqualForLB(oldService, newService) || oldService.Spec.SessionAffinity != newService.Spec.SessionAffinity {
0000000000000000000000000000000000000000;;			return true
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if !loadBalancerIPsAreEqual(oldService, newService) {
0000000000000000000000000000000000000000;;			s.eventRecorder.Eventf(newService, v1.EventTypeNormal, "LoadbalancerIP", "%v -> %v",
0000000000000000000000000000000000000000;;				oldService.Spec.LoadBalancerIP, newService.Spec.LoadBalancerIP)
0000000000000000000000000000000000000000;;			return true
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if len(oldService.Spec.ExternalIPs) != len(newService.Spec.ExternalIPs) {
0000000000000000000000000000000000000000;;			s.eventRecorder.Eventf(newService, v1.EventTypeNormal, "ExternalIP", "Count: %v -> %v",
0000000000000000000000000000000000000000;;				len(oldService.Spec.ExternalIPs), len(newService.Spec.ExternalIPs))
0000000000000000000000000000000000000000;;			return true
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		for i := range oldService.Spec.ExternalIPs {
0000000000000000000000000000000000000000;;			if oldService.Spec.ExternalIPs[i] != newService.Spec.ExternalIPs[i] {
0000000000000000000000000000000000000000;;				s.eventRecorder.Eventf(newService, v1.EventTypeNormal, "ExternalIP", "Added: %v",
0000000000000000000000000000000000000000;;					newService.Spec.ExternalIPs[i])
0000000000000000000000000000000000000000;;				return true
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if !reflect.DeepEqual(oldService.Annotations, newService.Annotations) {
0000000000000000000000000000000000000000;;			return true
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if oldService.UID != newService.UID {
0000000000000000000000000000000000000000;;			s.eventRecorder.Eventf(newService, v1.EventTypeNormal, "UID", "%v -> %v",
0000000000000000000000000000000000000000;;				oldService.UID, newService.UID)
0000000000000000000000000000000000000000;;			return true
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if oldService.Spec.ExternalTrafficPolicy != newService.Spec.ExternalTrafficPolicy {
0000000000000000000000000000000000000000;;			s.eventRecorder.Eventf(newService, v1.EventTypeNormal, "ExternalTrafficPolicy", "%v -> %v",
0000000000000000000000000000000000000000;;				oldService.Spec.ExternalTrafficPolicy, newService.Spec.ExternalTrafficPolicy)
0000000000000000000000000000000000000000;;			return true
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if oldService.Spec.HealthCheckNodePort != newService.Spec.HealthCheckNodePort {
0000000000000000000000000000000000000000;;			s.eventRecorder.Eventf(newService, v1.EventTypeNormal, "HealthCheckNodePort", "%v -> %v",
0000000000000000000000000000000000000000;;				oldService.Spec.HealthCheckNodePort, newService.Spec.HealthCheckNodePort)
0000000000000000000000000000000000000000;;			return true
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return false
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (s *ServiceController) loadBalancerName(service *v1.Service) string {
0000000000000000000000000000000000000000;;		return cloudprovider.GetLoadBalancerName(service)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func getPortsForLB(service *v1.Service) ([]*v1.ServicePort, error) {
0000000000000000000000000000000000000000;;		var protocol v1.Protocol
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		ports := []*v1.ServicePort{}
0000000000000000000000000000000000000000;;		for i := range service.Spec.Ports {
0000000000000000000000000000000000000000;;			sp := &service.Spec.Ports[i]
0000000000000000000000000000000000000000;;			// The check on protocol was removed here.  The cloud provider itself is now responsible for all protocol validation
0000000000000000000000000000000000000000;;			ports = append(ports, sp)
0000000000000000000000000000000000000000;;			if protocol == "" {
0000000000000000000000000000000000000000;;				protocol = sp.Protocol
0000000000000000000000000000000000000000;;			} else if protocol != sp.Protocol && wantsLoadBalancer(service) {
0000000000000000000000000000000000000000;;				// TODO:  Convert error messages to use event recorder
0000000000000000000000000000000000000000;;				return nil, fmt.Errorf("mixed protocol external load balancers are not supported.")
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return ports, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func portsEqualForLB(x, y *v1.Service) bool {
0000000000000000000000000000000000000000;;		xPorts, err := getPortsForLB(x)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return false
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		yPorts, err := getPortsForLB(y)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return false
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return portSlicesEqualForLB(xPorts, yPorts)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func portSlicesEqualForLB(x, y []*v1.ServicePort) bool {
0000000000000000000000000000000000000000;;		if len(x) != len(y) {
0000000000000000000000000000000000000000;;			return false
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		for i := range x {
0000000000000000000000000000000000000000;;			if !portEqualForLB(x[i], y[i]) {
0000000000000000000000000000000000000000;;				return false
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return true
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func portEqualForLB(x, y *v1.ServicePort) bool {
0000000000000000000000000000000000000000;;		// TODO: Should we check name?  (In theory, an LB could expose it)
0000000000000000000000000000000000000000;;		if x.Name != y.Name {
0000000000000000000000000000000000000000;;			return false
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if x.Protocol != y.Protocol {
0000000000000000000000000000000000000000;;			return false
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if x.Port != y.Port {
0000000000000000000000000000000000000000;;			return false
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if x.NodePort != y.NodePort {
0000000000000000000000000000000000000000;;			return false
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// We don't check TargetPort; that is not relevant for load balancing
0000000000000000000000000000000000000000;;		// TODO: Should we blank it out?  Or just check it anyway?
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return true
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func nodeNames(nodes []*v1.Node) []string {
0000000000000000000000000000000000000000;;		ret := make([]string, len(nodes))
0000000000000000000000000000000000000000;;		for i, node := range nodes {
0000000000000000000000000000000000000000;;			ret[i] = node.Name
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return ret
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func nodeSlicesEqualForLB(x, y []*v1.Node) bool {
0000000000000000000000000000000000000000;;		if len(x) != len(y) {
0000000000000000000000000000000000000000;;			return false
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return stringSlicesEqual(nodeNames(x), nodeNames(y))
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func stringSlicesEqual(x, y []string) bool {
0000000000000000000000000000000000000000;;		if len(x) != len(y) {
0000000000000000000000000000000000000000;;			return false
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if !sort.StringsAreSorted(x) {
0000000000000000000000000000000000000000;;			sort.Strings(x)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if !sort.StringsAreSorted(y) {
0000000000000000000000000000000000000000;;			sort.Strings(y)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		for i := range x {
0000000000000000000000000000000000000000;;			if x[i] != y[i] {
0000000000000000000000000000000000000000;;				return false
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return true
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func includeNodeFromNodeList(node *v1.Node) bool {
0000000000000000000000000000000000000000;;		return !node.Spec.Unschedulable
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func getNodeConditionPredicate() corelisters.NodeConditionPredicate {
0000000000000000000000000000000000000000;;		return func(node *v1.Node) bool {
0000000000000000000000000000000000000000;;			// We add the master to the node list, but its unschedulable.  So we use this to filter
0000000000000000000000000000000000000000;;			// the master.
0000000000000000000000000000000000000000;;			if node.Spec.Unschedulable {
0000000000000000000000000000000000000000;;				return false
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// As of 1.6, we will taint the master, but not necessarily mark it unschedulable.
0000000000000000000000000000000000000000;;			// Recognize nodes labeled as master, and filter them also, as we were doing previously.
0000000000000000000000000000000000000000;;			if _, hasMasterRoleLabel := node.Labels[constants.LabelNodeRoleMaster]; hasMasterRoleLabel {
0000000000000000000000000000000000000000;;				return false
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// If we have no info, don't accept
0000000000000000000000000000000000000000;;			if len(node.Status.Conditions) == 0 {
0000000000000000000000000000000000000000;;				return false
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			for _, cond := range node.Status.Conditions {
0000000000000000000000000000000000000000;;				// We consider the node for load balancing only when its NodeReady condition status
0000000000000000000000000000000000000000;;				// is ConditionTrue
0000000000000000000000000000000000000000;;				if cond.Type == v1.NodeReady && cond.Status != v1.ConditionTrue {
0000000000000000000000000000000000000000;;					glog.V(4).Infof("Ignoring node %v with %v condition status %v", node.Name, cond.Type, cond.Status)
0000000000000000000000000000000000000000;;					return false
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			return true
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// nodeSyncLoop handles updating the hosts pointed to by all load
0000000000000000000000000000000000000000;;	// balancers whenever the set of nodes in the cluster changes.
0000000000000000000000000000000000000000;;	func (s *ServiceController) nodeSyncLoop() {
0000000000000000000000000000000000000000;;		newHosts, err := s.nodeLister.ListWithPredicate(getNodeConditionPredicate())
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			glog.Errorf("Failed to retrieve current set of nodes from node lister: %v", err)
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if nodeSlicesEqualForLB(newHosts, s.knownHosts) {
0000000000000000000000000000000000000000;;			// The set of nodes in the cluster hasn't changed, but we can retry
0000000000000000000000000000000000000000;;			// updating any services that we failed to update last time around.
0000000000000000000000000000000000000000;;			s.servicesToUpdate = s.updateLoadBalancerHosts(s.servicesToUpdate, newHosts)
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		glog.Infof("Detected change in list of current cluster nodes. New node set: %v",
0000000000000000000000000000000000000000;;			nodeNames(newHosts))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Try updating all services, and save the ones that fail to try again next
0000000000000000000000000000000000000000;;		// round.
0000000000000000000000000000000000000000;;		s.servicesToUpdate = s.cache.allServices()
0000000000000000000000000000000000000000;;		numServices := len(s.servicesToUpdate)
0000000000000000000000000000000000000000;;		s.servicesToUpdate = s.updateLoadBalancerHosts(s.servicesToUpdate, newHosts)
0000000000000000000000000000000000000000;;		glog.Infof("Successfully updated %d out of %d load balancers to direct traffic to the updated set of nodes",
0000000000000000000000000000000000000000;;			numServices-len(s.servicesToUpdate), numServices)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		s.knownHosts = newHosts
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// updateLoadBalancerHosts updates all existing load balancers so that
0000000000000000000000000000000000000000;;	// they will match the list of hosts provided.
0000000000000000000000000000000000000000;;	// Returns the list of services that couldn't be updated.
0000000000000000000000000000000000000000;;	func (s *ServiceController) updateLoadBalancerHosts(services []*v1.Service, hosts []*v1.Node) (servicesToRetry []*v1.Service) {
0000000000000000000000000000000000000000;;		for _, service := range services {
0000000000000000000000000000000000000000;;			func() {
0000000000000000000000000000000000000000;;				if service == nil {
0000000000000000000000000000000000000000;;					return
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				if err := s.lockedUpdateLoadBalancerHosts(service, hosts); err != nil {
0000000000000000000000000000000000000000;;					glog.Errorf("External error while updating load balancer: %v.", err)
0000000000000000000000000000000000000000;;					servicesToRetry = append(servicesToRetry, service)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}()
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return servicesToRetry
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Updates the load balancer of a service, assuming we hold the mutex
0000000000000000000000000000000000000000;;	// associated with the service.
0000000000000000000000000000000000000000;;	func (s *ServiceController) lockedUpdateLoadBalancerHosts(service *v1.Service, hosts []*v1.Node) error {
0000000000000000000000000000000000000000;;		if !wantsLoadBalancer(service) {
0000000000000000000000000000000000000000;;			return nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// This operation doesn't normally take very long (and happens pretty often), so we only record the final event
0000000000000000000000000000000000000000;;		err := s.balancer.UpdateLoadBalancer(s.clusterName, service, hosts)
0000000000000000000000000000000000000000;;		if err == nil {
0000000000000000000000000000000000000000;;			s.eventRecorder.Event(service, v1.EventTypeNormal, "UpdatedLoadBalancer", "Updated load balancer with new hosts")
0000000000000000000000000000000000000000;;			return nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// It's only an actual error if the load balancer still exists.
0000000000000000000000000000000000000000;;		if _, exists, err := s.balancer.GetLoadBalancer(s.clusterName, service); err != nil {
0000000000000000000000000000000000000000;;			glog.Errorf("External error while checking if load balancer %q exists: name, %v", cloudprovider.GetLoadBalancerName(service), err)
0000000000000000000000000000000000000000;;		} else if !exists {
0000000000000000000000000000000000000000;;			return nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		s.eventRecorder.Eventf(service, v1.EventTypeWarning, "LoadBalancerUpdateFailed", "Error updating load balancer with new hosts %v: %v", nodeNames(hosts), err)
0000000000000000000000000000000000000000;;		return err
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func wantsLoadBalancer(service *v1.Service) bool {
0000000000000000000000000000000000000000;;		return service.Spec.Type == v1.ServiceTypeLoadBalancer
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func loadBalancerIPsAreEqual(oldService, newService *v1.Service) bool {
0000000000000000000000000000000000000000;;		return oldService.Spec.LoadBalancerIP == newService.Spec.LoadBalancerIP
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Computes the next retry, using exponential backoff
0000000000000000000000000000000000000000;;	// mutex must be held.
0000000000000000000000000000000000000000;;	func (s *cachedService) nextRetryDelay() time.Duration {
0000000000000000000000000000000000000000;;		s.lastRetryDelay = s.lastRetryDelay * 2
0000000000000000000000000000000000000000;;		if s.lastRetryDelay < minRetryDelay {
0000000000000000000000000000000000000000;;			s.lastRetryDelay = minRetryDelay
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if s.lastRetryDelay > maxRetryDelay {
0000000000000000000000000000000000000000;;			s.lastRetryDelay = maxRetryDelay
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return s.lastRetryDelay
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Resets the retry exponential backoff.  mutex must be held.
0000000000000000000000000000000000000000;;	func (s *cachedService) resetRetryDelay() {
0000000000000000000000000000000000000000;;		s.lastRetryDelay = time.Duration(0)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// syncService will sync the Service with the given key if it has had its expectations fulfilled,
0000000000000000000000000000000000000000;;	// meaning it did not expect to see any more of its pods created or deleted. This function is not meant to be
0000000000000000000000000000000000000000;;	// invoked concurrently with the same key.
0000000000000000000000000000000000000000;;	func (s *ServiceController) syncService(key string) error {
0000000000000000000000000000000000000000;;		startTime := time.Now()
0000000000000000000000000000000000000000;;		var cachedService *cachedService
0000000000000000000000000000000000000000;;		var retryDelay time.Duration
0000000000000000000000000000000000000000;;		defer func() {
0000000000000000000000000000000000000000;;			glog.V(4).Infof("Finished syncing service %q (%v)", key, time.Now().Sub(startTime))
0000000000000000000000000000000000000000;;		}()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		namespace, name, err := cache.SplitMetaNamespaceKey(key)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// service holds the latest service info from apiserver
0000000000000000000000000000000000000000;;		service, err := s.serviceLister.Services(namespace).Get(name)
0000000000000000000000000000000000000000;;		switch {
0000000000000000000000000000000000000000;;		case errors.IsNotFound(err):
0000000000000000000000000000000000000000;;			// service absence in store means watcher caught the deletion, ensure LB info is cleaned
0000000000000000000000000000000000000000;;			glog.Infof("Service has been deleted %v", key)
0000000000000000000000000000000000000000;;			err, retryDelay = s.processServiceDeletion(key)
0000000000000000000000000000000000000000;;		case err != nil:
0000000000000000000000000000000000000000;;			glog.Infof("Unable to retrieve service %v from store: %v", key, err)
0000000000000000000000000000000000000000;;			s.workingQueue.Add(key)
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		default:
0000000000000000000000000000000000000000;;			cachedService = s.cache.getOrCreate(key)
0000000000000000000000000000000000000000;;			err, retryDelay = s.processServiceUpdate(cachedService, service, key)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if retryDelay != 0 {
0000000000000000000000000000000000000000;;			// Add the failed service back to the queue so we'll retry it.
0000000000000000000000000000000000000000;;			glog.Errorf("Failed to process service. Retrying in %s: %v", retryDelay, err)
0000000000000000000000000000000000000000;;			go func(obj interface{}, delay time.Duration) {
0000000000000000000000000000000000000000;;				// put back the service key to working queue, it is possible that more entries of the service
0000000000000000000000000000000000000000;;				// were added into the queue during the delay, but it does not mess as when handling the retry,
0000000000000000000000000000000000000000;;				// it always get the last service info from service store
0000000000000000000000000000000000000000;;				s.workingQueue.AddAfter(obj, delay)
0000000000000000000000000000000000000000;;			}(key, retryDelay)
0000000000000000000000000000000000000000;;		} else if err != nil {
0000000000000000000000000000000000000000;;			runtime.HandleError(fmt.Errorf("Failed to process service. Not retrying: %v", err))
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Returns an error if processing the service deletion failed, along with a time.Duration
0000000000000000000000000000000000000000;;	// indicating whether processing should be retried; zero means no-retry; otherwise
0000000000000000000000000000000000000000;;	// we should retry after that Duration.
0000000000000000000000000000000000000000;;	func (s *ServiceController) processServiceDeletion(key string) (error, time.Duration) {
0000000000000000000000000000000000000000;;		cachedService, ok := s.cache.get(key)
0000000000000000000000000000000000000000;;		if !ok {
0000000000000000000000000000000000000000;;			return fmt.Errorf("Service %s not in cache even though the watcher thought it was. Ignoring the deletion.", key), doNotRetry
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		service := cachedService.state
0000000000000000000000000000000000000000;;		// delete load balancer info only if the service type is LoadBalancer
0000000000000000000000000000000000000000;;		if !wantsLoadBalancer(service) {
0000000000000000000000000000000000000000;;			return nil, doNotRetry
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		s.eventRecorder.Event(service, v1.EventTypeNormal, "DeletingLoadBalancer", "Deleting load balancer")
0000000000000000000000000000000000000000;;		err := s.balancer.EnsureLoadBalancerDeleted(s.clusterName, service)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			message := "Error deleting load balancer (will retry): " + err.Error()
0000000000000000000000000000000000000000;;			s.eventRecorder.Event(service, v1.EventTypeWarning, "DeletingLoadBalancerFailed", message)
0000000000000000000000000000000000000000;;			return err, cachedService.nextRetryDelay()
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		s.eventRecorder.Event(service, v1.EventTypeNormal, "DeletedLoadBalancer", "Deleted load balancer")
0000000000000000000000000000000000000000;;		s.cache.delete(key)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		cachedService.resetRetryDelay()
0000000000000000000000000000000000000000;;		return nil, doNotRetry
0000000000000000000000000000000000000000;;	}
