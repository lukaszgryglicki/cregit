0000000000000000000000000000000000000000;;	/*
0000000000000000000000000000000000000000;;	Copyright 2014 The Kubernetes Authors.
1237530784a7997bfb6109bf25c6341a7dfafd2f;pkg/registry/cloud_minion_registry.go[pkg/registry/cloud_minion_registry.go][pkg/controller/node/nodecontroller.go];	
0000000000000000000000000000000000000000;;	Licensed under the Apache License, Version 2.0 (the "License");
0000000000000000000000000000000000000000;;	you may not use this file except in compliance with the License.
0000000000000000000000000000000000000000;;	You may obtain a copy of the License at
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	    http://www.apache.org/licenses/LICENSE-2.0
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	Unless required by applicable law or agreed to in writing, software
0000000000000000000000000000000000000000;;	distributed under the License is distributed on an "AS IS" BASIS,
0000000000000000000000000000000000000000;;	WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
0000000000000000000000000000000000000000;;	See the License for the specific language governing permissions and
0000000000000000000000000000000000000000;;	limitations under the License.
0000000000000000000000000000000000000000;;	*/
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	package node
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	import (
0000000000000000000000000000000000000000;;		"errors"
0000000000000000000000000000000000000000;;		"fmt"
0000000000000000000000000000000000000000;;		"net"
0000000000000000000000000000000000000000;;		"sync"
0000000000000000000000000000000000000000;;		"time"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		apiequality "k8s.io/apimachinery/pkg/api/equality"
0000000000000000000000000000000000000000;;		apierrors "k8s.io/apimachinery/pkg/api/errors"
0000000000000000000000000000000000000000;;		metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/fields"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/labels"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/types"
0000000000000000000000000000000000000000;;		utilruntime "k8s.io/apimachinery/pkg/util/runtime"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/util/wait"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		clientv1 "k8s.io/api/core/v1"
0000000000000000000000000000000000000000;;		v1core "k8s.io/client-go/kubernetes/typed/core/v1"
0000000000000000000000000000000000000000;;		"k8s.io/client-go/tools/cache"
0000000000000000000000000000000000000000;;		"k8s.io/client-go/tools/record"
0000000000000000000000000000000000000000;;		"k8s.io/client-go/util/flowcontrol"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		"k8s.io/api/core/v1"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/api"
0000000000000000000000000000000000000000;;		v1helper "k8s.io/kubernetes/pkg/api/v1/helper"
0000000000000000000000000000000000000000;;		nodeutil "k8s.io/kubernetes/pkg/api/v1/node"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/client/clientset_generated/clientset"
0000000000000000000000000000000000000000;;		coreinformers "k8s.io/kubernetes/pkg/client/informers/informers_generated/externalversions/core/v1"
0000000000000000000000000000000000000000;;		extensionsinformers "k8s.io/kubernetes/pkg/client/informers/informers_generated/externalversions/extensions/v1beta1"
0000000000000000000000000000000000000000;;		corelisters "k8s.io/kubernetes/pkg/client/listers/core/v1"
0000000000000000000000000000000000000000;;		extensionslisters "k8s.io/kubernetes/pkg/client/listers/extensions/v1beta1"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/cloudprovider"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/controller"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/util/metrics"
0000000000000000000000000000000000000000;;		utilnode "k8s.io/kubernetes/pkg/util/node"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/util/system"
0000000000000000000000000000000000000000;;		utilversion "k8s.io/kubernetes/pkg/util/version"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/plugin/pkg/scheduler/algorithm"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		"github.com/golang/glog"
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func init() {
0000000000000000000000000000000000000000;;		// Register prometheus metrics
0000000000000000000000000000000000000000;;		Register()
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	var (
0000000000000000000000000000000000000000;;		ErrCloudInstance        = errors.New("cloud provider doesn't support instances.")
0000000000000000000000000000000000000000;;		gracefulDeletionVersion = utilversion.MustParseSemantic("v1.1.0")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// The minimum kubelet version for which the nodecontroller
0000000000000000000000000000000000000000;;		// can safely flip pod.Status to NotReady.
0000000000000000000000000000000000000000;;		podStatusReconciliationVersion = utilversion.MustParseSemantic("v1.2.0")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		UnreachableTaintTemplate = &v1.Taint{
0000000000000000000000000000000000000000;;			Key:    algorithm.TaintNodeUnreachable,
0000000000000000000000000000000000000000;;			Effect: v1.TaintEffectNoExecute,
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		NotReadyTaintTemplate = &v1.Taint{
0000000000000000000000000000000000000000;;			Key:    algorithm.TaintNodeNotReady,
0000000000000000000000000000000000000000;;			Effect: v1.TaintEffectNoExecute,
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	const (
0000000000000000000000000000000000000000;;		// nodeStatusUpdateRetry controls the number of retries of writing NodeStatus update.
0000000000000000000000000000000000000000;;		nodeStatusUpdateRetry = 5
0000000000000000000000000000000000000000;;		// controls how often NodeController will try to evict Pods from non-responsive Nodes.
0000000000000000000000000000000000000000;;		nodeEvictionPeriod = 100 * time.Millisecond
0000000000000000000000000000000000000000;;		// Burst value for all eviction rate limiters
0000000000000000000000000000000000000000;;		evictionRateLimiterBurst = 1
0000000000000000000000000000000000000000;;		// The amount of time the nodecontroller polls on the list nodes endpoint.
0000000000000000000000000000000000000000;;		apiserverStartupGracePeriod = 10 * time.Minute
0000000000000000000000000000000000000000;;		// The amount of time the nodecontroller should sleep between retrying NodeStatus updates
0000000000000000000000000000000000000000;;		retrySleepTime = 20 * time.Millisecond
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type zoneState string
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	const (
0000000000000000000000000000000000000000;;		stateInitial           = zoneState("Initial")
0000000000000000000000000000000000000000;;		stateNormal            = zoneState("Normal")
0000000000000000000000000000000000000000;;		stateFullDisruption    = zoneState("FullDisruption")
0000000000000000000000000000000000000000;;		statePartialDisruption = zoneState("PartialDisruption")
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type nodeStatusData struct {
0000000000000000000000000000000000000000;;		probeTimestamp           metav1.Time
0000000000000000000000000000000000000000;;		readyTransitionTimestamp metav1.Time
0000000000000000000000000000000000000000;;		status                   v1.NodeStatus
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type NodeController struct {
0000000000000000000000000000000000000000;;		allocateNodeCIDRs bool
0000000000000000000000000000000000000000;;		allocatorType     CIDRAllocatorType
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		cloud        cloudprovider.Interface
0000000000000000000000000000000000000000;;		clusterCIDR  *net.IPNet
0000000000000000000000000000000000000000;;		serviceCIDR  *net.IPNet
0000000000000000000000000000000000000000;;		knownNodeSet map[string]*v1.Node
0000000000000000000000000000000000000000;;		kubeClient   clientset.Interface
0000000000000000000000000000000000000000;;		// Method for easy mocking in unittest.
0000000000000000000000000000000000000000;;		lookupIP func(host string) ([]net.IP, error)
0000000000000000000000000000000000000000;;		// Value used if sync_nodes_status=False. NodeController will not proactively
0000000000000000000000000000000000000000;;		// sync node status in this case, but will monitor node status updated from kubelet. If
0000000000000000000000000000000000000000;;		// it doesn't receive update for this amount of time, it will start posting "NodeReady==
0000000000000000000000000000000000000000;;		// ConditionUnknown". The amount of time before which NodeController start evicting pods
0000000000000000000000000000000000000000;;		// is controlled via flag 'pod-eviction-timeout'.
0000000000000000000000000000000000000000;;		// Note: be cautious when changing the constant, it must work with nodeStatusUpdateFrequency
0000000000000000000000000000000000000000;;		// in kubelet. There are several constraints:
0000000000000000000000000000000000000000;;		// 1. nodeMonitorGracePeriod must be N times more than nodeStatusUpdateFrequency, where
0000000000000000000000000000000000000000;;		//    N means number of retries allowed for kubelet to post node status. It is pointless
0000000000000000000000000000000000000000;;		//    to make nodeMonitorGracePeriod be less than nodeStatusUpdateFrequency, since there
0000000000000000000000000000000000000000;;		//    will only be fresh values from Kubelet at an interval of nodeStatusUpdateFrequency.
0000000000000000000000000000000000000000;;		//    The constant must be less than podEvictionTimeout.
0000000000000000000000000000000000000000;;		// 2. nodeMonitorGracePeriod can't be too large for user experience - larger value takes
0000000000000000000000000000000000000000;;		//    longer for user to see up-to-date node status.
0000000000000000000000000000000000000000;;		nodeMonitorGracePeriod time.Duration
0000000000000000000000000000000000000000;;		// Value controlling NodeController monitoring period, i.e. how often does NodeController
0000000000000000000000000000000000000000;;		// check node status posted from kubelet. This value should be lower than nodeMonitorGracePeriod.
0000000000000000000000000000000000000000;;		// TODO: Change node status monitor to watch based.
0000000000000000000000000000000000000000;;		nodeMonitorPeriod time.Duration
0000000000000000000000000000000000000000;;		// Value used if sync_nodes_status=False, only for node startup. When node
0000000000000000000000000000000000000000;;		// is just created, e.g. cluster bootstrap or node creation, we give a longer grace period.
0000000000000000000000000000000000000000;;		nodeStartupGracePeriod time.Duration
0000000000000000000000000000000000000000;;		// per Node map storing last observed Status together with a local time when it was observed.
0000000000000000000000000000000000000000;;		// This timestamp is to be used instead of LastProbeTime stored in Condition. We do this
0000000000000000000000000000000000000000;;		// to aviod the problem with time skew across the cluster.
0000000000000000000000000000000000000000;;		nodeStatusMap map[string]nodeStatusData
0000000000000000000000000000000000000000;;		now           func() metav1.Time
0000000000000000000000000000000000000000;;		// Lock to access evictor workers
0000000000000000000000000000000000000000;;		evictorLock sync.Mutex
0000000000000000000000000000000000000000;;		// workers that evicts pods from unresponsive nodes.
0000000000000000000000000000000000000000;;		zonePodEvictor map[string]*RateLimitedTimedQueue
0000000000000000000000000000000000000000;;		// workers that are responsible for tainting nodes.
0000000000000000000000000000000000000000;;		zoneNotReadyOrUnreachableTainer map[string]*RateLimitedTimedQueue
0000000000000000000000000000000000000000;;		podEvictionTimeout              time.Duration
0000000000000000000000000000000000000000;;		// The maximum duration before a pod evicted from a node can be forcefully terminated.
0000000000000000000000000000000000000000;;		maximumGracePeriod time.Duration
0000000000000000000000000000000000000000;;		recorder           record.EventRecorder
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		nodeLister         corelisters.NodeLister
0000000000000000000000000000000000000000;;		nodeInformerSynced cache.InformerSynced
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		daemonSetStore          extensionslisters.DaemonSetLister
0000000000000000000000000000000000000000;;		daemonSetInformerSynced cache.InformerSynced
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		podInformerSynced cache.InformerSynced
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		cidrAllocator CIDRAllocator
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		taintManager *NoExecuteTaintManager
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		forcefullyDeletePod        func(*v1.Pod) error
0000000000000000000000000000000000000000;;		nodeExistsInCloudProvider  func(types.NodeName) (bool, error)
0000000000000000000000000000000000000000;;		computeZoneStateFunc       func(nodeConditions []*v1.NodeCondition) (int, zoneState)
0000000000000000000000000000000000000000;;		enterPartialDisruptionFunc func(nodeNum int) float32
0000000000000000000000000000000000000000;;		enterFullDisruptionFunc    func(nodeNum int) float32
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		zoneStates                  map[string]zoneState
0000000000000000000000000000000000000000;;		evictionLimiterQPS          float32
0000000000000000000000000000000000000000;;		secondaryEvictionLimiterQPS float32
0000000000000000000000000000000000000000;;		largeClusterThreshold       int32
0000000000000000000000000000000000000000;;		unhealthyZoneThreshold      float32
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// if set to true NodeController will start TaintManager that will evict Pods from
0000000000000000000000000000000000000000;;		// tainted nodes, if they're not tolerated.
0000000000000000000000000000000000000000;;		runTaintManager bool
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// if set to true NodeController will taint Nodes with 'TaintNodeNotReady' and 'TaintNodeUnreachable'
0000000000000000000000000000000000000000;;		// taints instead of evicting Pods itself.
0000000000000000000000000000000000000000;;		useTaintBasedEvictions bool
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// NewNodeController returns a new node controller to sync instances from cloudprovider.
0000000000000000000000000000000000000000;;	// This method returns an error if it is unable to initialize the CIDR bitmap with
0000000000000000000000000000000000000000;;	// podCIDRs it has already allocated to nodes. Since we don't allow podCIDR changes
0000000000000000000000000000000000000000;;	// currently, this should be handled as a fatal error.
0000000000000000000000000000000000000000;;	func NewNodeController(
0000000000000000000000000000000000000000;;		podInformer coreinformers.PodInformer,
0000000000000000000000000000000000000000;;		nodeInformer coreinformers.NodeInformer,
0000000000000000000000000000000000000000;;		daemonSetInformer extensionsinformers.DaemonSetInformer,
0000000000000000000000000000000000000000;;		cloud cloudprovider.Interface,
0000000000000000000000000000000000000000;;		kubeClient clientset.Interface,
0000000000000000000000000000000000000000;;		podEvictionTimeout time.Duration,
0000000000000000000000000000000000000000;;		evictionLimiterQPS float32,
0000000000000000000000000000000000000000;;		secondaryEvictionLimiterQPS float32,
0000000000000000000000000000000000000000;;		largeClusterThreshold int32,
0000000000000000000000000000000000000000;;		unhealthyZoneThreshold float32,
0000000000000000000000000000000000000000;;		nodeMonitorGracePeriod time.Duration,
0000000000000000000000000000000000000000;;		nodeStartupGracePeriod time.Duration,
0000000000000000000000000000000000000000;;		nodeMonitorPeriod time.Duration,
0000000000000000000000000000000000000000;;		clusterCIDR *net.IPNet,
0000000000000000000000000000000000000000;;		serviceCIDR *net.IPNet,
0000000000000000000000000000000000000000;;		nodeCIDRMaskSize int,
0000000000000000000000000000000000000000;;		allocateNodeCIDRs bool,
0000000000000000000000000000000000000000;;		allocatorType CIDRAllocatorType,
0000000000000000000000000000000000000000;;		runTaintManager bool,
0000000000000000000000000000000000000000;;		useTaintBasedEvictions bool) (*NodeController, error) {
0000000000000000000000000000000000000000;;		eventBroadcaster := record.NewBroadcaster()
0000000000000000000000000000000000000000;;		recorder := eventBroadcaster.NewRecorder(api.Scheme, clientv1.EventSource{Component: "controllermanager"})
0000000000000000000000000000000000000000;;		eventBroadcaster.StartLogging(glog.Infof)
0000000000000000000000000000000000000000;;		if kubeClient != nil {
0000000000000000000000000000000000000000;;			glog.V(0).Infof("Sending events to api server.")
0000000000000000000000000000000000000000;;			eventBroadcaster.StartRecordingToSink(&v1core.EventSinkImpl{Interface: v1core.New(kubeClient.Core().RESTClient()).Events("")})
0000000000000000000000000000000000000000;;		} else {
0000000000000000000000000000000000000000;;			glog.Fatalf("kubeClient is nil when starting NodeController")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if kubeClient != nil && kubeClient.Core().RESTClient().GetRateLimiter() != nil {
0000000000000000000000000000000000000000;;			metrics.RegisterMetricAndTrackRateLimiterUsage("node_controller", kubeClient.Core().RESTClient().GetRateLimiter())
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if allocateNodeCIDRs {
0000000000000000000000000000000000000000;;			if clusterCIDR == nil {
0000000000000000000000000000000000000000;;				glog.Fatal("NodeController: Must specify clusterCIDR if allocateNodeCIDRs == true.")
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			mask := clusterCIDR.Mask
0000000000000000000000000000000000000000;;			if maskSize, _ := mask.Size(); maskSize > nodeCIDRMaskSize {
0000000000000000000000000000000000000000;;				glog.Fatal("NodeController: Invalid clusterCIDR, mask size of clusterCIDR must be less than nodeCIDRMaskSize.")
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		nc := &NodeController{
0000000000000000000000000000000000000000;;			cloud:                           cloud,
0000000000000000000000000000000000000000;;			knownNodeSet:                    make(map[string]*v1.Node),
0000000000000000000000000000000000000000;;			kubeClient:                      kubeClient,
0000000000000000000000000000000000000000;;			recorder:                        recorder,
0000000000000000000000000000000000000000;;			podEvictionTimeout:              podEvictionTimeout,
0000000000000000000000000000000000000000;;			maximumGracePeriod:              5 * time.Minute,
0000000000000000000000000000000000000000;;			zonePodEvictor:                  make(map[string]*RateLimitedTimedQueue),
0000000000000000000000000000000000000000;;			zoneNotReadyOrUnreachableTainer: make(map[string]*RateLimitedTimedQueue),
0000000000000000000000000000000000000000;;			nodeStatusMap:                   make(map[string]nodeStatusData),
0000000000000000000000000000000000000000;;			nodeMonitorGracePeriod:          nodeMonitorGracePeriod,
0000000000000000000000000000000000000000;;			nodeMonitorPeriod:               nodeMonitorPeriod,
0000000000000000000000000000000000000000;;			nodeStartupGracePeriod:          nodeStartupGracePeriod,
0000000000000000000000000000000000000000;;			lookupIP:                        net.LookupIP,
0000000000000000000000000000000000000000;;			now:                             metav1.Now,
0000000000000000000000000000000000000000;;			clusterCIDR:                     clusterCIDR,
0000000000000000000000000000000000000000;;			serviceCIDR:                     serviceCIDR,
0000000000000000000000000000000000000000;;			allocateNodeCIDRs:               allocateNodeCIDRs,
0000000000000000000000000000000000000000;;			allocatorType:                   allocatorType,
0000000000000000000000000000000000000000;;			forcefullyDeletePod:             func(p *v1.Pod) error { return forcefullyDeletePod(kubeClient, p) },
0000000000000000000000000000000000000000;;			nodeExistsInCloudProvider:       func(nodeName types.NodeName) (bool, error) { return nodeExistsInCloudProvider(cloud, nodeName) },
0000000000000000000000000000000000000000;;			evictionLimiterQPS:              evictionLimiterQPS,
0000000000000000000000000000000000000000;;			secondaryEvictionLimiterQPS:     secondaryEvictionLimiterQPS,
0000000000000000000000000000000000000000;;			largeClusterThreshold:           largeClusterThreshold,
0000000000000000000000000000000000000000;;			unhealthyZoneThreshold:          unhealthyZoneThreshold,
0000000000000000000000000000000000000000;;			zoneStates:                      make(map[string]zoneState),
0000000000000000000000000000000000000000;;			runTaintManager:                 runTaintManager,
0000000000000000000000000000000000000000;;			useTaintBasedEvictions:          useTaintBasedEvictions && runTaintManager,
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if useTaintBasedEvictions {
0000000000000000000000000000000000000000;;			glog.Infof("NodeController is using taint based evictions.")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		nc.enterPartialDisruptionFunc = nc.ReducedQPSFunc
0000000000000000000000000000000000000000;;		nc.enterFullDisruptionFunc = nc.HealthyQPSFunc
0000000000000000000000000000000000000000;;		nc.computeZoneStateFunc = nc.ComputeZoneState
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		podInformer.Informer().AddEventHandler(cache.ResourceEventHandlerFuncs{
0000000000000000000000000000000000000000;;			AddFunc: func(obj interface{}) {
0000000000000000000000000000000000000000;;				nc.maybeDeleteTerminatingPod(obj)
0000000000000000000000000000000000000000;;				pod := obj.(*v1.Pod)
0000000000000000000000000000000000000000;;				if nc.taintManager != nil {
0000000000000000000000000000000000000000;;					nc.taintManager.PodUpdated(nil, pod)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			UpdateFunc: func(prev, obj interface{}) {
0000000000000000000000000000000000000000;;				nc.maybeDeleteTerminatingPod(obj)
0000000000000000000000000000000000000000;;				prevPod := prev.(*v1.Pod)
0000000000000000000000000000000000000000;;				newPod := obj.(*v1.Pod)
0000000000000000000000000000000000000000;;				if nc.taintManager != nil {
0000000000000000000000000000000000000000;;					nc.taintManager.PodUpdated(prevPod, newPod)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			DeleteFunc: func(obj interface{}) {
0000000000000000000000000000000000000000;;				pod, isPod := obj.(*v1.Pod)
0000000000000000000000000000000000000000;;				// We can get DeletedFinalStateUnknown instead of *v1.Pod here and we need to handle that correctly.
0000000000000000000000000000000000000000;;				if !isPod {
0000000000000000000000000000000000000000;;					deletedState, ok := obj.(cache.DeletedFinalStateUnknown)
0000000000000000000000000000000000000000;;					if !ok {
0000000000000000000000000000000000000000;;						glog.Errorf("Received unexpected object: %v", obj)
0000000000000000000000000000000000000000;;						return
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					pod, ok = deletedState.Obj.(*v1.Pod)
0000000000000000000000000000000000000000;;					if !ok {
0000000000000000000000000000000000000000;;						glog.Errorf("DeletedFinalStateUnknown contained non-Pod object: %v", deletedState.Obj)
0000000000000000000000000000000000000000;;						return
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				if nc.taintManager != nil {
0000000000000000000000000000000000000000;;					nc.taintManager.PodUpdated(pod, nil)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;		nc.podInformerSynced = podInformer.Informer().HasSynced
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if nc.allocateNodeCIDRs {
0000000000000000000000000000000000000000;;			var nodeList *v1.NodeList
0000000000000000000000000000000000000000;;			var err error
0000000000000000000000000000000000000000;;			// We must poll because apiserver might not be up. This error causes
0000000000000000000000000000000000000000;;			// controller manager to restart.
0000000000000000000000000000000000000000;;			if pollErr := wait.Poll(10*time.Second, apiserverStartupGracePeriod, func() (bool, error) {
0000000000000000000000000000000000000000;;				nodeList, err = kubeClient.Core().Nodes().List(metav1.ListOptions{
0000000000000000000000000000000000000000;;					FieldSelector: fields.Everything().String(),
0000000000000000000000000000000000000000;;					LabelSelector: labels.Everything().String(),
0000000000000000000000000000000000000000;;				})
0000000000000000000000000000000000000000;;				if err != nil {
0000000000000000000000000000000000000000;;					glog.Errorf("Failed to list all nodes: %v", err)
0000000000000000000000000000000000000000;;					return false, nil
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				return true, nil
0000000000000000000000000000000000000000;;			}); pollErr != nil {
0000000000000000000000000000000000000000;;				return nil, fmt.Errorf("Failed to list all nodes in %v, cannot proceed without updating CIDR map", apiserverStartupGracePeriod)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			switch nc.allocatorType {
0000000000000000000000000000000000000000;;			case RangeAllocatorType:
0000000000000000000000000000000000000000;;				nc.cidrAllocator, err = NewCIDRRangeAllocator(
0000000000000000000000000000000000000000;;					kubeClient, clusterCIDR, serviceCIDR, nodeCIDRMaskSize, nodeList)
0000000000000000000000000000000000000000;;			case CloudAllocatorType:
0000000000000000000000000000000000000000;;				nc.cidrAllocator, err = NewCloudCIDRAllocator(kubeClient, cloud)
0000000000000000000000000000000000000000;;			default:
0000000000000000000000000000000000000000;;				return nil, fmt.Errorf("Invalid CIDR allocator type: %v", nc.allocatorType)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				return nil, err
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			nodeInformer.Informer().AddEventHandler(cache.ResourceEventHandlerFuncs{
0000000000000000000000000000000000000000;;				AddFunc: createAddNodeHandler(nc.cidrAllocator.AllocateOrOccupyCIDR),
0000000000000000000000000000000000000000;;				UpdateFunc: createUpdateNodeHandler(func(_, newNode *v1.Node) error {
0000000000000000000000000000000000000000;;					// If the PodCIDR is not empty we either:
0000000000000000000000000000000000000000;;					// - already processed a Node that already had a CIDR after NC restarted
0000000000000000000000000000000000000000;;					//   (cidr is marked as used),
0000000000000000000000000000000000000000;;					// - already processed a Node successfully and allocated a CIDR for it
0000000000000000000000000000000000000000;;					//   (cidr is marked as used),
0000000000000000000000000000000000000000;;					// - already processed a Node but we did saw a "timeout" response and
0000000000000000000000000000000000000000;;					//   request eventually got through in this case we haven't released
0000000000000000000000000000000000000000;;					//   the allocated CIDR (cidr is still marked as used).
0000000000000000000000000000000000000000;;					// There's a possible error here:
0000000000000000000000000000000000000000;;					// - NC sees a new Node and assigns a CIDR X to it,
0000000000000000000000000000000000000000;;					// - Update Node call fails with a timeout,
0000000000000000000000000000000000000000;;					// - Node is updated by some other component, NC sees an update and
0000000000000000000000000000000000000000;;					//   assigns CIDR Y to the Node,
0000000000000000000000000000000000000000;;					// - Both CIDR X and CIDR Y are marked as used in the local cache,
0000000000000000000000000000000000000000;;					//   even though Node sees only CIDR Y
0000000000000000000000000000000000000000;;					// The problem here is that in in-memory cache we see CIDR X as marked,
0000000000000000000000000000000000000000;;					// which prevents it from being assigned to any new node. The cluster
0000000000000000000000000000000000000000;;					// state is correct.
0000000000000000000000000000000000000000;;					// Restart of NC fixes the issue.
0000000000000000000000000000000000000000;;					if newNode.Spec.PodCIDR == "" {
0000000000000000000000000000000000000000;;						return nc.cidrAllocator.AllocateOrOccupyCIDR(newNode)
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					return nil
0000000000000000000000000000000000000000;;				}),
0000000000000000000000000000000000000000;;				DeleteFunc: createDeleteNodeHandler(nc.cidrAllocator.ReleaseCIDR),
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if nc.runTaintManager {
0000000000000000000000000000000000000000;;			nodeInformer.Informer().AddEventHandler(cache.ResourceEventHandlerFuncs{
0000000000000000000000000000000000000000;;				AddFunc: createAddNodeHandler(func(node *v1.Node) error {
0000000000000000000000000000000000000000;;					nc.taintManager.NodeUpdated(nil, node)
0000000000000000000000000000000000000000;;					return nil
0000000000000000000000000000000000000000;;				}),
0000000000000000000000000000000000000000;;				UpdateFunc: createUpdateNodeHandler(func(oldNode, newNode *v1.Node) error {
0000000000000000000000000000000000000000;;					nc.taintManager.NodeUpdated(oldNode, newNode)
0000000000000000000000000000000000000000;;					return nil
0000000000000000000000000000000000000000;;				}),
0000000000000000000000000000000000000000;;				DeleteFunc: createDeleteNodeHandler(func(node *v1.Node) error {
0000000000000000000000000000000000000000;;					nc.taintManager.NodeUpdated(node, nil)
0000000000000000000000000000000000000000;;					return nil
0000000000000000000000000000000000000000;;				}),
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;			nc.taintManager = NewNoExecuteTaintManager(kubeClient)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		nc.nodeLister = nodeInformer.Lister()
0000000000000000000000000000000000000000;;		nc.nodeInformerSynced = nodeInformer.Informer().HasSynced
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		nc.daemonSetStore = daemonSetInformer.Lister()
0000000000000000000000000000000000000000;;		nc.daemonSetInformerSynced = daemonSetInformer.Informer().HasSynced
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return nc, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (nc *NodeController) doEvictionPass() {
0000000000000000000000000000000000000000;;		nc.evictorLock.Lock()
0000000000000000000000000000000000000000;;		defer nc.evictorLock.Unlock()
0000000000000000000000000000000000000000;;		for k := range nc.zonePodEvictor {
0000000000000000000000000000000000000000;;			// Function should return 'false' and a time after which it should be retried, or 'true' if it shouldn't (it succeeded).
0000000000000000000000000000000000000000;;			nc.zonePodEvictor[k].Try(func(value TimedValue) (bool, time.Duration) {
0000000000000000000000000000000000000000;;				node, err := nc.nodeLister.Get(value.Value)
0000000000000000000000000000000000000000;;				if apierrors.IsNotFound(err) {
0000000000000000000000000000000000000000;;					glog.Warningf("Node %v no longer present in nodeLister!", value.Value)
0000000000000000000000000000000000000000;;				} else if err != nil {
0000000000000000000000000000000000000000;;					glog.Warningf("Failed to get Node %v from the nodeLister: %v", value.Value, err)
0000000000000000000000000000000000000000;;				} else {
0000000000000000000000000000000000000000;;					zone := utilnode.GetZoneKey(node)
0000000000000000000000000000000000000000;;					EvictionsNumber.WithLabelValues(zone).Inc()
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				nodeUid, _ := value.UID.(string)
0000000000000000000000000000000000000000;;				remaining, err := deletePods(nc.kubeClient, nc.recorder, value.Value, nodeUid, nc.daemonSetStore)
0000000000000000000000000000000000000000;;				if err != nil {
0000000000000000000000000000000000000000;;					utilruntime.HandleError(fmt.Errorf("unable to evict node %q: %v", value.Value, err))
0000000000000000000000000000000000000000;;					return false, 0
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				if remaining {
0000000000000000000000000000000000000000;;					glog.Infof("Pods awaiting deletion due to NodeController eviction")
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				return true, 0
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (nc *NodeController) doTaintingPass() {
0000000000000000000000000000000000000000;;		nc.evictorLock.Lock()
0000000000000000000000000000000000000000;;		defer nc.evictorLock.Unlock()
0000000000000000000000000000000000000000;;		for k := range nc.zoneNotReadyOrUnreachableTainer {
0000000000000000000000000000000000000000;;			// Function should return 'false' and a time after which it should be retried, or 'true' if it shouldn't (it succeeded).
0000000000000000000000000000000000000000;;			nc.zoneNotReadyOrUnreachableTainer[k].Try(func(value TimedValue) (bool, time.Duration) {
0000000000000000000000000000000000000000;;				node, err := nc.nodeLister.Get(value.Value)
0000000000000000000000000000000000000000;;				if apierrors.IsNotFound(err) {
0000000000000000000000000000000000000000;;					glog.Warningf("Node %v no longer present in nodeLister!", value.Value)
0000000000000000000000000000000000000000;;					return true, 0
0000000000000000000000000000000000000000;;				} else if err != nil {
0000000000000000000000000000000000000000;;					glog.Warningf("Failed to get Node %v from the nodeLister: %v", value.Value, err)
0000000000000000000000000000000000000000;;					// retry in 50 millisecond
0000000000000000000000000000000000000000;;					return false, 50 * time.Millisecond
0000000000000000000000000000000000000000;;				} else {
0000000000000000000000000000000000000000;;					zone := utilnode.GetZoneKey(node)
0000000000000000000000000000000000000000;;					EvictionsNumber.WithLabelValues(zone).Inc()
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				_, condition := nodeutil.GetNodeCondition(&node.Status, v1.NodeReady)
0000000000000000000000000000000000000000;;				// Because we want to mimic NodeStatus.Condition["Ready"] we make "unreachable" and "not ready" taints mutually exclusive.
0000000000000000000000000000000000000000;;				taintToAdd := v1.Taint{}
0000000000000000000000000000000000000000;;				oppositeTaint := v1.Taint{}
0000000000000000000000000000000000000000;;				if condition.Status == v1.ConditionFalse {
0000000000000000000000000000000000000000;;					taintToAdd = *NotReadyTaintTemplate
0000000000000000000000000000000000000000;;					oppositeTaint = *UnreachableTaintTemplate
0000000000000000000000000000000000000000;;				} else if condition.Status == v1.ConditionUnknown {
0000000000000000000000000000000000000000;;					taintToAdd = *UnreachableTaintTemplate
0000000000000000000000000000000000000000;;					oppositeTaint = *NotReadyTaintTemplate
0000000000000000000000000000000000000000;;				} else {
0000000000000000000000000000000000000000;;					// It seems that the Node is ready again, so there's no need to taint it.
0000000000000000000000000000000000000000;;					glog.V(4).Infof("Node %v was in a taint queue, but it's ready now. Ignoring taint request.", value.Value)
0000000000000000000000000000000000000000;;					return true, 0
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				return swapNodeControllerTaint(nc.kubeClient, &taintToAdd, &oppositeTaint, node), 0
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Run starts an asynchronous loop that monitors the status of cluster nodes.
0000000000000000000000000000000000000000;;	func (nc *NodeController) Run(stopCh <-chan struct{}) {
0000000000000000000000000000000000000000;;		defer utilruntime.HandleCrash()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		glog.Infof("Starting node controller")
0000000000000000000000000000000000000000;;		defer glog.Infof("Shutting down node controller")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if !controller.WaitForCacheSync("node", stopCh, nc.nodeInformerSynced, nc.podInformerSynced, nc.daemonSetInformerSynced) {
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Incorporate the results of node status pushed from kubelet to master.
0000000000000000000000000000000000000000;;		go wait.Until(func() {
0000000000000000000000000000000000000000;;			if err := nc.monitorNodeStatus(); err != nil {
0000000000000000000000000000000000000000;;				glog.Errorf("Error monitoring node status: %v", err)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}, nc.nodeMonitorPeriod, wait.NeverStop)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if nc.runTaintManager {
0000000000000000000000000000000000000000;;			go nc.taintManager.Run(wait.NeverStop)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if nc.useTaintBasedEvictions {
0000000000000000000000000000000000000000;;			// Handling taint based evictions. Because we don't want a dedicated logic in TaintManager for NC-originated
0000000000000000000000000000000000000000;;			// taints and we normally don't rate limit evictions caused by taints, we need to rate limit adding taints.
0000000000000000000000000000000000000000;;			go wait.Until(nc.doTaintingPass, nodeEvictionPeriod, wait.NeverStop)
0000000000000000000000000000000000000000;;		} else {
0000000000000000000000000000000000000000;;			// Managing eviction of nodes:
0000000000000000000000000000000000000000;;			// When we delete pods off a node, if the node was not empty at the time we then
0000000000000000000000000000000000000000;;			// queue an eviction watcher. If we hit an error, retry deletion.
0000000000000000000000000000000000000000;;			go wait.Until(nc.doEvictionPass, nodeEvictionPeriod, wait.NeverStop)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		<-stopCh
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// addPodEvictorForNewZone checks if new zone appeared, and if so add new evictor.
0000000000000000000000000000000000000000;;	func (nc *NodeController) addPodEvictorForNewZone(node *v1.Node) {
0000000000000000000000000000000000000000;;		zone := utilnode.GetZoneKey(node)
0000000000000000000000000000000000000000;;		if _, found := nc.zoneStates[zone]; !found {
0000000000000000000000000000000000000000;;			nc.zoneStates[zone] = stateInitial
0000000000000000000000000000000000000000;;			if !nc.useTaintBasedEvictions {
0000000000000000000000000000000000000000;;				nc.zonePodEvictor[zone] =
0000000000000000000000000000000000000000;;					NewRateLimitedTimedQueue(
0000000000000000000000000000000000000000;;						flowcontrol.NewTokenBucketRateLimiter(nc.evictionLimiterQPS, evictionRateLimiterBurst))
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				nc.zoneNotReadyOrUnreachableTainer[zone] =
0000000000000000000000000000000000000000;;					NewRateLimitedTimedQueue(
0000000000000000000000000000000000000000;;						flowcontrol.NewTokenBucketRateLimiter(nc.evictionLimiterQPS, evictionRateLimiterBurst))
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			// Init the metric for the new zone.
0000000000000000000000000000000000000000;;			glog.Infof("Initializing eviction metric for zone: %v", zone)
0000000000000000000000000000000000000000;;			EvictionsNumber.WithLabelValues(zone).Add(0)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// monitorNodeStatus verifies node status are constantly updated by kubelet, and if not,
0000000000000000000000000000000000000000;;	// post "NodeReady==ConditionUnknown". It also evicts all pods if node is not ready or
0000000000000000000000000000000000000000;;	// not reachable for a long period of time.
0000000000000000000000000000000000000000;;	func (nc *NodeController) monitorNodeStatus() error {
0000000000000000000000000000000000000000;;		// We are listing nodes from local cache as we can tolerate some small delays
0000000000000000000000000000000000000000;;		// comparing to state from etcd and there is eventual consistency anyway.
0000000000000000000000000000000000000000;;		nodes, err := nc.nodeLister.List(labels.Everything())
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		added, deleted, newZoneRepresentatives := nc.classifyNodes(nodes)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		for i := range newZoneRepresentatives {
0000000000000000000000000000000000000000;;			nc.addPodEvictorForNewZone(newZoneRepresentatives[i])
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		for i := range added {
0000000000000000000000000000000000000000;;			glog.V(1).Infof("NodeController observed a new Node: %#v", added[i].Name)
0000000000000000000000000000000000000000;;			recordNodeEvent(nc.recorder, added[i].Name, string(added[i].UID), v1.EventTypeNormal, "RegisteredNode", fmt.Sprintf("Registered Node %v in NodeController", added[i].Name))
0000000000000000000000000000000000000000;;			nc.knownNodeSet[added[i].Name] = added[i]
0000000000000000000000000000000000000000;;			nc.addPodEvictorForNewZone(added[i])
0000000000000000000000000000000000000000;;			if nc.useTaintBasedEvictions {
0000000000000000000000000000000000000000;;				nc.markNodeAsHealthy(added[i])
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				nc.cancelPodEviction(added[i])
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		for i := range deleted {
0000000000000000000000000000000000000000;;			glog.V(1).Infof("NodeController observed a Node deletion: %v", deleted[i].Name)
0000000000000000000000000000000000000000;;			recordNodeEvent(nc.recorder, deleted[i].Name, string(deleted[i].UID), v1.EventTypeNormal, "RemovingNode", fmt.Sprintf("Removing Node %v from NodeController", deleted[i].Name))
0000000000000000000000000000000000000000;;			delete(nc.knownNodeSet, deleted[i].Name)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		zoneToNodeConditions := map[string][]*v1.NodeCondition{}
0000000000000000000000000000000000000000;;		for i := range nodes {
0000000000000000000000000000000000000000;;			var gracePeriod time.Duration
0000000000000000000000000000000000000000;;			var observedReadyCondition v1.NodeCondition
0000000000000000000000000000000000000000;;			var currentReadyCondition *v1.NodeCondition
0000000000000000000000000000000000000000;;			nodeCopy, err := api.Scheme.DeepCopy(nodes[i])
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				utilruntime.HandleError(err)
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			node := nodeCopy.(*v1.Node)
0000000000000000000000000000000000000000;;			if err := wait.PollImmediate(retrySleepTime, retrySleepTime*nodeStatusUpdateRetry, func() (bool, error) {
0000000000000000000000000000000000000000;;				gracePeriod, observedReadyCondition, currentReadyCondition, err = nc.tryUpdateNodeStatus(node)
0000000000000000000000000000000000000000;;				if err == nil {
0000000000000000000000000000000000000000;;					return true, nil
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				name := node.Name
0000000000000000000000000000000000000000;;				node, err = nc.kubeClient.Core().Nodes().Get(name, metav1.GetOptions{})
0000000000000000000000000000000000000000;;				if err != nil {
0000000000000000000000000000000000000000;;					glog.Errorf("Failed while getting a Node to retry updating NodeStatus. Probably Node %s was deleted.", name)
0000000000000000000000000000000000000000;;					return false, err
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				return false, nil
0000000000000000000000000000000000000000;;			}); err != nil {
0000000000000000000000000000000000000000;;				glog.Errorf("Update status  of Node %v from NodeController error : %v. "+
0000000000000000000000000000000000000000;;					"Skipping - no pods will be evicted.", node.Name, err)
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// We do not treat a master node as a part of the cluster for network disruption checking.
0000000000000000000000000000000000000000;;			if !system.IsMasterNode(node.Name) {
0000000000000000000000000000000000000000;;				zoneToNodeConditions[utilnode.GetZoneKey(node)] = append(zoneToNodeConditions[utilnode.GetZoneKey(node)], currentReadyCondition)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			decisionTimestamp := nc.now()
0000000000000000000000000000000000000000;;			if currentReadyCondition != nil {
0000000000000000000000000000000000000000;;				// Check eviction timeout against decisionTimestamp
0000000000000000000000000000000000000000;;				if observedReadyCondition.Status == v1.ConditionFalse {
0000000000000000000000000000000000000000;;					if nc.useTaintBasedEvictions {
0000000000000000000000000000000000000000;;						// We want to update the taint straight away if Node is already tainted with the UnreachableTaint
0000000000000000000000000000000000000000;;						if v1helper.TaintExists(node.Spec.Taints, UnreachableTaintTemplate) {
0000000000000000000000000000000000000000;;							taintToAdd := *NotReadyTaintTemplate
0000000000000000000000000000000000000000;;							if !swapNodeControllerTaint(nc.kubeClient, &taintToAdd, UnreachableTaintTemplate, node) {
0000000000000000000000000000000000000000;;								glog.Errorf("Failed to instantly swap UnreachableTaint to NotReadyTaint. Will try again in the next cycle.")
0000000000000000000000000000000000000000;;							}
0000000000000000000000000000000000000000;;						} else if nc.markNodeForTainting(node) {
0000000000000000000000000000000000000000;;							glog.V(2).Infof("Node %v is NotReady as of %v. Adding it to the Taint queue.",
0000000000000000000000000000000000000000;;								node.Name,
0000000000000000000000000000000000000000;;								decisionTimestamp,
0000000000000000000000000000000000000000;;							)
0000000000000000000000000000000000000000;;						}
0000000000000000000000000000000000000000;;					} else {
0000000000000000000000000000000000000000;;						if decisionTimestamp.After(nc.nodeStatusMap[node.Name].readyTransitionTimestamp.Add(nc.podEvictionTimeout)) {
0000000000000000000000000000000000000000;;							if nc.evictPods(node) {
0000000000000000000000000000000000000000;;								glog.V(2).Infof("Node is NotReady. Adding Pods on Node %s to eviction queue: %v is later than %v + %v",
0000000000000000000000000000000000000000;;									node.Name,
0000000000000000000000000000000000000000;;									decisionTimestamp,
0000000000000000000000000000000000000000;;									nc.nodeStatusMap[node.Name].readyTransitionTimestamp,
0000000000000000000000000000000000000000;;									nc.podEvictionTimeout,
0000000000000000000000000000000000000000;;								)
0000000000000000000000000000000000000000;;							}
0000000000000000000000000000000000000000;;						}
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				if observedReadyCondition.Status == v1.ConditionUnknown {
0000000000000000000000000000000000000000;;					if nc.useTaintBasedEvictions {
0000000000000000000000000000000000000000;;						// We want to update the taint straight away if Node is already tainted with the UnreachableTaint
0000000000000000000000000000000000000000;;						if v1helper.TaintExists(node.Spec.Taints, NotReadyTaintTemplate) {
0000000000000000000000000000000000000000;;							taintToAdd := *UnreachableTaintTemplate
0000000000000000000000000000000000000000;;							if !swapNodeControllerTaint(nc.kubeClient, &taintToAdd, NotReadyTaintTemplate, node) {
0000000000000000000000000000000000000000;;								glog.Errorf("Failed to instantly swap UnreachableTaint to NotReadyTaint. Will try again in the next cycle.")
0000000000000000000000000000000000000000;;							}
0000000000000000000000000000000000000000;;						} else if nc.markNodeForTainting(node) {
0000000000000000000000000000000000000000;;							glog.V(2).Infof("Node %v is unresponsive as of %v. Adding it to the Taint queue.",
0000000000000000000000000000000000000000;;								node.Name,
0000000000000000000000000000000000000000;;								decisionTimestamp,
0000000000000000000000000000000000000000;;							)
0000000000000000000000000000000000000000;;						}
0000000000000000000000000000000000000000;;					} else {
0000000000000000000000000000000000000000;;						if decisionTimestamp.After(nc.nodeStatusMap[node.Name].probeTimestamp.Add(nc.podEvictionTimeout)) {
0000000000000000000000000000000000000000;;							if nc.evictPods(node) {
0000000000000000000000000000000000000000;;								glog.V(2).Infof("Node is unresponsive. Adding Pods on Node %s to eviction queues: %v is later than %v + %v",
0000000000000000000000000000000000000000;;									node.Name,
0000000000000000000000000000000000000000;;									decisionTimestamp,
0000000000000000000000000000000000000000;;									nc.nodeStatusMap[node.Name].readyTransitionTimestamp,
0000000000000000000000000000000000000000;;									nc.podEvictionTimeout-gracePeriod,
0000000000000000000000000000000000000000;;								)
0000000000000000000000000000000000000000;;							}
0000000000000000000000000000000000000000;;						}
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				if observedReadyCondition.Status == v1.ConditionTrue {
0000000000000000000000000000000000000000;;					if nc.useTaintBasedEvictions {
0000000000000000000000000000000000000000;;						removed, err := nc.markNodeAsHealthy(node)
0000000000000000000000000000000000000000;;						if err != nil {
0000000000000000000000000000000000000000;;							glog.Errorf("Failed to remove taints from node %v. Will retry in next iteration.", node.Name)
0000000000000000000000000000000000000000;;						}
0000000000000000000000000000000000000000;;						if removed {
0000000000000000000000000000000000000000;;							glog.V(2).Infof("Node %s is healthy again, removing all taints", node.Name)
0000000000000000000000000000000000000000;;						}
0000000000000000000000000000000000000000;;					} else {
0000000000000000000000000000000000000000;;						if nc.cancelPodEviction(node) {
0000000000000000000000000000000000000000;;							glog.V(2).Infof("Node %s is ready again, cancelled pod eviction", node.Name)
0000000000000000000000000000000000000000;;						}
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				// Report node event.
0000000000000000000000000000000000000000;;				if currentReadyCondition.Status != v1.ConditionTrue && observedReadyCondition.Status == v1.ConditionTrue {
0000000000000000000000000000000000000000;;					recordNodeStatusChange(nc.recorder, node, "NodeNotReady")
0000000000000000000000000000000000000000;;					if err = markAllPodsNotReady(nc.kubeClient, node); err != nil {
0000000000000000000000000000000000000000;;						utilruntime.HandleError(fmt.Errorf("Unable to mark all pods NotReady on node %v: %v", node.Name, err))
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				// Check with the cloud provider to see if the node still exists. If it
0000000000000000000000000000000000000000;;				// doesn't, delete the node immediately.
0000000000000000000000000000000000000000;;				if currentReadyCondition.Status != v1.ConditionTrue && nc.cloud != nil {
0000000000000000000000000000000000000000;;					exists, err := nc.nodeExistsInCloudProvider(types.NodeName(node.Name))
0000000000000000000000000000000000000000;;					if err != nil {
0000000000000000000000000000000000000000;;						glog.Errorf("Error determining if node %v exists in cloud: %v", node.Name, err)
0000000000000000000000000000000000000000;;						continue
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					if !exists {
0000000000000000000000000000000000000000;;						glog.V(2).Infof("Deleting node (no longer present in cloud provider): %s", node.Name)
0000000000000000000000000000000000000000;;						recordNodeEvent(nc.recorder, node.Name, string(node.UID), v1.EventTypeNormal, "DeletingNode", fmt.Sprintf("Deleting Node %v because it's not present according to cloud provider", node.Name))
0000000000000000000000000000000000000000;;						go func(nodeName string) {
0000000000000000000000000000000000000000;;							defer utilruntime.HandleCrash()
0000000000000000000000000000000000000000;;							// Kubelet is not reporting and Cloud Provider says node
0000000000000000000000000000000000000000;;							// is gone. Delete it without worrying about grace
0000000000000000000000000000000000000000;;							// periods.
0000000000000000000000000000000000000000;;							if err := forcefullyDeleteNode(nc.kubeClient, nodeName); err != nil {
0000000000000000000000000000000000000000;;								glog.Errorf("Unable to forcefully delete node %q: %v", nodeName, err)
0000000000000000000000000000000000000000;;							}
0000000000000000000000000000000000000000;;						}(node.Name)
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		nc.handleDisruption(zoneToNodeConditions, nodes)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (nc *NodeController) handleDisruption(zoneToNodeConditions map[string][]*v1.NodeCondition, nodes []*v1.Node) {
0000000000000000000000000000000000000000;;		newZoneStates := map[string]zoneState{}
0000000000000000000000000000000000000000;;		allAreFullyDisrupted := true
0000000000000000000000000000000000000000;;		for k, v := range zoneToNodeConditions {
0000000000000000000000000000000000000000;;			ZoneSize.WithLabelValues(k).Set(float64(len(v)))
0000000000000000000000000000000000000000;;			unhealthy, newState := nc.computeZoneStateFunc(v)
0000000000000000000000000000000000000000;;			ZoneHealth.WithLabelValues(k).Set(float64(100*(len(v)-unhealthy)) / float64(len(v)))
0000000000000000000000000000000000000000;;			UnhealthyNodes.WithLabelValues(k).Set(float64(unhealthy))
0000000000000000000000000000000000000000;;			if newState != stateFullDisruption {
0000000000000000000000000000000000000000;;				allAreFullyDisrupted = false
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			newZoneStates[k] = newState
0000000000000000000000000000000000000000;;			if _, had := nc.zoneStates[k]; !had {
0000000000000000000000000000000000000000;;				glog.Errorf("Setting initial state for unseen zone: %v", k)
0000000000000000000000000000000000000000;;				nc.zoneStates[k] = stateInitial
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		allWasFullyDisrupted := true
0000000000000000000000000000000000000000;;		for k, v := range nc.zoneStates {
0000000000000000000000000000000000000000;;			if _, have := zoneToNodeConditions[k]; !have {
0000000000000000000000000000000000000000;;				ZoneSize.WithLabelValues(k).Set(0)
0000000000000000000000000000000000000000;;				ZoneHealth.WithLabelValues(k).Set(100)
0000000000000000000000000000000000000000;;				UnhealthyNodes.WithLabelValues(k).Set(0)
0000000000000000000000000000000000000000;;				delete(nc.zoneStates, k)
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if v != stateFullDisruption {
0000000000000000000000000000000000000000;;				allWasFullyDisrupted = false
0000000000000000000000000000000000000000;;				break
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// At least one node was responding in previous pass or in the current pass. Semantics is as follows:
0000000000000000000000000000000000000000;;		// - if the new state is "partialDisruption" we call a user defined function that returns a new limiter to use,
0000000000000000000000000000000000000000;;		// - if the new state is "normal" we resume normal operation (go back to default limiter settings),
0000000000000000000000000000000000000000;;		// - if new state is "fullDisruption" we restore normal eviction rate,
0000000000000000000000000000000000000000;;		//   - unless all zones in the cluster are in "fullDisruption" - in that case we stop all evictions.
0000000000000000000000000000000000000000;;		if !allAreFullyDisrupted || !allWasFullyDisrupted {
0000000000000000000000000000000000000000;;			// We're switching to full disruption mode
0000000000000000000000000000000000000000;;			if allAreFullyDisrupted {
0000000000000000000000000000000000000000;;				glog.V(0).Info("NodeController detected that all Nodes are not-Ready. Entering master disruption mode.")
0000000000000000000000000000000000000000;;				for i := range nodes {
0000000000000000000000000000000000000000;;					if nc.useTaintBasedEvictions {
0000000000000000000000000000000000000000;;						_, err := nc.markNodeAsHealthy(nodes[i])
0000000000000000000000000000000000000000;;						if err != nil {
0000000000000000000000000000000000000000;;							glog.Errorf("Failed to remove taints from Node %v", nodes[i].Name)
0000000000000000000000000000000000000000;;						}
0000000000000000000000000000000000000000;;					} else {
0000000000000000000000000000000000000000;;						nc.cancelPodEviction(nodes[i])
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				// We stop all evictions.
0000000000000000000000000000000000000000;;				for k := range nc.zoneStates {
0000000000000000000000000000000000000000;;					if nc.useTaintBasedEvictions {
0000000000000000000000000000000000000000;;						nc.zoneNotReadyOrUnreachableTainer[k].SwapLimiter(0)
0000000000000000000000000000000000000000;;					} else {
0000000000000000000000000000000000000000;;						nc.zonePodEvictor[k].SwapLimiter(0)
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				for k := range nc.zoneStates {
0000000000000000000000000000000000000000;;					nc.zoneStates[k] = stateFullDisruption
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				// All rate limiters are updated, so we can return early here.
0000000000000000000000000000000000000000;;				return
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			// We're exiting full disruption mode
0000000000000000000000000000000000000000;;			if allWasFullyDisrupted {
0000000000000000000000000000000000000000;;				glog.V(0).Info("NodeController detected that some Nodes are Ready. Exiting master disruption mode.")
0000000000000000000000000000000000000000;;				// When exiting disruption mode update probe timestamps on all Nodes.
0000000000000000000000000000000000000000;;				now := nc.now()
0000000000000000000000000000000000000000;;				for i := range nodes {
0000000000000000000000000000000000000000;;					v := nc.nodeStatusMap[nodes[i].Name]
0000000000000000000000000000000000000000;;					v.probeTimestamp = now
0000000000000000000000000000000000000000;;					v.readyTransitionTimestamp = now
0000000000000000000000000000000000000000;;					nc.nodeStatusMap[nodes[i].Name] = v
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				// We reset all rate limiters to settings appropriate for the given state.
0000000000000000000000000000000000000000;;				for k := range nc.zoneStates {
0000000000000000000000000000000000000000;;					nc.setLimiterInZone(k, len(zoneToNodeConditions[k]), newZoneStates[k])
0000000000000000000000000000000000000000;;					nc.zoneStates[k] = newZoneStates[k]
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				return
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			// We know that there's at least one not-fully disrupted so,
0000000000000000000000000000000000000000;;			// we can use default behavior for rate limiters
0000000000000000000000000000000000000000;;			for k, v := range nc.zoneStates {
0000000000000000000000000000000000000000;;				newState := newZoneStates[k]
0000000000000000000000000000000000000000;;				if v == newState {
0000000000000000000000000000000000000000;;					continue
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				glog.V(0).Infof("NodeController detected that zone %v is now in state %v.", k, newState)
0000000000000000000000000000000000000000;;				nc.setLimiterInZone(k, len(zoneToNodeConditions[k]), newState)
0000000000000000000000000000000000000000;;				nc.zoneStates[k] = newState
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (nc *NodeController) setLimiterInZone(zone string, zoneSize int, state zoneState) {
0000000000000000000000000000000000000000;;		switch state {
0000000000000000000000000000000000000000;;		case stateNormal:
0000000000000000000000000000000000000000;;			if nc.useTaintBasedEvictions {
0000000000000000000000000000000000000000;;				nc.zoneNotReadyOrUnreachableTainer[zone].SwapLimiter(nc.evictionLimiterQPS)
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				nc.zonePodEvictor[zone].SwapLimiter(nc.evictionLimiterQPS)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		case statePartialDisruption:
0000000000000000000000000000000000000000;;			if nc.useTaintBasedEvictions {
0000000000000000000000000000000000000000;;				nc.zoneNotReadyOrUnreachableTainer[zone].SwapLimiter(
0000000000000000000000000000000000000000;;					nc.enterPartialDisruptionFunc(zoneSize))
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				nc.zonePodEvictor[zone].SwapLimiter(
0000000000000000000000000000000000000000;;					nc.enterPartialDisruptionFunc(zoneSize))
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		case stateFullDisruption:
0000000000000000000000000000000000000000;;			if nc.useTaintBasedEvictions {
0000000000000000000000000000000000000000;;				nc.zoneNotReadyOrUnreachableTainer[zone].SwapLimiter(
0000000000000000000000000000000000000000;;					nc.enterFullDisruptionFunc(zoneSize))
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				nc.zonePodEvictor[zone].SwapLimiter(
0000000000000000000000000000000000000000;;					nc.enterFullDisruptionFunc(zoneSize))
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// For a given node checks its conditions and tries to update it. Returns grace period to which given node
0000000000000000000000000000000000000000;;	// is entitled, state of current and last observed Ready Condition, and an error if it occurred.
0000000000000000000000000000000000000000;;	func (nc *NodeController) tryUpdateNodeStatus(node *v1.Node) (time.Duration, v1.NodeCondition, *v1.NodeCondition, error) {
0000000000000000000000000000000000000000;;		var err error
0000000000000000000000000000000000000000;;		var gracePeriod time.Duration
0000000000000000000000000000000000000000;;		var observedReadyCondition v1.NodeCondition
0000000000000000000000000000000000000000;;		_, currentReadyCondition := nodeutil.GetNodeCondition(&node.Status, v1.NodeReady)
0000000000000000000000000000000000000000;;		if currentReadyCondition == nil {
0000000000000000000000000000000000000000;;			// If ready condition is nil, then kubelet (or nodecontroller) never posted node status.
0000000000000000000000000000000000000000;;			// A fake ready condition is created, where LastProbeTime and LastTransitionTime is set
0000000000000000000000000000000000000000;;			// to node.CreationTimestamp to avoid handle the corner case.
0000000000000000000000000000000000000000;;			observedReadyCondition = v1.NodeCondition{
0000000000000000000000000000000000000000;;				Type:               v1.NodeReady,
0000000000000000000000000000000000000000;;				Status:             v1.ConditionUnknown,
0000000000000000000000000000000000000000;;				LastHeartbeatTime:  node.CreationTimestamp,
0000000000000000000000000000000000000000;;				LastTransitionTime: node.CreationTimestamp,
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			gracePeriod = nc.nodeStartupGracePeriod
0000000000000000000000000000000000000000;;			nc.nodeStatusMap[node.Name] = nodeStatusData{
0000000000000000000000000000000000000000;;				status:                   node.Status,
0000000000000000000000000000000000000000;;				probeTimestamp:           node.CreationTimestamp,
0000000000000000000000000000000000000000;;				readyTransitionTimestamp: node.CreationTimestamp,
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		} else {
0000000000000000000000000000000000000000;;			// If ready condition is not nil, make a copy of it, since we may modify it in place later.
0000000000000000000000000000000000000000;;			observedReadyCondition = *currentReadyCondition
0000000000000000000000000000000000000000;;			gracePeriod = nc.nodeMonitorGracePeriod
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		savedNodeStatus, found := nc.nodeStatusMap[node.Name]
0000000000000000000000000000000000000000;;		// There are following cases to check:
0000000000000000000000000000000000000000;;		// - both saved and new status have no Ready Condition set - we leave everything as it is,
0000000000000000000000000000000000000000;;		// - saved status have no Ready Condition, but current one does - NodeController was restarted with Node data already present in etcd,
0000000000000000000000000000000000000000;;		// - saved status have some Ready Condition, but current one does not - it's an error, but we fill it up because that's probably a good thing to do,
0000000000000000000000000000000000000000;;		// - both saved and current statuses have Ready Conditions and they have the same LastProbeTime - nothing happened on that Node, it may be
0000000000000000000000000000000000000000;;		//   unresponsive, so we leave it as it is,
0000000000000000000000000000000000000000;;		// - both saved and current statuses have Ready Conditions, they have different LastProbeTimes, but the same Ready Condition State -
0000000000000000000000000000000000000000;;		//   everything's in order, no transition occurred, we update only probeTimestamp,
0000000000000000000000000000000000000000;;		// - both saved and current statuses have Ready Conditions, different LastProbeTimes and different Ready Condition State -
0000000000000000000000000000000000000000;;		//   Ready Condition changed it state since we last seen it, so we update both probeTimestamp and readyTransitionTimestamp.
0000000000000000000000000000000000000000;;		// TODO: things to consider:
0000000000000000000000000000000000000000;;		//   - if 'LastProbeTime' have gone back in time its probably an error, currently we ignore it,
0000000000000000000000000000000000000000;;		//   - currently only correct Ready State transition outside of Node Controller is marking it ready by Kubelet, we don't check
0000000000000000000000000000000000000000;;		//     if that's the case, but it does not seem necessary.
0000000000000000000000000000000000000000;;		var savedCondition *v1.NodeCondition
0000000000000000000000000000000000000000;;		if found {
0000000000000000000000000000000000000000;;			_, savedCondition = nodeutil.GetNodeCondition(&savedNodeStatus.status, v1.NodeReady)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		_, observedCondition := nodeutil.GetNodeCondition(&node.Status, v1.NodeReady)
0000000000000000000000000000000000000000;;		if !found {
0000000000000000000000000000000000000000;;			glog.Warningf("Missing timestamp for Node %s. Assuming now as a timestamp.", node.Name)
0000000000000000000000000000000000000000;;			savedNodeStatus = nodeStatusData{
0000000000000000000000000000000000000000;;				status:                   node.Status,
0000000000000000000000000000000000000000;;				probeTimestamp:           nc.now(),
0000000000000000000000000000000000000000;;				readyTransitionTimestamp: nc.now(),
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		} else if savedCondition == nil && observedCondition != nil {
0000000000000000000000000000000000000000;;			glog.V(1).Infof("Creating timestamp entry for newly observed Node %s", node.Name)
0000000000000000000000000000000000000000;;			savedNodeStatus = nodeStatusData{
0000000000000000000000000000000000000000;;				status:                   node.Status,
0000000000000000000000000000000000000000;;				probeTimestamp:           nc.now(),
0000000000000000000000000000000000000000;;				readyTransitionTimestamp: nc.now(),
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		} else if savedCondition != nil && observedCondition == nil {
0000000000000000000000000000000000000000;;			glog.Errorf("ReadyCondition was removed from Status of Node %s", node.Name)
0000000000000000000000000000000000000000;;			// TODO: figure out what to do in this case. For now we do the same thing as above.
0000000000000000000000000000000000000000;;			savedNodeStatus = nodeStatusData{
0000000000000000000000000000000000000000;;				status:                   node.Status,
0000000000000000000000000000000000000000;;				probeTimestamp:           nc.now(),
0000000000000000000000000000000000000000;;				readyTransitionTimestamp: nc.now(),
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		} else if savedCondition != nil && observedCondition != nil && savedCondition.LastHeartbeatTime != observedCondition.LastHeartbeatTime {
0000000000000000000000000000000000000000;;			var transitionTime metav1.Time
0000000000000000000000000000000000000000;;			// If ReadyCondition changed since the last time we checked, we update the transition timestamp to "now",
0000000000000000000000000000000000000000;;			// otherwise we leave it as it is.
0000000000000000000000000000000000000000;;			if savedCondition.LastTransitionTime != observedCondition.LastTransitionTime {
0000000000000000000000000000000000000000;;				glog.V(3).Infof("ReadyCondition for Node %s transitioned from %v to %v", node.Name, savedCondition.Status, observedCondition)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				transitionTime = nc.now()
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				transitionTime = savedNodeStatus.readyTransitionTimestamp
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if glog.V(5) {
0000000000000000000000000000000000000000;;				glog.V(5).Infof("Node %s ReadyCondition updated. Updating timestamp: %+v vs %+v.", node.Name, savedNodeStatus.status, node.Status)
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				glog.V(3).Infof("Node %s ReadyCondition updated. Updating timestamp.", node.Name)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			savedNodeStatus = nodeStatusData{
0000000000000000000000000000000000000000;;				status:                   node.Status,
0000000000000000000000000000000000000000;;				probeTimestamp:           nc.now(),
0000000000000000000000000000000000000000;;				readyTransitionTimestamp: transitionTime,
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		nc.nodeStatusMap[node.Name] = savedNodeStatus
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if nc.now().After(savedNodeStatus.probeTimestamp.Add(gracePeriod)) {
0000000000000000000000000000000000000000;;			// NodeReady condition was last set longer ago than gracePeriod, so update it to Unknown
0000000000000000000000000000000000000000;;			// (regardless of its current value) in the master.
0000000000000000000000000000000000000000;;			if currentReadyCondition == nil {
0000000000000000000000000000000000000000;;				glog.V(2).Infof("node %v is never updated by kubelet", node.Name)
0000000000000000000000000000000000000000;;				node.Status.Conditions = append(node.Status.Conditions, v1.NodeCondition{
0000000000000000000000000000000000000000;;					Type:               v1.NodeReady,
0000000000000000000000000000000000000000;;					Status:             v1.ConditionUnknown,
0000000000000000000000000000000000000000;;					Reason:             "NodeStatusNeverUpdated",
0000000000000000000000000000000000000000;;					Message:            fmt.Sprintf("Kubelet never posted node status."),
0000000000000000000000000000000000000000;;					LastHeartbeatTime:  node.CreationTimestamp,
0000000000000000000000000000000000000000;;					LastTransitionTime: nc.now(),
0000000000000000000000000000000000000000;;				})
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				glog.V(4).Infof("node %v hasn't been updated for %+v. Last ready condition is: %+v",
0000000000000000000000000000000000000000;;					node.Name, nc.now().Time.Sub(savedNodeStatus.probeTimestamp.Time), observedReadyCondition)
0000000000000000000000000000000000000000;;				if observedReadyCondition.Status != v1.ConditionUnknown {
0000000000000000000000000000000000000000;;					currentReadyCondition.Status = v1.ConditionUnknown
0000000000000000000000000000000000000000;;					currentReadyCondition.Reason = "NodeStatusUnknown"
0000000000000000000000000000000000000000;;					currentReadyCondition.Message = "Kubelet stopped posting node status."
0000000000000000000000000000000000000000;;					// LastProbeTime is the last time we heard from kubelet.
0000000000000000000000000000000000000000;;					currentReadyCondition.LastHeartbeatTime = observedReadyCondition.LastHeartbeatTime
0000000000000000000000000000000000000000;;					currentReadyCondition.LastTransitionTime = nc.now()
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// remaining node conditions should also be set to Unknown
0000000000000000000000000000000000000000;;			remainingNodeConditionTypes := []v1.NodeConditionType{v1.NodeOutOfDisk, v1.NodeMemoryPressure, v1.NodeDiskPressure}
0000000000000000000000000000000000000000;;			nowTimestamp := nc.now()
0000000000000000000000000000000000000000;;			for _, nodeConditionType := range remainingNodeConditionTypes {
0000000000000000000000000000000000000000;;				_, currentCondition := nodeutil.GetNodeCondition(&node.Status, nodeConditionType)
0000000000000000000000000000000000000000;;				if currentCondition == nil {
0000000000000000000000000000000000000000;;					glog.V(2).Infof("Condition %v of node %v was never updated by kubelet", nodeConditionType, node.Name)
0000000000000000000000000000000000000000;;					node.Status.Conditions = append(node.Status.Conditions, v1.NodeCondition{
0000000000000000000000000000000000000000;;						Type:               nodeConditionType,
0000000000000000000000000000000000000000;;						Status:             v1.ConditionUnknown,
0000000000000000000000000000000000000000;;						Reason:             "NodeStatusNeverUpdated",
0000000000000000000000000000000000000000;;						Message:            "Kubelet never posted node status.",
0000000000000000000000000000000000000000;;						LastHeartbeatTime:  node.CreationTimestamp,
0000000000000000000000000000000000000000;;						LastTransitionTime: nowTimestamp,
0000000000000000000000000000000000000000;;					})
0000000000000000000000000000000000000000;;				} else {
0000000000000000000000000000000000000000;;					glog.V(4).Infof("node %v hasn't been updated for %+v. Last %v is: %+v",
0000000000000000000000000000000000000000;;						node.Name, nc.now().Time.Sub(savedNodeStatus.probeTimestamp.Time), nodeConditionType, currentCondition)
0000000000000000000000000000000000000000;;					if currentCondition.Status != v1.ConditionUnknown {
0000000000000000000000000000000000000000;;						currentCondition.Status = v1.ConditionUnknown
0000000000000000000000000000000000000000;;						currentCondition.Reason = "NodeStatusUnknown"
0000000000000000000000000000000000000000;;						currentCondition.Message = "Kubelet stopped posting node status."
0000000000000000000000000000000000000000;;						currentCondition.LastTransitionTime = nowTimestamp
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			_, currentCondition := nodeutil.GetNodeCondition(&node.Status, v1.NodeReady)
0000000000000000000000000000000000000000;;			if !apiequality.Semantic.DeepEqual(currentCondition, &observedReadyCondition) {
0000000000000000000000000000000000000000;;				if _, err = nc.kubeClient.Core().Nodes().UpdateStatus(node); err != nil {
0000000000000000000000000000000000000000;;					glog.Errorf("Error updating node %s: %v", node.Name, err)
0000000000000000000000000000000000000000;;					return gracePeriod, observedReadyCondition, currentReadyCondition, err
0000000000000000000000000000000000000000;;				} else {
0000000000000000000000000000000000000000;;					nc.nodeStatusMap[node.Name] = nodeStatusData{
0000000000000000000000000000000000000000;;						status:                   node.Status,
0000000000000000000000000000000000000000;;						probeTimestamp:           nc.nodeStatusMap[node.Name].probeTimestamp,
0000000000000000000000000000000000000000;;						readyTransitionTimestamp: nc.now(),
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					return gracePeriod, observedReadyCondition, currentReadyCondition, nil
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return gracePeriod, observedReadyCondition, currentReadyCondition, err
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// classifyNodes classifies the allNodes to three categories:
0000000000000000000000000000000000000000;;	//   1. added: the nodes that in 'allNodes', but not in 'knownNodeSet'
0000000000000000000000000000000000000000;;	//   2. deleted: the nodes that in 'knownNodeSet', but not in 'allNodes'
0000000000000000000000000000000000000000;;	//   3. newZoneRepresentatives: the nodes that in both 'knownNodeSet' and 'allNodes', but no zone states
0000000000000000000000000000000000000000;;	func (nc *NodeController) classifyNodes(allNodes []*v1.Node) (added, deleted, newZoneRepresentatives []*v1.Node) {
0000000000000000000000000000000000000000;;		for i := range allNodes {
0000000000000000000000000000000000000000;;			if _, has := nc.knownNodeSet[allNodes[i].Name]; !has {
0000000000000000000000000000000000000000;;				added = append(added, allNodes[i])
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				// Currently, we only consider new zone as updated.
0000000000000000000000000000000000000000;;				zone := utilnode.GetZoneKey(allNodes[i])
0000000000000000000000000000000000000000;;				if _, found := nc.zoneStates[zone]; !found {
0000000000000000000000000000000000000000;;					newZoneRepresentatives = append(newZoneRepresentatives, allNodes[i])
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// If there's a difference between lengths of known Nodes and observed nodes
0000000000000000000000000000000000000000;;		// we must have removed some Node.
0000000000000000000000000000000000000000;;		if len(nc.knownNodeSet)+len(added) != len(allNodes) {
0000000000000000000000000000000000000000;;			knowSetCopy := map[string]*v1.Node{}
0000000000000000000000000000000000000000;;			for k, v := range nc.knownNodeSet {
0000000000000000000000000000000000000000;;				knowSetCopy[k] = v
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			for i := range allNodes {
0000000000000000000000000000000000000000;;				delete(knowSetCopy, allNodes[i].Name)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			for i := range knowSetCopy {
0000000000000000000000000000000000000000;;				deleted = append(deleted, knowSetCopy[i])
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// cancelPodEviction removes any queued evictions, typically because the node is available again. It
0000000000000000000000000000000000000000;;	// returns true if an eviction was queued.
0000000000000000000000000000000000000000;;	func (nc *NodeController) cancelPodEviction(node *v1.Node) bool {
0000000000000000000000000000000000000000;;		zone := utilnode.GetZoneKey(node)
0000000000000000000000000000000000000000;;		nc.evictorLock.Lock()
0000000000000000000000000000000000000000;;		defer nc.evictorLock.Unlock()
0000000000000000000000000000000000000000;;		wasDeleting := nc.zonePodEvictor[zone].Remove(node.Name)
0000000000000000000000000000000000000000;;		if wasDeleting {
0000000000000000000000000000000000000000;;			glog.V(2).Infof("Cancelling pod Eviction on Node: %v", node.Name)
0000000000000000000000000000000000000000;;			return true
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return false
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// evictPods queues an eviction for the provided node name, and returns false if the node is already
0000000000000000000000000000000000000000;;	// queued for eviction.
0000000000000000000000000000000000000000;;	func (nc *NodeController) evictPods(node *v1.Node) bool {
0000000000000000000000000000000000000000;;		nc.evictorLock.Lock()
0000000000000000000000000000000000000000;;		defer nc.evictorLock.Unlock()
0000000000000000000000000000000000000000;;		return nc.zonePodEvictor[utilnode.GetZoneKey(node)].Add(node.Name, string(node.UID))
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (nc *NodeController) markNodeForTainting(node *v1.Node) bool {
0000000000000000000000000000000000000000;;		nc.evictorLock.Lock()
0000000000000000000000000000000000000000;;		defer nc.evictorLock.Unlock()
0000000000000000000000000000000000000000;;		return nc.zoneNotReadyOrUnreachableTainer[utilnode.GetZoneKey(node)].Add(node.Name, string(node.UID))
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (nc *NodeController) markNodeAsHealthy(node *v1.Node) (bool, error) {
0000000000000000000000000000000000000000;;		nc.evictorLock.Lock()
0000000000000000000000000000000000000000;;		defer nc.evictorLock.Unlock()
0000000000000000000000000000000000000000;;		err := controller.RemoveTaintOffNode(nc.kubeClient, node.Name, UnreachableTaintTemplate, node)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			glog.Errorf("Failed to remove taint from node %v: %v", node.Name, err)
0000000000000000000000000000000000000000;;			return false, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		err = controller.RemoveTaintOffNode(nc.kubeClient, node.Name, NotReadyTaintTemplate, node)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			glog.Errorf("Failed to remove taint from node %v: %v", node.Name, err)
0000000000000000000000000000000000000000;;			return false, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return nc.zoneNotReadyOrUnreachableTainer[utilnode.GetZoneKey(node)].Remove(node.Name), nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Default value for cluster eviction rate - we take nodeNum for consistency with ReducedQPSFunc.
0000000000000000000000000000000000000000;;	func (nc *NodeController) HealthyQPSFunc(nodeNum int) float32 {
0000000000000000000000000000000000000000;;		return nc.evictionLimiterQPS
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// If the cluster is large make evictions slower, if they're small stop evictions altogether.
0000000000000000000000000000000000000000;;	func (nc *NodeController) ReducedQPSFunc(nodeNum int) float32 {
0000000000000000000000000000000000000000;;		if int32(nodeNum) > nc.largeClusterThreshold {
0000000000000000000000000000000000000000;;			return nc.secondaryEvictionLimiterQPS
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return 0
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// This function is expected to get a slice of NodeReadyConditions for all Nodes in a given zone.
0000000000000000000000000000000000000000;;	// The zone is considered:
0000000000000000000000000000000000000000;;	// - fullyDisrupted if there're no Ready Nodes,
0000000000000000000000000000000000000000;;	// - partiallyDisrupted if at least than nc.unhealthyZoneThreshold percent of Nodes are not Ready,
0000000000000000000000000000000000000000;;	// - normal otherwise
0000000000000000000000000000000000000000;;	func (nc *NodeController) ComputeZoneState(nodeReadyConditions []*v1.NodeCondition) (int, zoneState) {
0000000000000000000000000000000000000000;;		readyNodes := 0
0000000000000000000000000000000000000000;;		notReadyNodes := 0
0000000000000000000000000000000000000000;;		for i := range nodeReadyConditions {
0000000000000000000000000000000000000000;;			if nodeReadyConditions[i] != nil && nodeReadyConditions[i].Status == v1.ConditionTrue {
0000000000000000000000000000000000000000;;				readyNodes++
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				notReadyNodes++
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		switch {
0000000000000000000000000000000000000000;;		case readyNodes == 0 && notReadyNodes > 0:
0000000000000000000000000000000000000000;;			return notReadyNodes, stateFullDisruption
0000000000000000000000000000000000000000;;		case notReadyNodes > 2 && float32(notReadyNodes)/float32(notReadyNodes+readyNodes) >= nc.unhealthyZoneThreshold:
0000000000000000000000000000000000000000;;			return notReadyNodes, statePartialDisruption
0000000000000000000000000000000000000000;;		default:
0000000000000000000000000000000000000000;;			return notReadyNodes, stateNormal
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
