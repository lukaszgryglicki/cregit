0000000000000000000000000000000000000000;;	/*
0000000000000000000000000000000000000000;;	Copyright 2016 The Kubernetes Authors.
eb13d97426d7e893d937c289482038afe2dd545d;pkg/controller/node/deletion_utils.go[pkg/controller/node/deletion_utils.go][pkg/controller/node/controller_utils.go];	
0000000000000000000000000000000000000000;;	Licensed under the Apache License, Version 2.0 (the "License");
0000000000000000000000000000000000000000;;	you may not use this file except in compliance with the License.
0000000000000000000000000000000000000000;;	You may obtain a copy of the License at
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	    http://www.apache.org/licenses/LICENSE-2.0
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	Unless required by applicable law or agreed to in writing, software
0000000000000000000000000000000000000000;;	distributed under the License is distributed on an "AS IS" BASIS,
0000000000000000000000000000000000000000;;	WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
0000000000000000000000000000000000000000;;	See the License for the specific language governing permissions and
0000000000000000000000000000000000000000;;	limitations under the License.
0000000000000000000000000000000000000000;;	*/
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	package node
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	import (
0000000000000000000000000000000000000000;;		"fmt"
0000000000000000000000000000000000000000;;		"strings"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/api/errors"
0000000000000000000000000000000000000000;;		metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/fields"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/types"
0000000000000000000000000000000000000000;;		utilerrors "k8s.io/apimachinery/pkg/util/errors"
0000000000000000000000000000000000000000;;		utilruntime "k8s.io/apimachinery/pkg/util/runtime"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		clientv1 "k8s.io/api/core/v1"
0000000000000000000000000000000000000000;;		"k8s.io/client-go/tools/cache"
0000000000000000000000000000000000000000;;		"k8s.io/client-go/tools/record"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		"k8s.io/api/core/v1"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/api"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/client/clientset_generated/clientset"
0000000000000000000000000000000000000000;;		extensionslisters "k8s.io/kubernetes/pkg/client/listers/extensions/v1beta1"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/cloudprovider"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/controller"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/kubelet/util/format"
0000000000000000000000000000000000000000;;		nodepkg "k8s.io/kubernetes/pkg/util/node"
0000000000000000000000000000000000000000;;		utilversion "k8s.io/kubernetes/pkg/util/version"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		"github.com/golang/glog"
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// deletePods will delete all pods from master running on given node, and return true
0000000000000000000000000000000000000000;;	// if any pods were deleted, or were found pending deletion.
0000000000000000000000000000000000000000;;	func deletePods(kubeClient clientset.Interface, recorder record.EventRecorder, nodeName, nodeUID string, daemonStore extensionslisters.DaemonSetLister) (bool, error) {
0000000000000000000000000000000000000000;;		remaining := false
0000000000000000000000000000000000000000;;		selector := fields.OneTermEqualSelector(api.PodHostField, nodeName).String()
0000000000000000000000000000000000000000;;		options := metav1.ListOptions{FieldSelector: selector}
0000000000000000000000000000000000000000;;		pods, err := kubeClient.Core().Pods(metav1.NamespaceAll).List(options)
0000000000000000000000000000000000000000;;		var updateErrList []error
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return remaining, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if len(pods.Items) > 0 {
0000000000000000000000000000000000000000;;			recordNodeEvent(recorder, nodeName, nodeUID, v1.EventTypeNormal, "DeletingAllPods", fmt.Sprintf("Deleting all Pods from Node %v.", nodeName))
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		for _, pod := range pods.Items {
0000000000000000000000000000000000000000;;			// Defensive check, also needed for tests.
0000000000000000000000000000000000000000;;			if pod.Spec.NodeName != nodeName {
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Set reason and message in the pod object.
0000000000000000000000000000000000000000;;			if _, err = setPodTerminationReason(kubeClient, &pod, nodeName); err != nil {
0000000000000000000000000000000000000000;;				if errors.IsConflict(err) {
0000000000000000000000000000000000000000;;					updateErrList = append(updateErrList,
0000000000000000000000000000000000000000;;						fmt.Errorf("update status failed for pod %q: %v", format.Pod(&pod), err))
0000000000000000000000000000000000000000;;					continue
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			// if the pod has already been marked for deletion, we still return true that there are remaining pods.
0000000000000000000000000000000000000000;;			if pod.DeletionGracePeriodSeconds != nil {
0000000000000000000000000000000000000000;;				remaining = true
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			// if the pod is managed by a daemonset, ignore it
0000000000000000000000000000000000000000;;			_, err := daemonStore.GetPodDaemonSets(&pod)
0000000000000000000000000000000000000000;;			if err == nil { // No error means at least one daemonset was found
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			glog.V(2).Infof("Starting deletion of pod %v/%v", pod.Namespace, pod.Name)
0000000000000000000000000000000000000000;;			recorder.Eventf(&pod, v1.EventTypeNormal, "NodeControllerEviction", "Marking for deletion Pod %s from Node %s", pod.Name, nodeName)
0000000000000000000000000000000000000000;;			if err := kubeClient.Core().Pods(pod.Namespace).Delete(pod.Name, nil); err != nil {
0000000000000000000000000000000000000000;;				return false, err
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			remaining = true
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if len(updateErrList) > 0 {
0000000000000000000000000000000000000000;;			return false, utilerrors.NewAggregate(updateErrList)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return remaining, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// setPodTerminationReason attempts to set a reason and message in the pod status, updates it in the apiserver,
0000000000000000000000000000000000000000;;	// and returns an error if it encounters one.
0000000000000000000000000000000000000000;;	func setPodTerminationReason(kubeClient clientset.Interface, pod *v1.Pod, nodeName string) (*v1.Pod, error) {
0000000000000000000000000000000000000000;;		if pod.Status.Reason == nodepkg.NodeUnreachablePodReason {
0000000000000000000000000000000000000000;;			return pod, nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		pod.Status.Reason = nodepkg.NodeUnreachablePodReason
0000000000000000000000000000000000000000;;		pod.Status.Message = fmt.Sprintf(nodepkg.NodeUnreachablePodMessage, nodeName, pod.Name)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		var updatedPod *v1.Pod
0000000000000000000000000000000000000000;;		var err error
0000000000000000000000000000000000000000;;		if updatedPod, err = kubeClient.Core().Pods(pod.Namespace).UpdateStatus(pod); err != nil {
0000000000000000000000000000000000000000;;			return nil, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return updatedPod, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func forcefullyDeletePod(c clientset.Interface, pod *v1.Pod) error {
0000000000000000000000000000000000000000;;		var zero int64
0000000000000000000000000000000000000000;;		glog.Infof("NodeController is force deleting Pod: %v:%v", pod.Namespace, pod.Name)
0000000000000000000000000000000000000000;;		err := c.Core().Pods(pod.Namespace).Delete(pod.Name, &metav1.DeleteOptions{GracePeriodSeconds: &zero})
0000000000000000000000000000000000000000;;		if err == nil {
0000000000000000000000000000000000000000;;			glog.V(4).Infof("forceful deletion of %s succeeded", pod.Name)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return err
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// forcefullyDeleteNode immediately the node. The pods on the node are cleaned
0000000000000000000000000000000000000000;;	// up by the podGC.
0000000000000000000000000000000000000000;;	func forcefullyDeleteNode(kubeClient clientset.Interface, nodeName string) error {
0000000000000000000000000000000000000000;;		if err := kubeClient.Core().Nodes().Delete(nodeName, nil); err != nil {
0000000000000000000000000000000000000000;;			return fmt.Errorf("unable to delete node %q: %v", nodeName, err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// maybeDeleteTerminatingPod non-gracefully deletes pods that are terminating
0000000000000000000000000000000000000000;;	// that should not be gracefully terminated.
0000000000000000000000000000000000000000;;	func (nc *NodeController) maybeDeleteTerminatingPod(obj interface{}) {
0000000000000000000000000000000000000000;;		pod, ok := obj.(*v1.Pod)
0000000000000000000000000000000000000000;;		if !ok {
0000000000000000000000000000000000000000;;			tombstone, ok := obj.(cache.DeletedFinalStateUnknown)
0000000000000000000000000000000000000000;;			if !ok {
0000000000000000000000000000000000000000;;				glog.Errorf("Couldn't get object from tombstone %#v", obj)
0000000000000000000000000000000000000000;;				return
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			pod, ok = tombstone.Obj.(*v1.Pod)
0000000000000000000000000000000000000000;;			if !ok {
0000000000000000000000000000000000000000;;				glog.Errorf("Tombstone contained object that is not a Pod %#v", obj)
0000000000000000000000000000000000000000;;				return
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// consider only terminating pods
0000000000000000000000000000000000000000;;		if pod.DeletionTimestamp == nil {
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		node, err := nc.nodeLister.Get(pod.Spec.NodeName)
0000000000000000000000000000000000000000;;		// if there is no such node, do nothing and let the podGC clean it up.
0000000000000000000000000000000000000000;;		if errors.IsNotFound(err) {
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			// this can only happen if the Store.KeyFunc has a problem creating
0000000000000000000000000000000000000000;;			// a key for the pod. If it happens once, it will happen again so
0000000000000000000000000000000000000000;;			// don't bother requeuing the pod.
0000000000000000000000000000000000000000;;			utilruntime.HandleError(err)
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// delete terminating pods that have been scheduled on
0000000000000000000000000000000000000000;;		// nodes that do not support graceful termination
0000000000000000000000000000000000000000;;		// TODO(mikedanese): this can be removed when we no longer
0000000000000000000000000000000000000000;;		// guarantee backwards compatibility of master API to kubelets with
0000000000000000000000000000000000000000;;		// versions less than 1.1.0
0000000000000000000000000000000000000000;;		v, err := utilversion.ParseSemantic(node.Status.NodeInfo.KubeletVersion)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			glog.V(0).Infof("Couldn't parse version %q of node: %v", node.Status.NodeInfo.KubeletVersion, err)
0000000000000000000000000000000000000000;;			utilruntime.HandleError(nc.forcefullyDeletePod(pod))
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if v.LessThan(gracefulDeletionVersion) {
0000000000000000000000000000000000000000;;			utilruntime.HandleError(nc.forcefullyDeletePod(pod))
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// update ready status of all pods running on given node from master
0000000000000000000000000000000000000000;;	// return true if success
0000000000000000000000000000000000000000;;	func markAllPodsNotReady(kubeClient clientset.Interface, node *v1.Node) error {
0000000000000000000000000000000000000000;;		// Don't set pods to NotReady if the kubelet is running a version that
0000000000000000000000000000000000000000;;		// doesn't understand how to correct readiness.
0000000000000000000000000000000000000000;;		// TODO: Remove this check when we no longer guarantee backward compatibility
0000000000000000000000000000000000000000;;		// with node versions < 1.2.0.
0000000000000000000000000000000000000000;;		if nodeRunningOutdatedKubelet(node) {
0000000000000000000000000000000000000000;;			return nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		nodeName := node.Name
0000000000000000000000000000000000000000;;		glog.V(2).Infof("Update ready status of pods on node [%v]", nodeName)
0000000000000000000000000000000000000000;;		opts := metav1.ListOptions{FieldSelector: fields.OneTermEqualSelector(api.PodHostField, nodeName).String()}
0000000000000000000000000000000000000000;;		pods, err := kubeClient.Core().Pods(metav1.NamespaceAll).List(opts)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		errMsg := []string{}
0000000000000000000000000000000000000000;;		for _, pod := range pods.Items {
0000000000000000000000000000000000000000;;			// Defensive check, also needed for tests.
0000000000000000000000000000000000000000;;			if pod.Spec.NodeName != nodeName {
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			for i, cond := range pod.Status.Conditions {
0000000000000000000000000000000000000000;;				if cond.Type == v1.PodReady {
0000000000000000000000000000000000000000;;					pod.Status.Conditions[i].Status = v1.ConditionFalse
0000000000000000000000000000000000000000;;					glog.V(2).Infof("Updating ready status of pod %v to false", pod.Name)
0000000000000000000000000000000000000000;;					_, err := kubeClient.Core().Pods(pod.Namespace).UpdateStatus(&pod)
0000000000000000000000000000000000000000;;					if err != nil {
0000000000000000000000000000000000000000;;						glog.Warningf("Failed to update status for pod %q: %v", format.Pod(&pod), err)
0000000000000000000000000000000000000000;;						errMsg = append(errMsg, fmt.Sprintf("%v", err))
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					break
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if len(errMsg) == 0 {
0000000000000000000000000000000000000000;;			return nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return fmt.Errorf("%v", strings.Join(errMsg, "; "))
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// nodeRunningOutdatedKubelet returns true if the kubeletVersion reported
0000000000000000000000000000000000000000;;	// in the nodeInfo of the given node is "outdated", meaning < 1.2.0.
0000000000000000000000000000000000000000;;	// Older versions were inflexible and modifying pod.Status directly through
0000000000000000000000000000000000000000;;	// the apiserver would result in unexpected outcomes.
0000000000000000000000000000000000000000;;	func nodeRunningOutdatedKubelet(node *v1.Node) bool {
0000000000000000000000000000000000000000;;		v, err := utilversion.ParseSemantic(node.Status.NodeInfo.KubeletVersion)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			glog.Errorf("couldn't parse version %q of node %v", node.Status.NodeInfo.KubeletVersion, err)
0000000000000000000000000000000000000000;;			return true
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if v.LessThan(podStatusReconciliationVersion) {
0000000000000000000000000000000000000000;;			glog.Infof("Node %v running kubelet at (%v) which is less than the minimum version that allows nodecontroller to mark pods NotReady (%v).", node.Name, v, podStatusReconciliationVersion)
0000000000000000000000000000000000000000;;			return true
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return false
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func nodeExistsInCloudProvider(cloud cloudprovider.Interface, nodeName types.NodeName) (bool, error) {
0000000000000000000000000000000000000000;;		instances, ok := cloud.Instances()
0000000000000000000000000000000000000000;;		if !ok {
0000000000000000000000000000000000000000;;			return false, fmt.Errorf("%v", ErrCloudInstance)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if _, err := instances.ExternalID(nodeName); err != nil {
0000000000000000000000000000000000000000;;			if err == cloudprovider.InstanceNotFound {
0000000000000000000000000000000000000000;;				return false, nil
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			return false, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return true, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func recordNodeEvent(recorder record.EventRecorder, nodeName, nodeUID, eventtype, reason, event string) {
0000000000000000000000000000000000000000;;		ref := &clientv1.ObjectReference{
0000000000000000000000000000000000000000;;			Kind:      "Node",
0000000000000000000000000000000000000000;;			Name:      nodeName,
0000000000000000000000000000000000000000;;			UID:       types.UID(nodeUID),
0000000000000000000000000000000000000000;;			Namespace: "",
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		glog.V(2).Infof("Recording %s event message for node %s", event, nodeName)
0000000000000000000000000000000000000000;;		recorder.Eventf(ref, eventtype, reason, "Node %s event: %s", nodeName, event)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func recordNodeStatusChange(recorder record.EventRecorder, node *v1.Node, new_status string) {
0000000000000000000000000000000000000000;;		ref := &clientv1.ObjectReference{
0000000000000000000000000000000000000000;;			Kind:      "Node",
0000000000000000000000000000000000000000;;			Name:      node.Name,
0000000000000000000000000000000000000000;;			UID:       node.UID,
0000000000000000000000000000000000000000;;			Namespace: "",
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		glog.V(2).Infof("Recording status change %s event message for node %s", new_status, node.Name)
0000000000000000000000000000000000000000;;		// TODO: This requires a transaction, either both node status is updated
0000000000000000000000000000000000000000;;		// and event is recorded or neither should happen, see issue #6055.
0000000000000000000000000000000000000000;;		recorder.Eventf(ref, v1.EventTypeNormal, new_status, "Node %s status is now: %s", node.Name, new_status)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Returns true in case of success and false otherwise
0000000000000000000000000000000000000000;;	func swapNodeControllerTaint(kubeClient clientset.Interface, taintToAdd, taintToRemove *v1.Taint, node *v1.Node) bool {
0000000000000000000000000000000000000000;;		taintToAdd.TimeAdded = metav1.Now()
0000000000000000000000000000000000000000;;		err := controller.AddOrUpdateTaintOnNode(kubeClient, node.Name, taintToAdd)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			utilruntime.HandleError(
0000000000000000000000000000000000000000;;				fmt.Errorf(
0000000000000000000000000000000000000000;;					"unable to taint %v unresponsive Node %q: %v",
0000000000000000000000000000000000000000;;					taintToAdd.Key,
0000000000000000000000000000000000000000;;					node.Name,
0000000000000000000000000000000000000000;;					err))
0000000000000000000000000000000000000000;;			return false
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		glog.V(4).Infof("Added %v Taint to Node %v", taintToAdd, node.Name)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		err = controller.RemoveTaintOffNode(kubeClient, node.Name, taintToRemove, node)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			utilruntime.HandleError(
0000000000000000000000000000000000000000;;				fmt.Errorf(
0000000000000000000000000000000000000000;;					"unable to remove %v unneeded taint from unresponsive Node %q: %v",
0000000000000000000000000000000000000000;;					taintToRemove.Key,
0000000000000000000000000000000000000000;;					node.Name,
0000000000000000000000000000000000000000;;					err))
0000000000000000000000000000000000000000;;			return false
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		glog.V(4).Infof("Made sure that Node %v has no %v Taint", node.Name, taintToRemove)
0000000000000000000000000000000000000000;;		return true
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func createAddNodeHandler(f func(node *v1.Node) error) func(obj interface{}) {
0000000000000000000000000000000000000000;;		return func(originalObj interface{}) {
0000000000000000000000000000000000000000;;			obj, err := api.Scheme.DeepCopy(originalObj)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				utilruntime.HandleError(err)
0000000000000000000000000000000000000000;;				return
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			node := obj.(*v1.Node)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			if err := f(node); err != nil {
0000000000000000000000000000000000000000;;				utilruntime.HandleError(fmt.Errorf("Error while processing Node Delete: %v", err))
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func createUpdateNodeHandler(f func(oldNode, newNode *v1.Node) error) func(oldObj, newObj interface{}) {
0000000000000000000000000000000000000000;;		return func(origOldObj, origNewObj interface{}) {
0000000000000000000000000000000000000000;;			oldObj, err := api.Scheme.DeepCopy(origOldObj)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				utilruntime.HandleError(err)
0000000000000000000000000000000000000000;;				return
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			newObj, err := api.Scheme.DeepCopy(origNewObj)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				utilruntime.HandleError(err)
0000000000000000000000000000000000000000;;				return
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			node := newObj.(*v1.Node)
0000000000000000000000000000000000000000;;			prevNode := oldObj.(*v1.Node)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			if err := f(prevNode, node); err != nil {
0000000000000000000000000000000000000000;;				utilruntime.HandleError(fmt.Errorf("Error while processing Node Add/Delete: %v", err))
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func createDeleteNodeHandler(f func(node *v1.Node) error) func(obj interface{}) {
0000000000000000000000000000000000000000;;		return func(originalObj interface{}) {
0000000000000000000000000000000000000000;;			obj, err := api.Scheme.DeepCopy(originalObj)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				utilruntime.HandleError(err)
0000000000000000000000000000000000000000;;				return
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			node, isNode := obj.(*v1.Node)
0000000000000000000000000000000000000000;;			// We can get DeletedFinalStateUnknown instead of *v1.Node here and
0000000000000000000000000000000000000000;;			// we need to handle that correctly. #34692
0000000000000000000000000000000000000000;;			if !isNode {
0000000000000000000000000000000000000000;;				deletedState, ok := obj.(cache.DeletedFinalStateUnknown)
0000000000000000000000000000000000000000;;				if !ok {
0000000000000000000000000000000000000000;;					glog.Errorf("Received unexpected object: %v", obj)
0000000000000000000000000000000000000000;;					return
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				node, ok = deletedState.Obj.(*v1.Node)
0000000000000000000000000000000000000000;;				if !ok {
0000000000000000000000000000000000000000;;					glog.Errorf("DeletedFinalStateUnknown contained non-Node object: %v", deletedState.Obj)
0000000000000000000000000000000000000000;;					return
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			if err := f(node); err != nil {
0000000000000000000000000000000000000000;;				utilruntime.HandleError(fmt.Errorf("Error while processing Node Add/Delete: %v", err))
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
