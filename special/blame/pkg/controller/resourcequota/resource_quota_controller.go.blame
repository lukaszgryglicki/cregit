0000000000000000000000000000000000000000;;	/*
0000000000000000000000000000000000000000;;	Copyright 2014 The Kubernetes Authors.
56cc9a99f6473c6f8d2d30d86a5e04aa6a1fd6ac;pkg/resourcequota/resource_quota_controller.go[pkg/resourcequota/resource_quota_controller.go][pkg/controller/resourcequota/resource_quota_controller.go];	
0000000000000000000000000000000000000000;;	Licensed under the Apache License, Version 2.0 (the "License");
0000000000000000000000000000000000000000;;	you may not use this file except in compliance with the License.
0000000000000000000000000000000000000000;;	You may obtain a copy of the License at
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	    http://www.apache.org/licenses/LICENSE-2.0
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	Unless required by applicable law or agreed to in writing, software
0000000000000000000000000000000000000000;;	distributed under the License is distributed on an "AS IS" BASIS,
0000000000000000000000000000000000000000;;	WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
0000000000000000000000000000000000000000;;	See the License for the specific language governing permissions and
0000000000000000000000000000000000000000;;	limitations under the License.
0000000000000000000000000000000000000000;;	*/
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	package resourcequota
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	import (
0000000000000000000000000000000000000000;;		"fmt"
0000000000000000000000000000000000000000;;		"time"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		"github.com/golang/glog"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		"k8s.io/api/core/v1"
0000000000000000000000000000000000000000;;		apiequality "k8s.io/apimachinery/pkg/api/equality"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/api/errors"
0000000000000000000000000000000000000000;;		metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/labels"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/runtime"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/runtime/schema"
0000000000000000000000000000000000000000;;		utilruntime "k8s.io/apimachinery/pkg/util/runtime"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/util/wait"
0000000000000000000000000000000000000000;;		"k8s.io/client-go/tools/cache"
0000000000000000000000000000000000000000;;		"k8s.io/client-go/util/workqueue"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/api"
0000000000000000000000000000000000000000;;		k8s_api_v1 "k8s.io/kubernetes/pkg/api/v1"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/client/clientset_generated/clientset"
0000000000000000000000000000000000000000;;		coreinformers "k8s.io/kubernetes/pkg/client/informers/informers_generated/externalversions/core/v1"
0000000000000000000000000000000000000000;;		corelisters "k8s.io/kubernetes/pkg/client/listers/core/v1"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/controller"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/quota"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/util/metrics"
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// ResourceQuotaControllerOptions holds options for creating a quota controller
0000000000000000000000000000000000000000;;	type ResourceQuotaControllerOptions struct {
0000000000000000000000000000000000000000;;		// Must have authority to list all quotas, and update quota status
0000000000000000000000000000000000000000;;		KubeClient clientset.Interface
0000000000000000000000000000000000000000;;		// Shared informer for resource quotas
0000000000000000000000000000000000000000;;		ResourceQuotaInformer coreinformers.ResourceQuotaInformer
0000000000000000000000000000000000000000;;		// Controls full recalculation of quota usage
0000000000000000000000000000000000000000;;		ResyncPeriod controller.ResyncPeriodFunc
0000000000000000000000000000000000000000;;		// Knows how to calculate usage
0000000000000000000000000000000000000000;;		Registry quota.Registry
0000000000000000000000000000000000000000;;		// Knows how to build controllers that notify replenishment events
0000000000000000000000000000000000000000;;		ControllerFactory ReplenishmentControllerFactory
0000000000000000000000000000000000000000;;		// Controls full resync of objects monitored for replenishment.
0000000000000000000000000000000000000000;;		ReplenishmentResyncPeriod controller.ResyncPeriodFunc
0000000000000000000000000000000000000000;;		// List of GroupKind objects that should be monitored for replenishment at
0000000000000000000000000000000000000000;;		// a faster frequency than the quota controller recalculation interval
0000000000000000000000000000000000000000;;		GroupKindsToReplenish []schema.GroupKind
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// ResourceQuotaController is responsible for tracking quota usage status in the system
0000000000000000000000000000000000000000;;	type ResourceQuotaController struct {
0000000000000000000000000000000000000000;;		// Must have authority to list all resources in the system, and update quota status
0000000000000000000000000000000000000000;;		kubeClient clientset.Interface
0000000000000000000000000000000000000000;;		// A lister/getter of resource quota objects
0000000000000000000000000000000000000000;;		rqLister corelisters.ResourceQuotaLister
0000000000000000000000000000000000000000;;		// A list of functions that return true when their caches have synced
0000000000000000000000000000000000000000;;		informerSyncedFuncs []cache.InformerSynced
0000000000000000000000000000000000000000;;		// ResourceQuota objects that need to be synchronized
0000000000000000000000000000000000000000;;		queue workqueue.RateLimitingInterface
0000000000000000000000000000000000000000;;		// missingUsageQueue holds objects that are missing the initial usage information
0000000000000000000000000000000000000000;;		missingUsageQueue workqueue.RateLimitingInterface
0000000000000000000000000000000000000000;;		// To allow injection of syncUsage for testing.
0000000000000000000000000000000000000000;;		syncHandler func(key string) error
0000000000000000000000000000000000000000;;		// function that controls full recalculation of quota usage
0000000000000000000000000000000000000000;;		resyncPeriod controller.ResyncPeriodFunc
0000000000000000000000000000000000000000;;		// knows how to calculate usage
0000000000000000000000000000000000000000;;		registry quota.Registry
0000000000000000000000000000000000000000;;		// controllers monitoring to notify for replenishment
0000000000000000000000000000000000000000;;		replenishmentControllers []cache.Controller
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func NewResourceQuotaController(options *ResourceQuotaControllerOptions) *ResourceQuotaController {
0000000000000000000000000000000000000000;;		// build the resource quota controller
0000000000000000000000000000000000000000;;		rq := &ResourceQuotaController{
0000000000000000000000000000000000000000;;			kubeClient:               options.KubeClient,
0000000000000000000000000000000000000000;;			rqLister:                 options.ResourceQuotaInformer.Lister(),
0000000000000000000000000000000000000000;;			informerSyncedFuncs:      []cache.InformerSynced{options.ResourceQuotaInformer.Informer().HasSynced},
0000000000000000000000000000000000000000;;			queue:                    workqueue.NewNamedRateLimitingQueue(workqueue.DefaultControllerRateLimiter(), "resourcequota_primary"),
0000000000000000000000000000000000000000;;			missingUsageQueue:        workqueue.NewNamedRateLimitingQueue(workqueue.DefaultControllerRateLimiter(), "resourcequota_priority"),
0000000000000000000000000000000000000000;;			resyncPeriod:             options.ResyncPeriod,
0000000000000000000000000000000000000000;;			registry:                 options.Registry,
0000000000000000000000000000000000000000;;			replenishmentControllers: []cache.Controller{},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if options.KubeClient != nil && options.KubeClient.Core().RESTClient().GetRateLimiter() != nil {
0000000000000000000000000000000000000000;;			metrics.RegisterMetricAndTrackRateLimiterUsage("resource_quota_controller", options.KubeClient.Core().RESTClient().GetRateLimiter())
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		// set the synchronization handler
0000000000000000000000000000000000000000;;		rq.syncHandler = rq.syncResourceQuotaFromKey
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		options.ResourceQuotaInformer.Informer().AddEventHandlerWithResyncPeriod(
0000000000000000000000000000000000000000;;			cache.ResourceEventHandlerFuncs{
0000000000000000000000000000000000000000;;				AddFunc: rq.addQuota,
0000000000000000000000000000000000000000;;				UpdateFunc: func(old, cur interface{}) {
0000000000000000000000000000000000000000;;					// We are only interested in observing updates to quota.spec to drive updates to quota.status.
0000000000000000000000000000000000000000;;					// We ignore all updates to quota.Status because they are all driven by this controller.
0000000000000000000000000000000000000000;;					// IMPORTANT:
0000000000000000000000000000000000000000;;					// We do not use this function to queue up a full quota recalculation.  To do so, would require
0000000000000000000000000000000000000000;;					// us to enqueue all quota.Status updates, and since quota.Status updates involve additional queries
0000000000000000000000000000000000000000;;					// that cannot be backed by a cache and result in a full query of a namespace's content, we do not
0000000000000000000000000000000000000000;;					// want to pay the price on spurious status updates.  As a result, we have a separate routine that is
0000000000000000000000000000000000000000;;					// responsible for enqueue of all resource quotas when doing a full resync (enqueueAll)
0000000000000000000000000000000000000000;;					oldResourceQuota := old.(*v1.ResourceQuota)
0000000000000000000000000000000000000000;;					curResourceQuota := cur.(*v1.ResourceQuota)
0000000000000000000000000000000000000000;;					if quota.V1Equals(oldResourceQuota.Spec.Hard, curResourceQuota.Spec.Hard) {
0000000000000000000000000000000000000000;;						return
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					rq.addQuota(curResourceQuota)
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;				// This will enter the sync loop and no-op, because the controller has been deleted from the store.
0000000000000000000000000000000000000000;;				// Note that deleting a controller immediately after scaling it to 0 will not work. The recommended
0000000000000000000000000000000000000000;;				// way of achieving this is by performing a `stop` operation on the controller.
0000000000000000000000000000000000000000;;				DeleteFunc: rq.enqueueResourceQuota,
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			rq.resyncPeriod(),
0000000000000000000000000000000000000000;;		)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		for _, groupKindToReplenish := range options.GroupKindsToReplenish {
0000000000000000000000000000000000000000;;			controllerOptions := &ReplenishmentControllerOptions{
0000000000000000000000000000000000000000;;				GroupKind:         groupKindToReplenish,
0000000000000000000000000000000000000000;;				ResyncPeriod:      options.ReplenishmentResyncPeriod,
0000000000000000000000000000000000000000;;				ReplenishmentFunc: rq.replenishQuota,
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			replenishmentController, err := options.ControllerFactory.NewController(controllerOptions)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				glog.Warningf("quota controller unable to replenish %s due to %v, changes only accounted during full resync", groupKindToReplenish, err)
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				// make sure we wait for each shared informer's cache to sync
0000000000000000000000000000000000000000;;				rq.informerSyncedFuncs = append(rq.informerSyncedFuncs, replenishmentController.HasSynced)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return rq
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// enqueueAll is called at the fullResyncPeriod interval to force a full recalculation of quota usage statistics
0000000000000000000000000000000000000000;;	func (rq *ResourceQuotaController) enqueueAll() {
0000000000000000000000000000000000000000;;		defer glog.V(4).Infof("Resource quota controller queued all resource quota for full calculation of usage")
0000000000000000000000000000000000000000;;		rqs, err := rq.rqLister.List(labels.Everything())
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			utilruntime.HandleError(fmt.Errorf("unable to enqueue all - error listing resource quotas: %v", err))
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		for i := range rqs {
0000000000000000000000000000000000000000;;			key, err := controller.KeyFunc(rqs[i])
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				utilruntime.HandleError(fmt.Errorf("Couldn't get key for object %+v: %v", rqs[i], err))
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			rq.queue.Add(key)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// obj could be an *v1.ResourceQuota, or a DeletionFinalStateUnknown marker item.
0000000000000000000000000000000000000000;;	func (rq *ResourceQuotaController) enqueueResourceQuota(obj interface{}) {
0000000000000000000000000000000000000000;;		key, err := controller.KeyFunc(obj)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			glog.Errorf("Couldn't get key for object %+v: %v", obj, err)
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		rq.queue.Add(key)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (rq *ResourceQuotaController) addQuota(obj interface{}) {
0000000000000000000000000000000000000000;;		key, err := controller.KeyFunc(obj)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			glog.Errorf("Couldn't get key for object %+v: %v", obj, err)
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		resourceQuota := obj.(*v1.ResourceQuota)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// if we declared an intent that is not yet captured in status (prioritize it)
0000000000000000000000000000000000000000;;		if !apiequality.Semantic.DeepEqual(resourceQuota.Spec.Hard, resourceQuota.Status.Hard) {
0000000000000000000000000000000000000000;;			rq.missingUsageQueue.Add(key)
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// if we declared a constraint that has no usage (which this controller can calculate, prioritize it)
0000000000000000000000000000000000000000;;		for constraint := range resourceQuota.Status.Hard {
0000000000000000000000000000000000000000;;			if _, usageFound := resourceQuota.Status.Used[constraint]; !usageFound {
0000000000000000000000000000000000000000;;				matchedResources := []api.ResourceName{api.ResourceName(constraint)}
0000000000000000000000000000000000000000;;				for _, evaluator := range rq.registry.Evaluators() {
0000000000000000000000000000000000000000;;					if intersection := evaluator.MatchingResources(matchedResources); len(intersection) > 0 {
0000000000000000000000000000000000000000;;						rq.missingUsageQueue.Add(key)
0000000000000000000000000000000000000000;;						return
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// no special priority, go in normal recalc queue
0000000000000000000000000000000000000000;;		rq.queue.Add(key)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// worker runs a worker thread that just dequeues items, processes them, and marks them done.
0000000000000000000000000000000000000000;;	func (rq *ResourceQuotaController) worker(queue workqueue.RateLimitingInterface) func() {
0000000000000000000000000000000000000000;;		workFunc := func() bool {
0000000000000000000000000000000000000000;;			key, quit := queue.Get()
0000000000000000000000000000000000000000;;			if quit {
0000000000000000000000000000000000000000;;				return true
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			defer queue.Done(key)
0000000000000000000000000000000000000000;;			err := rq.syncHandler(key.(string))
0000000000000000000000000000000000000000;;			if err == nil {
0000000000000000000000000000000000000000;;				queue.Forget(key)
0000000000000000000000000000000000000000;;				return false
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			utilruntime.HandleError(err)
0000000000000000000000000000000000000000;;			queue.AddRateLimited(key)
0000000000000000000000000000000000000000;;			return false
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return func() {
0000000000000000000000000000000000000000;;			for {
0000000000000000000000000000000000000000;;				if quit := workFunc(); quit {
0000000000000000000000000000000000000000;;					glog.Infof("resource quota controller worker shutting down")
0000000000000000000000000000000000000000;;					return
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Run begins quota controller using the specified number of workers
0000000000000000000000000000000000000000;;	func (rq *ResourceQuotaController) Run(workers int, stopCh <-chan struct{}) {
0000000000000000000000000000000000000000;;		defer utilruntime.HandleCrash()
0000000000000000000000000000000000000000;;		defer rq.queue.ShutDown()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		glog.Infof("Starting resource quota controller")
0000000000000000000000000000000000000000;;		defer glog.Infof("Shutting down resource quota controller")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// the controllers that replenish other resources to respond rapidly to state changes
0000000000000000000000000000000000000000;;		for _, replenishmentController := range rq.replenishmentControllers {
0000000000000000000000000000000000000000;;			go replenishmentController.Run(stopCh)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if !controller.WaitForCacheSync("resource quota", stopCh, rq.informerSyncedFuncs...) {
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// the workers that chug through the quota calculation backlog
0000000000000000000000000000000000000000;;		for i := 0; i < workers; i++ {
0000000000000000000000000000000000000000;;			go wait.Until(rq.worker(rq.queue), time.Second, stopCh)
0000000000000000000000000000000000000000;;			go wait.Until(rq.worker(rq.missingUsageQueue), time.Second, stopCh)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		// the timer for how often we do a full recalculation across all quotas
0000000000000000000000000000000000000000;;		go wait.Until(func() { rq.enqueueAll() }, rq.resyncPeriod(), stopCh)
0000000000000000000000000000000000000000;;		<-stopCh
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// syncResourceQuotaFromKey syncs a quota key
0000000000000000000000000000000000000000;;	func (rq *ResourceQuotaController) syncResourceQuotaFromKey(key string) (err error) {
0000000000000000000000000000000000000000;;		startTime := time.Now()
0000000000000000000000000000000000000000;;		defer func() {
0000000000000000000000000000000000000000;;			glog.V(4).Infof("Finished syncing resource quota %q (%v)", key, time.Now().Sub(startTime))
0000000000000000000000000000000000000000;;		}()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		namespace, name, err := cache.SplitMetaNamespaceKey(key)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		quota, err := rq.rqLister.ResourceQuotas(namespace).Get(name)
0000000000000000000000000000000000000000;;		if errors.IsNotFound(err) {
0000000000000000000000000000000000000000;;			glog.Infof("Resource quota has been deleted %v", key)
0000000000000000000000000000000000000000;;			return nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			glog.Infof("Unable to retrieve resource quota %v from store: %v", key, err)
0000000000000000000000000000000000000000;;			rq.queue.Add(key)
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return rq.syncResourceQuota(quota)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// syncResourceQuota runs a complete sync of resource quota status across all known kinds
0000000000000000000000000000000000000000;;	func (rq *ResourceQuotaController) syncResourceQuota(v1ResourceQuota *v1.ResourceQuota) (err error) {
0000000000000000000000000000000000000000;;		// quota is dirty if any part of spec hard limits differs from the status hard limits
0000000000000000000000000000000000000000;;		dirty := !apiequality.Semantic.DeepEqual(v1ResourceQuota.Spec.Hard, v1ResourceQuota.Status.Hard)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		resourceQuota := api.ResourceQuota{}
0000000000000000000000000000000000000000;;		if err := k8s_api_v1.Convert_v1_ResourceQuota_To_api_ResourceQuota(v1ResourceQuota, &resourceQuota, nil); err != nil {
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// dirty tracks if the usage status differs from the previous sync,
0000000000000000000000000000000000000000;;		// if so, we send a new usage with latest status
0000000000000000000000000000000000000000;;		// if this is our first sync, it will be dirty by default, since we need track usage
0000000000000000000000000000000000000000;;		dirty = dirty || (resourceQuota.Status.Hard == nil || resourceQuota.Status.Used == nil)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		used := api.ResourceList{}
0000000000000000000000000000000000000000;;		if resourceQuota.Status.Used != nil {
0000000000000000000000000000000000000000;;			used = quota.Add(api.ResourceList{}, resourceQuota.Status.Used)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		hardLimits := quota.Add(api.ResourceList{}, resourceQuota.Spec.Hard)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		newUsage, err := quota.CalculateUsage(resourceQuota.Namespace, resourceQuota.Spec.Scopes, hardLimits, rq.registry)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		for key, value := range newUsage {
0000000000000000000000000000000000000000;;			used[key] = value
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// ensure set of used values match those that have hard constraints
0000000000000000000000000000000000000000;;		hardResources := quota.ResourceNames(hardLimits)
0000000000000000000000000000000000000000;;		used = quota.Mask(used, hardResources)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Create a usage object that is based on the quota resource version that will handle updates
0000000000000000000000000000000000000000;;		// by default, we preserve the past usage observation, and set hard to the current spec
0000000000000000000000000000000000000000;;		usage := api.ResourceQuota{
0000000000000000000000000000000000000000;;			ObjectMeta: metav1.ObjectMeta{
0000000000000000000000000000000000000000;;				Name:            resourceQuota.Name,
0000000000000000000000000000000000000000;;				Namespace:       resourceQuota.Namespace,
0000000000000000000000000000000000000000;;				ResourceVersion: resourceQuota.ResourceVersion,
0000000000000000000000000000000000000000;;				Labels:          resourceQuota.Labels,
0000000000000000000000000000000000000000;;				Annotations:     resourceQuota.Annotations},
0000000000000000000000000000000000000000;;			Status: api.ResourceQuotaStatus{
0000000000000000000000000000000000000000;;				Hard: hardLimits,
0000000000000000000000000000000000000000;;				Used: used,
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		dirty = dirty || !quota.Equals(usage.Status.Used, resourceQuota.Status.Used)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// there was a change observed by this controller that requires we update quota
0000000000000000000000000000000000000000;;		if dirty {
0000000000000000000000000000000000000000;;			v1Usage := &v1.ResourceQuota{}
0000000000000000000000000000000000000000;;			if err := k8s_api_v1.Convert_api_ResourceQuota_To_v1_ResourceQuota(&usage, v1Usage, nil); err != nil {
0000000000000000000000000000000000000000;;				return err
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			_, err = rq.kubeClient.Core().ResourceQuotas(usage.Namespace).UpdateStatus(v1Usage)
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// replenishQuota is a replenishment function invoked by a controller to notify that a quota should be recalculated
0000000000000000000000000000000000000000;;	func (rq *ResourceQuotaController) replenishQuota(groupKind schema.GroupKind, namespace string, object runtime.Object) {
0000000000000000000000000000000000000000;;		// check if the quota controller can evaluate this kind, if not, ignore it altogether...
0000000000000000000000000000000000000000;;		evaluators := rq.registry.Evaluators()
0000000000000000000000000000000000000000;;		evaluator, found := evaluators[groupKind]
0000000000000000000000000000000000000000;;		if !found {
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// check if this namespace even has a quota...
0000000000000000000000000000000000000000;;		resourceQuotas, err := rq.rqLister.ResourceQuotas(namespace).List(labels.Everything())
0000000000000000000000000000000000000000;;		if errors.IsNotFound(err) {
0000000000000000000000000000000000000000;;			utilruntime.HandleError(fmt.Errorf("quota controller could not find ResourceQuota associated with namespace: %s, could take up to %v before a quota replenishes", namespace, rq.resyncPeriod()))
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			utilruntime.HandleError(fmt.Errorf("error checking to see if namespace %s has any ResourceQuota associated with it: %v", namespace, err))
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if len(resourceQuotas) == 0 {
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// only queue those quotas that are tracking a resource associated with this kind.
0000000000000000000000000000000000000000;;		for i := range resourceQuotas {
0000000000000000000000000000000000000000;;			resourceQuota := resourceQuotas[i]
0000000000000000000000000000000000000000;;			internalResourceQuota := &api.ResourceQuota{}
0000000000000000000000000000000000000000;;			if err := k8s_api_v1.Convert_v1_ResourceQuota_To_api_ResourceQuota(resourceQuota, internalResourceQuota, nil); err != nil {
0000000000000000000000000000000000000000;;				glog.Error(err)
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			resourceQuotaResources := quota.ResourceNames(internalResourceQuota.Status.Hard)
0000000000000000000000000000000000000000;;			if intersection := evaluator.MatchingResources(resourceQuotaResources); len(intersection) > 0 {
0000000000000000000000000000000000000000;;				// TODO: make this support targeted replenishment to a specific kind, right now it does a full recalc on that quota.
0000000000000000000000000000000000000000;;				rq.enqueueResourceQuota(resourceQuota)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
