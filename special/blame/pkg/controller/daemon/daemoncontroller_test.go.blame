0000000000000000000000000000000000000000;;	/*
0000000000000000000000000000000000000000;;	Copyright 2015 The Kubernetes Authors.
c47674331a5a38e6753982ce760628167b2c6b0a;pkg/controller/daemon/manager_test.go[pkg/controller/daemon/manager_test.go][pkg/controller/daemon/daemoncontroller_test.go];	
0000000000000000000000000000000000000000;;	Licensed under the Apache License, Version 2.0 (the "License");
0000000000000000000000000000000000000000;;	you may not use this file except in compliance with the License.
0000000000000000000000000000000000000000;;	You may obtain a copy of the License at
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	    http://www.apache.org/licenses/LICENSE-2.0
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	Unless required by applicable law or agreed to in writing, software
0000000000000000000000000000000000000000;;	distributed under the License is distributed on an "AS IS" BASIS,
0000000000000000000000000000000000000000;;	WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
0000000000000000000000000000000000000000;;	See the License for the specific language governing permissions and
0000000000000000000000000000000000000000;;	limitations under the License.
0000000000000000000000000000000000000000;;	*/
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	package daemon
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	import (
0000000000000000000000000000000000000000;;		"fmt"
0000000000000000000000000000000000000000;;		"reflect"
0000000000000000000000000000000000000000;;		"sort"
0000000000000000000000000000000000000000;;		"strconv"
0000000000000000000000000000000000000000;;		"sync"
0000000000000000000000000000000000000000;;		"testing"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		"k8s.io/api/core/v1"
0000000000000000000000000000000000000000;;		extensions "k8s.io/api/extensions/v1beta1"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/api/resource"
0000000000000000000000000000000000000000;;		metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/runtime"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/util/intstr"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/util/uuid"
0000000000000000000000000000000000000000;;		"k8s.io/apiserver/pkg/storage/names"
0000000000000000000000000000000000000000;;		utilfeature "k8s.io/apiserver/pkg/util/feature"
0000000000000000000000000000000000000000;;		core "k8s.io/client-go/testing"
0000000000000000000000000000000000000000;;		"k8s.io/client-go/tools/cache"
0000000000000000000000000000000000000000;;		"k8s.io/client-go/tools/record"
0000000000000000000000000000000000000000;;		"k8s.io/client-go/util/workqueue"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/api"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/api/testapi"
0000000000000000000000000000000000000000;;		podutil "k8s.io/kubernetes/pkg/api/v1/pod"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/client/clientset_generated/clientset/fake"
0000000000000000000000000000000000000000;;		informers "k8s.io/kubernetes/pkg/client/informers/informers_generated/externalversions"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/controller"
0000000000000000000000000000000000000000;;		kubelettypes "k8s.io/kubernetes/pkg/kubelet/types"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/securitycontext"
0000000000000000000000000000000000000000;;		labelsutil "k8s.io/kubernetes/pkg/util/labels"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/plugin/pkg/scheduler/algorithm"
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	var (
0000000000000000000000000000000000000000;;		simpleDaemonSetLabel  = map[string]string{"name": "simple-daemon", "type": "production"}
0000000000000000000000000000000000000000;;		simpleDaemonSetLabel2 = map[string]string{"name": "simple-daemon", "type": "test"}
0000000000000000000000000000000000000000;;		simpleNodeLabel       = map[string]string{"color": "blue", "speed": "fast"}
0000000000000000000000000000000000000000;;		simpleNodeLabel2      = map[string]string{"color": "red", "speed": "fast"}
0000000000000000000000000000000000000000;;		alwaysReady           = func() bool { return true }
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	var (
0000000000000000000000000000000000000000;;		noScheduleTolerations = []v1.Toleration{{Key: "dedicated", Value: "user1", Effect: "NoSchedule"}}
0000000000000000000000000000000000000000;;		noScheduleTaints      = []v1.Taint{{Key: "dedicated", Value: "user1", Effect: "NoSchedule"}}
0000000000000000000000000000000000000000;;		noExecuteTaints       = []v1.Taint{{Key: "dedicated", Value: "user1", Effect: "NoExecute"}}
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	var (
0000000000000000000000000000000000000000;;		nodeNotReady = []v1.Taint{{
0000000000000000000000000000000000000000;;			Key:       algorithm.TaintNodeNotReady,
0000000000000000000000000000000000000000;;			Effect:    v1.TaintEffectNoExecute,
0000000000000000000000000000000000000000;;			TimeAdded: metav1.Now(),
0000000000000000000000000000000000000000;;		}}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		nodeUnreachable = []v1.Taint{{
0000000000000000000000000000000000000000;;			Key:       algorithm.TaintNodeUnreachable,
0000000000000000000000000000000000000000;;			Effect:    v1.TaintEffectNoExecute,
0000000000000000000000000000000000000000;;			TimeAdded: metav1.Now(),
0000000000000000000000000000000000000000;;		}}
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func getKey(ds *extensions.DaemonSet, t *testing.T) string {
0000000000000000000000000000000000000000;;		if key, err := controller.KeyFunc(ds); err != nil {
0000000000000000000000000000000000000000;;			t.Errorf("Unexpected error getting key for ds %v: %v", ds.Name, err)
0000000000000000000000000000000000000000;;			return ""
0000000000000000000000000000000000000000;;		} else {
0000000000000000000000000000000000000000;;			return key
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func newDaemonSet(name string) *extensions.DaemonSet {
0000000000000000000000000000000000000000;;		two := int32(2)
0000000000000000000000000000000000000000;;		return &extensions.DaemonSet{
0000000000000000000000000000000000000000;;			TypeMeta: metav1.TypeMeta{APIVersion: testapi.Extensions.GroupVersion().String()},
0000000000000000000000000000000000000000;;			ObjectMeta: metav1.ObjectMeta{
0000000000000000000000000000000000000000;;				UID:       uuid.NewUUID(),
0000000000000000000000000000000000000000;;				Name:      name,
0000000000000000000000000000000000000000;;				Namespace: metav1.NamespaceDefault,
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			Spec: extensions.DaemonSetSpec{
0000000000000000000000000000000000000000;;				RevisionHistoryLimit: &two,
0000000000000000000000000000000000000000;;				UpdateStrategy: extensions.DaemonSetUpdateStrategy{
0000000000000000000000000000000000000000;;					Type: extensions.OnDeleteDaemonSetStrategyType,
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;				Selector: &metav1.LabelSelector{MatchLabels: simpleDaemonSetLabel},
0000000000000000000000000000000000000000;;				Template: v1.PodTemplateSpec{
0000000000000000000000000000000000000000;;					ObjectMeta: metav1.ObjectMeta{
0000000000000000000000000000000000000000;;						Labels: simpleDaemonSetLabel,
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;					Spec: v1.PodSpec{
0000000000000000000000000000000000000000;;						Containers: []v1.Container{
0000000000000000000000000000000000000000;;							{
0000000000000000000000000000000000000000;;								Image: "foo/bar",
0000000000000000000000000000000000000000;;								TerminationMessagePath: v1.TerminationMessagePathDefault,
0000000000000000000000000000000000000000;;								ImagePullPolicy:        v1.PullIfNotPresent,
0000000000000000000000000000000000000000;;								SecurityContext:        securitycontext.ValidSecurityContextWithContainerDefaults(),
0000000000000000000000000000000000000000;;							},
0000000000000000000000000000000000000000;;						},
0000000000000000000000000000000000000000;;						DNSPolicy: v1.DNSDefault,
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func newRollbackStrategy() *extensions.DaemonSetUpdateStrategy {
0000000000000000000000000000000000000000;;		one := intstr.FromInt(1)
0000000000000000000000000000000000000000;;		return &extensions.DaemonSetUpdateStrategy{
0000000000000000000000000000000000000000;;			Type:          extensions.RollingUpdateDaemonSetStrategyType,
0000000000000000000000000000000000000000;;			RollingUpdate: &extensions.RollingUpdateDaemonSet{MaxUnavailable: &one},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func newOnDeleteStrategy() *extensions.DaemonSetUpdateStrategy {
0000000000000000000000000000000000000000;;		return &extensions.DaemonSetUpdateStrategy{
0000000000000000000000000000000000000000;;			Type: extensions.OnDeleteDaemonSetStrategyType,
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func updateStrategies() []*extensions.DaemonSetUpdateStrategy {
0000000000000000000000000000000000000000;;		return []*extensions.DaemonSetUpdateStrategy{newOnDeleteStrategy(), newRollbackStrategy()}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func newNode(name string, label map[string]string) *v1.Node {
0000000000000000000000000000000000000000;;		return &v1.Node{
0000000000000000000000000000000000000000;;			TypeMeta: metav1.TypeMeta{APIVersion: api.Registry.GroupOrDie(v1.GroupName).GroupVersion.String()},
0000000000000000000000000000000000000000;;			ObjectMeta: metav1.ObjectMeta{
0000000000000000000000000000000000000000;;				Name:      name,
0000000000000000000000000000000000000000;;				Labels:    label,
0000000000000000000000000000000000000000;;				Namespace: metav1.NamespaceDefault,
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			Status: v1.NodeStatus{
0000000000000000000000000000000000000000;;				Conditions: []v1.NodeCondition{
0000000000000000000000000000000000000000;;					{Type: v1.NodeReady, Status: v1.ConditionTrue},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;				Allocatable: v1.ResourceList{
0000000000000000000000000000000000000000;;					v1.ResourcePods: resource.MustParse("100"),
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func addNodes(nodeStore cache.Store, startIndex, numNodes int, label map[string]string) {
0000000000000000000000000000000000000000;;		for i := startIndex; i < startIndex+numNodes; i++ {
0000000000000000000000000000000000000000;;			nodeStore.Add(newNode(fmt.Sprintf("node-%d", i), label))
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func newPod(podName string, nodeName string, label map[string]string, ds *extensions.DaemonSet) *v1.Pod {
0000000000000000000000000000000000000000;;		// Add hash unique label to the pod
0000000000000000000000000000000000000000;;		newLabels := label
0000000000000000000000000000000000000000;;		var podSpec v1.PodSpec
0000000000000000000000000000000000000000;;		// Copy pod spec from DaemonSet template, or use a default one if DaemonSet is nil
0000000000000000000000000000000000000000;;		if ds != nil {
0000000000000000000000000000000000000000;;			hash := fmt.Sprint(controller.ComputeHash(&ds.Spec.Template, ds.Status.CollisionCount))
0000000000000000000000000000000000000000;;			newLabels = labelsutil.CloneAndAddLabel(label, extensions.DefaultDaemonSetUniqueLabelKey, hash)
0000000000000000000000000000000000000000;;			podSpec = ds.Spec.Template.Spec
0000000000000000000000000000000000000000;;		} else {
0000000000000000000000000000000000000000;;			podSpec = v1.PodSpec{
0000000000000000000000000000000000000000;;				Containers: []v1.Container{
0000000000000000000000000000000000000000;;					{
0000000000000000000000000000000000000000;;						Image: "foo/bar",
0000000000000000000000000000000000000000;;						TerminationMessagePath: v1.TerminationMessagePathDefault,
0000000000000000000000000000000000000000;;						ImagePullPolicy:        v1.PullIfNotPresent,
0000000000000000000000000000000000000000;;						SecurityContext:        securitycontext.ValidSecurityContextWithContainerDefaults(),
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		// Add node name to the pod
0000000000000000000000000000000000000000;;		if len(nodeName) > 0 {
0000000000000000000000000000000000000000;;			podSpec.NodeName = nodeName
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		pod := &v1.Pod{
0000000000000000000000000000000000000000;;			TypeMeta: metav1.TypeMeta{APIVersion: api.Registry.GroupOrDie(v1.GroupName).GroupVersion.String()},
0000000000000000000000000000000000000000;;			ObjectMeta: metav1.ObjectMeta{
0000000000000000000000000000000000000000;;				GenerateName: podName,
0000000000000000000000000000000000000000;;				Labels:       newLabels,
0000000000000000000000000000000000000000;;				Namespace:    metav1.NamespaceDefault,
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			Spec: podSpec,
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		pod.Name = names.SimpleNameGenerator.GenerateName(podName)
0000000000000000000000000000000000000000;;		if ds != nil {
0000000000000000000000000000000000000000;;			pod.OwnerReferences = []metav1.OwnerReference{*newControllerRef(ds)}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return pod
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func addPods(podStore cache.Store, nodeName string, label map[string]string, ds *extensions.DaemonSet, number int) {
0000000000000000000000000000000000000000;;		for i := 0; i < number; i++ {
0000000000000000000000000000000000000000;;			pod := newPod(fmt.Sprintf("%s-", nodeName), nodeName, label, ds)
0000000000000000000000000000000000000000;;			podStore.Add(pod)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func addFailedPods(podStore cache.Store, nodeName string, label map[string]string, ds *extensions.DaemonSet, number int) {
0000000000000000000000000000000000000000;;		for i := 0; i < number; i++ {
0000000000000000000000000000000000000000;;			pod := newPod(fmt.Sprintf("%s-", nodeName), nodeName, label, ds)
0000000000000000000000000000000000000000;;			pod.Status = v1.PodStatus{Phase: v1.PodFailed}
0000000000000000000000000000000000000000;;			podStore.Add(pod)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type fakePodControl struct {
0000000000000000000000000000000000000000;;		sync.Mutex
0000000000000000000000000000000000000000;;		*controller.FakePodControl
0000000000000000000000000000000000000000;;		podStore cache.Store
0000000000000000000000000000000000000000;;		podIDMap map[string]*v1.Pod
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func newFakePodControl() *fakePodControl {
0000000000000000000000000000000000000000;;		podIDMap := make(map[string]*v1.Pod)
0000000000000000000000000000000000000000;;		return &fakePodControl{
0000000000000000000000000000000000000000;;			FakePodControl: &controller.FakePodControl{},
0000000000000000000000000000000000000000;;			podIDMap:       podIDMap}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (f *fakePodControl) CreatePodsOnNode(nodeName, namespace string, template *v1.PodTemplateSpec, object runtime.Object, controllerRef *metav1.OwnerReference) error {
0000000000000000000000000000000000000000;;		f.Lock()
0000000000000000000000000000000000000000;;		defer f.Unlock()
0000000000000000000000000000000000000000;;		if err := f.FakePodControl.CreatePodsOnNode(nodeName, namespace, template, object, controllerRef); err != nil {
0000000000000000000000000000000000000000;;			return fmt.Errorf("failed to create pod on node %q", nodeName)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		pod := &v1.Pod{
0000000000000000000000000000000000000000;;			ObjectMeta: metav1.ObjectMeta{
0000000000000000000000000000000000000000;;				Labels:       template.Labels,
0000000000000000000000000000000000000000;;				Namespace:    namespace,
0000000000000000000000000000000000000000;;				GenerateName: fmt.Sprintf("%s-", nodeName),
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if err := api.Scheme.Convert(&template.Spec, &pod.Spec, nil); err != nil {
0000000000000000000000000000000000000000;;			return fmt.Errorf("unable to convert pod template: %v", err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if len(nodeName) != 0 {
0000000000000000000000000000000000000000;;			pod.Spec.NodeName = nodeName
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		pod.Name = names.SimpleNameGenerator.GenerateName(fmt.Sprintf("%s-", nodeName))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		f.podStore.Update(pod)
0000000000000000000000000000000000000000;;		f.podIDMap[pod.Name] = pod
0000000000000000000000000000000000000000;;		return nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (f *fakePodControl) DeletePod(namespace string, podID string, object runtime.Object) error {
0000000000000000000000000000000000000000;;		f.Lock()
0000000000000000000000000000000000000000;;		defer f.Unlock()
0000000000000000000000000000000000000000;;		if err := f.FakePodControl.DeletePod(namespace, podID, object); err != nil {
0000000000000000000000000000000000000000;;			return fmt.Errorf("failed to delete pod %q", podID)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		pod, ok := f.podIDMap[podID]
0000000000000000000000000000000000000000;;		if !ok {
0000000000000000000000000000000000000000;;			return fmt.Errorf("pod %q does not exist", podID)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		f.podStore.Delete(pod)
0000000000000000000000000000000000000000;;		delete(f.podIDMap, podID)
0000000000000000000000000000000000000000;;		return nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type daemonSetsController struct {
0000000000000000000000000000000000000000;;		*DaemonSetsController
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		dsStore      cache.Store
0000000000000000000000000000000000000000;;		historyStore cache.Store
0000000000000000000000000000000000000000;;		podStore     cache.Store
0000000000000000000000000000000000000000;;		nodeStore    cache.Store
0000000000000000000000000000000000000000;;		fakeRecorder *record.FakeRecorder
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func newTestController(initialObjects ...runtime.Object) (*daemonSetsController, *fakePodControl, *fake.Clientset) {
0000000000000000000000000000000000000000;;		clientset := fake.NewSimpleClientset(initialObjects...)
0000000000000000000000000000000000000000;;		informerFactory := informers.NewSharedInformerFactory(clientset, controller.NoResyncPeriodFunc())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		dsc := NewDaemonSetsController(
0000000000000000000000000000000000000000;;			informerFactory.Extensions().V1beta1().DaemonSets(),
0000000000000000000000000000000000000000;;			informerFactory.Apps().V1beta1().ControllerRevisions(),
0000000000000000000000000000000000000000;;			informerFactory.Core().V1().Pods(),
0000000000000000000000000000000000000000;;			informerFactory.Core().V1().Nodes(),
0000000000000000000000000000000000000000;;			clientset,
0000000000000000000000000000000000000000;;		)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		fakeRecorder := record.NewFakeRecorder(100)
0000000000000000000000000000000000000000;;		dsc.eventRecorder = fakeRecorder
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		dsc.podStoreSynced = alwaysReady
0000000000000000000000000000000000000000;;		dsc.nodeStoreSynced = alwaysReady
0000000000000000000000000000000000000000;;		dsc.dsStoreSynced = alwaysReady
0000000000000000000000000000000000000000;;		dsc.historyStoreSynced = alwaysReady
0000000000000000000000000000000000000000;;		podControl := newFakePodControl()
0000000000000000000000000000000000000000;;		dsc.podControl = podControl
0000000000000000000000000000000000000000;;		podControl.podStore = informerFactory.Core().V1().Pods().Informer().GetStore()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return &daemonSetsController{
0000000000000000000000000000000000000000;;			dsc,
0000000000000000000000000000000000000000;;			informerFactory.Extensions().V1beta1().DaemonSets().Informer().GetStore(),
0000000000000000000000000000000000000000;;			informerFactory.Apps().V1beta1().ControllerRevisions().Informer().GetStore(),
0000000000000000000000000000000000000000;;			informerFactory.Core().V1().Pods().Informer().GetStore(),
0000000000000000000000000000000000000000;;			informerFactory.Core().V1().Nodes().Informer().GetStore(),
0000000000000000000000000000000000000000;;			fakeRecorder,
0000000000000000000000000000000000000000;;		}, podControl, clientset
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func validateSyncDaemonSets(t *testing.T, manager *daemonSetsController, fakePodControl *fakePodControl, expectedCreates, expectedDeletes int, expectedEvents int) {
0000000000000000000000000000000000000000;;		if len(fakePodControl.Templates) != expectedCreates {
0000000000000000000000000000000000000000;;			t.Errorf("Unexpected number of creates.  Expected %d, saw %d\n", expectedCreates, len(fakePodControl.Templates))
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if len(fakePodControl.DeletePodName) != expectedDeletes {
0000000000000000000000000000000000000000;;			t.Errorf("Unexpected number of deletes.  Expected %d, saw %d\n", expectedDeletes, len(fakePodControl.DeletePodName))
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if len(manager.fakeRecorder.Events) != expectedEvents {
0000000000000000000000000000000000000000;;			t.Errorf("Unexpected number of events.  Expected %d, saw %d\n", expectedEvents, len(manager.fakeRecorder.Events))
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		// Every Pod created should have a ControllerRef.
0000000000000000000000000000000000000000;;		if got, want := len(fakePodControl.ControllerRefs), expectedCreates; got != want {
0000000000000000000000000000000000000000;;			t.Errorf("len(ControllerRefs) = %v, want %v", got, want)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		// Make sure the ControllerRefs are correct.
0000000000000000000000000000000000000000;;		for _, controllerRef := range fakePodControl.ControllerRefs {
0000000000000000000000000000000000000000;;			if got, want := controllerRef.APIVersion, "extensions/v1beta1"; got != want {
0000000000000000000000000000000000000000;;				t.Errorf("controllerRef.APIVersion = %q, want %q", got, want)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if got, want := controllerRef.Kind, "DaemonSet"; got != want {
0000000000000000000000000000000000000000;;				t.Errorf("controllerRef.Kind = %q, want %q", got, want)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if controllerRef.Controller == nil || *controllerRef.Controller != true {
0000000000000000000000000000000000000000;;				t.Errorf("controllerRef.Controller is not set to true")
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func syncAndValidateDaemonSets(t *testing.T, manager *daemonSetsController, ds *extensions.DaemonSet, podControl *fakePodControl, expectedCreates, expectedDeletes int, expectedEvents int) {
0000000000000000000000000000000000000000;;		key, err := controller.KeyFunc(ds)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			t.Errorf("Could not get key for daemon.")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		manager.syncHandler(key)
0000000000000000000000000000000000000000;;		validateSyncDaemonSets(t, manager, podControl, expectedCreates, expectedDeletes, expectedEvents)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// clearExpectations copies the FakePodControl to PodStore and clears the create and delete expectations.
0000000000000000000000000000000000000000;;	func clearExpectations(t *testing.T, manager *daemonSetsController, ds *extensions.DaemonSet, fakePodControl *fakePodControl) {
0000000000000000000000000000000000000000;;		fakePodControl.Clear()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		key, err := controller.KeyFunc(ds)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			t.Errorf("Could not get key for daemon.")
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		manager.expectations.DeleteExpectations(key)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestDeleteFinalStateUnknown(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			manager, _, _ := newTestController()
0000000000000000000000000000000000000000;;			addNodes(manager.nodeStore, 0, 1, nil)
0000000000000000000000000000000000000000;;			ds := newDaemonSet("foo")
0000000000000000000000000000000000000000;;			ds.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			// DeletedFinalStateUnknown should queue the embedded DS if found.
0000000000000000000000000000000000000000;;			manager.deleteDaemonset(cache.DeletedFinalStateUnknown{Key: "foo", Obj: ds})
0000000000000000000000000000000000000000;;			enqueuedKey, _ := manager.queue.Get()
0000000000000000000000000000000000000000;;			if enqueuedKey.(string) != "default/foo" {
0000000000000000000000000000000000000000;;				t.Errorf("expected delete of DeletedFinalStateUnknown to enqueue the daemonset but found: %#v", enqueuedKey)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func markPodsReady(store cache.Store) {
0000000000000000000000000000000000000000;;		// mark pods as ready
0000000000000000000000000000000000000000;;		for _, obj := range store.List() {
0000000000000000000000000000000000000000;;			pod := obj.(*v1.Pod)
0000000000000000000000000000000000000000;;			markPodReady(pod)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func markPodReady(pod *v1.Pod) {
0000000000000000000000000000000000000000;;		condition := v1.PodCondition{Type: v1.PodReady, Status: v1.ConditionTrue}
0000000000000000000000000000000000000000;;		podutil.UpdatePodCondition(&pod.Status, &condition)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// DaemonSets without node selectors should launch pods on every node.
0000000000000000000000000000000000000000;;	func TestSimpleDaemonSetLaunchesPods(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			ds := newDaemonSet("foo")
0000000000000000000000000000000000000000;;			ds.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			manager, podControl, _ := newTestController(ds)
0000000000000000000000000000000000000000;;			addNodes(manager.nodeStore, 0, 5, nil)
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds)
0000000000000000000000000000000000000000;;			syncAndValidateDaemonSets(t, manager, ds, podControl, 5, 0, 0)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestSimpleDaemonSetUpdatesStatusAfterLaunchingPods(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			ds := newDaemonSet("foo")
0000000000000000000000000000000000000000;;			ds.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			manager, podControl, clientset := newTestController(ds)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			var updated *extensions.DaemonSet
0000000000000000000000000000000000000000;;			clientset.PrependReactor("update", "daemonsets", func(action core.Action) (handled bool, ret runtime.Object, err error) {
0000000000000000000000000000000000000000;;				if action.GetSubresource() != "status" {
0000000000000000000000000000000000000000;;					return false, nil, nil
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				if u, ok := action.(core.UpdateAction); ok {
0000000000000000000000000000000000000000;;					updated = u.GetObject().(*extensions.DaemonSet)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				return false, nil, nil
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds)
0000000000000000000000000000000000000000;;			addNodes(manager.nodeStore, 0, 5, nil)
0000000000000000000000000000000000000000;;			syncAndValidateDaemonSets(t, manager, ds, podControl, 5, 0, 0)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Make sure the single sync() updated Status already for the change made
0000000000000000000000000000000000000000;;			// during the manage() phase.
0000000000000000000000000000000000000000;;			if got, want := updated.Status.CurrentNumberScheduled, int32(5); got != want {
0000000000000000000000000000000000000000;;				t.Errorf("Status.CurrentNumberScheduled = %v, want %v", got, want)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// DaemonSets should do nothing if there aren't any nodes
0000000000000000000000000000000000000000;;	func TestNoNodesDoesNothing(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			manager, podControl, _ := newTestController()
0000000000000000000000000000000000000000;;			ds := newDaemonSet("foo")
0000000000000000000000000000000000000000;;			ds.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds)
0000000000000000000000000000000000000000;;			syncAndValidateDaemonSets(t, manager, ds, podControl, 0, 0, 0)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// DaemonSets without node selectors should launch on a single node in a
0000000000000000000000000000000000000000;;	// single node cluster.
0000000000000000000000000000000000000000;;	func TestOneNodeDaemonLaunchesPod(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			ds := newDaemonSet("foo")
0000000000000000000000000000000000000000;;			ds.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			manager, podControl, _ := newTestController(ds)
0000000000000000000000000000000000000000;;			manager.nodeStore.Add(newNode("only-node", nil))
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds)
0000000000000000000000000000000000000000;;			syncAndValidateDaemonSets(t, manager, ds, podControl, 1, 0, 0)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// DaemonSets should place onto NotReady nodes
0000000000000000000000000000000000000000;;	func TestNotReadNodeDaemonDoesNotLaunchPod(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			ds := newDaemonSet("foo")
0000000000000000000000000000000000000000;;			ds.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			manager, podControl, _ := newTestController(ds)
0000000000000000000000000000000000000000;;			node := newNode("not-ready", nil)
0000000000000000000000000000000000000000;;			node.Status.Conditions = []v1.NodeCondition{
0000000000000000000000000000000000000000;;				{Type: v1.NodeReady, Status: v1.ConditionFalse},
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			manager.nodeStore.Add(node)
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds)
0000000000000000000000000000000000000000;;			syncAndValidateDaemonSets(t, manager, ds, podControl, 1, 0, 0)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// DaemonSets should not place onto OutOfDisk nodes
0000000000000000000000000000000000000000;;	func TestOutOfDiskNodeDaemonDoesNotLaunchPod(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			ds := newDaemonSet("foo")
0000000000000000000000000000000000000000;;			ds.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			manager, podControl, _ := newTestController(ds)
0000000000000000000000000000000000000000;;			node := newNode("not-enough-disk", nil)
0000000000000000000000000000000000000000;;			node.Status.Conditions = []v1.NodeCondition{{Type: v1.NodeOutOfDisk, Status: v1.ConditionTrue}}
0000000000000000000000000000000000000000;;			manager.nodeStore.Add(node)
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds)
0000000000000000000000000000000000000000;;			syncAndValidateDaemonSets(t, manager, ds, podControl, 0, 0, 0)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func resourcePodSpec(nodeName, memory, cpu string) v1.PodSpec {
0000000000000000000000000000000000000000;;		return v1.PodSpec{
0000000000000000000000000000000000000000;;			NodeName: nodeName,
0000000000000000000000000000000000000000;;			Containers: []v1.Container{{
0000000000000000000000000000000000000000;;				Resources: v1.ResourceRequirements{
0000000000000000000000000000000000000000;;					Requests: allocatableResources(memory, cpu),
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			}},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func resourcePodSpecWithoutNodeName(memory, cpu string) v1.PodSpec {
0000000000000000000000000000000000000000;;		return v1.PodSpec{
0000000000000000000000000000000000000000;;			Containers: []v1.Container{{
0000000000000000000000000000000000000000;;				Resources: v1.ResourceRequirements{
0000000000000000000000000000000000000000;;					Requests: allocatableResources(memory, cpu),
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			}},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func allocatableResources(memory, cpu string) v1.ResourceList {
0000000000000000000000000000000000000000;;		return v1.ResourceList{
0000000000000000000000000000000000000000;;			v1.ResourceMemory: resource.MustParse(memory),
0000000000000000000000000000000000000000;;			v1.ResourceCPU:    resource.MustParse(cpu),
0000000000000000000000000000000000000000;;			v1.ResourcePods:   resource.MustParse("100"),
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// DaemonSets should not place onto nodes with insufficient free resource
0000000000000000000000000000000000000000;;	func TestInsufficientCapacityNodeDaemonDoesNotLaunchPod(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			podSpec := resourcePodSpec("too-much-mem", "75M", "75m")
0000000000000000000000000000000000000000;;			ds := newDaemonSet("foo")
0000000000000000000000000000000000000000;;			ds.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			ds.Spec.Template.Spec = podSpec
0000000000000000000000000000000000000000;;			manager, podControl, _ := newTestController(ds)
0000000000000000000000000000000000000000;;			node := newNode("too-much-mem", nil)
0000000000000000000000000000000000000000;;			node.Status.Allocatable = allocatableResources("100M", "200m")
0000000000000000000000000000000000000000;;			manager.nodeStore.Add(node)
0000000000000000000000000000000000000000;;			manager.podStore.Add(&v1.Pod{
0000000000000000000000000000000000000000;;				Spec: podSpec,
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds)
0000000000000000000000000000000000000000;;			switch strategy.Type {
0000000000000000000000000000000000000000;;			case extensions.OnDeleteDaemonSetStrategyType:
0000000000000000000000000000000000000000;;				syncAndValidateDaemonSets(t, manager, ds, podControl, 0, 0, 2)
0000000000000000000000000000000000000000;;			case extensions.RollingUpdateDaemonSetStrategyType:
0000000000000000000000000000000000000000;;				syncAndValidateDaemonSets(t, manager, ds, podControl, 0, 0, 3)
0000000000000000000000000000000000000000;;			default:
0000000000000000000000000000000000000000;;				t.Fatalf("unexpected UpdateStrategy %+v", strategy)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// DaemonSets should not unschedule a daemonset pod from a node with insufficient free resource
0000000000000000000000000000000000000000;;	func TestInsufficientCapacityNodeDaemonDoesNotUnscheduleRunningPod(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			podSpec := resourcePodSpec("too-much-mem", "75M", "75m")
0000000000000000000000000000000000000000;;			podSpec.NodeName = "too-much-mem"
0000000000000000000000000000000000000000;;			ds := newDaemonSet("foo")
0000000000000000000000000000000000000000;;			ds.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			ds.Spec.Template.Spec = podSpec
0000000000000000000000000000000000000000;;			manager, podControl, _ := newTestController(ds)
0000000000000000000000000000000000000000;;			node := newNode("too-much-mem", nil)
0000000000000000000000000000000000000000;;			node.Status.Allocatable = allocatableResources("100M", "200m")
0000000000000000000000000000000000000000;;			manager.nodeStore.Add(node)
0000000000000000000000000000000000000000;;			manager.podStore.Add(&v1.Pod{
0000000000000000000000000000000000000000;;				Spec: podSpec,
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds)
0000000000000000000000000000000000000000;;			switch strategy.Type {
0000000000000000000000000000000000000000;;			case extensions.OnDeleteDaemonSetStrategyType:
0000000000000000000000000000000000000000;;				syncAndValidateDaemonSets(t, manager, ds, podControl, 0, 0, 2)
0000000000000000000000000000000000000000;;			case extensions.RollingUpdateDaemonSetStrategyType:
0000000000000000000000000000000000000000;;				syncAndValidateDaemonSets(t, manager, ds, podControl, 0, 0, 3)
0000000000000000000000000000000000000000;;			default:
0000000000000000000000000000000000000000;;				t.Fatalf("unexpected UpdateStrategy %+v", strategy)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// DaemonSets should only place onto nodes with sufficient free resource and matched node selector
0000000000000000000000000000000000000000;;	func TestInsufficientCapacityNodeSufficientCapacityWithNodeLabelDaemonLaunchPod(t *testing.T) {
0000000000000000000000000000000000000000;;		podSpec := resourcePodSpecWithoutNodeName("50M", "75m")
0000000000000000000000000000000000000000;;		ds := newDaemonSet("foo")
0000000000000000000000000000000000000000;;		ds.Spec.Template.Spec = podSpec
0000000000000000000000000000000000000000;;		ds.Spec.Template.Spec.NodeSelector = simpleNodeLabel
0000000000000000000000000000000000000000;;		manager, podControl, _ := newTestController(ds)
0000000000000000000000000000000000000000;;		node1 := newNode("not-enough-resource", nil)
0000000000000000000000000000000000000000;;		node1.Status.Allocatable = allocatableResources("10M", "20m")
0000000000000000000000000000000000000000;;		node2 := newNode("enough-resource", simpleNodeLabel)
0000000000000000000000000000000000000000;;		node2.Status.Allocatable = allocatableResources("100M", "200m")
0000000000000000000000000000000000000000;;		manager.nodeStore.Add(node1)
0000000000000000000000000000000000000000;;		manager.nodeStore.Add(node2)
0000000000000000000000000000000000000000;;		manager.dsStore.Add(ds)
0000000000000000000000000000000000000000;;		syncAndValidateDaemonSets(t, manager, ds, podControl, 1, 0, 0)
0000000000000000000000000000000000000000;;		// we do not expect any event for insufficient free resource
0000000000000000000000000000000000000000;;		if len(manager.fakeRecorder.Events) != 0 {
0000000000000000000000000000000000000000;;			t.Fatalf("unexpected events, got %v, expected %v: %+v", len(manager.fakeRecorder.Events), 0, manager.fakeRecorder.Events)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestSufficientCapacityWithTerminatedPodsDaemonLaunchesPod(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			podSpec := resourcePodSpec("too-much-mem", "75M", "75m")
0000000000000000000000000000000000000000;;			ds := newDaemonSet("foo")
0000000000000000000000000000000000000000;;			ds.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			ds.Spec.Template.Spec = podSpec
0000000000000000000000000000000000000000;;			manager, podControl, _ := newTestController(ds)
0000000000000000000000000000000000000000;;			node := newNode("too-much-mem", nil)
0000000000000000000000000000000000000000;;			node.Status.Allocatable = allocatableResources("100M", "200m")
0000000000000000000000000000000000000000;;			manager.nodeStore.Add(node)
0000000000000000000000000000000000000000;;			manager.podStore.Add(&v1.Pod{
0000000000000000000000000000000000000000;;				Spec:   podSpec,
0000000000000000000000000000000000000000;;				Status: v1.PodStatus{Phase: v1.PodSucceeded},
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds)
0000000000000000000000000000000000000000;;			syncAndValidateDaemonSets(t, manager, ds, podControl, 1, 0, 1)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// DaemonSets should place onto nodes with sufficient free resource
0000000000000000000000000000000000000000;;	func TestSufficientCapacityNodeDaemonLaunchesPod(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			podSpec := resourcePodSpec("not-too-much-mem", "75M", "75m")
0000000000000000000000000000000000000000;;			ds := newDaemonSet("foo")
0000000000000000000000000000000000000000;;			ds.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			ds.Spec.Template.Spec = podSpec
0000000000000000000000000000000000000000;;			manager, podControl, _ := newTestController(ds)
0000000000000000000000000000000000000000;;			node := newNode("not-too-much-mem", nil)
0000000000000000000000000000000000000000;;			node.Status.Allocatable = allocatableResources("200M", "200m")
0000000000000000000000000000000000000000;;			manager.nodeStore.Add(node)
0000000000000000000000000000000000000000;;			manager.podStore.Add(&v1.Pod{
0000000000000000000000000000000000000000;;				Spec: podSpec,
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds)
0000000000000000000000000000000000000000;;			syncAndValidateDaemonSets(t, manager, ds, podControl, 1, 0, 1)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// DaemonSet should launch a pod on a node with taint NetworkUnavailable condition.
0000000000000000000000000000000000000000;;	func TestNetworkUnavailableNodeDaemonLaunchesPod(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			ds := newDaemonSet("simple")
0000000000000000000000000000000000000000;;			ds.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			manager, podControl, _ := newTestController(ds)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			node := newNode("network-unavailable", nil)
0000000000000000000000000000000000000000;;			node.Status.Conditions = []v1.NodeCondition{
0000000000000000000000000000000000000000;;				{Type: v1.NodeNetworkUnavailable, Status: v1.ConditionTrue},
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			manager.nodeStore.Add(node)
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			syncAndValidateDaemonSets(t, manager, ds, podControl, 1, 0, 0)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// DaemonSets not take any actions when being deleted
0000000000000000000000000000000000000000;;	func TestDontDoAnythingIfBeingDeleted(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			podSpec := resourcePodSpec("not-too-much-mem", "75M", "75m")
0000000000000000000000000000000000000000;;			ds := newDaemonSet("foo")
0000000000000000000000000000000000000000;;			ds.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			ds.Spec.Template.Spec = podSpec
0000000000000000000000000000000000000000;;			now := metav1.Now()
0000000000000000000000000000000000000000;;			ds.DeletionTimestamp = &now
0000000000000000000000000000000000000000;;			manager, podControl, _ := newTestController(ds)
0000000000000000000000000000000000000000;;			node := newNode("not-too-much-mem", nil)
0000000000000000000000000000000000000000;;			node.Status.Allocatable = allocatableResources("200M", "200m")
0000000000000000000000000000000000000000;;			manager.nodeStore.Add(node)
0000000000000000000000000000000000000000;;			manager.podStore.Add(&v1.Pod{
0000000000000000000000000000000000000000;;				Spec: podSpec,
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds)
0000000000000000000000000000000000000000;;			syncAndValidateDaemonSets(t, manager, ds, podControl, 0, 0, 0)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestDontDoAnythingIfBeingDeletedRace(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			// Bare client says it IS deleted.
0000000000000000000000000000000000000000;;			ds := newDaemonSet("foo")
0000000000000000000000000000000000000000;;			ds.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			now := metav1.Now()
0000000000000000000000000000000000000000;;			ds.DeletionTimestamp = &now
0000000000000000000000000000000000000000;;			manager, podControl, _ := newTestController(ds)
0000000000000000000000000000000000000000;;			addNodes(manager.nodeStore, 0, 5, nil)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Lister (cache) says it's NOT deleted.
0000000000000000000000000000000000000000;;			ds2 := *ds
0000000000000000000000000000000000000000;;			ds2.DeletionTimestamp = nil
0000000000000000000000000000000000000000;;			manager.dsStore.Add(&ds2)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// The existence of a matching orphan should block all actions in this state.
0000000000000000000000000000000000000000;;			pod := newPod("pod1-", "node-0", simpleDaemonSetLabel, nil)
0000000000000000000000000000000000000000;;			manager.podStore.Add(pod)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			syncAndValidateDaemonSets(t, manager, ds, podControl, 0, 0, 0)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// DaemonSets should not place onto nodes that would cause port conflicts
0000000000000000000000000000000000000000;;	func TestPortConflictNodeDaemonDoesNotLaunchPod(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			podSpec := v1.PodSpec{
0000000000000000000000000000000000000000;;				NodeName: "port-conflict",
0000000000000000000000000000000000000000;;				Containers: []v1.Container{{
0000000000000000000000000000000000000000;;					Ports: []v1.ContainerPort{{
0000000000000000000000000000000000000000;;						HostPort: 666,
0000000000000000000000000000000000000000;;					}},
0000000000000000000000000000000000000000;;				}},
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			manager, podControl, _ := newTestController()
0000000000000000000000000000000000000000;;			node := newNode("port-conflict", nil)
0000000000000000000000000000000000000000;;			manager.nodeStore.Add(node)
0000000000000000000000000000000000000000;;			manager.podStore.Add(&v1.Pod{
0000000000000000000000000000000000000000;;				Spec: podSpec,
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			ds := newDaemonSet("foo")
0000000000000000000000000000000000000000;;			ds.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			ds.Spec.Template.Spec = podSpec
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds)
0000000000000000000000000000000000000000;;			syncAndValidateDaemonSets(t, manager, ds, podControl, 0, 0, 0)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Test that if the node is already scheduled with a pod using a host port
0000000000000000000000000000000000000000;;	// but belonging to the same daemonset, we don't delete that pod
0000000000000000000000000000000000000000;;	//
0000000000000000000000000000000000000000;;	// Issue: https://github.com/kubernetes/kubernetes/issues/22309
0000000000000000000000000000000000000000;;	func TestPortConflictWithSameDaemonPodDoesNotDeletePod(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			podSpec := v1.PodSpec{
0000000000000000000000000000000000000000;;				NodeName: "port-conflict",
0000000000000000000000000000000000000000;;				Containers: []v1.Container{{
0000000000000000000000000000000000000000;;					Ports: []v1.ContainerPort{{
0000000000000000000000000000000000000000;;						HostPort: 666,
0000000000000000000000000000000000000000;;					}},
0000000000000000000000000000000000000000;;				}},
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			manager, podControl, _ := newTestController()
0000000000000000000000000000000000000000;;			node := newNode("port-conflict", nil)
0000000000000000000000000000000000000000;;			manager.nodeStore.Add(node)
0000000000000000000000000000000000000000;;			ds := newDaemonSet("foo")
0000000000000000000000000000000000000000;;			ds.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			ds.Spec.Template.Spec = podSpec
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds)
0000000000000000000000000000000000000000;;			pod := newPod(ds.Name+"-", node.Name, simpleDaemonSetLabel, ds)
0000000000000000000000000000000000000000;;			manager.podStore.Add(pod)
0000000000000000000000000000000000000000;;			syncAndValidateDaemonSets(t, manager, ds, podControl, 0, 0, 0)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// DaemonSets should place onto nodes that would not cause port conflicts
0000000000000000000000000000000000000000;;	func TestNoPortConflictNodeDaemonLaunchesPod(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			podSpec1 := v1.PodSpec{
0000000000000000000000000000000000000000;;				NodeName: "no-port-conflict",
0000000000000000000000000000000000000000;;				Containers: []v1.Container{{
0000000000000000000000000000000000000000;;					Ports: []v1.ContainerPort{{
0000000000000000000000000000000000000000;;						HostPort: 6661,
0000000000000000000000000000000000000000;;					}},
0000000000000000000000000000000000000000;;				}},
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			podSpec2 := v1.PodSpec{
0000000000000000000000000000000000000000;;				NodeName: "no-port-conflict",
0000000000000000000000000000000000000000;;				Containers: []v1.Container{{
0000000000000000000000000000000000000000;;					Ports: []v1.ContainerPort{{
0000000000000000000000000000000000000000;;						HostPort: 6662,
0000000000000000000000000000000000000000;;					}},
0000000000000000000000000000000000000000;;				}},
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			ds := newDaemonSet("foo")
0000000000000000000000000000000000000000;;			ds.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			ds.Spec.Template.Spec = podSpec2
0000000000000000000000000000000000000000;;			manager, podControl, _ := newTestController(ds)
0000000000000000000000000000000000000000;;			node := newNode("no-port-conflict", nil)
0000000000000000000000000000000000000000;;			manager.nodeStore.Add(node)
0000000000000000000000000000000000000000;;			manager.podStore.Add(&v1.Pod{
0000000000000000000000000000000000000000;;				Spec: podSpec1,
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds)
0000000000000000000000000000000000000000;;			syncAndValidateDaemonSets(t, manager, ds, podControl, 1, 0, 0)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// DaemonSetController should not sync DaemonSets with empty pod selectors.
0000000000000000000000000000000000000000;;	//
0000000000000000000000000000000000000000;;	// issue https://github.com/kubernetes/kubernetes/pull/23223
0000000000000000000000000000000000000000;;	func TestPodIsNotDeletedByDaemonsetWithEmptyLabelSelector(t *testing.T) {
0000000000000000000000000000000000000000;;		// Create a misconfigured DaemonSet. An empty pod selector is invalid but could happen
0000000000000000000000000000000000000000;;		// if we upgrade and make a backwards incompatible change.
0000000000000000000000000000000000000000;;		//
0000000000000000000000000000000000000000;;		// The node selector matches no nodes which mimics the behavior of kubectl delete.
0000000000000000000000000000000000000000;;		//
0000000000000000000000000000000000000000;;		// The DaemonSet should not schedule pods and should not delete scheduled pods in
0000000000000000000000000000000000000000;;		// this case even though it's empty pod selector matches all pods. The DaemonSetController
0000000000000000000000000000000000000000;;		// should detect this misconfiguration and choose not to sync the DaemonSet. We should
0000000000000000000000000000000000000000;;		// not observe a deletion of the pod on node1.
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			ds := newDaemonSet("foo")
0000000000000000000000000000000000000000;;			ds.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			ls := metav1.LabelSelector{}
0000000000000000000000000000000000000000;;			ds.Spec.Selector = &ls
0000000000000000000000000000000000000000;;			ds.Spec.Template.Spec.NodeSelector = map[string]string{"foo": "bar"}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			manager, podControl, _ := newTestController(ds)
0000000000000000000000000000000000000000;;			manager.nodeStore.Add(newNode("node1", nil))
0000000000000000000000000000000000000000;;			// Create pod not controlled by a daemonset.
0000000000000000000000000000000000000000;;			manager.podStore.Add(&v1.Pod{
0000000000000000000000000000000000000000;;				ObjectMeta: metav1.ObjectMeta{
0000000000000000000000000000000000000000;;					Labels:    map[string]string{"bang": "boom"},
0000000000000000000000000000000000000000;;					Namespace: metav1.NamespaceDefault,
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;				Spec: v1.PodSpec{
0000000000000000000000000000000000000000;;					NodeName: "node1",
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			syncAndValidateDaemonSets(t, manager, ds, podControl, 0, 0, 1)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Controller should not create pods on nodes which have daemon pods, and should remove excess pods from nodes that have extra pods.
0000000000000000000000000000000000000000;;	func TestDealsWithExistingPods(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			ds := newDaemonSet("foo")
0000000000000000000000000000000000000000;;			ds.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			manager, podControl, _ := newTestController(ds)
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds)
0000000000000000000000000000000000000000;;			addNodes(manager.nodeStore, 0, 5, nil)
0000000000000000000000000000000000000000;;			addPods(manager.podStore, "node-1", simpleDaemonSetLabel, ds, 1)
0000000000000000000000000000000000000000;;			addPods(manager.podStore, "node-2", simpleDaemonSetLabel, ds, 2)
0000000000000000000000000000000000000000;;			addPods(manager.podStore, "node-3", simpleDaemonSetLabel, ds, 5)
0000000000000000000000000000000000000000;;			addPods(manager.podStore, "node-4", simpleDaemonSetLabel2, ds, 2)
0000000000000000000000000000000000000000;;			syncAndValidateDaemonSets(t, manager, ds, podControl, 2, 5, 0)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Daemon with node selector should launch pods on nodes matching selector.
0000000000000000000000000000000000000000;;	func TestSelectorDaemonLaunchesPods(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			daemon := newDaemonSet("foo")
0000000000000000000000000000000000000000;;			daemon.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			daemon.Spec.Template.Spec.NodeSelector = simpleNodeLabel
0000000000000000000000000000000000000000;;			manager, podControl, _ := newTestController(daemon)
0000000000000000000000000000000000000000;;			addNodes(manager.nodeStore, 0, 4, nil)
0000000000000000000000000000000000000000;;			addNodes(manager.nodeStore, 4, 3, simpleNodeLabel)
0000000000000000000000000000000000000000;;			manager.dsStore.Add(daemon)
0000000000000000000000000000000000000000;;			syncAndValidateDaemonSets(t, manager, daemon, podControl, 3, 0, 0)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Daemon with node selector should delete pods from nodes that do not satisfy selector.
0000000000000000000000000000000000000000;;	func TestSelectorDaemonDeletesUnselectedPods(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			ds := newDaemonSet("foo")
0000000000000000000000000000000000000000;;			ds.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			ds.Spec.Template.Spec.NodeSelector = simpleNodeLabel
0000000000000000000000000000000000000000;;			manager, podControl, _ := newTestController(ds)
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds)
0000000000000000000000000000000000000000;;			addNodes(manager.nodeStore, 0, 5, nil)
0000000000000000000000000000000000000000;;			addNodes(manager.nodeStore, 5, 5, simpleNodeLabel)
0000000000000000000000000000000000000000;;			addPods(manager.podStore, "node-0", simpleDaemonSetLabel2, ds, 2)
0000000000000000000000000000000000000000;;			addPods(manager.podStore, "node-1", simpleDaemonSetLabel, ds, 3)
0000000000000000000000000000000000000000;;			addPods(manager.podStore, "node-1", simpleDaemonSetLabel2, ds, 1)
0000000000000000000000000000000000000000;;			addPods(manager.podStore, "node-4", simpleDaemonSetLabel, ds, 1)
0000000000000000000000000000000000000000;;			syncAndValidateDaemonSets(t, manager, ds, podControl, 5, 4, 0)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// DaemonSet with node selector should launch pods on nodes matching selector, but also deal with existing pods on nodes.
0000000000000000000000000000000000000000;;	func TestSelectorDaemonDealsWithExistingPods(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			ds := newDaemonSet("foo")
0000000000000000000000000000000000000000;;			ds.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			ds.Spec.Template.Spec.NodeSelector = simpleNodeLabel
0000000000000000000000000000000000000000;;			manager, podControl, _ := newTestController(ds)
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds)
0000000000000000000000000000000000000000;;			addNodes(manager.nodeStore, 0, 5, nil)
0000000000000000000000000000000000000000;;			addNodes(manager.nodeStore, 5, 5, simpleNodeLabel)
0000000000000000000000000000000000000000;;			addPods(manager.podStore, "node-0", simpleDaemonSetLabel, ds, 1)
0000000000000000000000000000000000000000;;			addPods(manager.podStore, "node-1", simpleDaemonSetLabel, ds, 3)
0000000000000000000000000000000000000000;;			addPods(manager.podStore, "node-1", simpleDaemonSetLabel2, ds, 2)
0000000000000000000000000000000000000000;;			addPods(manager.podStore, "node-2", simpleDaemonSetLabel, ds, 4)
0000000000000000000000000000000000000000;;			addPods(manager.podStore, "node-6", simpleDaemonSetLabel, ds, 13)
0000000000000000000000000000000000000000;;			addPods(manager.podStore, "node-7", simpleDaemonSetLabel2, ds, 4)
0000000000000000000000000000000000000000;;			addPods(manager.podStore, "node-9", simpleDaemonSetLabel, ds, 1)
0000000000000000000000000000000000000000;;			addPods(manager.podStore, "node-9", simpleDaemonSetLabel2, ds, 1)
0000000000000000000000000000000000000000;;			syncAndValidateDaemonSets(t, manager, ds, podControl, 3, 20, 0)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// DaemonSet with node selector which does not match any node labels should not launch pods.
0000000000000000000000000000000000000000;;	func TestBadSelectorDaemonDoesNothing(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			manager, podControl, _ := newTestController()
0000000000000000000000000000000000000000;;			addNodes(manager.nodeStore, 0, 4, nil)
0000000000000000000000000000000000000000;;			addNodes(manager.nodeStore, 4, 3, simpleNodeLabel)
0000000000000000000000000000000000000000;;			ds := newDaemonSet("foo")
0000000000000000000000000000000000000000;;			ds.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			ds.Spec.Template.Spec.NodeSelector = simpleNodeLabel2
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds)
0000000000000000000000000000000000000000;;			syncAndValidateDaemonSets(t, manager, ds, podControl, 0, 0, 0)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// DaemonSet with node name should launch pod on node with corresponding name.
0000000000000000000000000000000000000000;;	func TestNameDaemonSetLaunchesPods(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			ds := newDaemonSet("foo")
0000000000000000000000000000000000000000;;			ds.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			ds.Spec.Template.Spec.NodeName = "node-0"
0000000000000000000000000000000000000000;;			manager, podControl, _ := newTestController(ds)
0000000000000000000000000000000000000000;;			addNodes(manager.nodeStore, 0, 5, nil)
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds)
0000000000000000000000000000000000000000;;			syncAndValidateDaemonSets(t, manager, ds, podControl, 1, 0, 0)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// DaemonSet with node name that does not exist should not launch pods.
0000000000000000000000000000000000000000;;	func TestBadNameDaemonSetDoesNothing(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			ds := newDaemonSet("foo")
0000000000000000000000000000000000000000;;			ds.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			ds.Spec.Template.Spec.NodeName = "node-10"
0000000000000000000000000000000000000000;;			manager, podControl, _ := newTestController(ds)
0000000000000000000000000000000000000000;;			addNodes(manager.nodeStore, 0, 5, nil)
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds)
0000000000000000000000000000000000000000;;			syncAndValidateDaemonSets(t, manager, ds, podControl, 0, 0, 0)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// DaemonSet with node selector, and node name, matching a node, should launch a pod on the node.
0000000000000000000000000000000000000000;;	func TestNameAndSelectorDaemonSetLaunchesPods(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			ds := newDaemonSet("foo")
0000000000000000000000000000000000000000;;			ds.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			ds.Spec.Template.Spec.NodeSelector = simpleNodeLabel
0000000000000000000000000000000000000000;;			ds.Spec.Template.Spec.NodeName = "node-6"
0000000000000000000000000000000000000000;;			manager, podControl, _ := newTestController(ds)
0000000000000000000000000000000000000000;;			addNodes(manager.nodeStore, 0, 4, nil)
0000000000000000000000000000000000000000;;			addNodes(manager.nodeStore, 4, 3, simpleNodeLabel)
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds)
0000000000000000000000000000000000000000;;			syncAndValidateDaemonSets(t, manager, ds, podControl, 1, 0, 0)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// DaemonSet with node selector that matches some nodes, and node name that matches a different node, should do nothing.
0000000000000000000000000000000000000000;;	func TestInconsistentNameSelectorDaemonSetDoesNothing(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			ds := newDaemonSet("foo")
0000000000000000000000000000000000000000;;			ds.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			ds.Spec.Template.Spec.NodeSelector = simpleNodeLabel
0000000000000000000000000000000000000000;;			ds.Spec.Template.Spec.NodeName = "node-0"
0000000000000000000000000000000000000000;;			manager, podControl, _ := newTestController(ds)
0000000000000000000000000000000000000000;;			addNodes(manager.nodeStore, 0, 4, nil)
0000000000000000000000000000000000000000;;			addNodes(manager.nodeStore, 4, 3, simpleNodeLabel)
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds)
0000000000000000000000000000000000000000;;			syncAndValidateDaemonSets(t, manager, ds, podControl, 0, 0, 0)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// DaemonSet with node selector, matching some nodes, should launch pods on all the nodes.
0000000000000000000000000000000000000000;;	func TestSelectorDaemonSetLaunchesPods(t *testing.T) {
0000000000000000000000000000000000000000;;		ds := newDaemonSet("foo")
0000000000000000000000000000000000000000;;		ds.Spec.Template.Spec.NodeSelector = simpleNodeLabel
0000000000000000000000000000000000000000;;		manager, podControl, _ := newTestController(ds)
0000000000000000000000000000000000000000;;		addNodes(manager.nodeStore, 0, 4, nil)
0000000000000000000000000000000000000000;;		addNodes(manager.nodeStore, 4, 3, simpleNodeLabel)
0000000000000000000000000000000000000000;;		manager.dsStore.Add(ds)
0000000000000000000000000000000000000000;;		syncAndValidateDaemonSets(t, manager, ds, podControl, 3, 0, 0)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Daemon with node affinity should launch pods on nodes matching affinity.
0000000000000000000000000000000000000000;;	func TestNodeAffinityDaemonLaunchesPods(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			daemon := newDaemonSet("foo")
0000000000000000000000000000000000000000;;			daemon.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			daemon.Spec.Template.Spec.Affinity = &v1.Affinity{
0000000000000000000000000000000000000000;;				NodeAffinity: &v1.NodeAffinity{
0000000000000000000000000000000000000000;;					RequiredDuringSchedulingIgnoredDuringExecution: &v1.NodeSelector{
0000000000000000000000000000000000000000;;						NodeSelectorTerms: []v1.NodeSelectorTerm{
0000000000000000000000000000000000000000;;							{
0000000000000000000000000000000000000000;;								MatchExpressions: []v1.NodeSelectorRequirement{
0000000000000000000000000000000000000000;;									{
0000000000000000000000000000000000000000;;										Key:      "color",
0000000000000000000000000000000000000000;;										Operator: v1.NodeSelectorOpIn,
0000000000000000000000000000000000000000;;										Values:   []string{simpleNodeLabel["color"]},
0000000000000000000000000000000000000000;;									},
0000000000000000000000000000000000000000;;								},
0000000000000000000000000000000000000000;;							},
0000000000000000000000000000000000000000;;						},
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			manager, podControl, _ := newTestController(daemon)
0000000000000000000000000000000000000000;;			addNodes(manager.nodeStore, 0, 4, nil)
0000000000000000000000000000000000000000;;			addNodes(manager.nodeStore, 4, 3, simpleNodeLabel)
0000000000000000000000000000000000000000;;			manager.dsStore.Add(daemon)
0000000000000000000000000000000000000000;;			syncAndValidateDaemonSets(t, manager, daemon, podControl, 3, 0, 0)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestNumberReadyStatus(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			ds := newDaemonSet("foo")
0000000000000000000000000000000000000000;;			ds.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			manager, podControl, clientset := newTestController(ds)
0000000000000000000000000000000000000000;;			var updated *extensions.DaemonSet
0000000000000000000000000000000000000000;;			clientset.PrependReactor("update", "daemonsets", func(action core.Action) (handled bool, ret runtime.Object, err error) {
0000000000000000000000000000000000000000;;				if action.GetSubresource() != "status" {
0000000000000000000000000000000000000000;;					return false, nil, nil
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				if u, ok := action.(core.UpdateAction); ok {
0000000000000000000000000000000000000000;;					updated = u.GetObject().(*extensions.DaemonSet)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				return false, nil, nil
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;			addNodes(manager.nodeStore, 0, 2, simpleNodeLabel)
0000000000000000000000000000000000000000;;			addPods(manager.podStore, "node-0", simpleDaemonSetLabel, ds, 1)
0000000000000000000000000000000000000000;;			addPods(manager.podStore, "node-1", simpleDaemonSetLabel, ds, 1)
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			syncAndValidateDaemonSets(t, manager, ds, podControl, 0, 0, 0)
0000000000000000000000000000000000000000;;			if updated.Status.NumberReady != 0 {
0000000000000000000000000000000000000000;;				t.Errorf("Wrong daemon %s status: %v", updated.Name, updated.Status)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			selector, _ := metav1.LabelSelectorAsSelector(ds.Spec.Selector)
0000000000000000000000000000000000000000;;			daemonPods, _ := manager.podLister.Pods(ds.Namespace).List(selector)
0000000000000000000000000000000000000000;;			for _, pod := range daemonPods {
0000000000000000000000000000000000000000;;				condition := v1.PodCondition{Type: v1.PodReady, Status: v1.ConditionTrue}
0000000000000000000000000000000000000000;;				pod.Status.Conditions = append(pod.Status.Conditions, condition)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			syncAndValidateDaemonSets(t, manager, ds, podControl, 0, 0, 0)
0000000000000000000000000000000000000000;;			if updated.Status.NumberReady != 2 {
0000000000000000000000000000000000000000;;				t.Errorf("Wrong daemon %s status: %v", updated.Name, updated.Status)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestObservedGeneration(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			ds := newDaemonSet("foo")
0000000000000000000000000000000000000000;;			ds.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			ds.Generation = 1
0000000000000000000000000000000000000000;;			manager, podControl, clientset := newTestController(ds)
0000000000000000000000000000000000000000;;			var updated *extensions.DaemonSet
0000000000000000000000000000000000000000;;			clientset.PrependReactor("update", "daemonsets", func(action core.Action) (handled bool, ret runtime.Object, err error) {
0000000000000000000000000000000000000000;;				if action.GetSubresource() != "status" {
0000000000000000000000000000000000000000;;					return false, nil, nil
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				if u, ok := action.(core.UpdateAction); ok {
0000000000000000000000000000000000000000;;					updated = u.GetObject().(*extensions.DaemonSet)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				return false, nil, nil
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			addNodes(manager.nodeStore, 0, 1, simpleNodeLabel)
0000000000000000000000000000000000000000;;			addPods(manager.podStore, "node-0", simpleDaemonSetLabel, ds, 1)
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			syncAndValidateDaemonSets(t, manager, ds, podControl, 0, 0, 0)
0000000000000000000000000000000000000000;;			if updated.Status.ObservedGeneration != ds.Generation {
0000000000000000000000000000000000000000;;				t.Errorf("Wrong ObservedGeneration for daemon %s in status. Expected %d, got %d", updated.Name, ds.Generation, updated.Status.ObservedGeneration)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// DaemonSet controller should kill all failed pods and create at most 1 pod on every node.
0000000000000000000000000000000000000000;;	func TestDaemonKillFailedPods(t *testing.T) {
0000000000000000000000000000000000000000;;		tests := []struct {
0000000000000000000000000000000000000000;;			numFailedPods, numNormalPods, expectedCreates, expectedDeletes, expectedEvents int
0000000000000000000000000000000000000000;;			test                                                                           string
0000000000000000000000000000000000000000;;		}{
0000000000000000000000000000000000000000;;			{numFailedPods: 0, numNormalPods: 1, expectedCreates: 0, expectedDeletes: 0, expectedEvents: 0, test: "normal (do nothing)"},
0000000000000000000000000000000000000000;;			{numFailedPods: 0, numNormalPods: 0, expectedCreates: 1, expectedDeletes: 0, expectedEvents: 0, test: "no pods (create 1)"},
0000000000000000000000000000000000000000;;			{numFailedPods: 1, numNormalPods: 0, expectedCreates: 0, expectedDeletes: 1, expectedEvents: 1, test: "1 failed pod (kill 1), 0 normal pod (create 0; will create in the next sync)"},
0000000000000000000000000000000000000000;;			{numFailedPods: 1, numNormalPods: 3, expectedCreates: 0, expectedDeletes: 3, expectedEvents: 1, test: "1 failed pod (kill 1), 3 normal pods (kill 2)"},
0000000000000000000000000000000000000000;;			{numFailedPods: 2, numNormalPods: 1, expectedCreates: 0, expectedDeletes: 2, expectedEvents: 2, test: "2 failed pods (kill 2), 1 normal pod"},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		for _, test := range tests {
0000000000000000000000000000000000000000;;			t.Logf("test case: %s\n", test.test)
0000000000000000000000000000000000000000;;			for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;				ds := newDaemonSet("foo")
0000000000000000000000000000000000000000;;				ds.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;				manager, podControl, _ := newTestController(ds)
0000000000000000000000000000000000000000;;				manager.dsStore.Add(ds)
0000000000000000000000000000000000000000;;				addNodes(manager.nodeStore, 0, 1, nil)
0000000000000000000000000000000000000000;;				addFailedPods(manager.podStore, "node-0", simpleDaemonSetLabel, ds, test.numFailedPods)
0000000000000000000000000000000000000000;;				addPods(manager.podStore, "node-0", simpleDaemonSetLabel, ds, test.numNormalPods)
0000000000000000000000000000000000000000;;				syncAndValidateDaemonSets(t, manager, ds, podControl, test.expectedCreates, test.expectedDeletes, test.expectedEvents)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Daemonset should not remove a running pod from a node if the pod doesn't
0000000000000000000000000000000000000000;;	// tolerate the nodes NoSchedule taint
0000000000000000000000000000000000000000;;	func TestNoScheduleTaintedDoesntEvicitRunningIntolerantPod(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			ds := newDaemonSet("intolerant")
0000000000000000000000000000000000000000;;			ds.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			manager, podControl, _ := newTestController(ds)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			node := newNode("tainted", nil)
0000000000000000000000000000000000000000;;			manager.nodeStore.Add(node)
0000000000000000000000000000000000000000;;			setNodeTaint(node, noScheduleTaints)
0000000000000000000000000000000000000000;;			manager.podStore.Add(newPod("keep-running-me", "tainted", simpleDaemonSetLabel, ds))
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			syncAndValidateDaemonSets(t, manager, ds, podControl, 0, 0, 0)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Daemonset should remove a running pod from a node if the pod doesn't
0000000000000000000000000000000000000000;;	// tolerate the nodes NoExecute taint
0000000000000000000000000000000000000000;;	func TestNoExecuteTaintedDoesEvicitRunningIntolerantPod(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			ds := newDaemonSet("intolerant")
0000000000000000000000000000000000000000;;			ds.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			manager, podControl, _ := newTestController(ds)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			node := newNode("tainted", nil)
0000000000000000000000000000000000000000;;			manager.nodeStore.Add(node)
0000000000000000000000000000000000000000;;			setNodeTaint(node, noExecuteTaints)
0000000000000000000000000000000000000000;;			manager.podStore.Add(newPod("stop-running-me", "tainted", simpleDaemonSetLabel, ds))
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			syncAndValidateDaemonSets(t, manager, ds, podControl, 0, 1, 0)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// DaemonSet should not launch a pod on a tainted node when the pod doesn't tolerate that taint.
0000000000000000000000000000000000000000;;	func TestTaintedNodeDaemonDoesNotLaunchIntolerantPod(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			ds := newDaemonSet("intolerant")
0000000000000000000000000000000000000000;;			ds.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			manager, podControl, _ := newTestController(ds)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			node := newNode("tainted", nil)
0000000000000000000000000000000000000000;;			setNodeTaint(node, noScheduleTaints)
0000000000000000000000000000000000000000;;			manager.nodeStore.Add(node)
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			syncAndValidateDaemonSets(t, manager, ds, podControl, 0, 0, 0)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// DaemonSet should launch a pod on a tainted node when the pod can tolerate that taint.
0000000000000000000000000000000000000000;;	func TestTaintedNodeDaemonLaunchesToleratePod(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			ds := newDaemonSet("tolerate")
0000000000000000000000000000000000000000;;			ds.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			setDaemonSetToleration(ds, noScheduleTolerations)
0000000000000000000000000000000000000000;;			manager, podControl, _ := newTestController(ds)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			node := newNode("tainted", nil)
0000000000000000000000000000000000000000;;			setNodeTaint(node, noScheduleTaints)
0000000000000000000000000000000000000000;;			manager.nodeStore.Add(node)
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			syncAndValidateDaemonSets(t, manager, ds, podControl, 1, 0, 0)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// DaemonSet should launch a pod on a not ready node with taint notReady:NoExecute.
0000000000000000000000000000000000000000;;	func TestNotReadyNodeDaemonLaunchesPod(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			ds := newDaemonSet("simple")
0000000000000000000000000000000000000000;;			ds.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			manager, podControl, _ := newTestController(ds)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			node := newNode("tainted", nil)
0000000000000000000000000000000000000000;;			setNodeTaint(node, nodeNotReady)
0000000000000000000000000000000000000000;;			node.Status.Conditions = []v1.NodeCondition{
0000000000000000000000000000000000000000;;				{Type: v1.NodeReady, Status: v1.ConditionFalse},
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			manager.nodeStore.Add(node)
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			syncAndValidateDaemonSets(t, manager, ds, podControl, 1, 0, 0)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// DaemonSet should launch a pod on an unreachable node with taint unreachable:NoExecute.
0000000000000000000000000000000000000000;;	func TestUnreachableNodeDaemonLaunchesPod(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			ds := newDaemonSet("simple")
0000000000000000000000000000000000000000;;			ds.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			manager, podControl, _ := newTestController(ds)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			node := newNode("tainted", nil)
0000000000000000000000000000000000000000;;			setNodeTaint(node, nodeUnreachable)
0000000000000000000000000000000000000000;;			node.Status.Conditions = []v1.NodeCondition{
0000000000000000000000000000000000000000;;				{Type: v1.NodeReady, Status: v1.ConditionUnknown},
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			manager.nodeStore.Add(node)
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			syncAndValidateDaemonSets(t, manager, ds, podControl, 1, 0, 0)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// DaemonSet should launch a pod on an untainted node when the pod has tolerations.
0000000000000000000000000000000000000000;;	func TestNodeDaemonLaunchesToleratePod(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			ds := newDaemonSet("tolerate")
0000000000000000000000000000000000000000;;			ds.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			setDaemonSetToleration(ds, noScheduleTolerations)
0000000000000000000000000000000000000000;;			manager, podControl, _ := newTestController(ds)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			node := newNode("untainted", nil)
0000000000000000000000000000000000000000;;			manager.nodeStore.Add(node)
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			syncAndValidateDaemonSets(t, manager, ds, podControl, 1, 0, 0)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func setNodeTaint(node *v1.Node, taints []v1.Taint) {
0000000000000000000000000000000000000000;;		node.Spec.Taints = taints
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func setDaemonSetToleration(ds *extensions.DaemonSet, tolerations []v1.Toleration) {
0000000000000000000000000000000000000000;;		ds.Spec.Template.Spec.Tolerations = tolerations
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// DaemonSet should launch a critical pod even when the node is OutOfDisk.
0000000000000000000000000000000000000000;;	func TestOutOfDiskNodeDaemonLaunchesCriticalPod(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			ds := newDaemonSet("critical")
0000000000000000000000000000000000000000;;			ds.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			setDaemonSetCritical(ds)
0000000000000000000000000000000000000000;;			manager, podControl, _ := newTestController(ds)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			node := newNode("not-enough-disk", nil)
0000000000000000000000000000000000000000;;			node.Status.Conditions = []v1.NodeCondition{{Type: v1.NodeOutOfDisk, Status: v1.ConditionTrue}}
0000000000000000000000000000000000000000;;			manager.nodeStore.Add(node)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Without enabling critical pod annotation feature gate, we shouldn't create critical pod
0000000000000000000000000000000000000000;;			utilfeature.DefaultFeatureGate.Set("ExperimentalCriticalPodAnnotation=False")
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds)
0000000000000000000000000000000000000000;;			syncAndValidateDaemonSets(t, manager, ds, podControl, 0, 0, 0)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Enabling critical pod annotation feature gate should create critical pod
0000000000000000000000000000000000000000;;			utilfeature.DefaultFeatureGate.Set("ExperimentalCriticalPodAnnotation=True")
0000000000000000000000000000000000000000;;			syncAndValidateDaemonSets(t, manager, ds, podControl, 1, 0, 0)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// DaemonSet should launch a critical pod even when the node has insufficient free resource.
0000000000000000000000000000000000000000;;	func TestInsufficientCapacityNodeDaemonLaunchesCriticalPod(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			podSpec := resourcePodSpec("too-much-mem", "75M", "75m")
0000000000000000000000000000000000000000;;			ds := newDaemonSet("critical")
0000000000000000000000000000000000000000;;			ds.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			ds.Spec.Template.Spec = podSpec
0000000000000000000000000000000000000000;;			setDaemonSetCritical(ds)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			manager, podControl, _ := newTestController(ds)
0000000000000000000000000000000000000000;;			node := newNode("too-much-mem", nil)
0000000000000000000000000000000000000000;;			node.Status.Allocatable = allocatableResources("100M", "200m")
0000000000000000000000000000000000000000;;			manager.nodeStore.Add(node)
0000000000000000000000000000000000000000;;			manager.podStore.Add(&v1.Pod{
0000000000000000000000000000000000000000;;				Spec: podSpec,
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Without enabling critical pod annotation feature gate, we shouldn't create critical pod
0000000000000000000000000000000000000000;;			utilfeature.DefaultFeatureGate.Set("ExperimentalCriticalPodAnnotation=False")
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds)
0000000000000000000000000000000000000000;;			switch strategy.Type {
0000000000000000000000000000000000000000;;			case extensions.OnDeleteDaemonSetStrategyType:
0000000000000000000000000000000000000000;;				syncAndValidateDaemonSets(t, manager, ds, podControl, 0, 0, 2)
0000000000000000000000000000000000000000;;			case extensions.RollingUpdateDaemonSetStrategyType:
0000000000000000000000000000000000000000;;				syncAndValidateDaemonSets(t, manager, ds, podControl, 0, 0, 3)
0000000000000000000000000000000000000000;;			default:
0000000000000000000000000000000000000000;;				t.Fatalf("unexpected UpdateStrategy %+v", strategy)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Enabling critical pod annotation feature gate should create critical pod
0000000000000000000000000000000000000000;;			utilfeature.DefaultFeatureGate.Set("ExperimentalCriticalPodAnnotation=True")
0000000000000000000000000000000000000000;;			switch strategy.Type {
0000000000000000000000000000000000000000;;			case extensions.OnDeleteDaemonSetStrategyType:
0000000000000000000000000000000000000000;;				syncAndValidateDaemonSets(t, manager, ds, podControl, 1, 0, 2)
0000000000000000000000000000000000000000;;			case extensions.RollingUpdateDaemonSetStrategyType:
0000000000000000000000000000000000000000;;				syncAndValidateDaemonSets(t, manager, ds, podControl, 1, 0, 3)
0000000000000000000000000000000000000000;;			default:
0000000000000000000000000000000000000000;;				t.Fatalf("unexpected UpdateStrategy %+v", strategy)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// DaemonSets should NOT launch a critical pod when there are port conflicts.
0000000000000000000000000000000000000000;;	func TestPortConflictNodeDaemonDoesNotLaunchCriticalPod(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			podSpec := v1.PodSpec{
0000000000000000000000000000000000000000;;				NodeName: "port-conflict",
0000000000000000000000000000000000000000;;				Containers: []v1.Container{{
0000000000000000000000000000000000000000;;					Ports: []v1.ContainerPort{{
0000000000000000000000000000000000000000;;						HostPort: 666,
0000000000000000000000000000000000000000;;					}},
0000000000000000000000000000000000000000;;				}},
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			manager, podControl, _ := newTestController()
0000000000000000000000000000000000000000;;			node := newNode("port-conflict", nil)
0000000000000000000000000000000000000000;;			manager.nodeStore.Add(node)
0000000000000000000000000000000000000000;;			manager.podStore.Add(&v1.Pod{
0000000000000000000000000000000000000000;;				Spec: podSpec,
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			utilfeature.DefaultFeatureGate.Set("ExperimentalCriticalPodAnnotation=True")
0000000000000000000000000000000000000000;;			ds := newDaemonSet("critical")
0000000000000000000000000000000000000000;;			ds.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			ds.Spec.Template.Spec = podSpec
0000000000000000000000000000000000000000;;			setDaemonSetCritical(ds)
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds)
0000000000000000000000000000000000000000;;			syncAndValidateDaemonSets(t, manager, ds, podControl, 0, 0, 0)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func setDaemonSetCritical(ds *extensions.DaemonSet) {
0000000000000000000000000000000000000000;;		ds.Namespace = api.NamespaceSystem
0000000000000000000000000000000000000000;;		if ds.Spec.Template.ObjectMeta.Annotations == nil {
0000000000000000000000000000000000000000;;			ds.Spec.Template.ObjectMeta.Annotations = make(map[string]string)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		ds.Spec.Template.ObjectMeta.Annotations[kubelettypes.CriticalPodAnnotationKey] = ""
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestNodeShouldRunDaemonPod(t *testing.T) {
0000000000000000000000000000000000000000;;		cases := []struct {
0000000000000000000000000000000000000000;;			podsOnNode                                       []*v1.Pod
0000000000000000000000000000000000000000;;			ds                                               *extensions.DaemonSet
0000000000000000000000000000000000000000;;			wantToRun, shouldSchedule, shouldContinueRunning bool
0000000000000000000000000000000000000000;;			err                                              error
0000000000000000000000000000000000000000;;		}{
0000000000000000000000000000000000000000;;			{
0000000000000000000000000000000000000000;;				ds: &extensions.DaemonSet{
0000000000000000000000000000000000000000;;					Spec: extensions.DaemonSetSpec{
0000000000000000000000000000000000000000;;						Selector: &metav1.LabelSelector{MatchLabels: simpleDaemonSetLabel},
0000000000000000000000000000000000000000;;						Template: v1.PodTemplateSpec{
0000000000000000000000000000000000000000;;							ObjectMeta: metav1.ObjectMeta{
0000000000000000000000000000000000000000;;								Labels: simpleDaemonSetLabel,
0000000000000000000000000000000000000000;;							},
0000000000000000000000000000000000000000;;							Spec: resourcePodSpec("", "50M", "0.5"),
0000000000000000000000000000000000000000;;						},
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;				wantToRun:             true,
0000000000000000000000000000000000000000;;				shouldSchedule:        true,
0000000000000000000000000000000000000000;;				shouldContinueRunning: true,
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			{
0000000000000000000000000000000000000000;;				ds: &extensions.DaemonSet{
0000000000000000000000000000000000000000;;					Spec: extensions.DaemonSetSpec{
0000000000000000000000000000000000000000;;						Selector: &metav1.LabelSelector{MatchLabels: simpleDaemonSetLabel},
0000000000000000000000000000000000000000;;						Template: v1.PodTemplateSpec{
0000000000000000000000000000000000000000;;							ObjectMeta: metav1.ObjectMeta{
0000000000000000000000000000000000000000;;								Labels: simpleDaemonSetLabel,
0000000000000000000000000000000000000000;;							},
0000000000000000000000000000000000000000;;							Spec: resourcePodSpec("", "200M", "0.5"),
0000000000000000000000000000000000000000;;						},
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;				wantToRun:             true,
0000000000000000000000000000000000000000;;				shouldSchedule:        false,
0000000000000000000000000000000000000000;;				shouldContinueRunning: true,
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			{
0000000000000000000000000000000000000000;;				ds: &extensions.DaemonSet{
0000000000000000000000000000000000000000;;					Spec: extensions.DaemonSetSpec{
0000000000000000000000000000000000000000;;						Selector: &metav1.LabelSelector{MatchLabels: simpleDaemonSetLabel},
0000000000000000000000000000000000000000;;						Template: v1.PodTemplateSpec{
0000000000000000000000000000000000000000;;							ObjectMeta: metav1.ObjectMeta{
0000000000000000000000000000000000000000;;								Labels: simpleDaemonSetLabel,
0000000000000000000000000000000000000000;;							},
0000000000000000000000000000000000000000;;							Spec: resourcePodSpec("other-node", "50M", "0.5"),
0000000000000000000000000000000000000000;;						},
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;				wantToRun:             false,
0000000000000000000000000000000000000000;;				shouldSchedule:        false,
0000000000000000000000000000000000000000;;				shouldContinueRunning: false,
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			{
0000000000000000000000000000000000000000;;				podsOnNode: []*v1.Pod{
0000000000000000000000000000000000000000;;					{
0000000000000000000000000000000000000000;;						Spec: v1.PodSpec{
0000000000000000000000000000000000000000;;							Containers: []v1.Container{{
0000000000000000000000000000000000000000;;								Ports: []v1.ContainerPort{{
0000000000000000000000000000000000000000;;									HostPort: 666,
0000000000000000000000000000000000000000;;								}},
0000000000000000000000000000000000000000;;							}},
0000000000000000000000000000000000000000;;						},
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;				ds: &extensions.DaemonSet{
0000000000000000000000000000000000000000;;					Spec: extensions.DaemonSetSpec{
0000000000000000000000000000000000000000;;						Selector: &metav1.LabelSelector{MatchLabels: simpleDaemonSetLabel},
0000000000000000000000000000000000000000;;						Template: v1.PodTemplateSpec{
0000000000000000000000000000000000000000;;							ObjectMeta: metav1.ObjectMeta{
0000000000000000000000000000000000000000;;								Labels: simpleDaemonSetLabel,
0000000000000000000000000000000000000000;;							},
0000000000000000000000000000000000000000;;							Spec: v1.PodSpec{
0000000000000000000000000000000000000000;;								Containers: []v1.Container{{
0000000000000000000000000000000000000000;;									Ports: []v1.ContainerPort{{
0000000000000000000000000000000000000000;;										HostPort: 666,
0000000000000000000000000000000000000000;;									}},
0000000000000000000000000000000000000000;;								}},
0000000000000000000000000000000000000000;;							},
0000000000000000000000000000000000000000;;						},
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;				wantToRun:             false,
0000000000000000000000000000000000000000;;				shouldSchedule:        false,
0000000000000000000000000000000000000000;;				shouldContinueRunning: false,
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		for i, c := range cases {
0000000000000000000000000000000000000000;;			for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;				node := newNode("test-node", nil)
0000000000000000000000000000000000000000;;				node.Status.Allocatable = allocatableResources("100M", "1")
0000000000000000000000000000000000000000;;				manager, _, _ := newTestController()
0000000000000000000000000000000000000000;;				manager.nodeStore.Add(node)
0000000000000000000000000000000000000000;;				for _, p := range c.podsOnNode {
0000000000000000000000000000000000000000;;					manager.podStore.Add(p)
0000000000000000000000000000000000000000;;					p.Spec.NodeName = "test-node"
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				c.ds.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;				wantToRun, shouldSchedule, shouldContinueRunning, err := manager.nodeShouldRunDaemonPod(node, c.ds)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				if wantToRun != c.wantToRun {
0000000000000000000000000000000000000000;;					t.Errorf("[%v] expected wantToRun: %v, got: %v", i, c.wantToRun, wantToRun)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				if shouldSchedule != c.shouldSchedule {
0000000000000000000000000000000000000000;;					t.Errorf("[%v] expected shouldSchedule: %v, got: %v", i, c.shouldSchedule, shouldSchedule)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				if shouldContinueRunning != c.shouldContinueRunning {
0000000000000000000000000000000000000000;;					t.Errorf("[%v] expected shouldContinueRunning: %v, got: %v", i, c.shouldContinueRunning, shouldContinueRunning)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				if err != c.err {
0000000000000000000000000000000000000000;;					t.Errorf("[%v] expected err: %v, got: %v", i, c.err, err)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// DaemonSets should be resynced when node labels or taints changed
0000000000000000000000000000000000000000;;	func TestUpdateNode(t *testing.T) {
0000000000000000000000000000000000000000;;		var enqueued bool
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		cases := []struct {
0000000000000000000000000000000000000000;;			test          string
0000000000000000000000000000000000000000;;			newNode       *v1.Node
0000000000000000000000000000000000000000;;			oldNode       *v1.Node
0000000000000000000000000000000000000000;;			ds            *extensions.DaemonSet
0000000000000000000000000000000000000000;;			shouldEnqueue bool
0000000000000000000000000000000000000000;;		}{
0000000000000000000000000000000000000000;;			{
0000000000000000000000000000000000000000;;				test:    "Nothing changed, should not enqueue",
0000000000000000000000000000000000000000;;				oldNode: newNode("node1", nil),
0000000000000000000000000000000000000000;;				newNode: newNode("node1", nil),
0000000000000000000000000000000000000000;;				ds: func() *extensions.DaemonSet {
0000000000000000000000000000000000000000;;					ds := newDaemonSet("ds")
0000000000000000000000000000000000000000;;					ds.Spec.Template.Spec.NodeSelector = simpleNodeLabel
0000000000000000000000000000000000000000;;					return ds
0000000000000000000000000000000000000000;;				}(),
0000000000000000000000000000000000000000;;				shouldEnqueue: false,
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			{
0000000000000000000000000000000000000000;;				test:    "Node labels changed",
0000000000000000000000000000000000000000;;				oldNode: newNode("node1", nil),
0000000000000000000000000000000000000000;;				newNode: newNode("node1", simpleNodeLabel),
0000000000000000000000000000000000000000;;				ds: func() *extensions.DaemonSet {
0000000000000000000000000000000000000000;;					ds := newDaemonSet("ds")
0000000000000000000000000000000000000000;;					ds.Spec.Template.Spec.NodeSelector = simpleNodeLabel
0000000000000000000000000000000000000000;;					return ds
0000000000000000000000000000000000000000;;				}(),
0000000000000000000000000000000000000000;;				shouldEnqueue: true,
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			{
0000000000000000000000000000000000000000;;				test: "Node taints changed",
0000000000000000000000000000000000000000;;				oldNode: func() *v1.Node {
0000000000000000000000000000000000000000;;					node := newNode("node1", nil)
0000000000000000000000000000000000000000;;					setNodeTaint(node, noScheduleTaints)
0000000000000000000000000000000000000000;;					return node
0000000000000000000000000000000000000000;;				}(),
0000000000000000000000000000000000000000;;				newNode:       newNode("node1", nil),
0000000000000000000000000000000000000000;;				ds:            newDaemonSet("ds"),
0000000000000000000000000000000000000000;;				shouldEnqueue: true,
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			{
0000000000000000000000000000000000000000;;				test: "Node conditions changed",
0000000000000000000000000000000000000000;;				oldNode: func() *v1.Node {
0000000000000000000000000000000000000000;;					node := newNode("node1", nil)
0000000000000000000000000000000000000000;;					node.Status.Conditions = []v1.NodeCondition{
0000000000000000000000000000000000000000;;						{Type: v1.NodeOutOfDisk, Status: v1.ConditionTrue},
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					return node
0000000000000000000000000000000000000000;;				}(),
0000000000000000000000000000000000000000;;				newNode:       newNode("node1", nil),
0000000000000000000000000000000000000000;;				ds:            newDaemonSet("ds"),
0000000000000000000000000000000000000000;;				shouldEnqueue: true,
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			{
0000000000000000000000000000000000000000;;				test: "Node conditions not changed",
0000000000000000000000000000000000000000;;				oldNode: func() *v1.Node {
0000000000000000000000000000000000000000;;					node := newNode("node1", nil)
0000000000000000000000000000000000000000;;					node.Status.Conditions = []v1.NodeCondition{
0000000000000000000000000000000000000000;;						{Type: v1.NodeOutOfDisk, Status: v1.ConditionTrue},
0000000000000000000000000000000000000000;;						{Type: v1.NodeMemoryPressure, Status: v1.ConditionFalse},
0000000000000000000000000000000000000000;;						{Type: v1.NodeDiskPressure, Status: v1.ConditionFalse},
0000000000000000000000000000000000000000;;						{Type: v1.NodeNetworkUnavailable, Status: v1.ConditionFalse},
0000000000000000000000000000000000000000;;						{Type: v1.NodeInodePressure, Status: v1.ConditionFalse},
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					return node
0000000000000000000000000000000000000000;;				}(),
0000000000000000000000000000000000000000;;				newNode: func() *v1.Node {
0000000000000000000000000000000000000000;;					node := newNode("node1", nil)
0000000000000000000000000000000000000000;;					node.Status.Conditions = []v1.NodeCondition{
0000000000000000000000000000000000000000;;						{Type: v1.NodeOutOfDisk, Status: v1.ConditionTrue},
0000000000000000000000000000000000000000;;						{Type: v1.NodeInodePressure, Status: v1.ConditionFalse},
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					return node
0000000000000000000000000000000000000000;;				}(),
0000000000000000000000000000000000000000;;				ds:            newDaemonSet("ds"),
0000000000000000000000000000000000000000;;				shouldEnqueue: false,
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		for _, c := range cases {
0000000000000000000000000000000000000000;;			for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;				manager, podControl, _ := newTestController()
0000000000000000000000000000000000000000;;				manager.nodeStore.Add(c.oldNode)
0000000000000000000000000000000000000000;;				c.ds.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;				manager.dsStore.Add(c.ds)
0000000000000000000000000000000000000000;;				syncAndValidateDaemonSets(t, manager, c.ds, podControl, 0, 0, 0)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				manager.enqueueDaemonSet = func(ds *extensions.DaemonSet) {
0000000000000000000000000000000000000000;;					if ds.Name == "ds" {
0000000000000000000000000000000000000000;;						enqueued = true
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				enqueued = false
0000000000000000000000000000000000000000;;				manager.updateNode(c.oldNode, c.newNode)
0000000000000000000000000000000000000000;;				if enqueued != c.shouldEnqueue {
0000000000000000000000000000000000000000;;					t.Errorf("Test case: '%s', expected: %t, got: %t", c.test, c.shouldEnqueue, enqueued)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestGetNodesToDaemonPods(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			ds := newDaemonSet("foo")
0000000000000000000000000000000000000000;;			ds.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			ds2 := newDaemonSet("foo2")
0000000000000000000000000000000000000000;;			ds2.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			manager, _, _ := newTestController(ds, ds2)
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds)
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds2)
0000000000000000000000000000000000000000;;			addNodes(manager.nodeStore, 0, 2, nil)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// These pods should be returned.
0000000000000000000000000000000000000000;;			wantedPods := []*v1.Pod{
0000000000000000000000000000000000000000;;				newPod("matching-owned-0-", "node-0", simpleDaemonSetLabel, ds),
0000000000000000000000000000000000000000;;				newPod("matching-orphan-0-", "node-0", simpleDaemonSetLabel, nil),
0000000000000000000000000000000000000000;;				newPod("matching-owned-1-", "node-1", simpleDaemonSetLabel, ds),
0000000000000000000000000000000000000000;;				newPod("matching-orphan-1-", "node-1", simpleDaemonSetLabel, nil),
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			failedPod := newPod("matching-owned-failed-pod-1-", "node-1", simpleDaemonSetLabel, ds)
0000000000000000000000000000000000000000;;			failedPod.Status = v1.PodStatus{Phase: v1.PodFailed}
0000000000000000000000000000000000000000;;			wantedPods = append(wantedPods, failedPod)
0000000000000000000000000000000000000000;;			for _, pod := range wantedPods {
0000000000000000000000000000000000000000;;				manager.podStore.Add(pod)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// These pods should be ignored.
0000000000000000000000000000000000000000;;			ignoredPods := []*v1.Pod{
0000000000000000000000000000000000000000;;				newPod("non-matching-owned-0-", "node-0", simpleDaemonSetLabel2, ds),
0000000000000000000000000000000000000000;;				newPod("non-matching-orphan-1-", "node-1", simpleDaemonSetLabel2, nil),
0000000000000000000000000000000000000000;;				newPod("matching-owned-by-other-0-", "node-0", simpleDaemonSetLabel, ds2),
0000000000000000000000000000000000000000;;				func() *v1.Pod {
0000000000000000000000000000000000000000;;					pod := newPod("matching-owned-2-but-set-for-deletion", "node-2", simpleDaemonSetLabel, ds)
0000000000000000000000000000000000000000;;					now := metav1.Now()
0000000000000000000000000000000000000000;;					pod.DeletionTimestamp = &now
0000000000000000000000000000000000000000;;					return pod
0000000000000000000000000000000000000000;;				}(),
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			for _, pod := range ignoredPods {
0000000000000000000000000000000000000000;;				manager.podStore.Add(pod)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			nodesToDaemonPods, err := manager.getNodesToDaemonPods(ds)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				t.Fatalf("getNodesToDaemonPods() error: %v", err)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			gotPods := map[string]bool{}
0000000000000000000000000000000000000000;;			for node, pods := range nodesToDaemonPods {
0000000000000000000000000000000000000000;;				for _, pod := range pods {
0000000000000000000000000000000000000000;;					if pod.Spec.NodeName != node {
0000000000000000000000000000000000000000;;						t.Errorf("pod %v grouped into %v but belongs in %v", pod.Name, node, pod.Spec.NodeName)
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					gotPods[pod.Name] = true
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			for _, pod := range wantedPods {
0000000000000000000000000000000000000000;;				if !gotPods[pod.Name] {
0000000000000000000000000000000000000000;;					t.Errorf("expected pod %v but didn't get it", pod.Name)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				delete(gotPods, pod.Name)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			for podName := range gotPods {
0000000000000000000000000000000000000000;;				t.Errorf("unexpected pod %v was returned", podName)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestAddNode(t *testing.T) {
0000000000000000000000000000000000000000;;		manager, _, _ := newTestController()
0000000000000000000000000000000000000000;;		node1 := newNode("node1", nil)
0000000000000000000000000000000000000000;;		ds := newDaemonSet("ds")
0000000000000000000000000000000000000000;;		ds.Spec.Template.Spec.NodeSelector = simpleNodeLabel
0000000000000000000000000000000000000000;;		manager.dsStore.Add(ds)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		manager.addNode(node1)
0000000000000000000000000000000000000000;;		if got, want := manager.queue.Len(), 0; got != want {
0000000000000000000000000000000000000000;;			t.Fatalf("queue.Len() = %v, want %v", got, want)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		node2 := newNode("node2", simpleNodeLabel)
0000000000000000000000000000000000000000;;		manager.addNode(node2)
0000000000000000000000000000000000000000;;		if got, want := manager.queue.Len(), 1; got != want {
0000000000000000000000000000000000000000;;			t.Fatalf("queue.Len() = %v, want %v", got, want)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		key, done := manager.queue.Get()
0000000000000000000000000000000000000000;;		if key == nil || done {
0000000000000000000000000000000000000000;;			t.Fatalf("failed to enqueue controller for node %v", node2.Name)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestAddPod(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			manager, _, _ := newTestController()
0000000000000000000000000000000000000000;;			ds1 := newDaemonSet("foo1")
0000000000000000000000000000000000000000;;			ds1.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			ds2 := newDaemonSet("foo2")
0000000000000000000000000000000000000000;;			ds2.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds1)
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds2)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			pod1 := newPod("pod1-", "node-0", simpleDaemonSetLabel, ds1)
0000000000000000000000000000000000000000;;			manager.addPod(pod1)
0000000000000000000000000000000000000000;;			if got, want := manager.queue.Len(), 1; got != want {
0000000000000000000000000000000000000000;;				t.Fatalf("queue.Len() = %v, want %v", got, want)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			key, done := manager.queue.Get()
0000000000000000000000000000000000000000;;			if key == nil || done {
0000000000000000000000000000000000000000;;				t.Fatalf("failed to enqueue controller for pod %v", pod1.Name)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			expectedKey, _ := controller.KeyFunc(ds1)
0000000000000000000000000000000000000000;;			if got, want := key.(string), expectedKey; got != want {
0000000000000000000000000000000000000000;;				t.Errorf("queue.Get() = %v, want %v", got, want)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			pod2 := newPod("pod2-", "node-0", simpleDaemonSetLabel, ds2)
0000000000000000000000000000000000000000;;			manager.addPod(pod2)
0000000000000000000000000000000000000000;;			if got, want := manager.queue.Len(), 1; got != want {
0000000000000000000000000000000000000000;;				t.Fatalf("queue.Len() = %v, want %v", got, want)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			key, done = manager.queue.Get()
0000000000000000000000000000000000000000;;			if key == nil || done {
0000000000000000000000000000000000000000;;				t.Fatalf("failed to enqueue controller for pod %v", pod2.Name)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			expectedKey, _ = controller.KeyFunc(ds2)
0000000000000000000000000000000000000000;;			if got, want := key.(string), expectedKey; got != want {
0000000000000000000000000000000000000000;;				t.Errorf("queue.Get() = %v, want %v", got, want)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestAddPodOrphan(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			manager, _, _ := newTestController()
0000000000000000000000000000000000000000;;			ds1 := newDaemonSet("foo1")
0000000000000000000000000000000000000000;;			ds1.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			ds2 := newDaemonSet("foo2")
0000000000000000000000000000000000000000;;			ds2.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			ds3 := newDaemonSet("foo3")
0000000000000000000000000000000000000000;;			ds3.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			ds3.Spec.Selector.MatchLabels = simpleDaemonSetLabel2
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds1)
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds2)
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds3)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Make pod an orphan. Expect matching sets to be queued.
0000000000000000000000000000000000000000;;			pod := newPod("pod1-", "node-0", simpleDaemonSetLabel, nil)
0000000000000000000000000000000000000000;;			manager.addPod(pod)
0000000000000000000000000000000000000000;;			if got, want := manager.queue.Len(), 2; got != want {
0000000000000000000000000000000000000000;;				t.Fatalf("queue.Len() = %v, want %v", got, want)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if got, want := getQueuedKeys(manager.queue), []string{"default/foo1", "default/foo2"}; !reflect.DeepEqual(got, want) {
0000000000000000000000000000000000000000;;				t.Errorf("getQueuedKeys() = %v, want %v", got, want)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestUpdatePod(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			manager, _, _ := newTestController()
0000000000000000000000000000000000000000;;			ds1 := newDaemonSet("foo1")
0000000000000000000000000000000000000000;;			ds1.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			ds2 := newDaemonSet("foo2")
0000000000000000000000000000000000000000;;			ds2.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds1)
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds2)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			pod1 := newPod("pod1-", "node-0", simpleDaemonSetLabel, ds1)
0000000000000000000000000000000000000000;;			prev := *pod1
0000000000000000000000000000000000000000;;			bumpResourceVersion(pod1)
0000000000000000000000000000000000000000;;			manager.updatePod(&prev, pod1)
0000000000000000000000000000000000000000;;			if got, want := manager.queue.Len(), 1; got != want {
0000000000000000000000000000000000000000;;				t.Fatalf("queue.Len() = %v, want %v", got, want)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			key, done := manager.queue.Get()
0000000000000000000000000000000000000000;;			if key == nil || done {
0000000000000000000000000000000000000000;;				t.Fatalf("failed to enqueue controller for pod %v", pod1.Name)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			expectedKey, _ := controller.KeyFunc(ds1)
0000000000000000000000000000000000000000;;			if got, want := key.(string), expectedKey; got != want {
0000000000000000000000000000000000000000;;				t.Errorf("queue.Get() = %v, want %v", got, want)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			pod2 := newPod("pod2-", "node-0", simpleDaemonSetLabel, ds2)
0000000000000000000000000000000000000000;;			prev = *pod2
0000000000000000000000000000000000000000;;			bumpResourceVersion(pod2)
0000000000000000000000000000000000000000;;			manager.updatePod(&prev, pod2)
0000000000000000000000000000000000000000;;			if got, want := manager.queue.Len(), 1; got != want {
0000000000000000000000000000000000000000;;				t.Fatalf("queue.Len() = %v, want %v", got, want)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			key, done = manager.queue.Get()
0000000000000000000000000000000000000000;;			if key == nil || done {
0000000000000000000000000000000000000000;;				t.Fatalf("failed to enqueue controller for pod %v", pod2.Name)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			expectedKey, _ = controller.KeyFunc(ds2)
0000000000000000000000000000000000000000;;			if got, want := key.(string), expectedKey; got != want {
0000000000000000000000000000000000000000;;				t.Errorf("queue.Get() = %v, want %v", got, want)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestUpdatePodOrphanSameLabels(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			manager, _, _ := newTestController()
0000000000000000000000000000000000000000;;			ds1 := newDaemonSet("foo1")
0000000000000000000000000000000000000000;;			ds1.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			ds2 := newDaemonSet("foo2")
0000000000000000000000000000000000000000;;			ds2.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds1)
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds2)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			pod := newPod("pod1-", "node-0", simpleDaemonSetLabel, nil)
0000000000000000000000000000000000000000;;			prev := *pod
0000000000000000000000000000000000000000;;			bumpResourceVersion(pod)
0000000000000000000000000000000000000000;;			manager.updatePod(&prev, pod)
0000000000000000000000000000000000000000;;			if got, want := manager.queue.Len(), 0; got != want {
0000000000000000000000000000000000000000;;				t.Fatalf("queue.Len() = %v, want %v", got, want)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestUpdatePodOrphanWithNewLabels(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			manager, _, _ := newTestController()
0000000000000000000000000000000000000000;;			ds1 := newDaemonSet("foo1")
0000000000000000000000000000000000000000;;			ds1.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			ds2 := newDaemonSet("foo2")
0000000000000000000000000000000000000000;;			ds2.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds1)
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds2)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			pod := newPod("pod1-", "node-0", simpleDaemonSetLabel, nil)
0000000000000000000000000000000000000000;;			prev := *pod
0000000000000000000000000000000000000000;;			prev.Labels = map[string]string{"foo2": "bar2"}
0000000000000000000000000000000000000000;;			bumpResourceVersion(pod)
0000000000000000000000000000000000000000;;			manager.updatePod(&prev, pod)
0000000000000000000000000000000000000000;;			if got, want := manager.queue.Len(), 2; got != want {
0000000000000000000000000000000000000000;;				t.Fatalf("queue.Len() = %v, want %v", got, want)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if got, want := getQueuedKeys(manager.queue), []string{"default/foo1", "default/foo2"}; !reflect.DeepEqual(got, want) {
0000000000000000000000000000000000000000;;				t.Errorf("getQueuedKeys() = %v, want %v", got, want)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestUpdatePodChangeControllerRef(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			ds := newDaemonSet("foo")
0000000000000000000000000000000000000000;;			ds.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			manager, _, _ := newTestController()
0000000000000000000000000000000000000000;;			ds1 := newDaemonSet("foo1")
0000000000000000000000000000000000000000;;			ds2 := newDaemonSet("foo2")
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds1)
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds2)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			pod := newPod("pod1-", "node-0", simpleDaemonSetLabel, ds1)
0000000000000000000000000000000000000000;;			prev := *pod
0000000000000000000000000000000000000000;;			prev.OwnerReferences = []metav1.OwnerReference{*newControllerRef(ds2)}
0000000000000000000000000000000000000000;;			bumpResourceVersion(pod)
0000000000000000000000000000000000000000;;			manager.updatePod(&prev, pod)
0000000000000000000000000000000000000000;;			if got, want := manager.queue.Len(), 2; got != want {
0000000000000000000000000000000000000000;;				t.Fatalf("queue.Len() = %v, want %v", got, want)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestUpdatePodControllerRefRemoved(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			manager, _, _ := newTestController()
0000000000000000000000000000000000000000;;			ds1 := newDaemonSet("foo1")
0000000000000000000000000000000000000000;;			ds1.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			ds2 := newDaemonSet("foo2")
0000000000000000000000000000000000000000;;			ds2.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds1)
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds2)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			pod := newPod("pod1-", "node-0", simpleDaemonSetLabel, ds1)
0000000000000000000000000000000000000000;;			prev := *pod
0000000000000000000000000000000000000000;;			pod.OwnerReferences = nil
0000000000000000000000000000000000000000;;			bumpResourceVersion(pod)
0000000000000000000000000000000000000000;;			manager.updatePod(&prev, pod)
0000000000000000000000000000000000000000;;			if got, want := manager.queue.Len(), 2; got != want {
0000000000000000000000000000000000000000;;				t.Fatalf("queue.Len() = %v, want %v", got, want)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestDeletePod(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			manager, _, _ := newTestController()
0000000000000000000000000000000000000000;;			ds1 := newDaemonSet("foo1")
0000000000000000000000000000000000000000;;			ds1.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			ds2 := newDaemonSet("foo2")
0000000000000000000000000000000000000000;;			ds2.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds1)
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds2)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			pod1 := newPod("pod1-", "node-0", simpleDaemonSetLabel, ds1)
0000000000000000000000000000000000000000;;			manager.deletePod(pod1)
0000000000000000000000000000000000000000;;			if got, want := manager.queue.Len(), 1; got != want {
0000000000000000000000000000000000000000;;				t.Fatalf("queue.Len() = %v, want %v", got, want)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			key, done := manager.queue.Get()
0000000000000000000000000000000000000000;;			if key == nil || done {
0000000000000000000000000000000000000000;;				t.Fatalf("failed to enqueue controller for pod %v", pod1.Name)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			expectedKey, _ := controller.KeyFunc(ds1)
0000000000000000000000000000000000000000;;			if got, want := key.(string), expectedKey; got != want {
0000000000000000000000000000000000000000;;				t.Errorf("queue.Get() = %v, want %v", got, want)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			pod2 := newPod("pod2-", "node-0", simpleDaemonSetLabel, ds2)
0000000000000000000000000000000000000000;;			manager.deletePod(pod2)
0000000000000000000000000000000000000000;;			if got, want := manager.queue.Len(), 1; got != want {
0000000000000000000000000000000000000000;;				t.Fatalf("queue.Len() = %v, want %v", got, want)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			key, done = manager.queue.Get()
0000000000000000000000000000000000000000;;			if key == nil || done {
0000000000000000000000000000000000000000;;				t.Fatalf("failed to enqueue controller for pod %v", pod2.Name)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			expectedKey, _ = controller.KeyFunc(ds2)
0000000000000000000000000000000000000000;;			if got, want := key.(string), expectedKey; got != want {
0000000000000000000000000000000000000000;;				t.Errorf("queue.Get() = %v, want %v", got, want)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestDeletePodOrphan(t *testing.T) {
0000000000000000000000000000000000000000;;		for _, strategy := range updateStrategies() {
0000000000000000000000000000000000000000;;			manager, _, _ := newTestController()
0000000000000000000000000000000000000000;;			ds1 := newDaemonSet("foo1")
0000000000000000000000000000000000000000;;			ds1.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			ds2 := newDaemonSet("foo2")
0000000000000000000000000000000000000000;;			ds2.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			ds3 := newDaemonSet("foo3")
0000000000000000000000000000000000000000;;			ds3.Spec.UpdateStrategy = *strategy
0000000000000000000000000000000000000000;;			ds3.Spec.Selector.MatchLabels = simpleDaemonSetLabel2
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds1)
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds2)
0000000000000000000000000000000000000000;;			manager.dsStore.Add(ds3)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			pod := newPod("pod1-", "node-0", simpleDaemonSetLabel, nil)
0000000000000000000000000000000000000000;;			manager.deletePod(pod)
0000000000000000000000000000000000000000;;			if got, want := manager.queue.Len(), 0; got != want {
0000000000000000000000000000000000000000;;				t.Fatalf("queue.Len() = %v, want %v", got, want)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func bumpResourceVersion(obj metav1.Object) {
0000000000000000000000000000000000000000;;		ver, _ := strconv.ParseInt(obj.GetResourceVersion(), 10, 32)
0000000000000000000000000000000000000000;;		obj.SetResourceVersion(strconv.FormatInt(ver+1, 10))
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// getQueuedKeys returns a sorted list of keys in the queue.
0000000000000000000000000000000000000000;;	// It can be used to quickly check that multiple keys are in there.
0000000000000000000000000000000000000000;;	func getQueuedKeys(queue workqueue.RateLimitingInterface) []string {
0000000000000000000000000000000000000000;;		var keys []string
0000000000000000000000000000000000000000;;		count := queue.Len()
0000000000000000000000000000000000000000;;		for i := 0; i < count; i++ {
0000000000000000000000000000000000000000;;			key, done := queue.Get()
0000000000000000000000000000000000000000;;			if done {
0000000000000000000000000000000000000000;;				return keys
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			keys = append(keys, key.(string))
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		sort.Strings(keys)
0000000000000000000000000000000000000000;;		return keys
0000000000000000000000000000000000000000;;	}
