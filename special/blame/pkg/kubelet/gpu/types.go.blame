0000000000000000000000000000000000000000;;	/*
0000000000000000000000000000000000000000;;	Copyright 2017 The Kubernetes Authors.
cbb0f53c1d06784cddbf1f23e0938cf3e579ef52;;	
0000000000000000000000000000000000000000;;	Licensed under the Apache License, Version 2.0 (the "License");
0000000000000000000000000000000000000000;;	you may not use this file except in compliance with the License.
0000000000000000000000000000000000000000;;	You may obtain a copy of the License at
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	    http://www.apache.org/licenses/LICENSE-2.0
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	Unless required by applicable law or agreed to in writing, software
0000000000000000000000000000000000000000;;	distributed under the License is distributed on an "AS IS" BASIS,
0000000000000000000000000000000000000000;;	WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
0000000000000000000000000000000000000000;;	See the License for the specific language governing permissions and
0000000000000000000000000000000000000000;;	limitations under the License.
0000000000000000000000000000000000000000;;	*/
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	package gpu
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	import "k8s.io/api/core/v1"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// GPUManager manages GPUs on a local node.
0000000000000000000000000000000000000000;;	// Implementations are expected to be thread safe.
0000000000000000000000000000000000000000;;	type GPUManager interface {
0000000000000000000000000000000000000000;;		// Start logically initializes GPUManager
0000000000000000000000000000000000000000;;		Start() error
0000000000000000000000000000000000000000;;		// Capacity returns the total number of GPUs on the node.
0000000000000000000000000000000000000000;;		Capacity() v1.ResourceList
0000000000000000000000000000000000000000;;		// AllocateGPU attempts to allocate GPUs for input container.
0000000000000000000000000000000000000000;;		// Returns paths to allocated GPUs and nil on success.
0000000000000000000000000000000000000000;;		// Returns an error on failure.
0000000000000000000000000000000000000000;;		AllocateGPU(*v1.Pod, *v1.Container) ([]string, error)
0000000000000000000000000000000000000000;;	}
