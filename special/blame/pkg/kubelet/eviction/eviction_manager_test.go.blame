0000000000000000000000000000000000000000;;	/*
0000000000000000000000000000000000000000;;	Copyright 2016 The Kubernetes Authors.
164ccd9ffae9b8f5c6e7dc54a3e47e56446b691d;pkg/kubelet/eviction/manager_test.go[pkg/kubelet/eviction/manager_test.go][pkg/kubelet/eviction/eviction_manager_test.go];	
0000000000000000000000000000000000000000;;	Licensed under the Apache License, Version 2.0 (the "License");
0000000000000000000000000000000000000000;;	you may not use this file except in compliance with the License.
0000000000000000000000000000000000000000;;	You may obtain a copy of the License at
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	    http://www.apache.org/licenses/LICENSE-2.0
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	Unless required by applicable law or agreed to in writing, software
0000000000000000000000000000000000000000;;	distributed under the License is distributed on an "AS IS" BASIS,
0000000000000000000000000000000000000000;;	WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
0000000000000000000000000000000000000000;;	See the License for the specific language governing permissions and
0000000000000000000000000000000000000000;;	limitations under the License.
0000000000000000000000000000000000000000;;	*/
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	package eviction
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	import (
0000000000000000000000000000000000000000;;		"testing"
0000000000000000000000000000000000000000;;		"time"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		"k8s.io/api/core/v1"
0000000000000000000000000000000000000000;;		clientv1 "k8s.io/api/core/v1"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/api/resource"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/types"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/util/clock"
0000000000000000000000000000000000000000;;		utilfeature "k8s.io/apiserver/pkg/util/feature"
0000000000000000000000000000000000000000;;		"k8s.io/client-go/tools/record"
0000000000000000000000000000000000000000;;		kubeapi "k8s.io/kubernetes/pkg/api"
0000000000000000000000000000000000000000;;		statsapi "k8s.io/kubernetes/pkg/kubelet/apis/stats/v1alpha1"
0000000000000000000000000000000000000000;;		evictionapi "k8s.io/kubernetes/pkg/kubelet/eviction/api"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/kubelet/lifecycle"
0000000000000000000000000000000000000000;;		kubelettypes "k8s.io/kubernetes/pkg/kubelet/types"
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// mockPodKiller is used to testing which pod is killed
0000000000000000000000000000000000000000;;	type mockPodKiller struct {
0000000000000000000000000000000000000000;;		pod                 *v1.Pod
0000000000000000000000000000000000000000;;		status              v1.PodStatus
0000000000000000000000000000000000000000;;		gracePeriodOverride *int64
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// killPodNow records the pod that was killed
0000000000000000000000000000000000000000;;	func (m *mockPodKiller) killPodNow(pod *v1.Pod, status v1.PodStatus, gracePeriodOverride *int64) error {
0000000000000000000000000000000000000000;;		m.pod = pod
0000000000000000000000000000000000000000;;		m.status = status
0000000000000000000000000000000000000000;;		m.gracePeriodOverride = gracePeriodOverride
0000000000000000000000000000000000000000;;		return nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// mockDiskInfoProvider is used to simulate testing.
0000000000000000000000000000000000000000;;	type mockDiskInfoProvider struct {
0000000000000000000000000000000000000000;;		dedicatedImageFs bool
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// HasDedicatedImageFs returns the mocked value
0000000000000000000000000000000000000000;;	func (m *mockDiskInfoProvider) HasDedicatedImageFs() (bool, error) {
0000000000000000000000000000000000000000;;		return m.dedicatedImageFs, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func newMockNodeProvider(allocatableCapacity v1.ResourceList) *mockNodeProvider {
0000000000000000000000000000000000000000;;		return &mockNodeProvider{
0000000000000000000000000000000000000000;;			node: v1.Node{
0000000000000000000000000000000000000000;;				Status: v1.NodeStatus{
0000000000000000000000000000000000000000;;					Allocatable: allocatableCapacity,
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type mockNodeProvider struct {
0000000000000000000000000000000000000000;;		node v1.Node
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (m *mockNodeProvider) GetNode() (*v1.Node, error) {
0000000000000000000000000000000000000000;;		return &m.node, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// mockDiskGC is used to simulate invoking image and container garbage collection.
0000000000000000000000000000000000000000;;	type mockDiskGC struct {
0000000000000000000000000000000000000000;;		err                error
0000000000000000000000000000000000000000;;		imageBytesFreed    int64
0000000000000000000000000000000000000000;;		imageGCInvoked     bool
0000000000000000000000000000000000000000;;		containerGCInvoked bool
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// DeleteUnusedImages returns the mocked values.
0000000000000000000000000000000000000000;;	func (m *mockDiskGC) DeleteUnusedImages() (int64, error) {
0000000000000000000000000000000000000000;;		m.imageGCInvoked = true
0000000000000000000000000000000000000000;;		return m.imageBytesFreed, m.err
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// DeleteAllUnusedContainers returns the mocked value
0000000000000000000000000000000000000000;;	func (m *mockDiskGC) DeleteAllUnusedContainers() error {
0000000000000000000000000000000000000000;;		m.containerGCInvoked = true
0000000000000000000000000000000000000000;;		return m.err
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func makePodWithMemoryStats(name string, requests v1.ResourceList, limits v1.ResourceList, memoryWorkingSet string) (*v1.Pod, statsapi.PodStats) {
0000000000000000000000000000000000000000;;		pod := newPod(name, []v1.Container{
0000000000000000000000000000000000000000;;			newContainer(name, requests, limits),
0000000000000000000000000000000000000000;;		}, nil)
0000000000000000000000000000000000000000;;		podStats := newPodMemoryStats(pod, resource.MustParse(memoryWorkingSet))
0000000000000000000000000000000000000000;;		return pod, podStats
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func makePodWithDiskStats(name string, requests v1.ResourceList, limits v1.ResourceList, rootFsUsed, logsUsed, perLocalVolumeUsed string) (*v1.Pod, statsapi.PodStats) {
0000000000000000000000000000000000000000;;		pod := newPod(name, []v1.Container{
0000000000000000000000000000000000000000;;			newContainer(name, requests, limits),
0000000000000000000000000000000000000000;;		}, nil)
0000000000000000000000000000000000000000;;		podStats := newPodDiskStats(pod, parseQuantity(rootFsUsed), parseQuantity(logsUsed), parseQuantity(perLocalVolumeUsed))
0000000000000000000000000000000000000000;;		return pod, podStats
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func makeMemoryStats(nodeAvailableBytes string, podStats map[*v1.Pod]statsapi.PodStats) *statsapi.Summary {
0000000000000000000000000000000000000000;;		val := resource.MustParse(nodeAvailableBytes)
0000000000000000000000000000000000000000;;		availableBytes := uint64(val.Value())
0000000000000000000000000000000000000000;;		WorkingSetBytes := uint64(val.Value())
0000000000000000000000000000000000000000;;		result := &statsapi.Summary{
0000000000000000000000000000000000000000;;			Node: statsapi.NodeStats{
0000000000000000000000000000000000000000;;				Memory: &statsapi.MemoryStats{
0000000000000000000000000000000000000000;;					AvailableBytes:  &availableBytes,
0000000000000000000000000000000000000000;;					WorkingSetBytes: &WorkingSetBytes,
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			Pods: []statsapi.PodStats{},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		for _, podStat := range podStats {
0000000000000000000000000000000000000000;;			result.Pods = append(result.Pods, podStat)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return result
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func makeDiskStats(rootFsAvailableBytes, imageFsAvailableBytes string, podStats map[*v1.Pod]statsapi.PodStats) *statsapi.Summary {
0000000000000000000000000000000000000000;;		rootFsVal := resource.MustParse(rootFsAvailableBytes)
0000000000000000000000000000000000000000;;		rootFsBytes := uint64(rootFsVal.Value())
0000000000000000000000000000000000000000;;		rootFsCapacityBytes := uint64(rootFsVal.Value() * 2)
0000000000000000000000000000000000000000;;		imageFsVal := resource.MustParse(imageFsAvailableBytes)
0000000000000000000000000000000000000000;;		imageFsBytes := uint64(imageFsVal.Value())
0000000000000000000000000000000000000000;;		imageFsCapacityBytes := uint64(imageFsVal.Value() * 2)
0000000000000000000000000000000000000000;;		result := &statsapi.Summary{
0000000000000000000000000000000000000000;;			Node: statsapi.NodeStats{
0000000000000000000000000000000000000000;;				Fs: &statsapi.FsStats{
0000000000000000000000000000000000000000;;					AvailableBytes: &rootFsBytes,
0000000000000000000000000000000000000000;;					CapacityBytes:  &rootFsCapacityBytes,
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;				Runtime: &statsapi.RuntimeStats{
0000000000000000000000000000000000000000;;					ImageFs: &statsapi.FsStats{
0000000000000000000000000000000000000000;;						AvailableBytes: &imageFsBytes,
0000000000000000000000000000000000000000;;						CapacityBytes:  &imageFsCapacityBytes,
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			Pods: []statsapi.PodStats{},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		for _, podStat := range podStats {
0000000000000000000000000000000000000000;;			result.Pods = append(result.Pods, podStat)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return result
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type podToMake struct {
0000000000000000000000000000000000000000;;		name                     string
0000000000000000000000000000000000000000;;		requests                 v1.ResourceList
0000000000000000000000000000000000000000;;		limits                   v1.ResourceList
0000000000000000000000000000000000000000;;		memoryWorkingSet         string
0000000000000000000000000000000000000000;;		rootFsUsed               string
0000000000000000000000000000000000000000;;		logsFsUsed               string
0000000000000000000000000000000000000000;;		logsFsInodesUsed         string
0000000000000000000000000000000000000000;;		rootFsInodesUsed         string
0000000000000000000000000000000000000000;;		perLocalVolumeUsed       string
0000000000000000000000000000000000000000;;		perLocalVolumeInodesUsed string
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// TestMemoryPressure
0000000000000000000000000000000000000000;;	func TestMemoryPressure(t *testing.T) {
0000000000000000000000000000000000000000;;		podMaker := makePodWithMemoryStats
0000000000000000000000000000000000000000;;		summaryStatsMaker := makeMemoryStats
0000000000000000000000000000000000000000;;		podsToMake := []podToMake{
0000000000000000000000000000000000000000;;			{name: "guaranteed-low", requests: newResourceList("100m", "1Gi"), limits: newResourceList("100m", "1Gi"), memoryWorkingSet: "200Mi"},
0000000000000000000000000000000000000000;;			{name: "guaranteed-high", requests: newResourceList("100m", "1Gi"), limits: newResourceList("100m", "1Gi"), memoryWorkingSet: "800Mi"},
0000000000000000000000000000000000000000;;			{name: "burstable-low", requests: newResourceList("100m", "100Mi"), limits: newResourceList("200m", "1Gi"), memoryWorkingSet: "300Mi"},
0000000000000000000000000000000000000000;;			{name: "burstable-high", requests: newResourceList("100m", "100Mi"), limits: newResourceList("200m", "1Gi"), memoryWorkingSet: "800Mi"},
0000000000000000000000000000000000000000;;			{name: "best-effort-low", requests: newResourceList("", ""), limits: newResourceList("", ""), memoryWorkingSet: "300Mi"},
0000000000000000000000000000000000000000;;			{name: "best-effort-high", requests: newResourceList("", ""), limits: newResourceList("", ""), memoryWorkingSet: "500Mi"},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		pods := []*v1.Pod{}
0000000000000000000000000000000000000000;;		podStats := map[*v1.Pod]statsapi.PodStats{}
0000000000000000000000000000000000000000;;		for _, podToMake := range podsToMake {
0000000000000000000000000000000000000000;;			pod, podStat := podMaker(podToMake.name, podToMake.requests, podToMake.limits, podToMake.memoryWorkingSet)
0000000000000000000000000000000000000000;;			pods = append(pods, pod)
0000000000000000000000000000000000000000;;			podStats[pod] = podStat
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		podToEvict := pods[5]
0000000000000000000000000000000000000000;;		activePodsFunc := func() []*v1.Pod {
0000000000000000000000000000000000000000;;			return pods
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		fakeClock := clock.NewFakeClock(time.Now())
0000000000000000000000000000000000000000;;		podKiller := &mockPodKiller{}
0000000000000000000000000000000000000000;;		diskInfoProvider := &mockDiskInfoProvider{dedicatedImageFs: false}
0000000000000000000000000000000000000000;;		nodeProvider := newMockNodeProvider(v1.ResourceList{v1.ResourceMemory: *quantityMustParse("2Gi")})
0000000000000000000000000000000000000000;;		imageGC := &mockDiskGC{imageBytesFreed: int64(0), err: nil}
0000000000000000000000000000000000000000;;		nodeRef := &clientv1.ObjectReference{Kind: "Node", Name: "test", UID: types.UID("test"), Namespace: ""}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		config := Config{
0000000000000000000000000000000000000000;;			MaxPodGracePeriodSeconds: 5,
0000000000000000000000000000000000000000;;			PressureTransitionPeriod: time.Minute * 5,
0000000000000000000000000000000000000000;;			Thresholds: []evictionapi.Threshold{
0000000000000000000000000000000000000000;;				{
0000000000000000000000000000000000000000;;					Signal:   evictionapi.SignalMemoryAvailable,
0000000000000000000000000000000000000000;;					Operator: evictionapi.OpLessThan,
0000000000000000000000000000000000000000;;					Value: evictionapi.ThresholdValue{
0000000000000000000000000000000000000000;;						Quantity: quantityMustParse("1Gi"),
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;				{
0000000000000000000000000000000000000000;;					Signal:   evictionapi.SignalMemoryAvailable,
0000000000000000000000000000000000000000;;					Operator: evictionapi.OpLessThan,
0000000000000000000000000000000000000000;;					Value: evictionapi.ThresholdValue{
0000000000000000000000000000000000000000;;						Quantity: quantityMustParse("2Gi"),
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;					GracePeriod: time.Minute * 2,
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		summaryProvider := &fakeSummaryProvider{result: summaryStatsMaker("2Gi", podStats)}
0000000000000000000000000000000000000000;;		manager := &managerImpl{
0000000000000000000000000000000000000000;;			clock:           fakeClock,
0000000000000000000000000000000000000000;;			killPodFunc:     podKiller.killPodNow,
0000000000000000000000000000000000000000;;			imageGC:         imageGC,
0000000000000000000000000000000000000000;;			config:          config,
0000000000000000000000000000000000000000;;			recorder:        &record.FakeRecorder{},
0000000000000000000000000000000000000000;;			summaryProvider: summaryProvider,
0000000000000000000000000000000000000000;;			nodeRef:         nodeRef,
0000000000000000000000000000000000000000;;			nodeConditionsLastObservedAt: nodeConditionsObservedAt{},
0000000000000000000000000000000000000000;;			thresholdsFirstObservedAt:    thresholdsObservedAt{},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// create a best effort pod to test admission
0000000000000000000000000000000000000000;;		bestEffortPodToAdmit, _ := podMaker("best-admit", newResourceList("", ""), newResourceList("", ""), "0Gi")
0000000000000000000000000000000000000000;;		burstablePodToAdmit, _ := podMaker("burst-admit", newResourceList("100m", "100Mi"), newResourceList("200m", "200Mi"), "0Gi")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// synchronize
0000000000000000000000000000000000000000;;		manager.synchronize(diskInfoProvider, activePodsFunc, nodeProvider)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// we should not have memory pressure
0000000000000000000000000000000000000000;;		if manager.IsUnderMemoryPressure() {
0000000000000000000000000000000000000000;;			t.Errorf("Manager should not report memory pressure")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// try to admit our pods (they should succeed)
0000000000000000000000000000000000000000;;		expected := []bool{true, true}
0000000000000000000000000000000000000000;;		for i, pod := range []*v1.Pod{bestEffortPodToAdmit, burstablePodToAdmit} {
0000000000000000000000000000000000000000;;			if result := manager.Admit(&lifecycle.PodAdmitAttributes{Pod: pod}); expected[i] != result.Admit {
0000000000000000000000000000000000000000;;				t.Errorf("Admit pod: %v, expected: %v, actual: %v", pod, expected[i], result.Admit)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// induce soft threshold
0000000000000000000000000000000000000000;;		fakeClock.Step(1 * time.Minute)
0000000000000000000000000000000000000000;;		summaryProvider.result = summaryStatsMaker("1500Mi", podStats)
0000000000000000000000000000000000000000;;		manager.synchronize(diskInfoProvider, activePodsFunc, nodeProvider)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// we should have memory pressure
0000000000000000000000000000000000000000;;		if !manager.IsUnderMemoryPressure() {
0000000000000000000000000000000000000000;;			t.Errorf("Manager should report memory pressure since soft threshold was met")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// verify no pod was yet killed because there has not yet been enough time passed.
0000000000000000000000000000000000000000;;		if podKiller.pod != nil {
0000000000000000000000000000000000000000;;			t.Errorf("Manager should not have killed a pod yet, but killed: %v", podKiller.pod.Name)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// step forward in time pass the grace period
0000000000000000000000000000000000000000;;		fakeClock.Step(3 * time.Minute)
0000000000000000000000000000000000000000;;		summaryProvider.result = summaryStatsMaker("1500Mi", podStats)
0000000000000000000000000000000000000000;;		manager.synchronize(diskInfoProvider, activePodsFunc, nodeProvider)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// we should have memory pressure
0000000000000000000000000000000000000000;;		if !manager.IsUnderMemoryPressure() {
0000000000000000000000000000000000000000;;			t.Errorf("Manager should report memory pressure since soft threshold was met")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// verify the right pod was killed with the right grace period.
0000000000000000000000000000000000000000;;		if podKiller.pod != podToEvict {
0000000000000000000000000000000000000000;;			t.Errorf("Manager chose to kill pod: %v, but should have chosen %v", podKiller.pod.Name, podToEvict.Name)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if podKiller.gracePeriodOverride == nil {
0000000000000000000000000000000000000000;;			t.Errorf("Manager chose to kill pod but should have had a grace period override.")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		observedGracePeriod := *podKiller.gracePeriodOverride
0000000000000000000000000000000000000000;;		if observedGracePeriod != manager.config.MaxPodGracePeriodSeconds {
0000000000000000000000000000000000000000;;			t.Errorf("Manager chose to kill pod with incorrect grace period.  Expected: %d, actual: %d", manager.config.MaxPodGracePeriodSeconds, observedGracePeriod)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		// reset state
0000000000000000000000000000000000000000;;		podKiller.pod = nil
0000000000000000000000000000000000000000;;		podKiller.gracePeriodOverride = nil
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// remove memory pressure
0000000000000000000000000000000000000000;;		fakeClock.Step(20 * time.Minute)
0000000000000000000000000000000000000000;;		summaryProvider.result = summaryStatsMaker("3Gi", podStats)
0000000000000000000000000000000000000000;;		manager.synchronize(diskInfoProvider, activePodsFunc, nodeProvider)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// we should not have memory pressure
0000000000000000000000000000000000000000;;		if manager.IsUnderMemoryPressure() {
0000000000000000000000000000000000000000;;			t.Errorf("Manager should not report memory pressure")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// induce memory pressure!
0000000000000000000000000000000000000000;;		fakeClock.Step(1 * time.Minute)
0000000000000000000000000000000000000000;;		summaryProvider.result = summaryStatsMaker("500Mi", podStats)
0000000000000000000000000000000000000000;;		manager.synchronize(diskInfoProvider, activePodsFunc, nodeProvider)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// we should have memory pressure
0000000000000000000000000000000000000000;;		if !manager.IsUnderMemoryPressure() {
0000000000000000000000000000000000000000;;			t.Errorf("Manager should report memory pressure")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// check the right pod was killed
0000000000000000000000000000000000000000;;		if podKiller.pod != podToEvict {
0000000000000000000000000000000000000000;;			t.Errorf("Manager chose to kill pod: %v, but should have chosen %v", podKiller.pod.Name, podToEvict.Name)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		observedGracePeriod = *podKiller.gracePeriodOverride
0000000000000000000000000000000000000000;;		if observedGracePeriod != int64(0) {
0000000000000000000000000000000000000000;;			t.Errorf("Manager chose to kill pod with incorrect grace period.  Expected: %d, actual: %d", 0, observedGracePeriod)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// the best-effort pod should not admit, burstable should
0000000000000000000000000000000000000000;;		expected = []bool{false, true}
0000000000000000000000000000000000000000;;		for i, pod := range []*v1.Pod{bestEffortPodToAdmit, burstablePodToAdmit} {
0000000000000000000000000000000000000000;;			if result := manager.Admit(&lifecycle.PodAdmitAttributes{Pod: pod}); expected[i] != result.Admit {
0000000000000000000000000000000000000000;;				t.Errorf("Admit pod: %v, expected: %v, actual: %v", pod, expected[i], result.Admit)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// reduce memory pressure
0000000000000000000000000000000000000000;;		fakeClock.Step(1 * time.Minute)
0000000000000000000000000000000000000000;;		summaryProvider.result = summaryStatsMaker("2Gi", podStats)
0000000000000000000000000000000000000000;;		podKiller.pod = nil // reset state
0000000000000000000000000000000000000000;;		manager.synchronize(diskInfoProvider, activePodsFunc, nodeProvider)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// we should have memory pressure (because transition period not yet met)
0000000000000000000000000000000000000000;;		if !manager.IsUnderMemoryPressure() {
0000000000000000000000000000000000000000;;			t.Errorf("Manager should report memory pressure")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// no pod should have been killed
0000000000000000000000000000000000000000;;		if podKiller.pod != nil {
0000000000000000000000000000000000000000;;			t.Errorf("Manager chose to kill pod: %v when no pod should have been killed", podKiller.pod.Name)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// the best-effort pod should not admit, burstable should
0000000000000000000000000000000000000000;;		expected = []bool{false, true}
0000000000000000000000000000000000000000;;		for i, pod := range []*v1.Pod{bestEffortPodToAdmit, burstablePodToAdmit} {
0000000000000000000000000000000000000000;;			if result := manager.Admit(&lifecycle.PodAdmitAttributes{Pod: pod}); expected[i] != result.Admit {
0000000000000000000000000000000000000000;;				t.Errorf("Admit pod: %v, expected: %v, actual: %v", pod, expected[i], result.Admit)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// move the clock past transition period to ensure that we stop reporting pressure
0000000000000000000000000000000000000000;;		fakeClock.Step(5 * time.Minute)
0000000000000000000000000000000000000000;;		summaryProvider.result = summaryStatsMaker("2Gi", podStats)
0000000000000000000000000000000000000000;;		podKiller.pod = nil // reset state
0000000000000000000000000000000000000000;;		manager.synchronize(diskInfoProvider, activePodsFunc, nodeProvider)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// we should not have memory pressure (because transition period met)
0000000000000000000000000000000000000000;;		if manager.IsUnderMemoryPressure() {
0000000000000000000000000000000000000000;;			t.Errorf("Manager should not report memory pressure")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// no pod should have been killed
0000000000000000000000000000000000000000;;		if podKiller.pod != nil {
0000000000000000000000000000000000000000;;			t.Errorf("Manager chose to kill pod: %v when no pod should have been killed", podKiller.pod.Name)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// all pods should admit now
0000000000000000000000000000000000000000;;		expected = []bool{true, true}
0000000000000000000000000000000000000000;;		for i, pod := range []*v1.Pod{bestEffortPodToAdmit, burstablePodToAdmit} {
0000000000000000000000000000000000000000;;			if result := manager.Admit(&lifecycle.PodAdmitAttributes{Pod: pod}); expected[i] != result.Admit {
0000000000000000000000000000000000000000;;				t.Errorf("Admit pod: %v, expected: %v, actual: %v", pod, expected[i], result.Admit)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// parseQuantity parses the specified value (if provided) otherwise returns 0 value
0000000000000000000000000000000000000000;;	func parseQuantity(value string) resource.Quantity {
0000000000000000000000000000000000000000;;		if len(value) == 0 {
0000000000000000000000000000000000000000;;			return resource.MustParse("0")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return resource.MustParse(value)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestDiskPressureNodeFs(t *testing.T) {
0000000000000000000000000000000000000000;;		podMaker := makePodWithDiskStats
0000000000000000000000000000000000000000;;		summaryStatsMaker := makeDiskStats
0000000000000000000000000000000000000000;;		podsToMake := []podToMake{
0000000000000000000000000000000000000000;;			{name: "guaranteed-low", requests: newResourceList("100m", "1Gi"), limits: newResourceList("100m", "1Gi"), rootFsUsed: "200Mi"},
0000000000000000000000000000000000000000;;			{name: "guaranteed-high", requests: newResourceList("100m", "1Gi"), limits: newResourceList("100m", "1Gi"), rootFsUsed: "800Mi"},
0000000000000000000000000000000000000000;;			{name: "burstable-low", requests: newResourceList("100m", "100Mi"), limits: newResourceList("200m", "1Gi"), logsFsUsed: "300Mi"},
0000000000000000000000000000000000000000;;			{name: "burstable-high", requests: newResourceList("100m", "100Mi"), limits: newResourceList("200m", "1Gi"), rootFsUsed: "800Mi"},
0000000000000000000000000000000000000000;;			{name: "best-effort-low", requests: newResourceList("", ""), limits: newResourceList("", ""), perLocalVolumeUsed: "300Mi"},
0000000000000000000000000000000000000000;;			{name: "best-effort-high", requests: newResourceList("", ""), limits: newResourceList("", ""), rootFsUsed: "500Mi"},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		pods := []*v1.Pod{}
0000000000000000000000000000000000000000;;		podStats := map[*v1.Pod]statsapi.PodStats{}
0000000000000000000000000000000000000000;;		for _, podToMake := range podsToMake {
0000000000000000000000000000000000000000;;			pod, podStat := podMaker(podToMake.name, podToMake.requests, podToMake.limits, podToMake.rootFsUsed, podToMake.logsFsUsed, podToMake.perLocalVolumeUsed)
0000000000000000000000000000000000000000;;			pods = append(pods, pod)
0000000000000000000000000000000000000000;;			podStats[pod] = podStat
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		podToEvict := pods[5]
0000000000000000000000000000000000000000;;		activePodsFunc := func() []*v1.Pod {
0000000000000000000000000000000000000000;;			return pods
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		fakeClock := clock.NewFakeClock(time.Now())
0000000000000000000000000000000000000000;;		podKiller := &mockPodKiller{}
0000000000000000000000000000000000000000;;		diskInfoProvider := &mockDiskInfoProvider{dedicatedImageFs: false}
0000000000000000000000000000000000000000;;		nodeProvider := newMockNodeProvider(v1.ResourceList{v1.ResourceMemory: *quantityMustParse("2Gi")})
0000000000000000000000000000000000000000;;		diskGC := &mockDiskGC{imageBytesFreed: int64(0), err: nil}
0000000000000000000000000000000000000000;;		nodeRef := &clientv1.ObjectReference{Kind: "Node", Name: "test", UID: types.UID("test"), Namespace: ""}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		config := Config{
0000000000000000000000000000000000000000;;			MaxPodGracePeriodSeconds: 5,
0000000000000000000000000000000000000000;;			PressureTransitionPeriod: time.Minute * 5,
0000000000000000000000000000000000000000;;			Thresholds: []evictionapi.Threshold{
0000000000000000000000000000000000000000;;				{
0000000000000000000000000000000000000000;;					Signal:   evictionapi.SignalNodeFsAvailable,
0000000000000000000000000000000000000000;;					Operator: evictionapi.OpLessThan,
0000000000000000000000000000000000000000;;					Value: evictionapi.ThresholdValue{
0000000000000000000000000000000000000000;;						Quantity: quantityMustParse("1Gi"),
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;				{
0000000000000000000000000000000000000000;;					Signal:   evictionapi.SignalNodeFsAvailable,
0000000000000000000000000000000000000000;;					Operator: evictionapi.OpLessThan,
0000000000000000000000000000000000000000;;					Value: evictionapi.ThresholdValue{
0000000000000000000000000000000000000000;;						Quantity: quantityMustParse("2Gi"),
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;					GracePeriod: time.Minute * 2,
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		summaryProvider := &fakeSummaryProvider{result: summaryStatsMaker("16Gi", "200Gi", podStats)}
0000000000000000000000000000000000000000;;		manager := &managerImpl{
0000000000000000000000000000000000000000;;			clock:           fakeClock,
0000000000000000000000000000000000000000;;			killPodFunc:     podKiller.killPodNow,
0000000000000000000000000000000000000000;;			imageGC:         diskGC,
0000000000000000000000000000000000000000;;			containerGC:     diskGC,
0000000000000000000000000000000000000000;;			config:          config,
0000000000000000000000000000000000000000;;			recorder:        &record.FakeRecorder{},
0000000000000000000000000000000000000000;;			summaryProvider: summaryProvider,
0000000000000000000000000000000000000000;;			nodeRef:         nodeRef,
0000000000000000000000000000000000000000;;			nodeConditionsLastObservedAt: nodeConditionsObservedAt{},
0000000000000000000000000000000000000000;;			thresholdsFirstObservedAt:    thresholdsObservedAt{},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// create a best effort pod to test admission
0000000000000000000000000000000000000000;;		podToAdmit, _ := podMaker("pod-to-admit", newResourceList("", ""), newResourceList("", ""), "0Gi", "0Gi", "0Gi")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// synchronize
0000000000000000000000000000000000000000;;		manager.synchronize(diskInfoProvider, activePodsFunc, nodeProvider)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// we should not have disk pressure
0000000000000000000000000000000000000000;;		if manager.IsUnderDiskPressure() {
0000000000000000000000000000000000000000;;			t.Errorf("Manager should not report disk pressure")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// try to admit our pod (should succeed)
0000000000000000000000000000000000000000;;		if result := manager.Admit(&lifecycle.PodAdmitAttributes{Pod: podToAdmit}); !result.Admit {
0000000000000000000000000000000000000000;;			t.Errorf("Admit pod: %v, expected: %v, actual: %v", podToAdmit, true, result.Admit)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// induce soft threshold
0000000000000000000000000000000000000000;;		fakeClock.Step(1 * time.Minute)
0000000000000000000000000000000000000000;;		summaryProvider.result = summaryStatsMaker("1.5Gi", "200Gi", podStats)
0000000000000000000000000000000000000000;;		manager.synchronize(diskInfoProvider, activePodsFunc, nodeProvider)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// we should have disk pressure
0000000000000000000000000000000000000000;;		if !manager.IsUnderDiskPressure() {
0000000000000000000000000000000000000000;;			t.Errorf("Manager should report disk pressure since soft threshold was met")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// verify no pod was yet killed because there has not yet been enough time passed.
0000000000000000000000000000000000000000;;		if podKiller.pod != nil {
0000000000000000000000000000000000000000;;			t.Errorf("Manager should not have killed a pod yet, but killed: %v", podKiller.pod.Name)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// step forward in time pass the grace period
0000000000000000000000000000000000000000;;		fakeClock.Step(3 * time.Minute)
0000000000000000000000000000000000000000;;		summaryProvider.result = summaryStatsMaker("1.5Gi", "200Gi", podStats)
0000000000000000000000000000000000000000;;		manager.synchronize(diskInfoProvider, activePodsFunc, nodeProvider)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// we should have disk pressure
0000000000000000000000000000000000000000;;		if !manager.IsUnderDiskPressure() {
0000000000000000000000000000000000000000;;			t.Errorf("Manager should report disk pressure since soft threshold was met")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// verify the right pod was killed with the right grace period.
0000000000000000000000000000000000000000;;		if podKiller.pod != podToEvict {
0000000000000000000000000000000000000000;;			t.Errorf("Manager chose to kill pod: %v, but should have chosen %v", podKiller.pod.Name, podToEvict.Name)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if podKiller.gracePeriodOverride == nil {
0000000000000000000000000000000000000000;;			t.Errorf("Manager chose to kill pod but should have had a grace period override.")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		observedGracePeriod := *podKiller.gracePeriodOverride
0000000000000000000000000000000000000000;;		if observedGracePeriod != manager.config.MaxPodGracePeriodSeconds {
0000000000000000000000000000000000000000;;			t.Errorf("Manager chose to kill pod with incorrect grace period.  Expected: %d, actual: %d", manager.config.MaxPodGracePeriodSeconds, observedGracePeriod)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		// reset state
0000000000000000000000000000000000000000;;		podKiller.pod = nil
0000000000000000000000000000000000000000;;		podKiller.gracePeriodOverride = nil
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// remove disk pressure
0000000000000000000000000000000000000000;;		fakeClock.Step(20 * time.Minute)
0000000000000000000000000000000000000000;;		summaryProvider.result = summaryStatsMaker("16Gi", "200Gi", podStats)
0000000000000000000000000000000000000000;;		manager.synchronize(diskInfoProvider, activePodsFunc, nodeProvider)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// we should not have disk pressure
0000000000000000000000000000000000000000;;		if manager.IsUnderDiskPressure() {
0000000000000000000000000000000000000000;;			t.Errorf("Manager should not report disk pressure")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// induce disk pressure!
0000000000000000000000000000000000000000;;		fakeClock.Step(1 * time.Minute)
0000000000000000000000000000000000000000;;		summaryProvider.result = summaryStatsMaker("500Mi", "200Gi", podStats)
0000000000000000000000000000000000000000;;		manager.synchronize(diskInfoProvider, activePodsFunc, nodeProvider)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// we should have disk pressure
0000000000000000000000000000000000000000;;		if !manager.IsUnderDiskPressure() {
0000000000000000000000000000000000000000;;			t.Errorf("Manager should report disk pressure")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// check the right pod was killed
0000000000000000000000000000000000000000;;		if podKiller.pod != podToEvict {
0000000000000000000000000000000000000000;;			t.Errorf("Manager chose to kill pod: %v, but should have chosen %v", podKiller.pod.Name, podToEvict.Name)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		observedGracePeriod = *podKiller.gracePeriodOverride
0000000000000000000000000000000000000000;;		if observedGracePeriod != int64(0) {
0000000000000000000000000000000000000000;;			t.Errorf("Manager chose to kill pod with incorrect grace period.  Expected: %d, actual: %d", 0, observedGracePeriod)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// try to admit our pod (should fail)
0000000000000000000000000000000000000000;;		if result := manager.Admit(&lifecycle.PodAdmitAttributes{Pod: podToAdmit}); result.Admit {
0000000000000000000000000000000000000000;;			t.Errorf("Admit pod: %v, expected: %v, actual: %v", podToAdmit, false, result.Admit)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// reduce disk pressure
0000000000000000000000000000000000000000;;		fakeClock.Step(1 * time.Minute)
0000000000000000000000000000000000000000;;		summaryProvider.result = summaryStatsMaker("16Gi", "200Gi", podStats)
0000000000000000000000000000000000000000;;		podKiller.pod = nil // reset state
0000000000000000000000000000000000000000;;		manager.synchronize(diskInfoProvider, activePodsFunc, nodeProvider)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// we should have disk pressure (because transition period not yet met)
0000000000000000000000000000000000000000;;		if !manager.IsUnderDiskPressure() {
0000000000000000000000000000000000000000;;			t.Errorf("Manager should report disk pressure")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// no pod should have been killed
0000000000000000000000000000000000000000;;		if podKiller.pod != nil {
0000000000000000000000000000000000000000;;			t.Errorf("Manager chose to kill pod: %v when no pod should have been killed", podKiller.pod.Name)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// try to admit our pod (should fail)
0000000000000000000000000000000000000000;;		if result := manager.Admit(&lifecycle.PodAdmitAttributes{Pod: podToAdmit}); result.Admit {
0000000000000000000000000000000000000000;;			t.Errorf("Admit pod: %v, expected: %v, actual: %v", podToAdmit, false, result.Admit)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// move the clock past transition period to ensure that we stop reporting pressure
0000000000000000000000000000000000000000;;		fakeClock.Step(5 * time.Minute)
0000000000000000000000000000000000000000;;		summaryProvider.result = summaryStatsMaker("16Gi", "200Gi", podStats)
0000000000000000000000000000000000000000;;		podKiller.pod = nil // reset state
0000000000000000000000000000000000000000;;		manager.synchronize(diskInfoProvider, activePodsFunc, nodeProvider)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// we should not have disk pressure (because transition period met)
0000000000000000000000000000000000000000;;		if manager.IsUnderDiskPressure() {
0000000000000000000000000000000000000000;;			t.Errorf("Manager should not report disk pressure")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// no pod should have been killed
0000000000000000000000000000000000000000;;		if podKiller.pod != nil {
0000000000000000000000000000000000000000;;			t.Errorf("Manager chose to kill pod: %v when no pod should have been killed", podKiller.pod.Name)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// try to admit our pod (should succeed)
0000000000000000000000000000000000000000;;		if result := manager.Admit(&lifecycle.PodAdmitAttributes{Pod: podToAdmit}); !result.Admit {
0000000000000000000000000000000000000000;;			t.Errorf("Admit pod: %v, expected: %v, actual: %v", podToAdmit, true, result.Admit)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// TestMinReclaim verifies that min-reclaim works as desired.
0000000000000000000000000000000000000000;;	func TestMinReclaim(t *testing.T) {
0000000000000000000000000000000000000000;;		podMaker := makePodWithMemoryStats
0000000000000000000000000000000000000000;;		summaryStatsMaker := makeMemoryStats
0000000000000000000000000000000000000000;;		podsToMake := []podToMake{
0000000000000000000000000000000000000000;;			{name: "guaranteed-low", requests: newResourceList("100m", "1Gi"), limits: newResourceList("100m", "1Gi"), memoryWorkingSet: "200Mi"},
0000000000000000000000000000000000000000;;			{name: "guaranteed-high", requests: newResourceList("100m", "1Gi"), limits: newResourceList("100m", "1Gi"), memoryWorkingSet: "800Mi"},
0000000000000000000000000000000000000000;;			{name: "burstable-low", requests: newResourceList("100m", "100Mi"), limits: newResourceList("200m", "1Gi"), memoryWorkingSet: "300Mi"},
0000000000000000000000000000000000000000;;			{name: "burstable-high", requests: newResourceList("100m", "100Mi"), limits: newResourceList("200m", "1Gi"), memoryWorkingSet: "800Mi"},
0000000000000000000000000000000000000000;;			{name: "best-effort-low", requests: newResourceList("", ""), limits: newResourceList("", ""), memoryWorkingSet: "300Mi"},
0000000000000000000000000000000000000000;;			{name: "best-effort-high", requests: newResourceList("", ""), limits: newResourceList("", ""), memoryWorkingSet: "500Mi"},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		pods := []*v1.Pod{}
0000000000000000000000000000000000000000;;		podStats := map[*v1.Pod]statsapi.PodStats{}
0000000000000000000000000000000000000000;;		for _, podToMake := range podsToMake {
0000000000000000000000000000000000000000;;			pod, podStat := podMaker(podToMake.name, podToMake.requests, podToMake.limits, podToMake.memoryWorkingSet)
0000000000000000000000000000000000000000;;			pods = append(pods, pod)
0000000000000000000000000000000000000000;;			podStats[pod] = podStat
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		podToEvict := pods[5]
0000000000000000000000000000000000000000;;		activePodsFunc := func() []*v1.Pod {
0000000000000000000000000000000000000000;;			return pods
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		fakeClock := clock.NewFakeClock(time.Now())
0000000000000000000000000000000000000000;;		podKiller := &mockPodKiller{}
0000000000000000000000000000000000000000;;		diskInfoProvider := &mockDiskInfoProvider{dedicatedImageFs: false}
0000000000000000000000000000000000000000;;		nodeProvider := newMockNodeProvider(v1.ResourceList{v1.ResourceMemory: *quantityMustParse("2Gi")})
0000000000000000000000000000000000000000;;		diskGC := &mockDiskGC{imageBytesFreed: int64(0), err: nil}
0000000000000000000000000000000000000000;;		nodeRef := &clientv1.ObjectReference{Kind: "Node", Name: "test", UID: types.UID("test"), Namespace: ""}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		config := Config{
0000000000000000000000000000000000000000;;			MaxPodGracePeriodSeconds: 5,
0000000000000000000000000000000000000000;;			PressureTransitionPeriod: time.Minute * 5,
0000000000000000000000000000000000000000;;			Thresholds: []evictionapi.Threshold{
0000000000000000000000000000000000000000;;				{
0000000000000000000000000000000000000000;;					Signal:   evictionapi.SignalMemoryAvailable,
0000000000000000000000000000000000000000;;					Operator: evictionapi.OpLessThan,
0000000000000000000000000000000000000000;;					Value: evictionapi.ThresholdValue{
0000000000000000000000000000000000000000;;						Quantity: quantityMustParse("1Gi"),
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;					MinReclaim: &evictionapi.ThresholdValue{
0000000000000000000000000000000000000000;;						Quantity: quantityMustParse("500Mi"),
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		summaryProvider := &fakeSummaryProvider{result: summaryStatsMaker("2Gi", podStats)}
0000000000000000000000000000000000000000;;		manager := &managerImpl{
0000000000000000000000000000000000000000;;			clock:           fakeClock,
0000000000000000000000000000000000000000;;			killPodFunc:     podKiller.killPodNow,
0000000000000000000000000000000000000000;;			imageGC:         diskGC,
0000000000000000000000000000000000000000;;			containerGC:     diskGC,
0000000000000000000000000000000000000000;;			config:          config,
0000000000000000000000000000000000000000;;			recorder:        &record.FakeRecorder{},
0000000000000000000000000000000000000000;;			summaryProvider: summaryProvider,
0000000000000000000000000000000000000000;;			nodeRef:         nodeRef,
0000000000000000000000000000000000000000;;			nodeConditionsLastObservedAt: nodeConditionsObservedAt{},
0000000000000000000000000000000000000000;;			thresholdsFirstObservedAt:    thresholdsObservedAt{},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// synchronize
0000000000000000000000000000000000000000;;		manager.synchronize(diskInfoProvider, activePodsFunc, nodeProvider)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// we should not have memory pressure
0000000000000000000000000000000000000000;;		if manager.IsUnderMemoryPressure() {
0000000000000000000000000000000000000000;;			t.Errorf("Manager should not report memory pressure")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// induce memory pressure!
0000000000000000000000000000000000000000;;		fakeClock.Step(1 * time.Minute)
0000000000000000000000000000000000000000;;		summaryProvider.result = summaryStatsMaker("500Mi", podStats)
0000000000000000000000000000000000000000;;		manager.synchronize(diskInfoProvider, activePodsFunc, nodeProvider)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// we should have memory pressure
0000000000000000000000000000000000000000;;		if !manager.IsUnderMemoryPressure() {
0000000000000000000000000000000000000000;;			t.Errorf("Manager should report memory pressure")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// check the right pod was killed
0000000000000000000000000000000000000000;;		if podKiller.pod != podToEvict {
0000000000000000000000000000000000000000;;			t.Errorf("Manager chose to kill pod: %v, but should have chosen %v", podKiller.pod.Name, podToEvict.Name)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		observedGracePeriod := *podKiller.gracePeriodOverride
0000000000000000000000000000000000000000;;		if observedGracePeriod != int64(0) {
0000000000000000000000000000000000000000;;			t.Errorf("Manager chose to kill pod with incorrect grace period.  Expected: %d, actual: %d", 0, observedGracePeriod)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// reduce memory pressure, but not below the min-reclaim amount
0000000000000000000000000000000000000000;;		fakeClock.Step(1 * time.Minute)
0000000000000000000000000000000000000000;;		summaryProvider.result = summaryStatsMaker("1.2Gi", podStats)
0000000000000000000000000000000000000000;;		podKiller.pod = nil // reset state
0000000000000000000000000000000000000000;;		manager.synchronize(diskInfoProvider, activePodsFunc, nodeProvider)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// we should have memory pressure (because transition period not yet met)
0000000000000000000000000000000000000000;;		if !manager.IsUnderMemoryPressure() {
0000000000000000000000000000000000000000;;			t.Errorf("Manager should report memory pressure")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// check the right pod was killed
0000000000000000000000000000000000000000;;		if podKiller.pod != podToEvict {
0000000000000000000000000000000000000000;;			t.Errorf("Manager chose to kill pod: %v, but should have chosen %v", podKiller.pod.Name, podToEvict.Name)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		observedGracePeriod = *podKiller.gracePeriodOverride
0000000000000000000000000000000000000000;;		if observedGracePeriod != int64(0) {
0000000000000000000000000000000000000000;;			t.Errorf("Manager chose to kill pod with incorrect grace period.  Expected: %d, actual: %d", 0, observedGracePeriod)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// reduce memory pressure and ensure the min-reclaim amount
0000000000000000000000000000000000000000;;		fakeClock.Step(1 * time.Minute)
0000000000000000000000000000000000000000;;		summaryProvider.result = summaryStatsMaker("2Gi", podStats)
0000000000000000000000000000000000000000;;		podKiller.pod = nil // reset state
0000000000000000000000000000000000000000;;		manager.synchronize(diskInfoProvider, activePodsFunc, nodeProvider)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// we should have memory pressure (because transition period not yet met)
0000000000000000000000000000000000000000;;		if !manager.IsUnderMemoryPressure() {
0000000000000000000000000000000000000000;;			t.Errorf("Manager should report memory pressure")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// no pod should have been killed
0000000000000000000000000000000000000000;;		if podKiller.pod != nil {
0000000000000000000000000000000000000000;;			t.Errorf("Manager chose to kill pod: %v when no pod should have been killed", podKiller.pod.Name)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// move the clock past transition period to ensure that we stop reporting pressure
0000000000000000000000000000000000000000;;		fakeClock.Step(5 * time.Minute)
0000000000000000000000000000000000000000;;		summaryProvider.result = summaryStatsMaker("2Gi", podStats)
0000000000000000000000000000000000000000;;		podKiller.pod = nil // reset state
0000000000000000000000000000000000000000;;		manager.synchronize(diskInfoProvider, activePodsFunc, nodeProvider)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// we should not have memory pressure (because transition period met)
0000000000000000000000000000000000000000;;		if manager.IsUnderMemoryPressure() {
0000000000000000000000000000000000000000;;			t.Errorf("Manager should not report memory pressure")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// no pod should have been killed
0000000000000000000000000000000000000000;;		if podKiller.pod != nil {
0000000000000000000000000000000000000000;;			t.Errorf("Manager chose to kill pod: %v when no pod should have been killed", podKiller.pod.Name)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestNodeReclaimFuncs(t *testing.T) {
0000000000000000000000000000000000000000;;		podMaker := makePodWithDiskStats
0000000000000000000000000000000000000000;;		summaryStatsMaker := makeDiskStats
0000000000000000000000000000000000000000;;		podsToMake := []podToMake{
0000000000000000000000000000000000000000;;			{name: "guaranteed-low", requests: newResourceList("100m", "1Gi"), limits: newResourceList("100m", "1Gi"), rootFsUsed: "200Mi"},
0000000000000000000000000000000000000000;;			{name: "guaranteed-high", requests: newResourceList("100m", "1Gi"), limits: newResourceList("100m", "1Gi"), rootFsUsed: "800Mi"},
0000000000000000000000000000000000000000;;			{name: "burstable-low", requests: newResourceList("100m", "100Mi"), limits: newResourceList("200m", "1Gi"), rootFsUsed: "300Mi"},
0000000000000000000000000000000000000000;;			{name: "burstable-high", requests: newResourceList("100m", "100Mi"), limits: newResourceList("200m", "1Gi"), rootFsUsed: "800Mi"},
0000000000000000000000000000000000000000;;			{name: "best-effort-low", requests: newResourceList("", ""), limits: newResourceList("", ""), rootFsUsed: "300Mi"},
0000000000000000000000000000000000000000;;			{name: "best-effort-high", requests: newResourceList("", ""), limits: newResourceList("", ""), rootFsUsed: "500Mi"},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		pods := []*v1.Pod{}
0000000000000000000000000000000000000000;;		podStats := map[*v1.Pod]statsapi.PodStats{}
0000000000000000000000000000000000000000;;		for _, podToMake := range podsToMake {
0000000000000000000000000000000000000000;;			pod, podStat := podMaker(podToMake.name, podToMake.requests, podToMake.limits, podToMake.rootFsUsed, podToMake.logsFsUsed, podToMake.perLocalVolumeUsed)
0000000000000000000000000000000000000000;;			pods = append(pods, pod)
0000000000000000000000000000000000000000;;			podStats[pod] = podStat
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		podToEvict := pods[5]
0000000000000000000000000000000000000000;;		activePodsFunc := func() []*v1.Pod {
0000000000000000000000000000000000000000;;			return pods
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		fakeClock := clock.NewFakeClock(time.Now())
0000000000000000000000000000000000000000;;		podKiller := &mockPodKiller{}
0000000000000000000000000000000000000000;;		diskInfoProvider := &mockDiskInfoProvider{dedicatedImageFs: false}
0000000000000000000000000000000000000000;;		nodeProvider := newMockNodeProvider(v1.ResourceList{v1.ResourceMemory: *quantityMustParse("2Gi")})
0000000000000000000000000000000000000000;;		imageGcFree := resource.MustParse("700Mi")
0000000000000000000000000000000000000000;;		diskGC := &mockDiskGC{imageBytesFreed: imageGcFree.Value(), err: nil}
0000000000000000000000000000000000000000;;		nodeRef := &clientv1.ObjectReference{Kind: "Node", Name: "test", UID: types.UID("test"), Namespace: ""}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		config := Config{
0000000000000000000000000000000000000000;;			MaxPodGracePeriodSeconds: 5,
0000000000000000000000000000000000000000;;			PressureTransitionPeriod: time.Minute * 5,
0000000000000000000000000000000000000000;;			Thresholds: []evictionapi.Threshold{
0000000000000000000000000000000000000000;;				{
0000000000000000000000000000000000000000;;					Signal:   evictionapi.SignalNodeFsAvailable,
0000000000000000000000000000000000000000;;					Operator: evictionapi.OpLessThan,
0000000000000000000000000000000000000000;;					Value: evictionapi.ThresholdValue{
0000000000000000000000000000000000000000;;						Quantity: quantityMustParse("1Gi"),
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;					MinReclaim: &evictionapi.ThresholdValue{
0000000000000000000000000000000000000000;;						Quantity: quantityMustParse("500Mi"),
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		summaryProvider := &fakeSummaryProvider{result: summaryStatsMaker("16Gi", "200Gi", podStats)}
0000000000000000000000000000000000000000;;		manager := &managerImpl{
0000000000000000000000000000000000000000;;			clock:           fakeClock,
0000000000000000000000000000000000000000;;			killPodFunc:     podKiller.killPodNow,
0000000000000000000000000000000000000000;;			imageGC:         diskGC,
0000000000000000000000000000000000000000;;			containerGC:     diskGC,
0000000000000000000000000000000000000000;;			config:          config,
0000000000000000000000000000000000000000;;			recorder:        &record.FakeRecorder{},
0000000000000000000000000000000000000000;;			summaryProvider: summaryProvider,
0000000000000000000000000000000000000000;;			nodeRef:         nodeRef,
0000000000000000000000000000000000000000;;			nodeConditionsLastObservedAt: nodeConditionsObservedAt{},
0000000000000000000000000000000000000000;;			thresholdsFirstObservedAt:    thresholdsObservedAt{},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// synchronize
0000000000000000000000000000000000000000;;		manager.synchronize(diskInfoProvider, activePodsFunc, nodeProvider)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// we should not have disk pressure
0000000000000000000000000000000000000000;;		if manager.IsUnderDiskPressure() {
0000000000000000000000000000000000000000;;			t.Errorf("Manager should not report disk pressure")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// induce hard threshold
0000000000000000000000000000000000000000;;		fakeClock.Step(1 * time.Minute)
0000000000000000000000000000000000000000;;		summaryProvider.result = summaryStatsMaker(".9Gi", "200Gi", podStats)
0000000000000000000000000000000000000000;;		manager.synchronize(diskInfoProvider, activePodsFunc, nodeProvider)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// we should have disk pressure
0000000000000000000000000000000000000000;;		if !manager.IsUnderDiskPressure() {
0000000000000000000000000000000000000000;;			t.Errorf("Manager should report disk pressure since soft threshold was met")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// verify image gc was invoked
0000000000000000000000000000000000000000;;		if !diskGC.imageGCInvoked || !diskGC.containerGCInvoked {
0000000000000000000000000000000000000000;;			t.Errorf("Manager should have invoked image gc")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// verify no pod was killed because image gc was sufficient
0000000000000000000000000000000000000000;;		if podKiller.pod != nil {
0000000000000000000000000000000000000000;;			t.Errorf("Manager should not have killed a pod, but killed: %v", podKiller.pod.Name)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// reset state
0000000000000000000000000000000000000000;;		diskGC.imageGCInvoked = false
0000000000000000000000000000000000000000;;		diskGC.containerGCInvoked = false
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// remove disk pressure
0000000000000000000000000000000000000000;;		fakeClock.Step(20 * time.Minute)
0000000000000000000000000000000000000000;;		summaryProvider.result = summaryStatsMaker("16Gi", "200Gi", podStats)
0000000000000000000000000000000000000000;;		manager.synchronize(diskInfoProvider, activePodsFunc, nodeProvider)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// we should not have disk pressure
0000000000000000000000000000000000000000;;		if manager.IsUnderDiskPressure() {
0000000000000000000000000000000000000000;;			t.Errorf("Manager should not report disk pressure")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// induce disk pressure!
0000000000000000000000000000000000000000;;		fakeClock.Step(1 * time.Minute)
0000000000000000000000000000000000000000;;		summaryProvider.result = summaryStatsMaker("400Mi", "200Gi", podStats)
0000000000000000000000000000000000000000;;		manager.synchronize(diskInfoProvider, activePodsFunc, nodeProvider)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// we should have disk pressure
0000000000000000000000000000000000000000;;		if !manager.IsUnderDiskPressure() {
0000000000000000000000000000000000000000;;			t.Errorf("Manager should report disk pressure")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// ensure disk gc was invoked
0000000000000000000000000000000000000000;;		if !diskGC.imageGCInvoked || !diskGC.containerGCInvoked {
0000000000000000000000000000000000000000;;			t.Errorf("Manager should have invoked image gc")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// check the right pod was killed
0000000000000000000000000000000000000000;;		if podKiller.pod != podToEvict {
0000000000000000000000000000000000000000;;			t.Errorf("Manager chose to kill pod: %v, but should have chosen %v", podKiller.pod.Name, podToEvict.Name)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		observedGracePeriod := *podKiller.gracePeriodOverride
0000000000000000000000000000000000000000;;		if observedGracePeriod != int64(0) {
0000000000000000000000000000000000000000;;			t.Errorf("Manager chose to kill pod with incorrect grace period.  Expected: %d, actual: %d", 0, observedGracePeriod)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// reduce disk pressure
0000000000000000000000000000000000000000;;		fakeClock.Step(1 * time.Minute)
0000000000000000000000000000000000000000;;		summaryProvider.result = summaryStatsMaker("16Gi", "200Gi", podStats)
0000000000000000000000000000000000000000;;		diskGC.imageGCInvoked = false     // reset state
0000000000000000000000000000000000000000;;		diskGC.containerGCInvoked = false // reset state
0000000000000000000000000000000000000000;;		podKiller.pod = nil               // reset state
0000000000000000000000000000000000000000;;		manager.synchronize(diskInfoProvider, activePodsFunc, nodeProvider)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// we should have disk pressure (because transition period not yet met)
0000000000000000000000000000000000000000;;		if !manager.IsUnderDiskPressure() {
0000000000000000000000000000000000000000;;			t.Errorf("Manager should report disk pressure")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// no image gc should have occurred
0000000000000000000000000000000000000000;;		if diskGC.imageGCInvoked || diskGC.containerGCInvoked {
0000000000000000000000000000000000000000;;			t.Errorf("Manager chose to perform image gc when it was not neeed")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// no pod should have been killed
0000000000000000000000000000000000000000;;		if podKiller.pod != nil {
0000000000000000000000000000000000000000;;			t.Errorf("Manager chose to kill pod: %v when no pod should have been killed", podKiller.pod.Name)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// move the clock past transition period to ensure that we stop reporting pressure
0000000000000000000000000000000000000000;;		fakeClock.Step(5 * time.Minute)
0000000000000000000000000000000000000000;;		summaryProvider.result = summaryStatsMaker("16Gi", "200Gi", podStats)
0000000000000000000000000000000000000000;;		diskGC.imageGCInvoked = false     // reset state
0000000000000000000000000000000000000000;;		diskGC.containerGCInvoked = false // reset state
0000000000000000000000000000000000000000;;		podKiller.pod = nil               // reset state
0000000000000000000000000000000000000000;;		manager.synchronize(diskInfoProvider, activePodsFunc, nodeProvider)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// we should not have disk pressure (because transition period met)
0000000000000000000000000000000000000000;;		if manager.IsUnderDiskPressure() {
0000000000000000000000000000000000000000;;			t.Errorf("Manager should not report disk pressure")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// no image gc should have occurred
0000000000000000000000000000000000000000;;		if diskGC.imageGCInvoked || diskGC.containerGCInvoked {
0000000000000000000000000000000000000000;;			t.Errorf("Manager chose to perform image gc when it was not neeed")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// no pod should have been killed
0000000000000000000000000000000000000000;;		if podKiller.pod != nil {
0000000000000000000000000000000000000000;;			t.Errorf("Manager chose to kill pod: %v when no pod should have been killed", podKiller.pod.Name)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestInodePressureNodeFsInodes(t *testing.T) {
0000000000000000000000000000000000000000;;		podMaker := func(name string, requests v1.ResourceList, limits v1.ResourceList, rootInodes, logInodes, volumeInodes string) (*v1.Pod, statsapi.PodStats) {
0000000000000000000000000000000000000000;;			pod := newPod(name, []v1.Container{
0000000000000000000000000000000000000000;;				newContainer(name, requests, limits),
0000000000000000000000000000000000000000;;			}, nil)
0000000000000000000000000000000000000000;;			podStats := newPodInodeStats(pod, parseQuantity(rootInodes), parseQuantity(logInodes), parseQuantity(volumeInodes))
0000000000000000000000000000000000000000;;			return pod, podStats
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		summaryStatsMaker := func(rootFsInodesFree, rootFsInodes string, podStats map[*v1.Pod]statsapi.PodStats) *statsapi.Summary {
0000000000000000000000000000000000000000;;			rootFsInodesFreeVal := resource.MustParse(rootFsInodesFree)
0000000000000000000000000000000000000000;;			internalRootFsInodesFree := uint64(rootFsInodesFreeVal.Value())
0000000000000000000000000000000000000000;;			rootFsInodesVal := resource.MustParse(rootFsInodes)
0000000000000000000000000000000000000000;;			internalRootFsInodes := uint64(rootFsInodesVal.Value())
0000000000000000000000000000000000000000;;			result := &statsapi.Summary{
0000000000000000000000000000000000000000;;				Node: statsapi.NodeStats{
0000000000000000000000000000000000000000;;					Fs: &statsapi.FsStats{
0000000000000000000000000000000000000000;;						InodesFree: &internalRootFsInodesFree,
0000000000000000000000000000000000000000;;						Inodes:     &internalRootFsInodes,
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;				Pods: []statsapi.PodStats{},
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			for _, podStat := range podStats {
0000000000000000000000000000000000000000;;				result.Pods = append(result.Pods, podStat)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			return result
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		podsToMake := []podToMake{
0000000000000000000000000000000000000000;;			{name: "guaranteed-low", requests: newResourceList("100m", "1Gi"), limits: newResourceList("100m", "1Gi"), rootFsInodesUsed: "200Mi"},
0000000000000000000000000000000000000000;;			{name: "guaranteed-high", requests: newResourceList("100m", "1Gi"), limits: newResourceList("100m", "1Gi"), rootFsInodesUsed: "800Mi"},
0000000000000000000000000000000000000000;;			{name: "burstable-low", requests: newResourceList("100m", "100Mi"), limits: newResourceList("200m", "1Gi"), rootFsInodesUsed: "300Mi"},
0000000000000000000000000000000000000000;;			{name: "burstable-high", requests: newResourceList("100m", "100Mi"), limits: newResourceList("200m", "1Gi"), rootFsInodesUsed: "800Mi"},
0000000000000000000000000000000000000000;;			{name: "best-effort-low", requests: newResourceList("", ""), limits: newResourceList("", ""), rootFsInodesUsed: "300Mi"},
0000000000000000000000000000000000000000;;			{name: "best-effort-high", requests: newResourceList("", ""), limits: newResourceList("", ""), rootFsInodesUsed: "800Mi"},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		pods := []*v1.Pod{}
0000000000000000000000000000000000000000;;		podStats := map[*v1.Pod]statsapi.PodStats{}
0000000000000000000000000000000000000000;;		for _, podToMake := range podsToMake {
0000000000000000000000000000000000000000;;			pod, podStat := podMaker(podToMake.name, podToMake.requests, podToMake.limits, podToMake.rootFsInodesUsed, podToMake.logsFsInodesUsed, podToMake.perLocalVolumeInodesUsed)
0000000000000000000000000000000000000000;;			pods = append(pods, pod)
0000000000000000000000000000000000000000;;			podStats[pod] = podStat
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		podToEvict := pods[5]
0000000000000000000000000000000000000000;;		activePodsFunc := func() []*v1.Pod {
0000000000000000000000000000000000000000;;			return pods
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		fakeClock := clock.NewFakeClock(time.Now())
0000000000000000000000000000000000000000;;		podKiller := &mockPodKiller{}
0000000000000000000000000000000000000000;;		diskInfoProvider := &mockDiskInfoProvider{dedicatedImageFs: false}
0000000000000000000000000000000000000000;;		nodeProvider := newMockNodeProvider(v1.ResourceList{v1.ResourceMemory: *quantityMustParse("2Gi")})
0000000000000000000000000000000000000000;;		diskGC := &mockDiskGC{imageBytesFreed: int64(0), err: nil}
0000000000000000000000000000000000000000;;		nodeRef := &clientv1.ObjectReference{Kind: "Node", Name: "test", UID: types.UID("test"), Namespace: ""}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		config := Config{
0000000000000000000000000000000000000000;;			MaxPodGracePeriodSeconds: 5,
0000000000000000000000000000000000000000;;			PressureTransitionPeriod: time.Minute * 5,
0000000000000000000000000000000000000000;;			Thresholds: []evictionapi.Threshold{
0000000000000000000000000000000000000000;;				{
0000000000000000000000000000000000000000;;					Signal:   evictionapi.SignalNodeFsInodesFree,
0000000000000000000000000000000000000000;;					Operator: evictionapi.OpLessThan,
0000000000000000000000000000000000000000;;					Value: evictionapi.ThresholdValue{
0000000000000000000000000000000000000000;;						Quantity: quantityMustParse("1Mi"),
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;				{
0000000000000000000000000000000000000000;;					Signal:   evictionapi.SignalNodeFsInodesFree,
0000000000000000000000000000000000000000;;					Operator: evictionapi.OpLessThan,
0000000000000000000000000000000000000000;;					Value: evictionapi.ThresholdValue{
0000000000000000000000000000000000000000;;						Quantity: quantityMustParse("2Mi"),
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;					GracePeriod: time.Minute * 2,
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		summaryProvider := &fakeSummaryProvider{result: summaryStatsMaker("3Mi", "4Mi", podStats)}
0000000000000000000000000000000000000000;;		manager := &managerImpl{
0000000000000000000000000000000000000000;;			clock:           fakeClock,
0000000000000000000000000000000000000000;;			killPodFunc:     podKiller.killPodNow,
0000000000000000000000000000000000000000;;			imageGC:         diskGC,
0000000000000000000000000000000000000000;;			containerGC:     diskGC,
0000000000000000000000000000000000000000;;			config:          config,
0000000000000000000000000000000000000000;;			recorder:        &record.FakeRecorder{},
0000000000000000000000000000000000000000;;			summaryProvider: summaryProvider,
0000000000000000000000000000000000000000;;			nodeRef:         nodeRef,
0000000000000000000000000000000000000000;;			nodeConditionsLastObservedAt: nodeConditionsObservedAt{},
0000000000000000000000000000000000000000;;			thresholdsFirstObservedAt:    thresholdsObservedAt{},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// create a best effort pod to test admission
0000000000000000000000000000000000000000;;		podToAdmit, _ := podMaker("pod-to-admit", newResourceList("", ""), newResourceList("", ""), "0", "0", "0")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// synchronize
0000000000000000000000000000000000000000;;		manager.synchronize(diskInfoProvider, activePodsFunc, nodeProvider)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// we should not have disk pressure
0000000000000000000000000000000000000000;;		if manager.IsUnderDiskPressure() {
0000000000000000000000000000000000000000;;			t.Errorf("Manager should not report inode pressure")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// try to admit our pod (should succeed)
0000000000000000000000000000000000000000;;		if result := manager.Admit(&lifecycle.PodAdmitAttributes{Pod: podToAdmit}); !result.Admit {
0000000000000000000000000000000000000000;;			t.Errorf("Admit pod: %v, expected: %v, actual: %v", podToAdmit, true, result.Admit)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// induce soft threshold
0000000000000000000000000000000000000000;;		fakeClock.Step(1 * time.Minute)
0000000000000000000000000000000000000000;;		summaryProvider.result = summaryStatsMaker("1.5Mi", "4Mi", podStats)
0000000000000000000000000000000000000000;;		manager.synchronize(diskInfoProvider, activePodsFunc, nodeProvider)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// we should have disk pressure
0000000000000000000000000000000000000000;;		if !manager.IsUnderDiskPressure() {
0000000000000000000000000000000000000000;;			t.Errorf("Manager should report inode pressure since soft threshold was met")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// verify no pod was yet killed because there has not yet been enough time passed.
0000000000000000000000000000000000000000;;		if podKiller.pod != nil {
0000000000000000000000000000000000000000;;			t.Errorf("Manager should not have killed a pod yet, but killed: %v", podKiller.pod.Name)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// step forward in time pass the grace period
0000000000000000000000000000000000000000;;		fakeClock.Step(3 * time.Minute)
0000000000000000000000000000000000000000;;		summaryProvider.result = summaryStatsMaker("1.5Mi", "4Mi", podStats)
0000000000000000000000000000000000000000;;		manager.synchronize(diskInfoProvider, activePodsFunc, nodeProvider)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// we should have disk pressure
0000000000000000000000000000000000000000;;		if !manager.IsUnderDiskPressure() {
0000000000000000000000000000000000000000;;			t.Errorf("Manager should report inode pressure since soft threshold was met")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// verify the right pod was killed with the right grace period.
0000000000000000000000000000000000000000;;		if podKiller.pod != podToEvict {
0000000000000000000000000000000000000000;;			t.Errorf("Manager chose to kill pod: %v, but should have chosen %v", podKiller.pod.Name, podToEvict.Name)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if podKiller.gracePeriodOverride == nil {
0000000000000000000000000000000000000000;;			t.Errorf("Manager chose to kill pod but should have had a grace period override.")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		observedGracePeriod := *podKiller.gracePeriodOverride
0000000000000000000000000000000000000000;;		if observedGracePeriod != manager.config.MaxPodGracePeriodSeconds {
0000000000000000000000000000000000000000;;			t.Errorf("Manager chose to kill pod with incorrect grace period.  Expected: %d, actual: %d", manager.config.MaxPodGracePeriodSeconds, observedGracePeriod)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		// reset state
0000000000000000000000000000000000000000;;		podKiller.pod = nil
0000000000000000000000000000000000000000;;		podKiller.gracePeriodOverride = nil
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// remove inode pressure
0000000000000000000000000000000000000000;;		fakeClock.Step(20 * time.Minute)
0000000000000000000000000000000000000000;;		summaryProvider.result = summaryStatsMaker("3Mi", "4Mi", podStats)
0000000000000000000000000000000000000000;;		manager.synchronize(diskInfoProvider, activePodsFunc, nodeProvider)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// we should not have disk pressure
0000000000000000000000000000000000000000;;		if manager.IsUnderDiskPressure() {
0000000000000000000000000000000000000000;;			t.Errorf("Manager should not report inode pressure")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// induce inode pressure!
0000000000000000000000000000000000000000;;		fakeClock.Step(1 * time.Minute)
0000000000000000000000000000000000000000;;		summaryProvider.result = summaryStatsMaker("0.5Mi", "4Mi", podStats)
0000000000000000000000000000000000000000;;		manager.synchronize(diskInfoProvider, activePodsFunc, nodeProvider)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// we should have disk pressure
0000000000000000000000000000000000000000;;		if !manager.IsUnderDiskPressure() {
0000000000000000000000000000000000000000;;			t.Errorf("Manager should report inode pressure")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// check the right pod was killed
0000000000000000000000000000000000000000;;		if podKiller.pod != podToEvict {
0000000000000000000000000000000000000000;;			t.Errorf("Manager chose to kill pod: %v, but should have chosen %v", podKiller.pod.Name, podToEvict.Name)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		observedGracePeriod = *podKiller.gracePeriodOverride
0000000000000000000000000000000000000000;;		if observedGracePeriod != int64(0) {
0000000000000000000000000000000000000000;;			t.Errorf("Manager chose to kill pod with incorrect grace period.  Expected: %d, actual: %d", 0, observedGracePeriod)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// try to admit our pod (should fail)
0000000000000000000000000000000000000000;;		if result := manager.Admit(&lifecycle.PodAdmitAttributes{Pod: podToAdmit}); result.Admit {
0000000000000000000000000000000000000000;;			t.Errorf("Admit pod: %v, expected: %v, actual: %v", podToAdmit, false, result.Admit)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// reduce inode pressure
0000000000000000000000000000000000000000;;		fakeClock.Step(1 * time.Minute)
0000000000000000000000000000000000000000;;		summaryProvider.result = summaryStatsMaker("3Mi", "4Mi", podStats)
0000000000000000000000000000000000000000;;		podKiller.pod = nil // reset state
0000000000000000000000000000000000000000;;		manager.synchronize(diskInfoProvider, activePodsFunc, nodeProvider)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// we should have disk pressure (because transition period not yet met)
0000000000000000000000000000000000000000;;		if !manager.IsUnderDiskPressure() {
0000000000000000000000000000000000000000;;			t.Errorf("Manager should report inode pressure")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// no pod should have been killed
0000000000000000000000000000000000000000;;		if podKiller.pod != nil {
0000000000000000000000000000000000000000;;			t.Errorf("Manager chose to kill pod: %v when no pod should have been killed", podKiller.pod.Name)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// try to admit our pod (should fail)
0000000000000000000000000000000000000000;;		if result := manager.Admit(&lifecycle.PodAdmitAttributes{Pod: podToAdmit}); result.Admit {
0000000000000000000000000000000000000000;;			t.Errorf("Admit pod: %v, expected: %v, actual: %v", podToAdmit, false, result.Admit)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// move the clock past transition period to ensure that we stop reporting pressure
0000000000000000000000000000000000000000;;		fakeClock.Step(5 * time.Minute)
0000000000000000000000000000000000000000;;		summaryProvider.result = summaryStatsMaker("3Mi", "4Mi", podStats)
0000000000000000000000000000000000000000;;		podKiller.pod = nil // reset state
0000000000000000000000000000000000000000;;		manager.synchronize(diskInfoProvider, activePodsFunc, nodeProvider)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// we should not have disk pressure (because transition period met)
0000000000000000000000000000000000000000;;		if manager.IsUnderDiskPressure() {
0000000000000000000000000000000000000000;;			t.Errorf("Manager should not report inode pressure")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// no pod should have been killed
0000000000000000000000000000000000000000;;		if podKiller.pod != nil {
0000000000000000000000000000000000000000;;			t.Errorf("Manager chose to kill pod: %v when no pod should have been killed", podKiller.pod.Name)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// try to admit our pod (should succeed)
0000000000000000000000000000000000000000;;		if result := manager.Admit(&lifecycle.PodAdmitAttributes{Pod: podToAdmit}); !result.Admit {
0000000000000000000000000000000000000000;;			t.Errorf("Admit pod: %v, expected: %v, actual: %v", podToAdmit, true, result.Admit)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// TestCriticalPodsAreNotEvicted
0000000000000000000000000000000000000000;;	func TestCriticalPodsAreNotEvicted(t *testing.T) {
0000000000000000000000000000000000000000;;		podMaker := makePodWithMemoryStats
0000000000000000000000000000000000000000;;		summaryStatsMaker := makeMemoryStats
0000000000000000000000000000000000000000;;		podsToMake := []podToMake{
0000000000000000000000000000000000000000;;			{name: "critical", requests: newResourceList("100m", "1Gi"), limits: newResourceList("100m", "1Gi"), memoryWorkingSet: "800Mi"},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		pods := []*v1.Pod{}
0000000000000000000000000000000000000000;;		podStats := map[*v1.Pod]statsapi.PodStats{}
0000000000000000000000000000000000000000;;		for _, podToMake := range podsToMake {
0000000000000000000000000000000000000000;;			pod, podStat := podMaker(podToMake.name, podToMake.requests, podToMake.limits, podToMake.memoryWorkingSet)
0000000000000000000000000000000000000000;;			pods = append(pods, pod)
0000000000000000000000000000000000000000;;			podStats[pod] = podStat
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Mark the pod as critical
0000000000000000000000000000000000000000;;		pods[0].Annotations = map[string]string{
0000000000000000000000000000000000000000;;			kubelettypes.CriticalPodAnnotationKey:  "",
0000000000000000000000000000000000000000;;			kubelettypes.ConfigSourceAnnotationKey: kubelettypes.FileSource,
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		pods[0].Namespace = kubeapi.NamespaceSystem
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		podToEvict := pods[0]
0000000000000000000000000000000000000000;;		activePodsFunc := func() []*v1.Pod {
0000000000000000000000000000000000000000;;			return pods
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		fakeClock := clock.NewFakeClock(time.Now())
0000000000000000000000000000000000000000;;		podKiller := &mockPodKiller{}
0000000000000000000000000000000000000000;;		diskInfoProvider := &mockDiskInfoProvider{dedicatedImageFs: false}
0000000000000000000000000000000000000000;;		nodeProvider := newMockNodeProvider(v1.ResourceList{v1.ResourceMemory: *quantityMustParse("2Gi")})
0000000000000000000000000000000000000000;;		diskGC := &mockDiskGC{imageBytesFreed: int64(0), err: nil}
0000000000000000000000000000000000000000;;		nodeRef := &clientv1.ObjectReference{
0000000000000000000000000000000000000000;;			Kind: "Node", Name: "test", UID: types.UID("test"), Namespace: "",
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		config := Config{
0000000000000000000000000000000000000000;;			MaxPodGracePeriodSeconds: 5,
0000000000000000000000000000000000000000;;			PressureTransitionPeriod: time.Minute * 5,
0000000000000000000000000000000000000000;;			Thresholds: []evictionapi.Threshold{
0000000000000000000000000000000000000000;;				{
0000000000000000000000000000000000000000;;					Signal:   evictionapi.SignalMemoryAvailable,
0000000000000000000000000000000000000000;;					Operator: evictionapi.OpLessThan,
0000000000000000000000000000000000000000;;					Value: evictionapi.ThresholdValue{
0000000000000000000000000000000000000000;;						Quantity: quantityMustParse("1Gi"),
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;				{
0000000000000000000000000000000000000000;;					Signal:   evictionapi.SignalMemoryAvailable,
0000000000000000000000000000000000000000;;					Operator: evictionapi.OpLessThan,
0000000000000000000000000000000000000000;;					Value: evictionapi.ThresholdValue{
0000000000000000000000000000000000000000;;						Quantity: quantityMustParse("2Gi"),
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;					GracePeriod: time.Minute * 2,
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		summaryProvider := &fakeSummaryProvider{result: summaryStatsMaker("2Gi", podStats)}
0000000000000000000000000000000000000000;;		manager := &managerImpl{
0000000000000000000000000000000000000000;;			clock:           fakeClock,
0000000000000000000000000000000000000000;;			killPodFunc:     podKiller.killPodNow,
0000000000000000000000000000000000000000;;			imageGC:         diskGC,
0000000000000000000000000000000000000000;;			containerGC:     diskGC,
0000000000000000000000000000000000000000;;			config:          config,
0000000000000000000000000000000000000000;;			recorder:        &record.FakeRecorder{},
0000000000000000000000000000000000000000;;			summaryProvider: summaryProvider,
0000000000000000000000000000000000000000;;			nodeRef:         nodeRef,
0000000000000000000000000000000000000000;;			nodeConditionsLastObservedAt: nodeConditionsObservedAt{},
0000000000000000000000000000000000000000;;			thresholdsFirstObservedAt:    thresholdsObservedAt{},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Enable critical pod annotation feature gate
0000000000000000000000000000000000000000;;		utilfeature.DefaultFeatureGate.Set("ExperimentalCriticalPodAnnotation=True")
0000000000000000000000000000000000000000;;		// induce soft threshold
0000000000000000000000000000000000000000;;		fakeClock.Step(1 * time.Minute)
0000000000000000000000000000000000000000;;		summaryProvider.result = summaryStatsMaker("1500Mi", podStats)
0000000000000000000000000000000000000000;;		manager.synchronize(diskInfoProvider, activePodsFunc, nodeProvider)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// we should have memory pressure
0000000000000000000000000000000000000000;;		if !manager.IsUnderMemoryPressure() {
0000000000000000000000000000000000000000;;			t.Errorf("Manager should report memory pressure since soft threshold was met")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// verify no pod was yet killed because there has not yet been enough time passed.
0000000000000000000000000000000000000000;;		if podKiller.pod != nil {
0000000000000000000000000000000000000000;;			t.Errorf("Manager should not have killed a pod yet, but killed: %v", podKiller.pod.Name)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// step forward in time pass the grace period
0000000000000000000000000000000000000000;;		fakeClock.Step(3 * time.Minute)
0000000000000000000000000000000000000000;;		summaryProvider.result = summaryStatsMaker("1500Mi", podStats)
0000000000000000000000000000000000000000;;		manager.synchronize(diskInfoProvider, activePodsFunc, nodeProvider)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// we should have memory pressure
0000000000000000000000000000000000000000;;		if !manager.IsUnderMemoryPressure() {
0000000000000000000000000000000000000000;;			t.Errorf("Manager should report memory pressure since soft threshold was met")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// verify the right pod was killed with the right grace period.
0000000000000000000000000000000000000000;;		if podKiller.pod == podToEvict {
0000000000000000000000000000000000000000;;			t.Errorf("Manager chose to kill critical pod: %v, but should have ignored it", podKiller.pod.Name)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		// reset state
0000000000000000000000000000000000000000;;		podKiller.pod = nil
0000000000000000000000000000000000000000;;		podKiller.gracePeriodOverride = nil
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// remove memory pressure
0000000000000000000000000000000000000000;;		fakeClock.Step(20 * time.Minute)
0000000000000000000000000000000000000000;;		summaryProvider.result = summaryStatsMaker("3Gi", podStats)
0000000000000000000000000000000000000000;;		manager.synchronize(diskInfoProvider, activePodsFunc, nodeProvider)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// we should not have memory pressure
0000000000000000000000000000000000000000;;		if manager.IsUnderMemoryPressure() {
0000000000000000000000000000000000000000;;			t.Errorf("Manager should not report memory pressure")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Disable critical pod annotation feature gate
0000000000000000000000000000000000000000;;		utilfeature.DefaultFeatureGate.Set("ExperimentalCriticalPodAnnotation=False")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// induce memory pressure!
0000000000000000000000000000000000000000;;		fakeClock.Step(1 * time.Minute)
0000000000000000000000000000000000000000;;		summaryProvider.result = summaryStatsMaker("500Mi", podStats)
0000000000000000000000000000000000000000;;		manager.synchronize(diskInfoProvider, activePodsFunc, nodeProvider)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// we should have memory pressure
0000000000000000000000000000000000000000;;		if !manager.IsUnderMemoryPressure() {
0000000000000000000000000000000000000000;;			t.Errorf("Manager should report memory pressure")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// check the right pod was killed
0000000000000000000000000000000000000000;;		if podKiller.pod != podToEvict {
0000000000000000000000000000000000000000;;			t.Errorf("Manager chose to kill pod: %v, but should have chosen %v", podKiller.pod.Name, podToEvict.Name)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// TestAllocatableMemoryPressure
0000000000000000000000000000000000000000;;	func TestAllocatableMemoryPressure(t *testing.T) {
0000000000000000000000000000000000000000;;		podMaker := makePodWithMemoryStats
0000000000000000000000000000000000000000;;		summaryStatsMaker := makeMemoryStats
0000000000000000000000000000000000000000;;		constantCapacity := "4Gi"
0000000000000000000000000000000000000000;;		podsToMake := []podToMake{
0000000000000000000000000000000000000000;;			{name: "guaranteed-low", requests: newResourceList("100m", "1Gi"), limits: newResourceList("100m", "1Gi"), memoryWorkingSet: "200Mi"},
0000000000000000000000000000000000000000;;			{name: "guaranteed-high", requests: newResourceList("100m", "1Gi"), limits: newResourceList("100m", "1Gi"), memoryWorkingSet: "400Mi"},
0000000000000000000000000000000000000000;;			{name: "burstable-low", requests: newResourceList("100m", "100Mi"), limits: newResourceList("200m", "1Gi"), memoryWorkingSet: "300Mi"},
0000000000000000000000000000000000000000;;			{name: "burstable-high", requests: newResourceList("100m", "100Mi"), limits: newResourceList("200m", "1Gi"), memoryWorkingSet: "500Mi"},
0000000000000000000000000000000000000000;;			{name: "best-effort-low", requests: newResourceList("", ""), limits: newResourceList("", ""), memoryWorkingSet: "100Mi"},
0000000000000000000000000000000000000000;;			{name: "best-effort-high", requests: newResourceList("", ""), limits: newResourceList("", ""), memoryWorkingSet: "200Mi"},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		pods := []*v1.Pod{}
0000000000000000000000000000000000000000;;		podStats := map[*v1.Pod]statsapi.PodStats{}
0000000000000000000000000000000000000000;;		for _, podToMake := range podsToMake {
0000000000000000000000000000000000000000;;			pod, podStat := podMaker(podToMake.name, podToMake.requests, podToMake.limits, podToMake.memoryWorkingSet)
0000000000000000000000000000000000000000;;			pods = append(pods, pod)
0000000000000000000000000000000000000000;;			podStats[pod] = podStat
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		podToEvict := pods[5]
0000000000000000000000000000000000000000;;		activePodsFunc := func() []*v1.Pod {
0000000000000000000000000000000000000000;;			return pods
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		fakeClock := clock.NewFakeClock(time.Now())
0000000000000000000000000000000000000000;;		podKiller := &mockPodKiller{}
0000000000000000000000000000000000000000;;		diskInfoProvider := &mockDiskInfoProvider{dedicatedImageFs: false}
0000000000000000000000000000000000000000;;		nodeProvider := newMockNodeProvider(v1.ResourceList{v1.ResourceMemory: *quantityMustParse("2Gi")})
0000000000000000000000000000000000000000;;		diskGC := &mockDiskGC{imageBytesFreed: int64(0), err: nil}
0000000000000000000000000000000000000000;;		nodeRef := &clientv1.ObjectReference{Kind: "Node", Name: "test", UID: types.UID("test"), Namespace: ""}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		config := Config{
0000000000000000000000000000000000000000;;			MaxPodGracePeriodSeconds: 5,
0000000000000000000000000000000000000000;;			PressureTransitionPeriod: time.Minute * 5,
0000000000000000000000000000000000000000;;			Thresholds: []evictionapi.Threshold{
0000000000000000000000000000000000000000;;				{
0000000000000000000000000000000000000000;;					Signal:   evictionapi.SignalAllocatableMemoryAvailable,
0000000000000000000000000000000000000000;;					Operator: evictionapi.OpLessThan,
0000000000000000000000000000000000000000;;					Value: evictionapi.ThresholdValue{
0000000000000000000000000000000000000000;;						Quantity: quantityMustParse("1Ki"),
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		summaryProvider := &fakeSummaryProvider{result: summaryStatsMaker(constantCapacity, podStats)}
0000000000000000000000000000000000000000;;		manager := &managerImpl{
0000000000000000000000000000000000000000;;			clock:           fakeClock,
0000000000000000000000000000000000000000;;			killPodFunc:     podKiller.killPodNow,
0000000000000000000000000000000000000000;;			imageGC:         diskGC,
0000000000000000000000000000000000000000;;			containerGC:     diskGC,
0000000000000000000000000000000000000000;;			config:          config,
0000000000000000000000000000000000000000;;			recorder:        &record.FakeRecorder{},
0000000000000000000000000000000000000000;;			summaryProvider: summaryProvider,
0000000000000000000000000000000000000000;;			nodeRef:         nodeRef,
0000000000000000000000000000000000000000;;			nodeConditionsLastObservedAt: nodeConditionsObservedAt{},
0000000000000000000000000000000000000000;;			thresholdsFirstObservedAt:    thresholdsObservedAt{},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// create a best effort pod to test admission
0000000000000000000000000000000000000000;;		bestEffortPodToAdmit, _ := podMaker("best-admit", newResourceList("", ""), newResourceList("", ""), "0Gi")
0000000000000000000000000000000000000000;;		burstablePodToAdmit, _ := podMaker("burst-admit", newResourceList("100m", "100Mi"), newResourceList("200m", "200Mi"), "0Gi")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// synchronize
0000000000000000000000000000000000000000;;		manager.synchronize(diskInfoProvider, activePodsFunc, nodeProvider)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// we should not have memory pressure
0000000000000000000000000000000000000000;;		if manager.IsUnderMemoryPressure() {
0000000000000000000000000000000000000000;;			t.Errorf("Manager should not report memory pressure")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// try to admit our pods (they should succeed)
0000000000000000000000000000000000000000;;		expected := []bool{true, true}
0000000000000000000000000000000000000000;;		for i, pod := range []*v1.Pod{bestEffortPodToAdmit, burstablePodToAdmit} {
0000000000000000000000000000000000000000;;			if result := manager.Admit(&lifecycle.PodAdmitAttributes{Pod: pod}); expected[i] != result.Admit {
0000000000000000000000000000000000000000;;				t.Errorf("Admit pod: %v, expected: %v, actual: %v", pod, expected[i], result.Admit)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// induce memory pressure!
0000000000000000000000000000000000000000;;		fakeClock.Step(1 * time.Minute)
0000000000000000000000000000000000000000;;		pod, podStat := podMaker("guaranteed-high-2", newResourceList("100m", "1Gi"), newResourceList("100m", "1Gi"), "1Gi")
0000000000000000000000000000000000000000;;		podStats[pod] = podStat
0000000000000000000000000000000000000000;;		summaryProvider.result = summaryStatsMaker(constantCapacity, podStats)
0000000000000000000000000000000000000000;;		manager.synchronize(diskInfoProvider, activePodsFunc, nodeProvider)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// we should have memory pressure
0000000000000000000000000000000000000000;;		if !manager.IsUnderMemoryPressure() {
0000000000000000000000000000000000000000;;			t.Errorf("Manager should report memory pressure")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// check the right pod was killed
0000000000000000000000000000000000000000;;		if podKiller.pod != podToEvict {
0000000000000000000000000000000000000000;;			t.Errorf("Manager chose to kill pod: %v, but should have chosen %v", podKiller.pod.Name, podToEvict.Name)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		observedGracePeriod := *podKiller.gracePeriodOverride
0000000000000000000000000000000000000000;;		if observedGracePeriod != int64(0) {
0000000000000000000000000000000000000000;;			t.Errorf("Manager chose to kill pod with incorrect grace period.  Expected: %d, actual: %d", 0, observedGracePeriod)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		// reset state
0000000000000000000000000000000000000000;;		podKiller.pod = nil
0000000000000000000000000000000000000000;;		podKiller.gracePeriodOverride = nil
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// the best-effort pod should not admit, burstable should
0000000000000000000000000000000000000000;;		expected = []bool{false, true}
0000000000000000000000000000000000000000;;		for i, pod := range []*v1.Pod{bestEffortPodToAdmit, burstablePodToAdmit} {
0000000000000000000000000000000000000000;;			if result := manager.Admit(&lifecycle.PodAdmitAttributes{Pod: pod}); expected[i] != result.Admit {
0000000000000000000000000000000000000000;;				t.Errorf("Admit pod: %v, expected: %v, actual: %v", pod, expected[i], result.Admit)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// reduce memory pressure
0000000000000000000000000000000000000000;;		fakeClock.Step(1 * time.Minute)
0000000000000000000000000000000000000000;;		for pod := range podStats {
0000000000000000000000000000000000000000;;			if pod.Name == "guaranteed-high-2" {
0000000000000000000000000000000000000000;;				delete(podStats, pod)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		summaryProvider.result = summaryStatsMaker(constantCapacity, podStats)
0000000000000000000000000000000000000000;;		podKiller.pod = nil // reset state
0000000000000000000000000000000000000000;;		manager.synchronize(diskInfoProvider, activePodsFunc, nodeProvider)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// we should have memory pressure (because transition period not yet met)
0000000000000000000000000000000000000000;;		if !manager.IsUnderMemoryPressure() {
0000000000000000000000000000000000000000;;			t.Errorf("Manager should report memory pressure")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// no pod should have been killed
0000000000000000000000000000000000000000;;		if podKiller.pod != nil {
0000000000000000000000000000000000000000;;			t.Errorf("Manager chose to kill pod: %v when no pod should have been killed", podKiller.pod.Name)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// the best-effort pod should not admit, burstable should
0000000000000000000000000000000000000000;;		expected = []bool{false, true}
0000000000000000000000000000000000000000;;		for i, pod := range []*v1.Pod{bestEffortPodToAdmit, burstablePodToAdmit} {
0000000000000000000000000000000000000000;;			if result := manager.Admit(&lifecycle.PodAdmitAttributes{Pod: pod}); expected[i] != result.Admit {
0000000000000000000000000000000000000000;;				t.Errorf("Admit pod: %v, expected: %v, actual: %v", pod, expected[i], result.Admit)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// move the clock past transition period to ensure that we stop reporting pressure
0000000000000000000000000000000000000000;;		fakeClock.Step(5 * time.Minute)
0000000000000000000000000000000000000000;;		summaryProvider.result = summaryStatsMaker(constantCapacity, podStats)
0000000000000000000000000000000000000000;;		podKiller.pod = nil // reset state
0000000000000000000000000000000000000000;;		manager.synchronize(diskInfoProvider, activePodsFunc, nodeProvider)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// we should not have memory pressure (because transition period met)
0000000000000000000000000000000000000000;;		if manager.IsUnderMemoryPressure() {
0000000000000000000000000000000000000000;;			t.Errorf("Manager should not report memory pressure")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// no pod should have been killed
0000000000000000000000000000000000000000;;		if podKiller.pod != nil {
0000000000000000000000000000000000000000;;			t.Errorf("Manager chose to kill pod: %v when no pod should have been killed", podKiller.pod.Name)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// all pods should admit now
0000000000000000000000000000000000000000;;		expected = []bool{true, true}
0000000000000000000000000000000000000000;;		for i, pod := range []*v1.Pod{bestEffortPodToAdmit, burstablePodToAdmit} {
0000000000000000000000000000000000000000;;			if result := manager.Admit(&lifecycle.PodAdmitAttributes{Pod: pod}); expected[i] != result.Admit {
0000000000000000000000000000000000000000;;				t.Errorf("Admit pod: %v, expected: %v, actual: %v", pod, expected[i], result.Admit)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
