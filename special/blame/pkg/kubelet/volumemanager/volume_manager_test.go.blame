0000000000000000000000000000000000000000;;	/*
0000000000000000000000000000000000000000;;	Copyright 2016 The Kubernetes Authors.
f793337edef4f0a60617044101051ad183871e88;;	
0000000000000000000000000000000000000000;;	Licensed under the Apache License, Version 2.0 (the "License");
0000000000000000000000000000000000000000;;	you may not use this file except in compliance with the License.
0000000000000000000000000000000000000000;;	You may obtain a copy of the License at
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	    http://www.apache.org/licenses/LICENSE-2.0
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	Unless required by applicable law or agreed to in writing, software
0000000000000000000000000000000000000000;;	distributed under the License is distributed on an "AS IS" BASIS,
0000000000000000000000000000000000000000;;	WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
0000000000000000000000000000000000000000;;	See the License for the specific language governing permissions and
0000000000000000000000000000000000000000;;	limitations under the License.
0000000000000000000000000000000000000000;;	*/
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	package volumemanager
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	import (
0000000000000000000000000000000000000000;;		"os"
0000000000000000000000000000000000000000;;		"reflect"
0000000000000000000000000000000000000000;;		"strconv"
0000000000000000000000000000000000000000;;		"testing"
0000000000000000000000000000000000000000;;		"time"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		"k8s.io/api/core/v1"
0000000000000000000000000000000000000000;;		metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/util/sets"
0000000000000000000000000000000000000000;;		"k8s.io/client-go/tools/record"
0000000000000000000000000000000000000000;;		utiltesting "k8s.io/client-go/util/testing"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/client/clientset_generated/clientset"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/client/clientset_generated/clientset/fake"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/kubelet/config"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/kubelet/configmap"
0000000000000000000000000000000000000000;;		containertest "k8s.io/kubernetes/pkg/kubelet/container/testing"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/kubelet/pod"
0000000000000000000000000000000000000000;;		kubepod "k8s.io/kubernetes/pkg/kubelet/pod"
0000000000000000000000000000000000000000;;		podtest "k8s.io/kubernetes/pkg/kubelet/pod/testing"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/kubelet/secret"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/kubelet/status"
0000000000000000000000000000000000000000;;		statustest "k8s.io/kubernetes/pkg/kubelet/status/testing"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/util/mount"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/volume"
0000000000000000000000000000000000000000;;		volumetest "k8s.io/kubernetes/pkg/volume/testing"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/volume/util/types"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/volume/util/volumehelper"
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	const (
0000000000000000000000000000000000000000;;		testHostname = "test-hostname"
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestGetMountedVolumesForPodAndGetVolumesInUse(t *testing.T) {
0000000000000000000000000000000000000000;;		tmpDir, err := utiltesting.MkTmpdir("volumeManagerTest")
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			t.Fatalf("can't make a temp dir: %v", err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		defer os.RemoveAll(tmpDir)
0000000000000000000000000000000000000000;;		podManager := kubepod.NewBasicPodManager(podtest.NewFakeMirrorClient(), secret.NewFakeManager(), configmap.NewFakeManager())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		node, pod, pv, claim := createObjects()
0000000000000000000000000000000000000000;;		kubeClient := fake.NewSimpleClientset(node, pod, pv, claim)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		manager := newTestVolumeManager(tmpDir, podManager, kubeClient)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		stopCh := runVolumeManager(manager)
0000000000000000000000000000000000000000;;		defer close(stopCh)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		podManager.SetPods([]*v1.Pod{pod})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Fake node status update
0000000000000000000000000000000000000000;;		go simulateVolumeInUseUpdate(
0000000000000000000000000000000000000000;;			v1.UniqueVolumeName(node.Status.VolumesAttached[0].Name),
0000000000000000000000000000000000000000;;			stopCh,
0000000000000000000000000000000000000000;;			manager)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		err = manager.WaitForAttachAndMount(pod)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			t.Errorf("Expected success: %v", err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		expectedMounted := pod.Spec.Volumes[0].Name
0000000000000000000000000000000000000000;;		actualMounted := manager.GetMountedVolumesForPod(types.UniquePodName(pod.ObjectMeta.UID))
0000000000000000000000000000000000000000;;		if _, ok := actualMounted[expectedMounted]; !ok || (len(actualMounted) != 1) {
0000000000000000000000000000000000000000;;			t.Errorf("Expected %v to be mounted to pod but got %v", expectedMounted, actualMounted)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		expectedInUse := []v1.UniqueVolumeName{v1.UniqueVolumeName(node.Status.VolumesAttached[0].Name)}
0000000000000000000000000000000000000000;;		actualInUse := manager.GetVolumesInUse()
0000000000000000000000000000000000000000;;		if !reflect.DeepEqual(expectedInUse, actualInUse) {
0000000000000000000000000000000000000000;;			t.Errorf("Expected %v to be in use but got %v", expectedInUse, actualInUse)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestInitialPendingVolumesForPodAndGetVolumesInUse(t *testing.T) {
0000000000000000000000000000000000000000;;		tmpDir, err := utiltesting.MkTmpdir("volumeManagerTest")
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			t.Fatalf("can't make a temp dir: %v", err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		defer os.RemoveAll(tmpDir)
0000000000000000000000000000000000000000;;		podManager := kubepod.NewBasicPodManager(podtest.NewFakeMirrorClient(), secret.NewFakeManager(), configmap.NewFakeManager())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		node, pod, pv, claim := createObjects()
0000000000000000000000000000000000000000;;		claim.Status = v1.PersistentVolumeClaimStatus{
0000000000000000000000000000000000000000;;			Phase: v1.ClaimPending,
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		kubeClient := fake.NewSimpleClientset(node, pod, pv, claim)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		manager := newTestVolumeManager(tmpDir, podManager, kubeClient)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		stopCh := runVolumeManager(manager)
0000000000000000000000000000000000000000;;		defer close(stopCh)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		podManager.SetPods([]*v1.Pod{pod})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Fake node status update
0000000000000000000000000000000000000000;;		go simulateVolumeInUseUpdate(
0000000000000000000000000000000000000000;;			v1.UniqueVolumeName(node.Status.VolumesAttached[0].Name),
0000000000000000000000000000000000000000;;			stopCh,
0000000000000000000000000000000000000000;;			manager)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// delayed claim binding
0000000000000000000000000000000000000000;;		go delayClaimBecomesBound(kubeClient, claim.GetNamespace(), claim.ObjectMeta.Name)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		err = manager.WaitForAttachAndMount(pod)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			t.Errorf("Expected success: %v", err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func TestGetExtraSupplementalGroupsForPod(t *testing.T) {
0000000000000000000000000000000000000000;;		tmpDir, err := utiltesting.MkTmpdir("volumeManagerTest")
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			t.Fatalf("can't make a temp dir: %v", err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		defer os.RemoveAll(tmpDir)
0000000000000000000000000000000000000000;;		podManager := kubepod.NewBasicPodManager(podtest.NewFakeMirrorClient(), secret.NewFakeManager(), configmap.NewFakeManager())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		node, pod, _, claim := createObjects()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		existingGid := pod.Spec.SecurityContext.SupplementalGroups[0]
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		cases := []struct {
0000000000000000000000000000000000000000;;			gidAnnotation string
0000000000000000000000000000000000000000;;			expected      []int64
0000000000000000000000000000000000000000;;		}{
0000000000000000000000000000000000000000;;			{
0000000000000000000000000000000000000000;;				gidAnnotation: "777",
0000000000000000000000000000000000000000;;				expected:      []int64{777},
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			{
0000000000000000000000000000000000000000;;				gidAnnotation: strconv.FormatInt(int64(existingGid), 10),
0000000000000000000000000000000000000000;;				expected:      []int64{},
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			{
0000000000000000000000000000000000000000;;				gidAnnotation: "a",
0000000000000000000000000000000000000000;;				expected:      []int64{},
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			{
0000000000000000000000000000000000000000;;				gidAnnotation: "",
0000000000000000000000000000000000000000;;				expected:      []int64{},
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		for _, tc := range cases {
0000000000000000000000000000000000000000;;			pv := &v1.PersistentVolume{
0000000000000000000000000000000000000000;;				ObjectMeta: metav1.ObjectMeta{
0000000000000000000000000000000000000000;;					Name: "pvA",
0000000000000000000000000000000000000000;;					Annotations: map[string]string{
0000000000000000000000000000000000000000;;						volumehelper.VolumeGidAnnotationKey: tc.gidAnnotation,
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;				Spec: v1.PersistentVolumeSpec{
0000000000000000000000000000000000000000;;					PersistentVolumeSource: v1.PersistentVolumeSource{
0000000000000000000000000000000000000000;;						GCEPersistentDisk: &v1.GCEPersistentDiskVolumeSource{
0000000000000000000000000000000000000000;;							PDName: "fake-device",
0000000000000000000000000000000000000000;;						},
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;					ClaimRef: &v1.ObjectReference{
0000000000000000000000000000000000000000;;						Name: claim.ObjectMeta.Name,
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			kubeClient := fake.NewSimpleClientset(node, pod, pv, claim)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			manager := newTestVolumeManager(tmpDir, podManager, kubeClient)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			stopCh := runVolumeManager(manager)
0000000000000000000000000000000000000000;;			defer func() {
0000000000000000000000000000000000000000;;				close(stopCh)
0000000000000000000000000000000000000000;;			}()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			podManager.SetPods([]*v1.Pod{pod})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Fake node status update
0000000000000000000000000000000000000000;;			go simulateVolumeInUseUpdate(
0000000000000000000000000000000000000000;;				v1.UniqueVolumeName(node.Status.VolumesAttached[0].Name),
0000000000000000000000000000000000000000;;				stopCh,
0000000000000000000000000000000000000000;;				manager)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			err = manager.WaitForAttachAndMount(pod)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				t.Errorf("Expected success: %v", err)
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			actual := manager.GetExtraSupplementalGroupsForPod(pod)
0000000000000000000000000000000000000000;;			if !reflect.DeepEqual(tc.expected, actual) {
0000000000000000000000000000000000000000;;				t.Errorf("Expected supplemental groups %v, got %v", tc.expected, actual)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func newTestVolumeManager(tmpDir string, podManager pod.Manager, kubeClient clientset.Interface) VolumeManager {
0000000000000000000000000000000000000000;;		plug := &volumetest.FakeVolumePlugin{PluginName: "fake", Host: nil}
0000000000000000000000000000000000000000;;		fakeRecorder := &record.FakeRecorder{}
0000000000000000000000000000000000000000;;		plugMgr := &volume.VolumePluginMgr{}
0000000000000000000000000000000000000000;;		plugMgr.InitPlugins([]volume.VolumePlugin{plug}, volumetest.NewFakeVolumeHost(tmpDir, kubeClient, nil))
0000000000000000000000000000000000000000;;		statusManager := status.NewManager(kubeClient, podManager, &statustest.FakePodDeletionSafetyProvider{})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		vm := NewVolumeManager(
0000000000000000000000000000000000000000;;			true,
0000000000000000000000000000000000000000;;			testHostname,
0000000000000000000000000000000000000000;;			podManager,
0000000000000000000000000000000000000000;;			statusManager,
0000000000000000000000000000000000000000;;			kubeClient,
0000000000000000000000000000000000000000;;			plugMgr,
0000000000000000000000000000000000000000;;			&containertest.FakeRuntime{},
0000000000000000000000000000000000000000;;			&mount.FakeMounter{},
0000000000000000000000000000000000000000;;			"",
0000000000000000000000000000000000000000;;			fakeRecorder,
0000000000000000000000000000000000000000;;			false, /* experimentalCheckNodeCapabilitiesBeforeMount */
0000000000000000000000000000000000000000;;			false /* keepTerminatedPodVolumes */)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return vm
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// createObjects returns objects for making a fake clientset. The pv is
0000000000000000000000000000000000000000;;	// already attached to the node and bound to the claim used by the pod.
0000000000000000000000000000000000000000;;	func createObjects() (*v1.Node, *v1.Pod, *v1.PersistentVolume, *v1.PersistentVolumeClaim) {
0000000000000000000000000000000000000000;;		node := &v1.Node{
0000000000000000000000000000000000000000;;			ObjectMeta: metav1.ObjectMeta{Name: testHostname},
0000000000000000000000000000000000000000;;			Status: v1.NodeStatus{
0000000000000000000000000000000000000000;;				VolumesAttached: []v1.AttachedVolume{
0000000000000000000000000000000000000000;;					{
0000000000000000000000000000000000000000;;						Name:       "fake/pvA",
0000000000000000000000000000000000000000;;						DevicePath: "fake/path",
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;				}},
0000000000000000000000000000000000000000;;			Spec: v1.NodeSpec{ExternalID: testHostname},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		pod := &v1.Pod{
0000000000000000000000000000000000000000;;			ObjectMeta: metav1.ObjectMeta{
0000000000000000000000000000000000000000;;				Name:      "abc",
0000000000000000000000000000000000000000;;				Namespace: "nsA",
0000000000000000000000000000000000000000;;				UID:       "1234",
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			Spec: v1.PodSpec{
0000000000000000000000000000000000000000;;				Volumes: []v1.Volume{
0000000000000000000000000000000000000000;;					{
0000000000000000000000000000000000000000;;						Name: "vol1",
0000000000000000000000000000000000000000;;						VolumeSource: v1.VolumeSource{
0000000000000000000000000000000000000000;;							PersistentVolumeClaim: &v1.PersistentVolumeClaimVolumeSource{
0000000000000000000000000000000000000000;;								ClaimName: "claimA",
0000000000000000000000000000000000000000;;							},
0000000000000000000000000000000000000000;;						},
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;				SecurityContext: &v1.PodSecurityContext{
0000000000000000000000000000000000000000;;					SupplementalGroups: []int64{555},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		pv := &v1.PersistentVolume{
0000000000000000000000000000000000000000;;			ObjectMeta: metav1.ObjectMeta{
0000000000000000000000000000000000000000;;				Name: "pvA",
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			Spec: v1.PersistentVolumeSpec{
0000000000000000000000000000000000000000;;				PersistentVolumeSource: v1.PersistentVolumeSource{
0000000000000000000000000000000000000000;;					GCEPersistentDisk: &v1.GCEPersistentDiskVolumeSource{
0000000000000000000000000000000000000000;;						PDName: "fake-device",
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;				ClaimRef: &v1.ObjectReference{
0000000000000000000000000000000000000000;;					Name: "claimA",
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		claim := &v1.PersistentVolumeClaim{
0000000000000000000000000000000000000000;;			ObjectMeta: metav1.ObjectMeta{
0000000000000000000000000000000000000000;;				Name:      "claimA",
0000000000000000000000000000000000000000;;				Namespace: "nsA",
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			Spec: v1.PersistentVolumeClaimSpec{
0000000000000000000000000000000000000000;;				VolumeName: "pvA",
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			Status: v1.PersistentVolumeClaimStatus{
0000000000000000000000000000000000000000;;				Phase: v1.ClaimBound,
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return node, pod, pv, claim
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func simulateVolumeInUseUpdate(volumeName v1.UniqueVolumeName, stopCh <-chan struct{}, volumeManager VolumeManager) {
0000000000000000000000000000000000000000;;		ticker := time.NewTicker(100 * time.Millisecond)
0000000000000000000000000000000000000000;;		defer ticker.Stop()
0000000000000000000000000000000000000000;;		for {
0000000000000000000000000000000000000000;;			select {
0000000000000000000000000000000000000000;;			case <-ticker.C:
0000000000000000000000000000000000000000;;				volumeManager.MarkVolumesAsReportedInUse(
0000000000000000000000000000000000000000;;					[]v1.UniqueVolumeName{volumeName})
0000000000000000000000000000000000000000;;			case <-stopCh:
0000000000000000000000000000000000000000;;				return
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func delayClaimBecomesBound(
0000000000000000000000000000000000000000;;		kubeClient clientset.Interface,
0000000000000000000000000000000000000000;;		namespace, claimName string,
0000000000000000000000000000000000000000;;	) {
0000000000000000000000000000000000000000;;		time.Sleep(500 * time.Millisecond)
0000000000000000000000000000000000000000;;		volumeClaim, _ :=
0000000000000000000000000000000000000000;;			kubeClient.Core().PersistentVolumeClaims(namespace).Get(claimName, metav1.GetOptions{})
0000000000000000000000000000000000000000;;		volumeClaim.Status = v1.PersistentVolumeClaimStatus{
0000000000000000000000000000000000000000;;			Phase: v1.ClaimBound,
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		kubeClient.Core().PersistentVolumeClaims(namespace).Update(volumeClaim)
0000000000000000000000000000000000000000;;		return
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func runVolumeManager(manager VolumeManager) chan struct{} {
0000000000000000000000000000000000000000;;		stopCh := make(chan struct{})
0000000000000000000000000000000000000000;;		//readyCh := make(chan bool, 1)
0000000000000000000000000000000000000000;;		//readyCh <- true
0000000000000000000000000000000000000000;;		sourcesReady := config.NewSourcesReady(func(_ sets.String) bool { return true })
0000000000000000000000000000000000000000;;		go manager.Run(sourcesReady, stopCh)
0000000000000000000000000000000000000000;;		return stopCh
0000000000000000000000000000000000000000;;	}
