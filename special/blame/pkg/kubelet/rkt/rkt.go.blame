0000000000000000000000000000000000000000;;	/*
0000000000000000000000000000000000000000;;	Copyright 2015 The Kubernetes Authors.
09b65755e0f47b4458a86fda51603b2414965cf1;;	
0000000000000000000000000000000000000000;;	Licensed under the Apache License, Version 2.0 (the "License");
0000000000000000000000000000000000000000;;	you may not use this file except in compliance with the License.
0000000000000000000000000000000000000000;;	You may obtain a copy of the License at
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	    http://www.apache.org/licenses/LICENSE-2.0
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	Unless required by applicable law or agreed to in writing, software
0000000000000000000000000000000000000000;;	distributed under the License is distributed on an "AS IS" BASIS,
0000000000000000000000000000000000000000;;	WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
0000000000000000000000000000000000000000;;	See the License for the specific language governing permissions and
0000000000000000000000000000000000000000;;	limitations under the License.
0000000000000000000000000000000000000000;;	*/
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	package rkt
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	import (
0000000000000000000000000000000000000000;;		"bufio"
0000000000000000000000000000000000000000;;		"bytes"
0000000000000000000000000000000000000000;;		"encoding/json"
0000000000000000000000000000000000000000;;		"fmt"
0000000000000000000000000000000000000000;;		"io"
0000000000000000000000000000000000000000;;		"io/ioutil"
0000000000000000000000000000000000000000;;		"os"
0000000000000000000000000000000000000000;;		"os/exec"
0000000000000000000000000000000000000000;;		"path"
0000000000000000000000000000000000000000;;		"path/filepath"
0000000000000000000000000000000000000000;;		"sort"
0000000000000000000000000000000000000000;;		"strconv"
0000000000000000000000000000000000000000;;		"strings"
0000000000000000000000000000000000000000;;		"sync"
0000000000000000000000000000000000000000;;		"syscall"
0000000000000000000000000000000000000000;;		"time"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		appcschema "github.com/appc/spec/schema"
0000000000000000000000000000000000000000;;		appctypes "github.com/appc/spec/schema/types"
0000000000000000000000000000000000000000;;		"github.com/coreos/go-systemd/unit"
0000000000000000000000000000000000000000;;		rktapi "github.com/coreos/rkt/api/v1alpha"
0000000000000000000000000000000000000000;;		"github.com/golang/glog"
0000000000000000000000000000000000000000;;		"golang.org/x/net/context"
0000000000000000000000000000000000000000;;		"google.golang.org/grpc"
0000000000000000000000000000000000000000;;		"k8s.io/api/core/v1"
0000000000000000000000000000000000000000;;		metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
0000000000000000000000000000000000000000;;		kubetypes "k8s.io/apimachinery/pkg/types"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/util/errors"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/util/uuid"
0000000000000000000000000000000000000000;;		utilwait "k8s.io/apimachinery/pkg/util/wait"
0000000000000000000000000000000000000000;;		"k8s.io/client-go/tools/record"
0000000000000000000000000000000000000000;;		"k8s.io/client-go/tools/remotecommand"
0000000000000000000000000000000000000000;;		"k8s.io/client-go/util/flowcontrol"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/credentialprovider"
0000000000000000000000000000000000000000;;		kubecontainer "k8s.io/kubernetes/pkg/kubelet/container"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/kubelet/events"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/kubelet/images"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/kubelet/leaky"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/kubelet/lifecycle"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/kubelet/network"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/kubelet/network/hairpin"
0000000000000000000000000000000000000000;;		proberesults "k8s.io/kubernetes/pkg/kubelet/prober/results"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/kubelet/types"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/kubelet/util/format"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/securitycontext"
0000000000000000000000000000000000000000;;		utilexec "k8s.io/kubernetes/pkg/util/exec"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/util/selinux"
0000000000000000000000000000000000000000;;		utilstrings "k8s.io/kubernetes/pkg/util/strings"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/util/term"
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	const (
0000000000000000000000000000000000000000;;		RktType                      = "rkt"
0000000000000000000000000000000000000000;;		DefaultRktAPIServiceEndpoint = "localhost:15441"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		minimumRktBinVersion = "1.13.0"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		minimumRktApiVersion  = "1.0.0-alpha"
0000000000000000000000000000000000000000;;		minimumSystemdVersion = "219"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		systemdServiceDir = "/run/systemd/system"
0000000000000000000000000000000000000000;;		rktDataDir        = "/var/lib/rkt"
0000000000000000000000000000000000000000;;		rktLocalConfigDir = "/etc/rkt"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		kubernetesUnitPrefix    = "k8s_"
0000000000000000000000000000000000000000;;		unitKubernetesSection   = "X-Kubernetes"
0000000000000000000000000000000000000000;;		unitPodUID              = "PodUID"
0000000000000000000000000000000000000000;;		unitPodName             = "PodName"
0000000000000000000000000000000000000000;;		unitPodNamespace        = "PodNamespace"
0000000000000000000000000000000000000000;;		unitPodHostNetwork      = "PodHostNetwork"
0000000000000000000000000000000000000000;;		unitPodNetworkNamespace = "PodNetworkNamespace"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		k8sRktKubeletAnno                = "rkt.kubernetes.io/managed-by-kubelet"
0000000000000000000000000000000000000000;;		k8sRktKubeletAnnoValue           = "true"
0000000000000000000000000000000000000000;;		k8sRktContainerHashAnno          = "rkt.kubernetes.io/container-hash"
0000000000000000000000000000000000000000;;		k8sRktRestartCountAnno           = "rkt.kubernetes.io/restart-count"
0000000000000000000000000000000000000000;;		k8sRktTerminationMessagePathAnno = "rkt.kubernetes.io/termination-message-path"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		k8sRktLimitNoFileAnno = "systemd-unit-option.rkt.kubernetes.io/LimitNOFILE"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// TODO(euank): This has significant security concerns as a stage1 image is
0000000000000000000000000000000000000000;;		// effectively root.
0000000000000000000000000000000000000000;;		// Furthermore, this (using an annotation) is a hack to pass an extra
0000000000000000000000000000000000000000;;		// non-portable argument in. It should not be relied on to be stable.
0000000000000000000000000000000000000000;;		// In the future, this might be subsumed by a first-class api object, or by a
0000000000000000000000000000000000000000;;		// kitchen-sink params object (#17064).
0000000000000000000000000000000000000000;;		// See discussion in #23944
0000000000000000000000000000000000000000;;		// Also, do we want more granularity than path-at-the-kubelet-level and
0000000000000000000000000000000000000000;;		// image/name-at-the-pod-level?
0000000000000000000000000000000000000000;;		k8sRktStage1NameAnno = "rkt.alpha.kubernetes.io/stage1-name-override"
0000000000000000000000000000000000000000;;		dockerPrefix         = "docker://"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		authDir            = "auth.d"
0000000000000000000000000000000000000000;;		dockerAuthTemplate = `{"rktKind":"dockerAuth","rktVersion":"v1","registries":[%q],"credentials":{"user":%q,"password":%q}}`
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		defaultRktAPIServiceAddr = "localhost:15441"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// ndots specifies the minimum number of dots that a domain name must contain for the resolver to consider it as FQDN (fully-qualified)
0000000000000000000000000000000000000000;;		// we want to able to consider SRV lookup names like _dns._udp.kube-dns.default.svc to be considered relative.
0000000000000000000000000000000000000000;;		// hence, setting ndots to be 5.
0000000000000000000000000000000000000000;;		// TODO(yifan): Move this and dockertools.ndotsDNSOption to a common package.
0000000000000000000000000000000000000000;;		defaultDNSOption = "ndots:5"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Annotations for the ENTRYPOINT and CMD for an ACI that's converted from Docker image.
0000000000000000000000000000000000000000;;		// Taken from https://github.com/appc/docker2aci/blob/v0.12.3/lib/common/common.go#L33
0000000000000000000000000000000000000000;;		appcDockerEntrypoint  = "appc.io/docker/entrypoint"
0000000000000000000000000000000000000000;;		appcDockerCmd         = "appc.io/docker/cmd"
0000000000000000000000000000000000000000;;		appcDockerRegistryURL = "appc.io/docker/registryurl"
0000000000000000000000000000000000000000;;		appcDockerRepository  = "appc.io/docker/repository"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// TODO(yifan): Reuse this const with Docker runtime.
0000000000000000000000000000000000000000;;		minimumGracePeriodInSeconds = 2
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// The network name of the network when no-op plugin is being used.
0000000000000000000000000000000000000000;;		// TODO(yifan): This is not ideal since today we cannot make the rkt's 'net.d' dir point to the
0000000000000000000000000000000000000000;;		// CNI directory specified by kubelet. Once that is fixed, we can just use the network config
0000000000000000000000000000000000000000;;		// under the CNI directory directly.
0000000000000000000000000000000000000000;;		// See https://github.com/coreos/rkt/pull/2312#issuecomment-200068370.
0000000000000000000000000000000000000000;;		defaultNetworkName = "rkt.kubernetes.io"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// defaultRequestTimeout is the default timeout of rkt requests.
0000000000000000000000000000000000000000;;		// Value is slightly offset from 2 minutes to make timeouts due to this
0000000000000000000000000000000000000000;;		// constant recognizable.
0000000000000000000000000000000000000000;;		defaultRequestTimeout = 2*time.Minute - 1*time.Second
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		etcHostsPath      = "/etc/hosts"
0000000000000000000000000000000000000000;;		etcResolvConfPath = "/etc/resolv.conf"
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Runtime implements the Containerruntime for rkt. The implementation
0000000000000000000000000000000000000000;;	// uses systemd, so in order to run this runtime, systemd must be installed
0000000000000000000000000000000000000000;;	// on the machine.
0000000000000000000000000000000000000000;;	type Runtime struct {
0000000000000000000000000000000000000000;;		cli     cliInterface
0000000000000000000000000000000000000000;;		systemd systemdInterface
0000000000000000000000000000000000000000;;		// The grpc client for rkt api-service.
0000000000000000000000000000000000000000;;		apisvcConn *grpc.ClientConn
0000000000000000000000000000000000000000;;		apisvc     rktapi.PublicAPIClient
0000000000000000000000000000000000000000;;		config     *Config
0000000000000000000000000000000000000000;;		// TODO(yifan): Refactor this to be generic keyring.
0000000000000000000000000000000000000000;;		dockerKeyring credentialprovider.DockerKeyring
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		containerRefManager *kubecontainer.RefManager
0000000000000000000000000000000000000000;;		podGetter           podGetter
0000000000000000000000000000000000000000;;		runtimeHelper       kubecontainer.RuntimeHelper
0000000000000000000000000000000000000000;;		recorder            record.EventRecorder
0000000000000000000000000000000000000000;;		livenessManager     proberesults.Manager
0000000000000000000000000000000000000000;;		imagePuller         images.ImageManager
0000000000000000000000000000000000000000;;		runner              kubecontainer.HandlerRunner
0000000000000000000000000000000000000000;;		execer              utilexec.Interface
0000000000000000000000000000000000000000;;		os                  kubecontainer.OSInterface
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Network plugin manager.
0000000000000000000000000000000000000000;;		network *network.PluginManager
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// If true, the "hairpin mode" flag is set on container interfaces.
0000000000000000000000000000000000000000;;		// A false value means the kubelet just backs off from setting it,
0000000000000000000000000000000000000000;;		// it might already be true.
0000000000000000000000000000000000000000;;		configureHairpinMode bool
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// used for a systemd Exec, which requires the full path.
0000000000000000000000000000000000000000;;		touchPath   string
0000000000000000000000000000000000000000;;		nsenterPath string
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		versions versions
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// requestTimeout is the timeout of rkt requests.
0000000000000000000000000000000000000000;;		requestTimeout time.Duration
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		unitGetter unitServiceGetter
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Field of the X-Kubernetes directive of a systemd service file
0000000000000000000000000000000000000000;;	type podServiceDirective struct {
0000000000000000000000000000000000000000;;		id               string
0000000000000000000000000000000000000000;;		name             string
0000000000000000000000000000000000000000;;		namespace        string
0000000000000000000000000000000000000000;;		hostNetwork      bool
0000000000000000000000000000000000000000;;		networkNamespace kubecontainer.ContainerID
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	var _ kubecontainer.Runtime = &Runtime{}
0000000000000000000000000000000000000000;;	var _ kubecontainer.DirectStreamingRuntime = &Runtime{}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// TODO(yifan): This duplicates the podGetter in dockertools.
0000000000000000000000000000000000000000;;	type podGetter interface {
0000000000000000000000000000000000000000;;		GetPodByUID(kubetypes.UID) (*v1.Pod, bool)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// cliInterface wrapps the command line calls for testing purpose.
0000000000000000000000000000000000000000;;	type cliInterface interface {
0000000000000000000000000000000000000000;;		// RunCommand creates rkt commands and runs it with the given config.
0000000000000000000000000000000000000000;;		// If the config is nil, it will use the one inferred from rkt API service.
0000000000000000000000000000000000000000;;		RunCommand(config *Config, args ...string) (result []string, err error)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// unitServiceGetter wrapps the systemd open files for testing purpose
0000000000000000000000000000000000000000;;	type unitServiceGetter interface {
0000000000000000000000000000000000000000;;		getKubernetesDirective(string) (podServiceDirective, error)
0000000000000000000000000000000000000000;;		getNetworkNamespace(kubetypes.UID, *rktapi.Pod) (kubecontainer.ContainerID, error)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// New creates the rkt container runtime which implements the container runtime interface.
0000000000000000000000000000000000000000;;	// It will test if the rkt binary is in the $PATH, and whether we can get the
0000000000000000000000000000000000000000;;	// version of it. If so, creates the rkt container runtime, otherwise returns an error.
0000000000000000000000000000000000000000;;	func New(
0000000000000000000000000000000000000000;;		apiEndpoint string,
0000000000000000000000000000000000000000;;		config *Config,
0000000000000000000000000000000000000000;;		runtimeHelper kubecontainer.RuntimeHelper,
0000000000000000000000000000000000000000;;		recorder record.EventRecorder,
0000000000000000000000000000000000000000;;		containerRefManager *kubecontainer.RefManager,
0000000000000000000000000000000000000000;;		podGetter podGetter,
0000000000000000000000000000000000000000;;		livenessManager proberesults.Manager,
0000000000000000000000000000000000000000;;		httpClient types.HttpGetter,
0000000000000000000000000000000000000000;;		networkPlugin network.NetworkPlugin,
0000000000000000000000000000000000000000;;		hairpinMode bool,
0000000000000000000000000000000000000000;;		execer utilexec.Interface,
0000000000000000000000000000000000000000;;		os kubecontainer.OSInterface,
0000000000000000000000000000000000000000;;		imageBackOff *flowcontrol.Backoff,
0000000000000000000000000000000000000000;;		serializeImagePulls bool,
0000000000000000000000000000000000000000;;		imagePullQPS float32,
0000000000000000000000000000000000000000;;		imagePullBurst int,
0000000000000000000000000000000000000000;;		requestTimeout time.Duration,
0000000000000000000000000000000000000000;;	) (*Runtime, error) {
0000000000000000000000000000000000000000;;		// Create dbus connection.
0000000000000000000000000000000000000000;;		systemd, err := newSystemd()
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return nil, fmt.Errorf("rkt: cannot create systemd interface: %v", err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// TODO(yifan): Use secure connection.
0000000000000000000000000000000000000000;;		apisvcConn, err := grpc.Dial(apiEndpoint, grpc.WithInsecure())
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return nil, fmt.Errorf("rkt: cannot connect to rkt api service: %v", err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// TODO(yifan): Get the rkt path from API service.
0000000000000000000000000000000000000000;;		if config.Path == "" {
0000000000000000000000000000000000000000;;			// No default rkt path was set, so try to find one in $PATH.
0000000000000000000000000000000000000000;;			var err error
0000000000000000000000000000000000000000;;			config.Path, err = execer.LookPath("rkt")
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				return nil, fmt.Errorf("cannot find rkt binary: %v", err)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		touchPath, err := execer.LookPath("touch")
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return nil, fmt.Errorf("cannot find touch binary: %v", err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		nsenterPath, err := execer.LookPath("nsenter")
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return nil, fmt.Errorf("cannot find nsenter binary: %v", err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if requestTimeout == 0 {
0000000000000000000000000000000000000000;;			requestTimeout = defaultRequestTimeout
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		rkt := &Runtime{
0000000000000000000000000000000000000000;;			os:                  kubecontainer.RealOS{},
0000000000000000000000000000000000000000;;			systemd:             systemd,
0000000000000000000000000000000000000000;;			apisvcConn:          apisvcConn,
0000000000000000000000000000000000000000;;			apisvc:              rktapi.NewPublicAPIClient(apisvcConn),
0000000000000000000000000000000000000000;;			config:              config,
0000000000000000000000000000000000000000;;			dockerKeyring:       credentialprovider.NewDockerKeyring(),
0000000000000000000000000000000000000000;;			containerRefManager: containerRefManager,
0000000000000000000000000000000000000000;;			podGetter:           podGetter,
0000000000000000000000000000000000000000;;			runtimeHelper:       runtimeHelper,
0000000000000000000000000000000000000000;;			recorder:            recorder,
0000000000000000000000000000000000000000;;			livenessManager:     livenessManager,
0000000000000000000000000000000000000000;;			network:             network.NewPluginManager(networkPlugin),
0000000000000000000000000000000000000000;;			execer:              execer,
0000000000000000000000000000000000000000;;			touchPath:           touchPath,
0000000000000000000000000000000000000000;;			nsenterPath:         nsenterPath,
0000000000000000000000000000000000000000;;			requestTimeout:      requestTimeout,
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		rkt.config, err = rkt.getConfig(rkt.config)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return nil, fmt.Errorf("rkt: cannot get config from rkt api service: %v", err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		cmdRunner := kubecontainer.DirectStreamingRunner(rkt)
0000000000000000000000000000000000000000;;		rkt.runner = lifecycle.NewHandlerRunner(httpClient, cmdRunner, rkt)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		rkt.imagePuller = images.NewImageManager(recorder, rkt, imageBackOff, serializeImagePulls, imagePullQPS, imagePullBurst)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if err := rkt.getVersions(); err != nil {
0000000000000000000000000000000000000000;;			return nil, fmt.Errorf("rkt: error getting version info: %v", err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		rkt.cli = rkt
0000000000000000000000000000000000000000;;		rkt.unitGetter = rkt
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return rkt, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func buildCommand(config *Config, args ...string) *exec.Cmd {
0000000000000000000000000000000000000000;;		cmd := exec.Command(config.Path)
0000000000000000000000000000000000000000;;		cmd.Args = append(cmd.Args, config.buildGlobalOptions()...)
0000000000000000000000000000000000000000;;		cmd.Args = append(cmd.Args, args...)
0000000000000000000000000000000000000000;;		return cmd
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// convertToACName converts a string into ACName.
0000000000000000000000000000000000000000;;	func convertToACName(name string) appctypes.ACName {
0000000000000000000000000000000000000000;;		// Note that as the 'name' already matches 'DNS_LABEL'
0000000000000000000000000000000000000000;;		// defined in pkg/api/types.go, there shouldn't be error or panic.
0000000000000000000000000000000000000000;;		acname, _ := appctypes.SanitizeACName(name)
0000000000000000000000000000000000000000;;		return *appctypes.MustACName(acname)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// RunCommand invokes rkt binary with arguments and returns the result
0000000000000000000000000000000000000000;;	// from stdout in a list of strings. Each string in the list is a line.
0000000000000000000000000000000000000000;;	// If config is non-nil, it will use the given config instead of the config
0000000000000000000000000000000000000000;;	// inferred from rkt API service.
0000000000000000000000000000000000000000;;	func (r *Runtime) RunCommand(config *Config, args ...string) ([]string, error) {
0000000000000000000000000000000000000000;;		if config == nil {
0000000000000000000000000000000000000000;;			config = r.config
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		glog.V(4).Infof("rkt: Run command: %q with config: %#v", args, config)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		var stdout, stderr bytes.Buffer
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		cmd := buildCommand(config, args...)
0000000000000000000000000000000000000000;;		cmd.Stdout, cmd.Stderr = &stdout, &stderr
0000000000000000000000000000000000000000;;		if err := cmd.Run(); err != nil {
0000000000000000000000000000000000000000;;			return nil, fmt.Errorf("failed to run %v: %v\nstdout: %v\nstderr: %v", args, err, stdout.String(), stderr.String())
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return strings.Split(strings.TrimSpace(stdout.String()), "\n"), nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// makePodServiceFileName constructs the unit file name for a pod using its rkt pod uuid.
0000000000000000000000000000000000000000;;	func makePodServiceFileName(uuid string) string {
0000000000000000000000000000000000000000;;		// TODO(yifan): Add name for readability? We need to consider the
0000000000000000000000000000000000000000;;		// limit of the length.
0000000000000000000000000000000000000000;;		return fmt.Sprintf("%s%s.service", kubernetesUnitPrefix, uuid)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func getRktUUIDFromServiceFileName(filename string) string {
0000000000000000000000000000000000000000;;		return strings.TrimPrefix(strings.TrimSuffix(filename, path.Ext(filename)), kubernetesUnitPrefix)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// setIsolators sets the apps' isolators according to the security context and resource spec.
0000000000000000000000000000000000000000;;	func setIsolators(app *appctypes.App, c *v1.Container, ctx *v1.SecurityContext) error {
0000000000000000000000000000000000000000;;		var isolators []appctypes.Isolator
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Capabilities isolators.
0000000000000000000000000000000000000000;;		if ctx != nil {
0000000000000000000000000000000000000000;;			var addCaps, dropCaps []string
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			if ctx.Capabilities != nil {
0000000000000000000000000000000000000000;;				addCaps, dropCaps = kubecontainer.MakeCapabilities(ctx.Capabilities.Add, ctx.Capabilities.Drop)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if ctx.Privileged != nil && *ctx.Privileged {
0000000000000000000000000000000000000000;;				addCaps, dropCaps = allCapabilities(), []string{}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if len(addCaps) > 0 {
0000000000000000000000000000000000000000;;				set, err := appctypes.NewLinuxCapabilitiesRetainSet(addCaps...)
0000000000000000000000000000000000000000;;				if err != nil {
0000000000000000000000000000000000000000;;					return err
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				isolator, err := set.AsIsolator()
0000000000000000000000000000000000000000;;				if err != nil {
0000000000000000000000000000000000000000;;					return err
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				isolators = append(isolators, *isolator)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if len(dropCaps) > 0 {
0000000000000000000000000000000000000000;;				set, err := appctypes.NewLinuxCapabilitiesRevokeSet(dropCaps...)
0000000000000000000000000000000000000000;;				if err != nil {
0000000000000000000000000000000000000000;;					return err
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				isolator, err := set.AsIsolator()
0000000000000000000000000000000000000000;;				if err != nil {
0000000000000000000000000000000000000000;;					return err
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				isolators = append(isolators, *isolator)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Resources isolators.
0000000000000000000000000000000000000000;;		type resource struct {
0000000000000000000000000000000000000000;;			limit   string
0000000000000000000000000000000000000000;;			request string
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// If limit is empty, populate it with request and vice versa.
0000000000000000000000000000000000000000;;		resources := make(map[v1.ResourceName]*resource)
0000000000000000000000000000000000000000;;		for name, quantity := range c.Resources.Limits {
0000000000000000000000000000000000000000;;			resources[name] = &resource{limit: quantity.String(), request: quantity.String()}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		for name, quantity := range c.Resources.Requests {
0000000000000000000000000000000000000000;;			r, ok := resources[name]
0000000000000000000000000000000000000000;;			if ok {
0000000000000000000000000000000000000000;;				r.request = quantity.String()
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			resources[name] = &resource{limit: quantity.String(), request: quantity.String()}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		for name, res := range resources {
0000000000000000000000000000000000000000;;			switch name {
0000000000000000000000000000000000000000;;			case v1.ResourceCPU:
0000000000000000000000000000000000000000;;				cpu, err := appctypes.NewResourceCPUIsolator(res.request, res.limit)
0000000000000000000000000000000000000000;;				if err != nil {
0000000000000000000000000000000000000000;;					return err
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				isolators = append(isolators, cpu.AsIsolator())
0000000000000000000000000000000000000000;;			case v1.ResourceMemory:
0000000000000000000000000000000000000000;;				memory, err := appctypes.NewResourceMemoryIsolator(res.request, res.limit)
0000000000000000000000000000000000000000;;				if err != nil {
0000000000000000000000000000000000000000;;					return err
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				isolators = append(isolators, memory.AsIsolator())
0000000000000000000000000000000000000000;;			default:
0000000000000000000000000000000000000000;;				return fmt.Errorf("resource type not supported: %v", name)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		mergeIsolators(app, isolators)
0000000000000000000000000000000000000000;;		return nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// mergeIsolators replaces the app.Isolators with isolators.
0000000000000000000000000000000000000000;;	func mergeIsolators(app *appctypes.App, isolators []appctypes.Isolator) {
0000000000000000000000000000000000000000;;		for _, is := range isolators {
0000000000000000000000000000000000000000;;			found := false
0000000000000000000000000000000000000000;;			for j, js := range app.Isolators {
0000000000000000000000000000000000000000;;				if is.Name.Equals(js.Name) {
0000000000000000000000000000000000000000;;					switch is.Name {
0000000000000000000000000000000000000000;;					case appctypes.LinuxCapabilitiesRetainSetName:
0000000000000000000000000000000000000000;;						// TODO(yifan): More fine grain merge for capability set instead of override.
0000000000000000000000000000000000000000;;						fallthrough
0000000000000000000000000000000000000000;;					case appctypes.LinuxCapabilitiesRevokeSetName:
0000000000000000000000000000000000000000;;						fallthrough
0000000000000000000000000000000000000000;;					case appctypes.ResourceCPUName:
0000000000000000000000000000000000000000;;						fallthrough
0000000000000000000000000000000000000000;;					case appctypes.ResourceMemoryName:
0000000000000000000000000000000000000000;;						app.Isolators[j] = is
0000000000000000000000000000000000000000;;					default:
0000000000000000000000000000000000000000;;						panic(fmt.Sprintf("unexpected isolator name: %v", is.Name))
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					found = true
0000000000000000000000000000000000000000;;					break
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if !found {
0000000000000000000000000000000000000000;;				app.Isolators = append(app.Isolators, is)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// mergeEnv merges the optEnv with the image's environments.
0000000000000000000000000000000000000000;;	// The environments defined in the image will be overridden by
0000000000000000000000000000000000000000;;	// the ones with the same name in optEnv.
0000000000000000000000000000000000000000;;	func mergeEnv(app *appctypes.App, optEnv []kubecontainer.EnvVar) {
0000000000000000000000000000000000000000;;		envMap := make(map[string]string)
0000000000000000000000000000000000000000;;		for _, e := range app.Environment {
0000000000000000000000000000000000000000;;			envMap[e.Name] = e.Value
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		for _, e := range optEnv {
0000000000000000000000000000000000000000;;			envMap[e.Name] = e.Value
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		app.Environment = nil
0000000000000000000000000000000000000000;;		for name, value := range envMap {
0000000000000000000000000000000000000000;;			app.Environment = append(app.Environment, appctypes.EnvironmentVariable{
0000000000000000000000000000000000000000;;				Name:  name,
0000000000000000000000000000000000000000;;				Value: value,
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// mergeMounts merges the mountPoints with the image's mount points.
0000000000000000000000000000000000000000;;	// The mount points defined in the image will be overridden by the ones
0000000000000000000000000000000000000000;;	// with the same container path.
0000000000000000000000000000000000000000;;	func mergeMounts(app *appctypes.App, mountPoints []appctypes.MountPoint) {
0000000000000000000000000000000000000000;;		mountMap := make(map[string]appctypes.MountPoint)
0000000000000000000000000000000000000000;;		for _, m := range app.MountPoints {
0000000000000000000000000000000000000000;;			mountMap[m.Path] = m
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		for _, m := range mountPoints {
0000000000000000000000000000000000000000;;			mountMap[m.Path] = m
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		app.MountPoints = nil
0000000000000000000000000000000000000000;;		for _, mount := range mountMap {
0000000000000000000000000000000000000000;;			app.MountPoints = append(app.MountPoints, mount)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// mergePortMappings merges the containerPorts with the image's container ports.
0000000000000000000000000000000000000000;;	// The port mappings defined in the image will be overridden by the ones
0000000000000000000000000000000000000000;;	// with the same name in optPortMappings.
0000000000000000000000000000000000000000;;	func mergePortMappings(app *appctypes.App, containerPorts []appctypes.Port) {
0000000000000000000000000000000000000000;;		portMap := make(map[appctypes.ACName]appctypes.Port)
0000000000000000000000000000000000000000;;		for _, p := range app.Ports {
0000000000000000000000000000000000000000;;			portMap[p.Name] = p
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		for _, p := range containerPorts {
0000000000000000000000000000000000000000;;			portMap[p.Name] = p
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		app.Ports = nil
0000000000000000000000000000000000000000;;		for _, port := range portMap {
0000000000000000000000000000000000000000;;			app.Ports = append(app.Ports, port)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func verifyNonRoot(app *appctypes.App, ctx *v1.SecurityContext) error {
0000000000000000000000000000000000000000;;		if ctx != nil && ctx.RunAsNonRoot != nil && *ctx.RunAsNonRoot {
0000000000000000000000000000000000000000;;			if ctx.RunAsUser != nil && *ctx.RunAsUser == 0 {
0000000000000000000000000000000000000000;;				return fmt.Errorf("container's runAsUser breaks non-root policy")
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if ctx.RunAsUser == nil && app.User == "0" {
0000000000000000000000000000000000000000;;				return fmt.Errorf("container has no runAsUser and image will run as root")
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func setSupplementalGIDs(app *appctypes.App, podCtx *v1.PodSecurityContext, supplementalGids []int64) {
0000000000000000000000000000000000000000;;		if podCtx != nil || len(supplementalGids) != 0 {
0000000000000000000000000000000000000000;;			app.SupplementaryGIDs = app.SupplementaryGIDs[:0]
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if podCtx != nil {
0000000000000000000000000000000000000000;;			for _, v := range podCtx.SupplementalGroups {
0000000000000000000000000000000000000000;;				app.SupplementaryGIDs = append(app.SupplementaryGIDs, int(v))
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if podCtx.FSGroup != nil {
0000000000000000000000000000000000000000;;				app.SupplementaryGIDs = append(app.SupplementaryGIDs, int(*podCtx.FSGroup))
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		for _, v := range supplementalGids {
0000000000000000000000000000000000000000;;			app.SupplementaryGIDs = append(app.SupplementaryGIDs, int(v))
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// setApp merges the container spec with the image's manifest.
0000000000000000000000000000000000000000;;	func setApp(imgManifest *appcschema.ImageManifest, c *v1.Container,
0000000000000000000000000000000000000000;;		mountPoints []appctypes.MountPoint, containerPorts []appctypes.Port, envs []kubecontainer.EnvVar,
0000000000000000000000000000000000000000;;		ctx *v1.SecurityContext, podCtx *v1.PodSecurityContext, supplementalGids []int64) error {
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		app := imgManifest.App
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Set up Exec.
0000000000000000000000000000000000000000;;		var command, args []string
0000000000000000000000000000000000000000;;		cmd, ok := imgManifest.Annotations.Get(appcDockerEntrypoint)
0000000000000000000000000000000000000000;;		if ok {
0000000000000000000000000000000000000000;;			err := json.Unmarshal([]byte(cmd), &command)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				return fmt.Errorf("cannot unmarshal ENTRYPOINT %q: %v", cmd, err)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		ag, ok := imgManifest.Annotations.Get(appcDockerCmd)
0000000000000000000000000000000000000000;;		if ok {
0000000000000000000000000000000000000000;;			err := json.Unmarshal([]byte(ag), &args)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				return fmt.Errorf("cannot unmarshal CMD %q: %v", ag, err)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		userCommand, userArgs := kubecontainer.ExpandContainerCommandAndArgs(c, envs)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if len(userCommand) > 0 {
0000000000000000000000000000000000000000;;			command = userCommand
0000000000000000000000000000000000000000;;			args = nil // If 'command' is specified, then drop the default args.
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if len(userArgs) > 0 {
0000000000000000000000000000000000000000;;			args = userArgs
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		exec := append(command, args...)
0000000000000000000000000000000000000000;;		if len(exec) > 0 {
0000000000000000000000000000000000000000;;			app.Exec = exec
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Set UID and GIDs.
0000000000000000000000000000000000000000;;		if err := verifyNonRoot(app, ctx); err != nil {
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if ctx != nil && ctx.RunAsUser != nil {
0000000000000000000000000000000000000000;;			app.User = strconv.Itoa(int(*ctx.RunAsUser))
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		setSupplementalGIDs(app, podCtx, supplementalGids)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// If 'User' or 'Group' are still empty at this point,
0000000000000000000000000000000000000000;;		// then apply the root UID and GID.
0000000000000000000000000000000000000000;;		// TODO(yifan): If only the GID is empty, rkt should be able to determine the GID
0000000000000000000000000000000000000000;;		// using the /etc/passwd file in the image.
0000000000000000000000000000000000000000;;		// See https://github.com/appc/docker2aci/issues/175.
0000000000000000000000000000000000000000;;		// Maybe we can remove this check in the future.
0000000000000000000000000000000000000000;;		if app.User == "" {
0000000000000000000000000000000000000000;;			app.User = "0"
0000000000000000000000000000000000000000;;			app.Group = "0"
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if app.Group == "" {
0000000000000000000000000000000000000000;;			return fmt.Errorf("cannot determine the GID of the app %q", imgManifest.Name)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Set working directory.
0000000000000000000000000000000000000000;;		if len(c.WorkingDir) > 0 {
0000000000000000000000000000000000000000;;			app.WorkingDirectory = c.WorkingDir
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Notes that we don't create Mounts section in the pod manifest here,
0000000000000000000000000000000000000000;;		// as Mounts will be automatically generated by rkt.
0000000000000000000000000000000000000000;;		mergeMounts(app, mountPoints)
0000000000000000000000000000000000000000;;		mergeEnv(app, envs)
0000000000000000000000000000000000000000;;		mergePortMappings(app, containerPorts)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return setIsolators(app, c, ctx)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// makePodManifest transforms a kubelet pod spec to the rkt pod manifest.
0000000000000000000000000000000000000000;;	func (r *Runtime) makePodManifest(pod *v1.Pod, podIP string, pullSecrets []v1.Secret) (*appcschema.PodManifest, error) {
0000000000000000000000000000000000000000;;		manifest := appcschema.BlankPodManifest()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		ctx, cancel := context.WithTimeout(context.Background(), r.requestTimeout)
0000000000000000000000000000000000000000;;		defer cancel()
0000000000000000000000000000000000000000;;		listResp, err := r.apisvc.ListPods(ctx, &rktapi.ListPodsRequest{
0000000000000000000000000000000000000000;;			Detail:  true,
0000000000000000000000000000000000000000;;			Filters: kubernetesPodFilters(pod.UID),
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return nil, fmt.Errorf("couldn't list pods: %v", err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		restartCount := 0
0000000000000000000000000000000000000000;;		for _, pod := range listResp.Pods {
0000000000000000000000000000000000000000;;			manifest := &appcschema.PodManifest{}
0000000000000000000000000000000000000000;;			err = json.Unmarshal(pod.Manifest, manifest)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				glog.Warningf("rkt: error unmatshaling pod manifest: %v", err)
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			if countString, ok := manifest.Annotations.Get(k8sRktRestartCountAnno); ok {
0000000000000000000000000000000000000000;;				num, err := strconv.Atoi(countString)
0000000000000000000000000000000000000000;;				if err != nil {
0000000000000000000000000000000000000000;;					glog.Warningf("rkt: error reading restart count on pod: %v", err)
0000000000000000000000000000000000000000;;					continue
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				if num+1 > restartCount {
0000000000000000000000000000000000000000;;					restartCount = num + 1
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		requiresPrivileged := false
0000000000000000000000000000000000000000;;		manifest.Annotations.Set(*appctypes.MustACIdentifier(k8sRktKubeletAnno), k8sRktKubeletAnnoValue)
0000000000000000000000000000000000000000;;		manifest.Annotations.Set(*appctypes.MustACIdentifier(types.KubernetesPodUIDLabel), string(pod.UID))
0000000000000000000000000000000000000000;;		manifest.Annotations.Set(*appctypes.MustACIdentifier(types.KubernetesPodNameLabel), pod.Name)
0000000000000000000000000000000000000000;;		manifest.Annotations.Set(*appctypes.MustACIdentifier(types.KubernetesPodNamespaceLabel), pod.Namespace)
0000000000000000000000000000000000000000;;		manifest.Annotations.Set(*appctypes.MustACIdentifier(types.KubernetesContainerNameLabel), leaky.PodInfraContainerName)
0000000000000000000000000000000000000000;;		manifest.Annotations.Set(*appctypes.MustACIdentifier(k8sRktRestartCountAnno), strconv.Itoa(restartCount))
0000000000000000000000000000000000000000;;		if stage1Name, ok := pod.Annotations[k8sRktStage1NameAnno]; ok {
0000000000000000000000000000000000000000;;			requiresPrivileged = true
0000000000000000000000000000000000000000;;			manifest.Annotations.Set(*appctypes.MustACIdentifier(k8sRktStage1NameAnno), stage1Name)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		for _, c := range pod.Spec.Containers {
0000000000000000000000000000000000000000;;			err := r.newAppcRuntimeApp(pod, podIP, c, requiresPrivileged, pullSecrets, manifest)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				return nil, err
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// TODO(yifan): Set pod-level isolators once it's supported in kubernetes.
0000000000000000000000000000000000000000;;		return manifest, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func copyfile(src, dst string) error {
0000000000000000000000000000000000000000;;		data, err := ioutil.ReadFile(src)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return ioutil.WriteFile(dst, data, 0644)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// TODO(yifan): Can make rkt handle this when '--net=host'. See https://github.com/coreos/rkt/issues/2430.
0000000000000000000000000000000000000000;;	func makeHostNetworkMount(opts *kubecontainer.RunContainerOptions) (*kubecontainer.Mount, *kubecontainer.Mount, error) {
0000000000000000000000000000000000000000;;		mountHosts, mountResolvConf := true, true
0000000000000000000000000000000000000000;;		for _, mnt := range opts.Mounts {
0000000000000000000000000000000000000000;;			switch mnt.ContainerPath {
0000000000000000000000000000000000000000;;			case etcHostsPath:
0000000000000000000000000000000000000000;;				mountHosts = false
0000000000000000000000000000000000000000;;			case etcResolvConfPath:
0000000000000000000000000000000000000000;;				mountResolvConf = false
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		var hostsMount, resolvMount kubecontainer.Mount
0000000000000000000000000000000000000000;;		if mountHosts {
0000000000000000000000000000000000000000;;			hostsPath := filepath.Join(opts.PodContainerDir, "etc-hosts")
0000000000000000000000000000000000000000;;			if err := copyfile(etcHostsPath, hostsPath); err != nil {
0000000000000000000000000000000000000000;;				return nil, nil, err
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			hostsMount = kubecontainer.Mount{
0000000000000000000000000000000000000000;;				Name:          "kubernetes-hostnetwork-hosts-conf",
0000000000000000000000000000000000000000;;				ContainerPath: etcHostsPath,
0000000000000000000000000000000000000000;;				HostPath:      hostsPath,
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			opts.Mounts = append(opts.Mounts, hostsMount)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if mountResolvConf {
0000000000000000000000000000000000000000;;			resolvPath := filepath.Join(opts.PodContainerDir, "etc-resolv-conf")
0000000000000000000000000000000000000000;;			if err := copyfile(etcResolvConfPath, resolvPath); err != nil {
0000000000000000000000000000000000000000;;				return nil, nil, err
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			resolvMount = kubecontainer.Mount{
0000000000000000000000000000000000000000;;				Name:          "kubernetes-hostnetwork-resolv-conf",
0000000000000000000000000000000000000000;;				ContainerPath: etcResolvConfPath,
0000000000000000000000000000000000000000;;				HostPath:      resolvPath,
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			opts.Mounts = append(opts.Mounts, resolvMount)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return &hostsMount, &resolvMount, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// podFinishedMarkerPath returns the path to a file which should be used to
0000000000000000000000000000000000000000;;	// indicate the pod exiting, and the time thereof.
0000000000000000000000000000000000000000;;	// If the file at the path does not exist, the pod should not be exited. If it
0000000000000000000000000000000000000000;;	// does exist, then the ctime of the file should indicate the time the pod
0000000000000000000000000000000000000000;;	// exited.
0000000000000000000000000000000000000000;;	func podFinishedMarkerPath(podDir string, rktUID string) string {
0000000000000000000000000000000000000000;;		return filepath.Join(podDir, "finished-"+rktUID)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func podFinishedMarkCommand(touchPath, podDir, rktUID string) string {
0000000000000000000000000000000000000000;;		// TODO, if the path has a `'` character in it, this breaks.
0000000000000000000000000000000000000000;;		return touchPath + " " + podFinishedMarkerPath(podDir, rktUID)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// podFinishedAt returns the time that a pod exited, or a zero time if it has
0000000000000000000000000000000000000000;;	// not.
0000000000000000000000000000000000000000;;	func (r *Runtime) podFinishedAt(podUID kubetypes.UID, rktUID string) time.Time {
0000000000000000000000000000000000000000;;		markerFile := podFinishedMarkerPath(r.runtimeHelper.GetPodDir(podUID), rktUID)
0000000000000000000000000000000000000000;;		stat, err := r.os.Stat(markerFile)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			if !os.IsNotExist(err) {
0000000000000000000000000000000000000000;;				glog.Warningf("rkt: unexpected fs error checking pod finished marker: %v", err)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			return time.Time{}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return stat.ModTime()
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (r *Runtime) makeContainerLogMount(opts *kubecontainer.RunContainerOptions, container *v1.Container) (*kubecontainer.Mount, error) {
0000000000000000000000000000000000000000;;		if opts.PodContainerDir == "" || container.TerminationMessagePath == "" {
0000000000000000000000000000000000000000;;			return nil, nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// In docker runtime, the container log path contains the container ID.
0000000000000000000000000000000000000000;;		// However, for rkt runtime, we cannot get the container ID before the
0000000000000000000000000000000000000000;;		// the container is launched, so here we generate a random uuid to enable
0000000000000000000000000000000000000000;;		// us to map a container's termination message path to a unique log file
0000000000000000000000000000000000000000;;		// on the disk.
0000000000000000000000000000000000000000;;		randomUID := uuid.NewUUID()
0000000000000000000000000000000000000000;;		containerLogPath := path.Join(opts.PodContainerDir, string(randomUID))
0000000000000000000000000000000000000000;;		fs, err := r.os.Create(containerLogPath)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return nil, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if err := fs.Close(); err != nil {
0000000000000000000000000000000000000000;;			return nil, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		mnt := kubecontainer.Mount{
0000000000000000000000000000000000000000;;			// Use a random name for the termination message mount, so that
0000000000000000000000000000000000000000;;			// when a container restarts, it will not overwrite the old termination
0000000000000000000000000000000000000000;;			// message.
0000000000000000000000000000000000000000;;			Name:          fmt.Sprintf("termination-message-%s", randomUID),
0000000000000000000000000000000000000000;;			ContainerPath: container.TerminationMessagePath,
0000000000000000000000000000000000000000;;			HostPath:      containerLogPath,
0000000000000000000000000000000000000000;;			ReadOnly:      false,
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		opts.Mounts = append(opts.Mounts, mnt)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return &mnt, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (r *Runtime) newAppcRuntimeApp(pod *v1.Pod, podIP string, c v1.Container, requiresPrivileged bool, pullSecrets []v1.Secret, manifest *appcschema.PodManifest) error {
0000000000000000000000000000000000000000;;		var annotations appctypes.Annotations = []appctypes.Annotation{
0000000000000000000000000000000000000000;;			{
0000000000000000000000000000000000000000;;				Name:  *appctypes.MustACIdentifier(k8sRktContainerHashAnno),
0000000000000000000000000000000000000000;;				Value: strconv.FormatUint(kubecontainer.HashContainerLegacy(&c), 10),
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			{
0000000000000000000000000000000000000000;;				Name:  *appctypes.MustACIdentifier(types.KubernetesContainerNameLabel),
0000000000000000000000000000000000000000;;				Value: c.Name,
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if requiresPrivileged && !securitycontext.HasPrivilegedRequest(&c) {
0000000000000000000000000000000000000000;;			return fmt.Errorf("cannot make %q: running a custom stage1 requires a privileged security context", format.Pod(pod))
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		imageRef, _, err := r.imagePuller.EnsureImageExists(pod, &c, pullSecrets)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		imgManifest, err := r.getImageManifest(c.Image)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if imgManifest.App == nil {
0000000000000000000000000000000000000000;;			imgManifest.App = new(appctypes.App)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		hash, err := appctypes.NewHash(imageRef)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// TODO: determine how this should be handled for rkt
0000000000000000000000000000000000000000;;		opts, _, err := r.runtimeHelper.GenerateRunContainerOptions(pod, &c, podIP)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Create additional mount for termintation message path.
0000000000000000000000000000000000000000;;		mount, err := r.makeContainerLogMount(opts, &c)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		mounts := append(opts.Mounts, *mount)
0000000000000000000000000000000000000000;;		annotations = append(annotations, appctypes.Annotation{
0000000000000000000000000000000000000000;;			Name:  *appctypes.MustACIdentifier(k8sRktTerminationMessagePathAnno),
0000000000000000000000000000000000000000;;			Value: mount.HostPath,
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// If run in 'hostnetwork' mode, then copy the host's /etc/resolv.conf and /etc/hosts,
0000000000000000000000000000000000000000;;		// and add mounts.
0000000000000000000000000000000000000000;;		if kubecontainer.IsHostNetworkPod(pod) {
0000000000000000000000000000000000000000;;			hostsMount, resolvMount, err := makeHostNetworkMount(opts)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				return err
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			mounts = append(mounts, *hostsMount, *resolvMount)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		supplementalGids := r.runtimeHelper.GetExtraSupplementalGroupsForPod(pod)
0000000000000000000000000000000000000000;;		ctx := securitycontext.DetermineEffectiveSecurityContext(pod, &c)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		volumes, mountPoints := convertKubeMounts(mounts)
0000000000000000000000000000000000000000;;		containerPorts, hostPorts := convertKubePortMappings(opts.PortMappings)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if err := setApp(imgManifest, &c, mountPoints, containerPorts, opts.Envs, ctx, pod.Spec.SecurityContext, supplementalGids); err != nil {
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		ra := appcschema.RuntimeApp{
0000000000000000000000000000000000000000;;			Name:        convertToACName(c.Name),
0000000000000000000000000000000000000000;;			Image:       appcschema.RuntimeImage{ID: *hash},
0000000000000000000000000000000000000000;;			App:         imgManifest.App,
0000000000000000000000000000000000000000;;			Annotations: annotations,
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if c.SecurityContext != nil && c.SecurityContext.ReadOnlyRootFilesystem != nil {
0000000000000000000000000000000000000000;;			ra.ReadOnlyRootFS = *c.SecurityContext.ReadOnlyRootFilesystem
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		manifest.Apps = append(manifest.Apps, ra)
0000000000000000000000000000000000000000;;		manifest.Volumes = append(manifest.Volumes, volumes...)
0000000000000000000000000000000000000000;;		manifest.Ports = append(manifest.Ports, hostPorts...)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func runningKubernetesPodFilters(uid kubetypes.UID) []*rktapi.PodFilter {
0000000000000000000000000000000000000000;;		return []*rktapi.PodFilter{
0000000000000000000000000000000000000000;;			{
0000000000000000000000000000000000000000;;				States: []rktapi.PodState{
0000000000000000000000000000000000000000;;					rktapi.PodState_POD_STATE_RUNNING,
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;				Annotations: []*rktapi.KeyValue{
0000000000000000000000000000000000000000;;					{
0000000000000000000000000000000000000000;;						Key:   k8sRktKubeletAnno,
0000000000000000000000000000000000000000;;						Value: k8sRktKubeletAnnoValue,
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;					{
0000000000000000000000000000000000000000;;						Key:   types.KubernetesPodUIDLabel,
0000000000000000000000000000000000000000;;						Value: string(uid),
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func kubernetesPodFilters(uid kubetypes.UID) []*rktapi.PodFilter {
0000000000000000000000000000000000000000;;		return []*rktapi.PodFilter{
0000000000000000000000000000000000000000;;			{
0000000000000000000000000000000000000000;;				Annotations: []*rktapi.KeyValue{
0000000000000000000000000000000000000000;;					{
0000000000000000000000000000000000000000;;						Key:   k8sRktKubeletAnno,
0000000000000000000000000000000000000000;;						Value: k8sRktKubeletAnnoValue,
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;					{
0000000000000000000000000000000000000000;;						Key:   types.KubernetesPodUIDLabel,
0000000000000000000000000000000000000000;;						Value: string(uid),
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func kubernetesPodsFilters() []*rktapi.PodFilter {
0000000000000000000000000000000000000000;;		return []*rktapi.PodFilter{
0000000000000000000000000000000000000000;;			{
0000000000000000000000000000000000000000;;				Annotations: []*rktapi.KeyValue{
0000000000000000000000000000000000000000;;					{
0000000000000000000000000000000000000000;;						Key:   k8sRktKubeletAnno,
0000000000000000000000000000000000000000;;						Value: k8sRktKubeletAnnoValue,
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func newUnitOption(section, name, value string) *unit.UnitOption {
0000000000000000000000000000000000000000;;		return &unit.UnitOption{Section: section, Name: name, Value: value}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// apiPodToruntimePod converts an v1.Pod to kubelet/container.Pod.
0000000000000000000000000000000000000000;;	func apiPodToruntimePod(uuid string, pod *v1.Pod) *kubecontainer.Pod {
0000000000000000000000000000000000000000;;		p := &kubecontainer.Pod{
0000000000000000000000000000000000000000;;			ID:        pod.UID,
0000000000000000000000000000000000000000;;			Name:      pod.Name,
0000000000000000000000000000000000000000;;			Namespace: pod.Namespace,
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		for i := range pod.Spec.Containers {
0000000000000000000000000000000000000000;;			c := &pod.Spec.Containers[i]
0000000000000000000000000000000000000000;;			p.Containers = append(p.Containers, &kubecontainer.Container{
0000000000000000000000000000000000000000;;				ID:    buildContainerID(&containerID{uuid, c.Name}),
0000000000000000000000000000000000000000;;				Name:  c.Name,
0000000000000000000000000000000000000000;;				Image: c.Image,
0000000000000000000000000000000000000000;;				Hash:  kubecontainer.HashContainerLegacy(c),
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return p
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// serviceFilePath returns the absolute path of the service file.
0000000000000000000000000000000000000000;;	func serviceFilePath(serviceName string) string {
0000000000000000000000000000000000000000;;		return path.Join(systemdServiceDir, serviceName)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// shouldCreateNetns returns true if:
0000000000000000000000000000000000000000;;	// The pod does not run in host network. And
0000000000000000000000000000000000000000;;	// The pod runs inside a netns created outside of rkt.
0000000000000000000000000000000000000000;;	func (r *Runtime) shouldCreateNetns(pod *v1.Pod) bool {
0000000000000000000000000000000000000000;;		return !kubecontainer.IsHostNetworkPod(pod) && r.network.PluginName() != network.DefaultPluginName
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// usesRktHostNetwork returns true if:
0000000000000000000000000000000000000000;;	// The pod runs in the host network. Or
0000000000000000000000000000000000000000;;	// The pod runs inside a netns created outside of rkt.
0000000000000000000000000000000000000000;;	func (r *Runtime) usesRktHostNetwork(pod *v1.Pod) bool {
0000000000000000000000000000000000000000;;		return kubecontainer.IsHostNetworkPod(pod) || r.shouldCreateNetns(pod)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// generateRunCommand crafts a 'rkt run-prepared' command with necessary parameters.
0000000000000000000000000000000000000000;;	func (r *Runtime) generateRunCommand(pod *v1.Pod, uuid, networkNamespaceID string) (string, error) {
0000000000000000000000000000000000000000;;		config := *r.config
0000000000000000000000000000000000000000;;		privileged := true
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		for _, c := range pod.Spec.Containers {
0000000000000000000000000000000000000000;;			ctx := securitycontext.DetermineEffectiveSecurityContext(pod, &c)
0000000000000000000000000000000000000000;;			if ctx == nil || ctx.Privileged == nil || *ctx.Privileged == false {
0000000000000000000000000000000000000000;;				privileged = false
0000000000000000000000000000000000000000;;				break
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Use "all-run" insecure option (https://github.com/coreos/rkt/pull/2983) to take care
0000000000000000000000000000000000000000;;		// of privileged pod.
0000000000000000000000000000000000000000;;		// TODO(yifan): Have more granular app-level control of the insecure options.
0000000000000000000000000000000000000000;;		// See: https://github.com/coreos/rkt/issues/2996.
0000000000000000000000000000000000000000;;		if privileged {
0000000000000000000000000000000000000000;;			config.InsecureOptions = fmt.Sprintf("%s,%s", config.InsecureOptions, "all-run")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		runPrepared := buildCommand(&config, "run-prepared").Args
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		var hostname string
0000000000000000000000000000000000000000;;		var err error
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		osInfos, err := getOSReleaseInfo()
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			glog.Warningf("rkt: Failed to read the os release info: %v", err)
0000000000000000000000000000000000000000;;		} else {
0000000000000000000000000000000000000000;;			// Overlay fs is not supported for SELinux yet on many distros.
0000000000000000000000000000000000000000;;			// See https://github.com/coreos/rkt/issues/1727#issuecomment-173203129.
0000000000000000000000000000000000000000;;			// For now, coreos carries a patch to support it: https://github.com/coreos/coreos-overlay/pull/1703
0000000000000000000000000000000000000000;;			if osInfos["ID"] != "coreos" && pod.Spec.SecurityContext != nil && pod.Spec.SecurityContext.SELinuxOptions != nil {
0000000000000000000000000000000000000000;;				runPrepared = append(runPrepared, "--no-overlay=true")
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Apply '--net=host' to pod that is running on host network or inside a network namespace.
0000000000000000000000000000000000000000;;		if r.usesRktHostNetwork(pod) {
0000000000000000000000000000000000000000;;			runPrepared = append(runPrepared, "--net=host")
0000000000000000000000000000000000000000;;		} else {
0000000000000000000000000000000000000000;;			runPrepared = append(runPrepared, fmt.Sprintf("--net=%s", defaultNetworkName))
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if kubecontainer.IsHostNetworkPod(pod) {
0000000000000000000000000000000000000000;;			// TODO(yifan): Let runtimeHelper.GeneratePodHostNameAndDomain() to handle this.
0000000000000000000000000000000000000000;;			hostname, err = r.os.Hostname()
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				return "", err
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		} else {
0000000000000000000000000000000000000000;;			// Setup DNS.
0000000000000000000000000000000000000000;;			dnsServers, dnsSearches, _, err := r.runtimeHelper.GetClusterDNS(pod)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				return "", err
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			for _, server := range dnsServers {
0000000000000000000000000000000000000000;;				runPrepared = append(runPrepared, fmt.Sprintf("--dns=%s", server))
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			for _, search := range dnsSearches {
0000000000000000000000000000000000000000;;				runPrepared = append(runPrepared, fmt.Sprintf("--dns-search=%s", search))
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if len(dnsServers) > 0 || len(dnsSearches) > 0 {
0000000000000000000000000000000000000000;;				runPrepared = append(runPrepared, fmt.Sprintf("--dns-opt=%s", defaultDNSOption))
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// TODO(yifan): host domain is not being used.
0000000000000000000000000000000000000000;;			hostname, _, err = r.runtimeHelper.GeneratePodHostNameAndDomain(pod)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				return "", err
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		runPrepared = append(runPrepared, fmt.Sprintf("--hostname=%s", hostname))
0000000000000000000000000000000000000000;;		runPrepared = append(runPrepared, uuid)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if r.shouldCreateNetns(pod) {
0000000000000000000000000000000000000000;;			// Drop the `rkt run-prepared` into the network namespace we
0000000000000000000000000000000000000000;;			// created.
0000000000000000000000000000000000000000;;			// TODO: switch to 'ip netns exec' once we can depend on a new
0000000000000000000000000000000000000000;;			// enough version that doesn't have bugs like
0000000000000000000000000000000000000000;;			// https://bugzilla.redhat.com/show_bug.cgi?id=882047
0000000000000000000000000000000000000000;;			nsenterExec := []string{r.nsenterPath, "--net=" + netnsPathFromName(networkNamespaceID), "--"}
0000000000000000000000000000000000000000;;			runPrepared = append(nsenterExec, runPrepared...)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return strings.Join(runPrepared, " "), nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (r *Runtime) cleanupPodNetwork(pod *v1.Pod, networkNamespace kubecontainer.ContainerID) error {
0000000000000000000000000000000000000000;;		// No-op if the pod is not running in a created netns.
0000000000000000000000000000000000000000;;		if !r.shouldCreateNetns(pod) {
0000000000000000000000000000000000000000;;			return nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		glog.V(3).Infof("Calling network plugin %s to tear down pod for %s", r.network.PluginName(), format.Pod(pod))
0000000000000000000000000000000000000000;;		teardownErr := r.network.TearDownPod(pod.Namespace, pod.Name, networkNamespace)
0000000000000000000000000000000000000000;;		if teardownErr != nil {
0000000000000000000000000000000000000000;;			glog.Error(teardownErr)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if _, err := r.execer.Command("ip", "netns", "del", networkNamespace.ID).Output(); err != nil {
0000000000000000000000000000000000000000;;			return fmt.Errorf("rkt: Failed to remove network namespace for pod %s: %v", format.Pod(pod), err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return teardownErr
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (r *Runtime) preparePodArgs(manifest *appcschema.PodManifest, manifestFileName string) []string {
0000000000000000000000000000000000000000;;		// Order of precedence for the stage1:
0000000000000000000000000000000000000000;;		// 1) pod annotation (stage1 name)
0000000000000000000000000000000000000000;;		// 2) kubelet configured stage1 (stage1 path)
0000000000000000000000000000000000000000;;		// 3) empty; whatever rkt's compiled to default to
0000000000000000000000000000000000000000;;		stage1ImageCmd := ""
0000000000000000000000000000000000000000;;		if r.config.Stage1Image != "" {
0000000000000000000000000000000000000000;;			stage1ImageCmd = "--stage1-name=" + r.config.Stage1Image
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if stage1Name, ok := manifest.Annotations.Get(k8sRktStage1NameAnno); ok {
0000000000000000000000000000000000000000;;			stage1ImageCmd = "--stage1-name=" + stage1Name
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Run 'rkt prepare' to get the rkt UUID.
0000000000000000000000000000000000000000;;		cmds := []string{"prepare", "--quiet", "--pod-manifest", manifestFileName}
0000000000000000000000000000000000000000;;		if stage1ImageCmd != "" {
0000000000000000000000000000000000000000;;			cmds = append(cmds, stage1ImageCmd)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return cmds
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (r *Runtime) getSelinuxContext(opt *v1.SELinuxOptions) (string, error) {
0000000000000000000000000000000000000000;;		selinuxRunner := selinux.NewSELinuxRunner()
0000000000000000000000000000000000000000;;		str, err := selinuxRunner.Getfilecon(r.config.Dir)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return "", err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		ctx := strings.SplitN(str, ":", 4)
0000000000000000000000000000000000000000;;		if len(ctx) != 4 {
0000000000000000000000000000000000000000;;			return "", fmt.Errorf("malformated selinux context")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if opt.User != "" {
0000000000000000000000000000000000000000;;			ctx[0] = opt.User
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if opt.Role != "" {
0000000000000000000000000000000000000000;;			ctx[1] = opt.Role
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if opt.Type != "" {
0000000000000000000000000000000000000000;;			ctx[2] = opt.Type
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if opt.Level != "" {
0000000000000000000000000000000000000000;;			ctx[3] = opt.Level
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return strings.Join(ctx, ":"), nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// From the generateName or the podName return a basename for improving the logging with the Journal
0000000000000000000000000000000000000000;;	// journalctl -t podBaseName
0000000000000000000000000000000000000000;;	func constructSyslogIdentifier(generateName string, podName string) string {
0000000000000000000000000000000000000000;;		if len(generateName) > 1 && generateName[len(generateName)-1] == '-' {
0000000000000000000000000000000000000000;;			return generateName[0 : len(generateName)-1]
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if len(generateName) > 0 {
0000000000000000000000000000000000000000;;			return generateName
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return podName
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Setup additional systemd field specified in the Pod Annotation
0000000000000000000000000000000000000000;;	func setupSystemdCustomFields(annotations map[string]string, unitOptionArray []*unit.UnitOption) ([]*unit.UnitOption, error) {
0000000000000000000000000000000000000000;;		// LimitNOFILE
0000000000000000000000000000000000000000;;		if strSize := annotations[k8sRktLimitNoFileAnno]; strSize != "" {
0000000000000000000000000000000000000000;;			size, err := strconv.Atoi(strSize)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				return unitOptionArray, err
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if size < 1 {
0000000000000000000000000000000000000000;;				return unitOptionArray, fmt.Errorf("invalid value for %s: %s", k8sRktLimitNoFileAnno, strSize)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			unitOptionArray = append(unitOptionArray, newUnitOption("Service", "LimitNOFILE", strSize))
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return unitOptionArray, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// preparePod will:
0000000000000000000000000000000000000000;;	//
0000000000000000000000000000000000000000;;	// 1. Invoke 'rkt prepare' to prepare the pod, and get the rkt pod uuid.
0000000000000000000000000000000000000000;;	// 2. Create the unit file and save it under systemdUnitDir.
0000000000000000000000000000000000000000;;	//
0000000000000000000000000000000000000000;;	// On success, it will return a string that represents name of the unit file
0000000000000000000000000000000000000000;;	// and the runtime pod.
0000000000000000000000000000000000000000;;	func (r *Runtime) preparePod(pod *v1.Pod, podIP string, pullSecrets []v1.Secret, networkNamespaceID string) (string, *kubecontainer.Pod, error) {
0000000000000000000000000000000000000000;;		// Generate the appc pod manifest from the k8s pod spec.
0000000000000000000000000000000000000000;;		manifest, err := r.makePodManifest(pod, podIP, pullSecrets)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return "", nil, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		manifestFile, err := ioutil.TempFile("", fmt.Sprintf("manifest-%s-", pod.Name))
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return "", nil, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		defer func() {
0000000000000000000000000000000000000000;;			manifestFile.Close()
0000000000000000000000000000000000000000;;			if err := r.os.Remove(manifestFile.Name()); err != nil {
0000000000000000000000000000000000000000;;				glog.Warningf("rkt: Cannot remove temp manifest file %q: %v", manifestFile.Name(), err)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		data, err := json.Marshal(manifest)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return "", nil, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		glog.V(4).Infof("Generating pod manifest for pod %q: %v", format.Pod(pod), string(data))
0000000000000000000000000000000000000000;;		// Since File.Write returns error if the written length is less than len(data),
0000000000000000000000000000000000000000;;		// so check error is enough for us.
0000000000000000000000000000000000000000;;		if _, err := manifestFile.Write(data); err != nil {
0000000000000000000000000000000000000000;;			return "", nil, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		prepareCmd := r.preparePodArgs(manifest, manifestFile.Name())
0000000000000000000000000000000000000000;;		output, err := r.cli.RunCommand(nil, prepareCmd...)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return "", nil, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if len(output) != 1 {
0000000000000000000000000000000000000000;;			return "", nil, fmt.Errorf("invalid output from 'rkt prepare': %v", output)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		uuid := output[0]
0000000000000000000000000000000000000000;;		glog.V(4).Infof("'rkt prepare' returns %q", uuid)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Create systemd service file for the rkt pod.
0000000000000000000000000000000000000000;;		runPrepared, err := r.generateRunCommand(pod, uuid, networkNamespaceID)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return "", nil, fmt.Errorf("failed to generate 'rkt run-prepared' command: %v", err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// TODO handle pod.Spec.HostPID
0000000000000000000000000000000000000000;;		// TODO handle pod.Spec.HostIPC
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// TODO per container finishedAt, not just per pod
0000000000000000000000000000000000000000;;		markPodFinished := podFinishedMarkCommand(r.touchPath, r.runtimeHelper.GetPodDir(pod.UID), uuid)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		hostNetwork := kubecontainer.IsHostNetworkPod(pod)
0000000000000000000000000000000000000000;;		units := []*unit.UnitOption{
0000000000000000000000000000000000000000;;			newUnitOption("Service", "ExecStart", runPrepared),
0000000000000000000000000000000000000000;;			newUnitOption("Service", "ExecStopPost", markPodFinished),
0000000000000000000000000000000000000000;;			// This enables graceful stop.
0000000000000000000000000000000000000000;;			newUnitOption("Service", "KillMode", "mixed"),
0000000000000000000000000000000000000000;;			newUnitOption("Service", "TimeoutStopSec", fmt.Sprintf("%ds", getPodTerminationGracePeriodInSecond(pod))),
0000000000000000000000000000000000000000;;			// Ops helpers
0000000000000000000000000000000000000000;;			newUnitOption("Unit", "Description", pod.Name),
0000000000000000000000000000000000000000;;			newUnitOption("Service", "SyslogIdentifier", constructSyslogIdentifier(pod.GenerateName, pod.Name)),
0000000000000000000000000000000000000000;;			// Track pod info for garbage collection
0000000000000000000000000000000000000000;;			newUnitOption(unitKubernetesSection, unitPodUID, string(pod.UID)),
0000000000000000000000000000000000000000;;			newUnitOption(unitKubernetesSection, unitPodName, pod.Name),
0000000000000000000000000000000000000000;;			newUnitOption(unitKubernetesSection, unitPodNamespace, pod.Namespace),
0000000000000000000000000000000000000000;;			newUnitOption(unitKubernetesSection, unitPodHostNetwork, fmt.Sprintf("%v", hostNetwork)),
0000000000000000000000000000000000000000;;			newUnitOption(unitKubernetesSection, unitPodNetworkNamespace, networkNamespaceID),
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if pod.Spec.SecurityContext != nil && pod.Spec.SecurityContext.SELinuxOptions != nil {
0000000000000000000000000000000000000000;;			opt := pod.Spec.SecurityContext.SELinuxOptions
0000000000000000000000000000000000000000;;			selinuxContext, err := r.getSelinuxContext(opt)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				glog.Errorf("rkt: Failed to construct selinux context with selinux option %q: %v", opt, err)
0000000000000000000000000000000000000000;;				return "", nil, err
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			units = append(units, newUnitOption("Service", "SELinuxContext", selinuxContext))
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		units, err = setupSystemdCustomFields(pod.Annotations, units)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			glog.Warningf("fail to add custom systemd fields provided by pod Annotations: %q", err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		serviceName := makePodServiceFileName(uuid)
0000000000000000000000000000000000000000;;		glog.V(4).Infof("rkt: Creating service file %q for pod %q", serviceName, format.Pod(pod))
0000000000000000000000000000000000000000;;		serviceFile, err := r.os.Create(serviceFilePath(serviceName))
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return "", nil, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if _, err := io.Copy(serviceFile, unit.Serialize(units)); err != nil {
0000000000000000000000000000000000000000;;			return "", nil, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		serviceFile.Close()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return serviceName, apiPodToruntimePod(uuid, pod), nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// generateEvents is a helper function that generates some container
0000000000000000000000000000000000000000;;	// life cycle events for containers in a pod.
0000000000000000000000000000000000000000;;	func (r *Runtime) generateEvents(runtimePod *kubecontainer.Pod, reason string, failure error) {
0000000000000000000000000000000000000000;;		// Set up container references.
0000000000000000000000000000000000000000;;		for _, c := range runtimePod.Containers {
0000000000000000000000000000000000000000;;			containerID := c.ID
0000000000000000000000000000000000000000;;			id, err := parseContainerID(containerID)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				glog.Warningf("Invalid container ID %q", containerID)
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			ref, ok := r.containerRefManager.GetRef(containerID)
0000000000000000000000000000000000000000;;			if !ok {
0000000000000000000000000000000000000000;;				glog.Warningf("No ref for container %q", containerID)
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Note that 'rkt id' is the pod id.
0000000000000000000000000000000000000000;;			uuid := utilstrings.ShortenString(id.uuid, 8)
0000000000000000000000000000000000000000;;			switch reason {
0000000000000000000000000000000000000000;;			case "Created":
0000000000000000000000000000000000000000;;				r.recorder.Eventf(ref, v1.EventTypeNormal, events.CreatedContainer, "Created with rkt id %v", uuid)
0000000000000000000000000000000000000000;;			case "Started":
0000000000000000000000000000000000000000;;				r.recorder.Eventf(ref, v1.EventTypeNormal, events.StartedContainer, "Started with rkt id %v", uuid)
0000000000000000000000000000000000000000;;			case "Failed":
0000000000000000000000000000000000000000;;				r.recorder.Eventf(ref, v1.EventTypeWarning, events.FailedToStartContainer, "Failed to start with rkt id %v with error %v", uuid, failure)
0000000000000000000000000000000000000000;;			case "Killing":
0000000000000000000000000000000000000000;;				r.recorder.Eventf(ref, v1.EventTypeNormal, events.KillingContainer, "Killing with rkt id %v", uuid)
0000000000000000000000000000000000000000;;			default:
0000000000000000000000000000000000000000;;				glog.Errorf("rkt: Unexpected event %q", reason)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Generate a Network Namespace based on a New UUID
0000000000000000000000000000000000000000;;	// to run the Pod and all of its containers inside a dedicated unique namespace
0000000000000000000000000000000000000000;;	func generateNetworkNamespaceUUID() kubecontainer.ContainerID {
0000000000000000000000000000000000000000;;		return kubecontainer.ContainerID{ID: fmt.Sprintf("%s%s", kubernetesUnitPrefix, uuid.NewUUID())}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func netnsPathFromName(netnsName string) string {
0000000000000000000000000000000000000000;;		return fmt.Sprintf("/var/run/netns/%s", netnsName)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// setupPodNetwork creates a network namespace for the given pod and calls
0000000000000000000000000000000000000000;;	// configured NetworkPlugin's setup function on it.
0000000000000000000000000000000000000000;;	// It returns the namespace name, configured IP (if available), and an error if
0000000000000000000000000000000000000000;;	// one occurred.
0000000000000000000000000000000000000000;;	//
0000000000000000000000000000000000000000;;	// If the pod is running in host network or is running using the no-op plugin, then nothing will be done.
0000000000000000000000000000000000000000;;	func (r *Runtime) setupPodNetwork(pod *v1.Pod) (kubecontainer.ContainerID, string, error) {
0000000000000000000000000000000000000000;;		glog.V(3).Infof("Calling network plugin %s to set up pod for %s", r.network.PluginName(), format.Pod(pod))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		var networkNamespace kubecontainer.ContainerID
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// No-op if the pod is not running in a created netns.
0000000000000000000000000000000000000000;;		if !r.shouldCreateNetns(pod) {
0000000000000000000000000000000000000000;;			return networkNamespace, "", nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		networkNamespace = generateNetworkNamespaceUUID()
0000000000000000000000000000000000000000;;		glog.V(5).Infof("New network namespace %q generated for pod %s", networkNamespace.ID, format.Pod(pod))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Create the network namespace for the pod
0000000000000000000000000000000000000000;;		_, err := r.execer.Command("ip", "netns", "add", networkNamespace.ID).Output()
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return networkNamespace, "", fmt.Errorf("failed to create pod network namespace: %v", err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Set up networking with the network plugin
0000000000000000000000000000000000000000;;		err = r.network.SetUpPod(pod.Namespace, pod.Name, networkNamespace, pod.Annotations)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return networkNamespace, "", err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		status, err := r.network.GetPodNetworkStatus(pod.Namespace, pod.Name, networkNamespace)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return networkNamespace, "", err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if r.configureHairpinMode {
0000000000000000000000000000000000000000;;			if err = hairpin.SetUpContainerPath(netnsPathFromName(networkNamespace.ID), network.DefaultInterfaceName); err != nil {
0000000000000000000000000000000000000000;;				glog.Warningf("Hairpin setup failed for pod %q: %v", format.Pod(pod), err)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return networkNamespace, status.IP.String(), nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// For a hostPath volume: rkt doesn't create any missing volume on the node/host so we need to create it
0000000000000000000000000000000000000000;;	func createHostPathVolumes(pod *v1.Pod) (err error) {
0000000000000000000000000000000000000000;;		for _, v := range pod.Spec.Volumes {
0000000000000000000000000000000000000000;;			if v.VolumeSource.HostPath != nil {
0000000000000000000000000000000000000000;;				_, err = os.Stat(v.HostPath.Path)
0000000000000000000000000000000000000000;;				if os.IsNotExist(err) {
0000000000000000000000000000000000000000;;					if err = os.MkdirAll(v.HostPath.Path, os.ModePerm); err != nil {
0000000000000000000000000000000000000000;;						glog.Errorf("Create volume HostPath %q for Pod %q failed: %q", v.HostPath.Path, format.Pod(pod), err.Error())
0000000000000000000000000000000000000000;;						return err
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					glog.V(4).Infof("Created volume HostPath %q for Pod %q", v.HostPath.Path, format.Pod(pod))
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// RunPod first creates the unit file for a pod, and then
0000000000000000000000000000000000000000;;	// starts the unit over d-bus.
0000000000000000000000000000000000000000;;	func (r *Runtime) RunPod(pod *v1.Pod, pullSecrets []v1.Secret) error {
0000000000000000000000000000000000000000;;		glog.V(4).Infof("Rkt starts to run pod: name %q.", format.Pod(pod))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		var err error
0000000000000000000000000000000000000000;;		var networkNamespace kubecontainer.ContainerID
0000000000000000000000000000000000000000;;		var podIP string
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		err = createHostPathVolumes(pod)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		networkNamespace, podIP, err = r.setupPodNetwork(pod)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			r.cleanupPodNetwork(pod, networkNamespace)
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		name, runtimePod, prepareErr := r.preparePod(pod, podIP, pullSecrets, networkNamespace.ID)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Set container references and generate events.
0000000000000000000000000000000000000000;;		// If preparedPod fails, then send out 'failed' events for each container.
0000000000000000000000000000000000000000;;		// Otherwise, store the container references so we can use them later to send events.
0000000000000000000000000000000000000000;;		for i, c := range pod.Spec.Containers {
0000000000000000000000000000000000000000;;			ref, err := kubecontainer.GenerateContainerRef(pod, &c)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				glog.Errorf("Couldn't make a ref to pod %q, container %v: '%v'", format.Pod(pod), c.Name, err)
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if prepareErr != nil {
0000000000000000000000000000000000000000;;				r.recorder.Eventf(ref, v1.EventTypeWarning, events.FailedToCreateContainer, "Failed to create rkt container with error: %v", prepareErr)
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			containerID := runtimePod.Containers[i].ID
0000000000000000000000000000000000000000;;			r.containerRefManager.SetRef(containerID, ref)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if prepareErr != nil {
0000000000000000000000000000000000000000;;			r.cleanupPodNetwork(pod, networkNamespace)
0000000000000000000000000000000000000000;;			return prepareErr
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		r.generateEvents(runtimePod, "Created", nil)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// RestartUnit has the same effect as StartUnit if the unit is not running, besides it can restart
0000000000000000000000000000000000000000;;		// a unit if the unit file is changed and reloaded.
0000000000000000000000000000000000000000;;		reschan := make(chan string)
0000000000000000000000000000000000000000;;		_, err = r.systemd.RestartUnit(name, "replace", reschan)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			r.generateEvents(runtimePod, "Failed", err)
0000000000000000000000000000000000000000;;			r.cleanupPodNetwork(pod, networkNamespace)
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		res := <-reschan
0000000000000000000000000000000000000000;;		if res != "done" {
0000000000000000000000000000000000000000;;			err := fmt.Errorf("Failed to restart unit %q: %s", name, res)
0000000000000000000000000000000000000000;;			r.generateEvents(runtimePod, "Failed", err)
0000000000000000000000000000000000000000;;			r.cleanupPodNetwork(pod, networkNamespace)
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		r.generateEvents(runtimePod, "Started", nil)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// This is a temporary solution until we have a clean design on how
0000000000000000000000000000000000000000;;		// kubelet handles events. See https://github.com/kubernetes/kubernetes/issues/23084.
0000000000000000000000000000000000000000;;		if err := r.runLifecycleHooks(pod, runtimePod, lifecyclePostStartHook); err != nil {
0000000000000000000000000000000000000000;;			if errKill := r.KillPod(pod, *runtimePod, nil); errKill != nil {
0000000000000000000000000000000000000000;;				return errors.NewAggregate([]error{err, errKill})
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			r.cleanupPodNetwork(pod, networkNamespace)
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (r *Runtime) runPreStopHook(containerID kubecontainer.ContainerID, pod *v1.Pod, container *v1.Container) error {
0000000000000000000000000000000000000000;;		glog.V(4).Infof("rkt: Running pre-stop hook for container %q of pod %q", container.Name, format.Pod(pod))
0000000000000000000000000000000000000000;;		msg, err := r.runner.Run(containerID, pod, container, container.Lifecycle.PreStop)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			ref, ok := r.containerRefManager.GetRef(containerID)
0000000000000000000000000000000000000000;;			if !ok {
0000000000000000000000000000000000000000;;				glog.Warningf("No ref for container %q", containerID)
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				r.recorder.Eventf(ref, v1.EventTypeWarning, events.FailedPreStopHook, msg)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return err
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (r *Runtime) runPostStartHook(containerID kubecontainer.ContainerID, pod *v1.Pod, container *v1.Container) error {
0000000000000000000000000000000000000000;;		glog.V(4).Infof("rkt: Running post-start hook for container %q of pod %q", container.Name, format.Pod(pod))
0000000000000000000000000000000000000000;;		cid, err := parseContainerID(containerID)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return fmt.Errorf("cannot parse container ID %v", containerID)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		isContainerRunning := func() (done bool, err error) {
0000000000000000000000000000000000000000;;			ctx, cancel := context.WithTimeout(context.Background(), r.requestTimeout)
0000000000000000000000000000000000000000;;			defer cancel()
0000000000000000000000000000000000000000;;			resp, err := r.apisvc.InspectPod(ctx, &rktapi.InspectPodRequest{Id: cid.uuid})
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				return false, fmt.Errorf("failed to inspect rkt pod %q for pod %q", cid.uuid, format.Pod(pod))
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			for _, app := range resp.Pod.Apps {
0000000000000000000000000000000000000000;;				if app.Name == cid.appName {
0000000000000000000000000000000000000000;;					return app.State == rktapi.AppState_APP_STATE_RUNNING, nil
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			return false, fmt.Errorf("failed to find container %q in rkt pod %q", cid.appName, cid.uuid)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// TODO(yifan): Polling the pod's state for now.
0000000000000000000000000000000000000000;;		timeout := time.Second * 5
0000000000000000000000000000000000000000;;		pollInterval := time.Millisecond * 500
0000000000000000000000000000000000000000;;		if err := utilwait.Poll(pollInterval, timeout, isContainerRunning); err != nil {
0000000000000000000000000000000000000000;;			return fmt.Errorf("rkt: Pod %q doesn't become running in %v: %v", format.Pod(pod), timeout, err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		msg, err := r.runner.Run(containerID, pod, container, container.Lifecycle.PostStart)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			ref, ok := r.containerRefManager.GetRef(containerID)
0000000000000000000000000000000000000000;;			if !ok {
0000000000000000000000000000000000000000;;				glog.Warningf("No ref for container %q", containerID)
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				r.recorder.Eventf(ref, v1.EventTypeWarning, events.FailedPostStartHook, msg)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return err
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type lifecycleHookType string
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	const (
0000000000000000000000000000000000000000;;		lifecyclePostStartHook lifecycleHookType = "post-start"
0000000000000000000000000000000000000000;;		lifecyclePreStopHook   lifecycleHookType = "pre-stop"
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (r *Runtime) runLifecycleHooks(pod *v1.Pod, runtimePod *kubecontainer.Pod, typ lifecycleHookType) error {
0000000000000000000000000000000000000000;;		var wg sync.WaitGroup
0000000000000000000000000000000000000000;;		var errlist []error
0000000000000000000000000000000000000000;;		errCh := make(chan error, len(pod.Spec.Containers))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		wg.Add(len(pod.Spec.Containers))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		for i, c := range pod.Spec.Containers {
0000000000000000000000000000000000000000;;			var hookFunc func(kubecontainer.ContainerID, *v1.Pod, *v1.Container) error
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			switch typ {
0000000000000000000000000000000000000000;;			case lifecyclePostStartHook:
0000000000000000000000000000000000000000;;				if c.Lifecycle != nil && c.Lifecycle.PostStart != nil {
0000000000000000000000000000000000000000;;					hookFunc = r.runPostStartHook
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			case lifecyclePreStopHook:
0000000000000000000000000000000000000000;;				if c.Lifecycle != nil && c.Lifecycle.PreStop != nil {
0000000000000000000000000000000000000000;;					hookFunc = r.runPreStopHook
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			default:
0000000000000000000000000000000000000000;;				errCh <- fmt.Errorf("Unrecognized lifecycle hook type %q for container %q in pod %q", typ, c.Name, format.Pod(pod))
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			if hookFunc == nil {
0000000000000000000000000000000000000000;;				wg.Done()
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			container := &pod.Spec.Containers[i]
0000000000000000000000000000000000000000;;			runtimeContainer := runtimePod.FindContainerByName(container.Name)
0000000000000000000000000000000000000000;;			if runtimeContainer == nil {
0000000000000000000000000000000000000000;;				// Container already gone.
0000000000000000000000000000000000000000;;				wg.Done()
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			containerID := runtimeContainer.ID
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			go func() {
0000000000000000000000000000000000000000;;				defer wg.Done()
0000000000000000000000000000000000000000;;				if err := hookFunc(containerID, pod, container); err != nil {
0000000000000000000000000000000000000000;;					glog.Errorf("rkt: Failed to run %s hook for container %q of pod %q: %v", typ, container.Name, format.Pod(pod), err)
0000000000000000000000000000000000000000;;					errCh <- err
0000000000000000000000000000000000000000;;				} else {
0000000000000000000000000000000000000000;;					glog.V(4).Infof("rkt: %s hook completed successfully for container %q of pod %q", typ, container.Name, format.Pod(pod))
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}()
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		wg.Wait()
0000000000000000000000000000000000000000;;		close(errCh)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		for err := range errCh {
0000000000000000000000000000000000000000;;			errlist = append(errlist, err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return errors.NewAggregate(errlist)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// convertRktPod will convert a rktapi.Pod to a kubecontainer.Pod
0000000000000000000000000000000000000000;;	func (r *Runtime) convertRktPod(rktpod *rktapi.Pod) (*kubecontainer.Pod, error) {
0000000000000000000000000000000000000000;;		manifest := &appcschema.PodManifest{}
0000000000000000000000000000000000000000;;		err := json.Unmarshal(rktpod.Manifest, manifest)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return nil, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		podUID, ok := manifest.Annotations.Get(types.KubernetesPodUIDLabel)
0000000000000000000000000000000000000000;;		if !ok {
0000000000000000000000000000000000000000;;			return nil, fmt.Errorf("pod is missing annotation %s", types.KubernetesPodUIDLabel)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		podName, ok := manifest.Annotations.Get(types.KubernetesPodNameLabel)
0000000000000000000000000000000000000000;;		if !ok {
0000000000000000000000000000000000000000;;			return nil, fmt.Errorf("pod is missing annotation %s", types.KubernetesPodNameLabel)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		podNamespace, ok := manifest.Annotations.Get(types.KubernetesPodNamespaceLabel)
0000000000000000000000000000000000000000;;		if !ok {
0000000000000000000000000000000000000000;;			return nil, fmt.Errorf("pod is missing annotation %s", types.KubernetesPodNamespaceLabel)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		kubepod := &kubecontainer.Pod{
0000000000000000000000000000000000000000;;			ID:        kubetypes.UID(podUID),
0000000000000000000000000000000000000000;;			Name:      podName,
0000000000000000000000000000000000000000;;			Namespace: podNamespace,
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		for i, app := range rktpod.Apps {
0000000000000000000000000000000000000000;;			// The order of the apps is determined by the rkt pod manifest.
0000000000000000000000000000000000000000;;			// TODO(yifan): Let the server to unmarshal the annotations? https://github.com/coreos/rkt/issues/1872
0000000000000000000000000000000000000000;;			hashStr, ok := manifest.Apps[i].Annotations.Get(k8sRktContainerHashAnno)
0000000000000000000000000000000000000000;;			if !ok {
0000000000000000000000000000000000000000;;				return nil, fmt.Errorf("app %q is missing annotation %s", app.Name, k8sRktContainerHashAnno)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			containerHash, err := strconv.ParseUint(hashStr, 10, 64)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				return nil, fmt.Errorf("couldn't parse container's hash %q: %v", hashStr, err)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			kubepod.Containers = append(kubepod.Containers, &kubecontainer.Container{
0000000000000000000000000000000000000000;;				ID:   buildContainerID(&containerID{rktpod.Id, app.Name}),
0000000000000000000000000000000000000000;;				Name: app.Name,
0000000000000000000000000000000000000000;;				// By default, the version returned by rkt API service will be "latest" if not specified.
0000000000000000000000000000000000000000;;				Image:   fmt.Sprintf("%s:%s", app.Image.Name, app.Image.Version),
0000000000000000000000000000000000000000;;				ImageID: app.Image.Id,
0000000000000000000000000000000000000000;;				Hash:    containerHash,
0000000000000000000000000000000000000000;;				State:   appStateToContainerState(app.State),
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return kubepod, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// GetPods runs 'rkt list' to get the list of rkt pods.
0000000000000000000000000000000000000000;;	// Then it will use the result to construct a list of container runtime pods.
0000000000000000000000000000000000000000;;	// If all is false, then only running pods will be returned, otherwise all pods will be
0000000000000000000000000000000000000000;;	// returned.
0000000000000000000000000000000000000000;;	func (r *Runtime) GetPods(all bool) ([]*kubecontainer.Pod, error) {
0000000000000000000000000000000000000000;;		glog.V(4).Infof("Rkt getting pods")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		listReq := &rktapi.ListPodsRequest{
0000000000000000000000000000000000000000;;			Detail: true,
0000000000000000000000000000000000000000;;			Filters: []*rktapi.PodFilter{
0000000000000000000000000000000000000000;;				{
0000000000000000000000000000000000000000;;					Annotations: []*rktapi.KeyValue{
0000000000000000000000000000000000000000;;						{
0000000000000000000000000000000000000000;;							Key:   k8sRktKubeletAnno,
0000000000000000000000000000000000000000;;							Value: k8sRktKubeletAnnoValue,
0000000000000000000000000000000000000000;;						},
0000000000000000000000000000000000000000;;					},
0000000000000000000000000000000000000000;;				},
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if !all {
0000000000000000000000000000000000000000;;			listReq.Filters[0].States = []rktapi.PodState{rktapi.PodState_POD_STATE_RUNNING}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		ctx, cancel := context.WithTimeout(context.Background(), r.requestTimeout)
0000000000000000000000000000000000000000;;		defer cancel()
0000000000000000000000000000000000000000;;		listResp, err := r.apisvc.ListPods(ctx, listReq)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return nil, fmt.Errorf("couldn't list pods: %v", err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		pods := make(map[kubetypes.UID]*kubecontainer.Pod)
0000000000000000000000000000000000000000;;		var podIDs []kubetypes.UID
0000000000000000000000000000000000000000;;		for _, pod := range listResp.Pods {
0000000000000000000000000000000000000000;;			pod, err := r.convertRktPod(pod)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				glog.Warningf("rkt: Cannot construct pod from unit file: %v.", err)
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Group pods together.
0000000000000000000000000000000000000000;;			oldPod, found := pods[pod.ID]
0000000000000000000000000000000000000000;;			if !found {
0000000000000000000000000000000000000000;;				pods[pod.ID] = pod
0000000000000000000000000000000000000000;;				podIDs = append(podIDs, pod.ID)
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			oldPod.Containers = append(oldPod.Containers, pod.Containers...)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Convert map to list, using the consistent order from the podIDs array.
0000000000000000000000000000000000000000;;		var result []*kubecontainer.Pod
0000000000000000000000000000000000000000;;		for _, id := range podIDs {
0000000000000000000000000000000000000000;;			result = append(result, pods[id])
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return result, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func getPodTerminationGracePeriodInSecond(pod *v1.Pod) int64 {
0000000000000000000000000000000000000000;;		var gracePeriod int64
0000000000000000000000000000000000000000;;		switch {
0000000000000000000000000000000000000000;;		case pod.DeletionGracePeriodSeconds != nil:
0000000000000000000000000000000000000000;;			gracePeriod = *pod.DeletionGracePeriodSeconds
0000000000000000000000000000000000000000;;		case pod.Spec.TerminationGracePeriodSeconds != nil:
0000000000000000000000000000000000000000;;			gracePeriod = *pod.Spec.TerminationGracePeriodSeconds
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if gracePeriod < minimumGracePeriodInSeconds {
0000000000000000000000000000000000000000;;			gracePeriod = minimumGracePeriodInSeconds
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return gracePeriod
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (r *Runtime) waitPreStopHooks(pod *v1.Pod, runningPod *kubecontainer.Pod) {
0000000000000000000000000000000000000000;;		gracePeriod := getPodTerminationGracePeriodInSecond(pod)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		done := make(chan struct{})
0000000000000000000000000000000000000000;;		go func() {
0000000000000000000000000000000000000000;;			if err := r.runLifecycleHooks(pod, runningPod, lifecyclePreStopHook); err != nil {
0000000000000000000000000000000000000000;;				glog.Errorf("rkt: Some pre-stop hooks failed for pod %q: %v", format.Pod(pod), err)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			close(done)
0000000000000000000000000000000000000000;;		}()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		select {
0000000000000000000000000000000000000000;;		case <-time.After(time.Duration(gracePeriod) * time.Second):
0000000000000000000000000000000000000000;;			glog.V(2).Infof("rkt: Some pre-stop hooks did not complete in %d seconds for pod %q", gracePeriod, format.Pod(pod))
0000000000000000000000000000000000000000;;		case <-done:
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// KillPod invokes 'systemctl kill' to kill the unit that runs the pod.
0000000000000000000000000000000000000000;;	// TODO: add support for gracePeriodOverride which is used in eviction scenarios
0000000000000000000000000000000000000000;;	func (r *Runtime) KillPod(pod *v1.Pod, runningPod kubecontainer.Pod, gracePeriodOverride *int64) error {
0000000000000000000000000000000000000000;;		glog.V(4).Infof("Rkt is killing pod: name %q.", runningPod.Name)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if len(runningPod.Containers) == 0 {
0000000000000000000000000000000000000000;;			glog.V(4).Infof("rkt: Pod %q is already being killed, no action will be taken", runningPod.Name)
0000000000000000000000000000000000000000;;			return nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if pod != nil {
0000000000000000000000000000000000000000;;			r.waitPreStopHooks(pod, &runningPod)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		containerID, err := parseContainerID(runningPod.Containers[0].ID)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			glog.Errorf("rkt: Failed to get rkt uuid of the pod %q: %v", runningPod.Name, err)
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		serviceName := makePodServiceFileName(containerID.uuid)
0000000000000000000000000000000000000000;;		serviceFile := serviceFilePath(serviceName)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		r.generateEvents(&runningPod, "Killing", nil)
0000000000000000000000000000000000000000;;		for _, c := range runningPod.Containers {
0000000000000000000000000000000000000000;;			r.containerRefManager.ClearRef(c.ID)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Since all service file have 'KillMode=mixed', the processes in
0000000000000000000000000000000000000000;;		// the unit's cgroup will receive a SIGKILL if the normal stop timeouts.
0000000000000000000000000000000000000000;;		reschan := make(chan string)
0000000000000000000000000000000000000000;;		if _, err = r.systemd.StopUnit(serviceName, "replace", reschan); err != nil {
0000000000000000000000000000000000000000;;			glog.Errorf("rkt: Failed to stop unit %q: %v", serviceName, err)
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		res := <-reschan
0000000000000000000000000000000000000000;;		if res != "done" {
0000000000000000000000000000000000000000;;			err := fmt.Errorf("invalid result: %s", res)
0000000000000000000000000000000000000000;;			glog.Errorf("rkt: Failed to stop unit %q: %v", serviceName, err)
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Clean up networking. Use the service file to get pod details since 'pod' can be nil.
0000000000000000000000000000000000000000;;		if err := r.cleanupPodNetworkFromServiceFile(serviceFile); err != nil {
0000000000000000000000000000000000000000;;			glog.Errorf("rkt: failed to tear down network for unit %q: %v", serviceName, err)
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (r *Runtime) Type() string {
0000000000000000000000000000000000000000;;		return RktType
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (r *Runtime) Version() (kubecontainer.Version, error) {
0000000000000000000000000000000000000000;;		r.versions.RLock()
0000000000000000000000000000000000000000;;		defer r.versions.RUnlock()
0000000000000000000000000000000000000000;;		return r.versions.binVersion, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (r *Runtime) APIVersion() (kubecontainer.Version, error) {
0000000000000000000000000000000000000000;;		r.versions.RLock()
0000000000000000000000000000000000000000;;		defer r.versions.RUnlock()
0000000000000000000000000000000000000000;;		return r.versions.apiVersion, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Status returns error if rkt is unhealthy, nil otherwise.
0000000000000000000000000000000000000000;;	func (r *Runtime) Status() (*kubecontainer.RuntimeStatus, error) {
0000000000000000000000000000000000000000;;		return nil, r.checkVersion(minimumRktBinVersion, minimumRktApiVersion, minimumSystemdVersion)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// SyncPod syncs the running pod to match the specified desired pod.
0000000000000000000000000000000000000000;;	func (r *Runtime) SyncPod(pod *v1.Pod, _ v1.PodStatus, podStatus *kubecontainer.PodStatus, pullSecrets []v1.Secret, backOff *flowcontrol.Backoff) (result kubecontainer.PodSyncResult) {
0000000000000000000000000000000000000000;;		var err error
0000000000000000000000000000000000000000;;		defer func() {
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				result.Fail(err)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}()
0000000000000000000000000000000000000000;;		// TODO: (random-liu) Stop using running pod in SyncPod()
0000000000000000000000000000000000000000;;		runningPod := kubecontainer.ConvertPodStatusToRunningPod(r.Type(), podStatus)
0000000000000000000000000000000000000000;;		// Add references to all containers.
0000000000000000000000000000000000000000;;		unidentifiedContainers := make(map[kubecontainer.ContainerID]*kubecontainer.Container)
0000000000000000000000000000000000000000;;		for _, c := range runningPod.Containers {
0000000000000000000000000000000000000000;;			unidentifiedContainers[c.ID] = c
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		restartPod := false
0000000000000000000000000000000000000000;;		for _, container := range pod.Spec.Containers {
0000000000000000000000000000000000000000;;			expectedHash := kubecontainer.HashContainerLegacy(&container)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			c := runningPod.FindContainerByName(container.Name)
0000000000000000000000000000000000000000;;			if c == nil {
0000000000000000000000000000000000000000;;				if kubecontainer.ShouldContainerBeRestarted(&container, pod, podStatus) {
0000000000000000000000000000000000000000;;					glog.V(3).Infof("Container %+v is dead, but RestartPolicy says that we should restart it.", container)
0000000000000000000000000000000000000000;;					// TODO(yifan): Containers in one pod are fate-sharing at this moment, see:
0000000000000000000000000000000000000000;;					// https://github.com/appc/spec/issues/276.
0000000000000000000000000000000000000000;;					restartPod = true
0000000000000000000000000000000000000000;;					break
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// TODO: check for non-root image directives.  See ../docker/manager.go#SyncPod
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// TODO(yifan): Take care of host network change.
0000000000000000000000000000000000000000;;			containerChanged := c.Hash != 0 && c.Hash != expectedHash
0000000000000000000000000000000000000000;;			if containerChanged {
0000000000000000000000000000000000000000;;				glog.Infof("Pod %q container %q hash changed (%d vs %d), it will be killed and re-created.", format.Pod(pod), container.Name, c.Hash, expectedHash)
0000000000000000000000000000000000000000;;				restartPod = true
0000000000000000000000000000000000000000;;				break
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			liveness, found := r.livenessManager.Get(c.ID)
0000000000000000000000000000000000000000;;			if found && liveness != proberesults.Success && pod.Spec.RestartPolicy != v1.RestartPolicyNever {
0000000000000000000000000000000000000000;;				glog.Infof("Pod %q container %q is unhealthy, it will be killed and re-created.", format.Pod(pod), container.Name)
0000000000000000000000000000000000000000;;				restartPod = true
0000000000000000000000000000000000000000;;				break
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			delete(unidentifiedContainers, c.ID)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// If there is any unidentified containers, restart the pod.
0000000000000000000000000000000000000000;;		if len(unidentifiedContainers) > 0 {
0000000000000000000000000000000000000000;;			restartPod = true
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if restartPod {
0000000000000000000000000000000000000000;;			// Kill the pod only if the pod is actually running.
0000000000000000000000000000000000000000;;			if len(runningPod.Containers) > 0 {
0000000000000000000000000000000000000000;;				if err = r.KillPod(pod, runningPod, nil); err != nil {
0000000000000000000000000000000000000000;;					return
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if err = r.RunPod(pod, pullSecrets); err != nil {
0000000000000000000000000000000000000000;;				return
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Sort rkt pods by creation time.
0000000000000000000000000000000000000000;;	type podsByCreatedAt []*rktapi.Pod
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (s podsByCreatedAt) Len() int           { return len(s) }
0000000000000000000000000000000000000000;;	func (s podsByCreatedAt) Swap(i, j int)      { s[i], s[j] = s[j], s[i] }
0000000000000000000000000000000000000000;;	func (s podsByCreatedAt) Less(i, j int) bool { return s[i].CreatedAt < s[j].CreatedAt }
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// getPodUID returns the pod's API UID, it returns
0000000000000000000000000000000000000000;;	// empty UID if the UID cannot be determined.
0000000000000000000000000000000000000000;;	func getPodUID(pod *rktapi.Pod) kubetypes.UID {
0000000000000000000000000000000000000000;;		for _, anno := range pod.Annotations {
0000000000000000000000000000000000000000;;			if anno.Key == types.KubernetesPodUIDLabel {
0000000000000000000000000000000000000000;;				return kubetypes.UID(anno.Value)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return kubetypes.UID("")
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// podIsActive returns true if the pod is embryo, preparing or running.
0000000000000000000000000000000000000000;;	// If a pod is prepared, it is not guaranteed to be active (e.g. the systemd
0000000000000000000000000000000000000000;;	// service might fail).
0000000000000000000000000000000000000000;;	func podIsActive(pod *rktapi.Pod) bool {
0000000000000000000000000000000000000000;;		return pod.State == rktapi.PodState_POD_STATE_EMBRYO ||
0000000000000000000000000000000000000000;;			pod.State == rktapi.PodState_POD_STATE_PREPARING ||
0000000000000000000000000000000000000000;;			pod.State == rktapi.PodState_POD_STATE_RUNNING
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// GetNetNS returns the network namespace path for the given container
0000000000000000000000000000000000000000;;	func (r *Runtime) GetNetNS(containerID kubecontainer.ContainerID) (string, error) {
0000000000000000000000000000000000000000;;		// Currently the containerID is a UUID for a network namespace
0000000000000000000000000000000000000000;;		// This hack is a way to create an unique network namespace for each new starting/restarting Pod
0000000000000000000000000000000000000000;;		// We can do this because we played the same trick in
0000000000000000000000000000000000000000;;		// `networkPlugin.SetUpPod` and `networkPlugin.TearDownPod`.
0000000000000000000000000000000000000000;;		// See https://github.com/kubernetes/kubernetes/issues/45149
0000000000000000000000000000000000000000;;		return netnsPathFromName(containerID.ID), nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (r *Runtime) GetPodContainerID(pod *kubecontainer.Pod) (kubecontainer.ContainerID, error) {
0000000000000000000000000000000000000000;;		return kubecontainer.ContainerID{ID: string(pod.ID)}, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (r *Runtime) getKubernetesDirective(serviceFilePath string) (podService podServiceDirective, err error) {
0000000000000000000000000000000000000000;;		f, err := os.Open(serviceFilePath)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return podService, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		defer f.Close()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		opts, err := unit.Deserialize(f)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return podService, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		var hostnetwork, networkNamespace string
0000000000000000000000000000000000000000;;		for _, o := range opts {
0000000000000000000000000000000000000000;;			if o.Section != unitKubernetesSection {
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			switch o.Name {
0000000000000000000000000000000000000000;;			case unitPodUID:
0000000000000000000000000000000000000000;;				podService.id = o.Value
0000000000000000000000000000000000000000;;			case unitPodName:
0000000000000000000000000000000000000000;;				podService.name = o.Value
0000000000000000000000000000000000000000;;			case unitPodNamespace:
0000000000000000000000000000000000000000;;				podService.namespace = o.Value
0000000000000000000000000000000000000000;;			case unitPodHostNetwork:
0000000000000000000000000000000000000000;;				hostnetwork = o.Value
0000000000000000000000000000000000000000;;			case unitPodNetworkNamespace:
0000000000000000000000000000000000000000;;				networkNamespace = o.Value
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			if podService.id != "" && podService.name != "" && podService.namespace != "" && hostnetwork != "" && networkNamespace != "" {
0000000000000000000000000000000000000000;;				podService.hostNetwork, err = strconv.ParseBool(hostnetwork)
0000000000000000000000000000000000000000;;				podService.networkNamespace = kubecontainer.ContainerID{ID: networkNamespace}
0000000000000000000000000000000000000000;;				if err != nil {
0000000000000000000000000000000000000000;;					return podService, err
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				return podService, nil
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return podService, fmt.Errorf("failed to parse pod from file %s", serviceFilePath)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (r *Runtime) DeleteContainer(containerID kubecontainer.ContainerID) error {
0000000000000000000000000000000000000000;;		return fmt.Errorf("unimplemented")
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Collects all the systemd units for k8s Pods
0000000000000000000000000000000000000000;;	func (r *Runtime) getPodSystemdServiceFiles() ([]os.FileInfo, error) {
0000000000000000000000000000000000000000;;		// Get all the current units
0000000000000000000000000000000000000000;;		files, err := r.os.ReadDir(systemdServiceDir)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			glog.Errorf("rkt: Failed to read the systemd service directory: %v", err)
0000000000000000000000000000000000000000;;			return files, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Keep only k8s unit files
0000000000000000000000000000000000000000;;		k8sSystemdServiceFiles := files[:0]
0000000000000000000000000000000000000000;;		for _, f := range files {
0000000000000000000000000000000000000000;;			if strings.HasPrefix(f.Name(), kubernetesUnitPrefix) {
0000000000000000000000000000000000000000;;				k8sSystemdServiceFiles = append(k8sSystemdServiceFiles, f)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return k8sSystemdServiceFiles, err
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// GarbageCollect collects the pods/containers.
0000000000000000000000000000000000000000;;	// After one GC iteration:
0000000000000000000000000000000000000000;;	// - The deleted pods will be removed.
0000000000000000000000000000000000000000;;	// - If the number of containers exceeds gcPolicy.MaxContainers,
0000000000000000000000000000000000000000;;	//   then containers whose ages are older than gcPolicy.minAge will
0000000000000000000000000000000000000000;;	//   be removed.
0000000000000000000000000000000000000000;;	func (r *Runtime) GarbageCollect(gcPolicy kubecontainer.ContainerGCPolicy, allSourcesReady bool, _ bool) error {
0000000000000000000000000000000000000000;;		var errlist []error
0000000000000000000000000000000000000000;;		var totalInactiveContainers int
0000000000000000000000000000000000000000;;		var inactivePods []*rktapi.Pod
0000000000000000000000000000000000000000;;		var removeCandidates []*rktapi.Pod
0000000000000000000000000000000000000000;;		var allPods = map[string]*rktapi.Pod{}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		glog.V(4).Infof("rkt: Garbage collecting triggered with policy %v", gcPolicy)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// GC all inactive systemd service files and pods.
0000000000000000000000000000000000000000;;		files, err := r.getPodSystemdServiceFiles()
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		ctx, cancel := context.WithTimeout(context.Background(), r.requestTimeout)
0000000000000000000000000000000000000000;;		defer cancel()
0000000000000000000000000000000000000000;;		resp, err := r.apisvc.ListPods(ctx, &rktapi.ListPodsRequest{Filters: kubernetesPodsFilters()})
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			glog.Errorf("rkt: Failed to list pods: %v", err)
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Mark inactive pods.
0000000000000000000000000000000000000000;;		for _, pod := range resp.Pods {
0000000000000000000000000000000000000000;;			allPods[pod.Id] = pod
0000000000000000000000000000000000000000;;			if !podIsActive(pod) {
0000000000000000000000000000000000000000;;				uid := getPodUID(pod)
0000000000000000000000000000000000000000;;				if uid == kubetypes.UID("") {
0000000000000000000000000000000000000000;;					glog.Errorf("rkt: Cannot get the UID of pod %q, pod is broken, will remove it", pod.Id)
0000000000000000000000000000000000000000;;					removeCandidates = append(removeCandidates, pod)
0000000000000000000000000000000000000000;;					continue
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				_, found := r.podGetter.GetPodByUID(uid)
0000000000000000000000000000000000000000;;				if !found && allSourcesReady {
0000000000000000000000000000000000000000;;					removeCandidates = append(removeCandidates, pod)
0000000000000000000000000000000000000000;;					continue
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				inactivePods = append(inactivePods, pod)
0000000000000000000000000000000000000000;;				totalInactiveContainers = totalInactiveContainers + len(pod.Apps)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Remove any orphan service files.
0000000000000000000000000000000000000000;;		for _, f := range files {
0000000000000000000000000000000000000000;;			serviceName := f.Name()
0000000000000000000000000000000000000000;;			rktUUID := getRktUUIDFromServiceFileName(serviceName)
0000000000000000000000000000000000000000;;			if _, ok := allPods[rktUUID]; !ok {
0000000000000000000000000000000000000000;;				glog.V(4).Infof("rkt: No rkt pod found for service file %q, will remove it", serviceName)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				if err := r.cleanupByPodId(rktUUID); err != nil {
0000000000000000000000000000000000000000;;					errlist = append(errlist, fmt.Errorf("rkt: Failed to clean up rkt pod %q: %v", rktUUID, err))
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		sort.Sort(podsByCreatedAt(inactivePods))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Enforce GCPolicy.MaxContainers.
0000000000000000000000000000000000000000;;		for _, pod := range inactivePods {
0000000000000000000000000000000000000000;;			if totalInactiveContainers <= gcPolicy.MaxContainers {
0000000000000000000000000000000000000000;;				break
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			creationTime := time.Unix(0, pod.CreatedAt)
0000000000000000000000000000000000000000;;			if creationTime.Add(gcPolicy.MinAge).Before(time.Now()) {
0000000000000000000000000000000000000000;;				// The pod is old and we are exceeding the MaxContainers limit.
0000000000000000000000000000000000000000;;				// Delete the pod.
0000000000000000000000000000000000000000;;				removeCandidates = append(removeCandidates, pod)
0000000000000000000000000000000000000000;;				totalInactiveContainers = totalInactiveContainers - len(pod.Apps)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Remove pods and their service files.
0000000000000000000000000000000000000000;;		for _, pod := range removeCandidates {
0000000000000000000000000000000000000000;;			if err := r.removePod(pod); err != nil {
0000000000000000000000000000000000000000;;				errlist = append(errlist, fmt.Errorf("rkt: Failed to clean up rkt pod %q: %v", pod.Id, err))
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return errors.NewAggregate(errlist)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Read kubernetes pod UUID, namespace, netns and name from systemd service file and
0000000000000000000000000000000000000000;;	// use that to clean up any pod network that may still exist.
0000000000000000000000000000000000000000;;	func (r *Runtime) cleanupPodNetworkFromServiceFile(serviceFilePath string) error {
0000000000000000000000000000000000000000;;		podService, err := r.unitGetter.getKubernetesDirective(serviceFilePath)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return r.cleanupPodNetwork(&v1.Pod{
0000000000000000000000000000000000000000;;			ObjectMeta: metav1.ObjectMeta{
0000000000000000000000000000000000000000;;				UID:       kubetypes.UID(podService.id),
0000000000000000000000000000000000000000;;				Name:      podService.name,
0000000000000000000000000000000000000000;;				Namespace: podService.namespace,
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;			Spec: v1.PodSpec{
0000000000000000000000000000000000000000;;				HostNetwork: podService.hostNetwork,
0000000000000000000000000000000000000000;;			},
0000000000000000000000000000000000000000;;		}, podService.networkNamespace)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Remove the touched file created by ExecStartPost in the systemd service file
0000000000000000000000000000000000000000;;	func (r *Runtime) removeFinishedMarkerFile(serviceName string) error {
0000000000000000000000000000000000000000;;		serviceFile := serviceFilePath(serviceName)
0000000000000000000000000000000000000000;;		podDetail, err := r.unitGetter.getKubernetesDirective(serviceFile)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		podDir := r.runtimeHelper.GetPodDir(kubetypes.UID(podDetail.id))
0000000000000000000000000000000000000000;;		finishedFile := podFinishedMarkerPath(podDir, getRktUUIDFromServiceFileName(serviceName))
0000000000000000000000000000000000000000;;		return r.os.Remove(finishedFile)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Iter over each container in the pod to delete its termination log file
0000000000000000000000000000000000000000;;	func (r *Runtime) removeTerminationFiles(pod *rktapi.Pod) (errlist []error) {
0000000000000000000000000000000000000000;;		// container == app
0000000000000000000000000000000000000000;;		for _, app := range pod.Apps {
0000000000000000000000000000000000000000;;			for _, annotation := range app.Annotations {
0000000000000000000000000000000000000000;;				if annotation.GetKey() == k8sRktTerminationMessagePathAnno {
0000000000000000000000000000000000000000;;					if err := r.os.Remove(annotation.GetValue()); err != nil {
0000000000000000000000000000000000000000;;						errlist = append(errlist, fmt.Errorf("rkt: Failed to remove for pod %q container file %v", pod.Id, err))
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return errlist
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (r *Runtime) cleanupByPodId(podID string) (errlist []error) {
0000000000000000000000000000000000000000;;		serviceName := makePodServiceFileName(podID)
0000000000000000000000000000000000000000;;		serviceFile := serviceFilePath(serviceName)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if err := r.cleanupPodNetworkFromServiceFile(serviceFile); err != nil {
0000000000000000000000000000000000000000;;			errlist = append(errlist, fmt.Errorf("rkt: Failed to clean up pod network from service %q: %v, the network may not be around already", serviceName, err))
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// GC finished marker, termination-log file, systemd service files as well.
0000000000000000000000000000000000000000;;		if err := r.systemd.ResetFailedUnit(serviceName); err != nil {
0000000000000000000000000000000000000000;;			errlist = append(errlist, fmt.Errorf("rkt: Failed to reset the failed systemd service %q: %v", serviceName, err))
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if err := r.removeFinishedMarkerFile(serviceName); err != nil {
0000000000000000000000000000000000000000;;			errlist = append(errlist, fmt.Errorf("rkt: Failed to remove finished file %q for unit %q: %v", serviceName, podID, err))
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if err := r.os.Remove(serviceFile); err != nil {
0000000000000000000000000000000000000000;;			errlist = append(errlist, fmt.Errorf("rkt: Failed to remove service file %q for pod %q: %v", serviceFile, podID, err))
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return errlist
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// removePod calls 'rkt rm $UUID' to delete a rkt pod,
0000000000000000000000000000000000000000;;	// it also remove the systemd service file,
0000000000000000000000000000000000000000;;	// the finished-* marker and the termination-log files
0000000000000000000000000000000000000000;;	// related to the pod.
0000000000000000000000000000000000000000;;	func (r *Runtime) removePod(pod *rktapi.Pod) error {
0000000000000000000000000000000000000000;;		var errlist []error
0000000000000000000000000000000000000000;;		glog.V(4).Infof("rkt: GC is removing pod %q", pod)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if err := r.cleanupByPodId(pod.Id); err != nil {
0000000000000000000000000000000000000000;;			errlist = append(errlist, fmt.Errorf("rkt: Failed to remove pod %q: %v", pod.Id, err))
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if err := r.removeTerminationFiles(pod); err != nil {
0000000000000000000000000000000000000000;;			errlist = append(errlist, fmt.Errorf("rkt: Failed to clean up pod TerminationMessageFile %q: %v", pod.Id, err))
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if _, err := r.cli.RunCommand(nil, "rm", pod.Id); err != nil {
0000000000000000000000000000000000000000;;			errlist = append(errlist, fmt.Errorf("rkt: Failed to remove pod %q: %v", pod.Id, err))
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return errors.NewAggregate(errlist)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// rktExitError implements /pkg/util/exec.ExitError interface.
0000000000000000000000000000000000000000;;	type rktExitError struct{ *exec.ExitError }
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	var _ utilexec.ExitError = &rktExitError{}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (r *rktExitError) ExitStatus() int {
0000000000000000000000000000000000000000;;		if status, ok := r.Sys().(syscall.WaitStatus); ok {
0000000000000000000000000000000000000000;;			return status.ExitStatus()
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return 0
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func newRktExitError(e error) error {
0000000000000000000000000000000000000000;;		if exitErr, ok := e.(*exec.ExitError); ok {
0000000000000000000000000000000000000000;;			return &rktExitError{exitErr}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return e
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (r *Runtime) AttachContainer(containerID kubecontainer.ContainerID, stdin io.Reader, stdout, stderr io.WriteCloser, tty bool, resize <-chan remotecommand.TerminalSize) error {
0000000000000000000000000000000000000000;;		return fmt.Errorf("unimplemented")
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Note: In rkt, the container ID is in the form of "UUID:appName", where UUID is
0000000000000000000000000000000000000000;;	// the rkt UUID, and appName is the container name.
0000000000000000000000000000000000000000;;	// TODO(yifan): If the rkt is using lkvm as the stage1 image, then this function will fail.
0000000000000000000000000000000000000000;;	func (r *Runtime) ExecInContainer(containerID kubecontainer.ContainerID, cmd []string, stdin io.Reader, stdout, stderr io.WriteCloser, tty bool, resize <-chan remotecommand.TerminalSize, timeout time.Duration) error {
0000000000000000000000000000000000000000;;		glog.V(4).Infof("Rkt execing in container.")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		id, err := parseContainerID(containerID)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		args := []string{"enter", fmt.Sprintf("--app=%s", id.appName), id.uuid}
0000000000000000000000000000000000000000;;		args = append(args, cmd...)
0000000000000000000000000000000000000000;;		command := buildCommand(r.config, args...)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if tty {
0000000000000000000000000000000000000000;;			p, err := kubecontainer.StartPty(command)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				return err
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			defer p.Close()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// make sure to close the stdout stream
0000000000000000000000000000000000000000;;			defer stdout.Close()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			kubecontainer.HandleResizing(resize, func(size remotecommand.TerminalSize) {
0000000000000000000000000000000000000000;;				term.SetSize(p.Fd(), size)
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			if stdin != nil {
0000000000000000000000000000000000000000;;				go io.Copy(p, stdin)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if stdout != nil {
0000000000000000000000000000000000000000;;				go io.Copy(stdout, p)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			return newRktExitError(command.Wait())
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if stdin != nil {
0000000000000000000000000000000000000000;;			// Use an os.Pipe here as it returns true *os.File objects.
0000000000000000000000000000000000000000;;			// This way, if you run 'kubectl exec <pod> -i bash' (no tty) and type 'exit',
0000000000000000000000000000000000000000;;			// the call below to command.Run() can unblock because its Stdin is the read half
0000000000000000000000000000000000000000;;			// of the pipe.
0000000000000000000000000000000000000000;;			r, w, err := r.os.Pipe()
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				return newRktExitError(err)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			go io.Copy(w, stdin)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			command.Stdin = r
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if stdout != nil {
0000000000000000000000000000000000000000;;			command.Stdout = stdout
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if stderr != nil {
0000000000000000000000000000000000000000;;			command.Stderr = stderr
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return newRktExitError(command.Run())
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// PortForward executes socat in the pod's network namespace and copies
0000000000000000000000000000000000000000;;	// data between stream (representing the user's local connection on their
0000000000000000000000000000000000000000;;	// computer) and the specified port in the container.
0000000000000000000000000000000000000000;;	//
0000000000000000000000000000000000000000;;	// TODO:
0000000000000000000000000000000000000000;;	//  - match cgroups of container
0000000000000000000000000000000000000000;;	//  - should we support nsenter + socat on the host? (current impl)
0000000000000000000000000000000000000000;;	//  - should we support nsenter + socat in a container, running with elevated privs and --pid=host?
0000000000000000000000000000000000000000;;	//
0000000000000000000000000000000000000000;;	// TODO(yifan): Merge with the same function in dockertools.
0000000000000000000000000000000000000000;;	func (r *Runtime) PortForward(pod *kubecontainer.Pod, port int32, stream io.ReadWriteCloser) error {
0000000000000000000000000000000000000000;;		glog.V(4).Infof("Rkt port forwarding in container.")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		ctx, cancel := context.WithTimeout(context.Background(), r.requestTimeout)
0000000000000000000000000000000000000000;;		defer cancel()
0000000000000000000000000000000000000000;;		listResp, err := r.apisvc.ListPods(ctx, &rktapi.ListPodsRequest{
0000000000000000000000000000000000000000;;			Detail:  true,
0000000000000000000000000000000000000000;;			Filters: runningKubernetesPodFilters(pod.ID),
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return fmt.Errorf("couldn't list pods: %v", err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if len(listResp.Pods) != 1 {
0000000000000000000000000000000000000000;;			var podlist []string
0000000000000000000000000000000000000000;;			for _, p := range listResp.Pods {
0000000000000000000000000000000000000000;;				podlist = append(podlist, p.Id)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			return fmt.Errorf("more than one running rkt pod for the kubernetes pod [%s]", strings.Join(podlist, ", "))
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		listPod := listResp.Pods[0]
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		socatPath, lookupErr := exec.LookPath("socat")
0000000000000000000000000000000000000000;;		if lookupErr != nil {
0000000000000000000000000000000000000000;;			return fmt.Errorf("unable to do port forwarding: socat not found.")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Check in config and in annotations if we're running kvm flavor
0000000000000000000000000000000000000000;;		isKvm := strings.Contains(r.config.Stage1Image, "kvm")
0000000000000000000000000000000000000000;;		for _, anno := range listPod.Annotations {
0000000000000000000000000000000000000000;;			if anno.Key == k8sRktStage1NameAnno {
0000000000000000000000000000000000000000;;				isKvm = strings.Contains(anno.Value, "kvm")
0000000000000000000000000000000000000000;;				break
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		var args []string
0000000000000000000000000000000000000000;;		var fwCaller string
0000000000000000000000000000000000000000;;		if isKvm {
0000000000000000000000000000000000000000;;			podNetworks := listPod.GetNetworks()
0000000000000000000000000000000000000000;;			if podNetworks == nil {
0000000000000000000000000000000000000000;;				return fmt.Errorf("unable to get networks")
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			args = []string{"-", fmt.Sprintf("TCP4:%s:%d", podNetworks[0].Ipv4, port)}
0000000000000000000000000000000000000000;;			fwCaller = socatPath
0000000000000000000000000000000000000000;;		} else {
0000000000000000000000000000000000000000;;			args = []string{"-t", fmt.Sprintf("%d", listPod.Pid), "-n", socatPath, "-", fmt.Sprintf("TCP4:localhost:%d", port)}
0000000000000000000000000000000000000000;;			nsenterPath, lookupErr := exec.LookPath("nsenter")
0000000000000000000000000000000000000000;;			if lookupErr != nil {
0000000000000000000000000000000000000000;;				return fmt.Errorf("unable to do port forwarding: nsenter not found")
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			fwCaller = nsenterPath
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		command := exec.Command(fwCaller, args...)
0000000000000000000000000000000000000000;;		command.Stdout = stream
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// If we use Stdin, command.Run() won't return until the goroutine that's copying
0000000000000000000000000000000000000000;;		// from stream finishes. Unfortunately, if you have a client like telnet connected
0000000000000000000000000000000000000000;;		// via port forwarding, as long as the user's telnet client is connected to the user's
0000000000000000000000000000000000000000;;		// local listener that port forwarding sets up, the telnet session never exits. This
0000000000000000000000000000000000000000;;		// means that even if socat has finished running, command.Run() won't ever return
0000000000000000000000000000000000000000;;		// (because the client still has the connection and stream open).
0000000000000000000000000000000000000000;;		//
0000000000000000000000000000000000000000;;		// The work around is to use StdinPipe(), as Wait() (called by Run()) closes the pipe
0000000000000000000000000000000000000000;;		// when the command (socat) exits.
0000000000000000000000000000000000000000;;		inPipe, err := command.StdinPipe()
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return fmt.Errorf("unable to do port forwarding: error creating stdin pipe: %v", err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		go func() {
0000000000000000000000000000000000000000;;			io.Copy(inPipe, stream)
0000000000000000000000000000000000000000;;			inPipe.Close()
0000000000000000000000000000000000000000;;		}()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return command.Run()
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// UpdatePodCIDR updates the runtimeconfig with the podCIDR.
0000000000000000000000000000000000000000;;	// Currently no-ops, just implemented to satisfy the cri.
0000000000000000000000000000000000000000;;	func (r *Runtime) UpdatePodCIDR(podCIDR string) error {
0000000000000000000000000000000000000000;;		return nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// appStateToContainerState converts rktapi.AppState to kubecontainer.ContainerState.
0000000000000000000000000000000000000000;;	func appStateToContainerState(state rktapi.AppState) kubecontainer.ContainerState {
0000000000000000000000000000000000000000;;		switch state {
0000000000000000000000000000000000000000;;		case rktapi.AppState_APP_STATE_RUNNING:
0000000000000000000000000000000000000000;;			return kubecontainer.ContainerStateRunning
0000000000000000000000000000000000000000;;		case rktapi.AppState_APP_STATE_EXITED:
0000000000000000000000000000000000000000;;			return kubecontainer.ContainerStateExited
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return kubecontainer.ContainerStateUnknown
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// getPodInfo returns the pod manifest, creation time and restart count of the pod.
0000000000000000000000000000000000000000;;	func getPodInfo(pod *rktapi.Pod) (podManifest *appcschema.PodManifest, restartCount int, err error) {
0000000000000000000000000000000000000000;;		// TODO(yifan): The manifest is only used for getting the annotations.
0000000000000000000000000000000000000000;;		// Consider to let the server to unmarshal the annotations.
0000000000000000000000000000000000000000;;		var manifest appcschema.PodManifest
0000000000000000000000000000000000000000;;		if err = json.Unmarshal(pod.Manifest, &manifest); err != nil {
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if countString, ok := manifest.Annotations.Get(k8sRktRestartCountAnno); ok {
0000000000000000000000000000000000000000;;			restartCount, err = strconv.Atoi(countString)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				return
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return &manifest, restartCount, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// populateContainerStatus fills the container status according to the app's information.
0000000000000000000000000000000000000000;;	func populateContainerStatus(pod rktapi.Pod, app rktapi.App, runtimeApp appcschema.RuntimeApp, restartCount int, finishedTime time.Time) (*kubecontainer.ContainerStatus, error) {
0000000000000000000000000000000000000000;;		hashStr, ok := runtimeApp.Annotations.Get(k8sRktContainerHashAnno)
0000000000000000000000000000000000000000;;		if !ok {
0000000000000000000000000000000000000000;;			return nil, fmt.Errorf("No container hash in pod manifest")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		hashNum, err := strconv.ParseUint(hashStr, 10, 64)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return nil, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		var reason, message string
0000000000000000000000000000000000000000;;		if app.State == rktapi.AppState_APP_STATE_EXITED {
0000000000000000000000000000000000000000;;			if app.ExitCode == 0 {
0000000000000000000000000000000000000000;;				reason = "Completed"
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				reason = "Error"
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		terminationMessagePath, ok := runtimeApp.Annotations.Get(k8sRktTerminationMessagePathAnno)
0000000000000000000000000000000000000000;;		if ok {
0000000000000000000000000000000000000000;;			if data, err := ioutil.ReadFile(terminationMessagePath); err != nil {
0000000000000000000000000000000000000000;;				message = fmt.Sprintf("Error on reading termination-log %s: %v", terminationMessagePath, err)
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				message = string(data)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		createdTime := time.Unix(0, pod.CreatedAt)
0000000000000000000000000000000000000000;;		startedTime := time.Unix(0, pod.StartedAt)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return &kubecontainer.ContainerStatus{
0000000000000000000000000000000000000000;;			ID:         buildContainerID(&containerID{uuid: pod.Id, appName: app.Name}),
0000000000000000000000000000000000000000;;			Name:       app.Name,
0000000000000000000000000000000000000000;;			State:      appStateToContainerState(app.State),
0000000000000000000000000000000000000000;;			CreatedAt:  createdTime,
0000000000000000000000000000000000000000;;			StartedAt:  startedTime,
0000000000000000000000000000000000000000;;			FinishedAt: finishedTime,
0000000000000000000000000000000000000000;;			ExitCode:   int(app.ExitCode),
0000000000000000000000000000000000000000;;			// By default, the version returned by rkt API service will be "latest" if not specified.
0000000000000000000000000000000000000000;;			Image:   fmt.Sprintf("%s:%s", app.Image.Name, app.Image.Version),
0000000000000000000000000000000000000000;;			ImageID: "rkt://" + app.Image.Id, // TODO(yifan): Add the prefix only in v1.PodStatus.
0000000000000000000000000000000000000000;;			Hash:    hashNum,
0000000000000000000000000000000000000000;;			// TODO(yifan): Note that now all apps share the same restart count, this might
0000000000000000000000000000000000000000;;			// change once apps don't share the same lifecycle.
0000000000000000000000000000000000000000;;			// See https://github.com/appc/spec/pull/547.
0000000000000000000000000000000000000000;;			RestartCount: restartCount,
0000000000000000000000000000000000000000;;			Reason:       reason,
0000000000000000000000000000000000000000;;			Message:      message,
0000000000000000000000000000000000000000;;		}, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// from a running systemd unit, return the network namespace of a Pod
0000000000000000000000000000000000000000;;	// this field is inside the X-Kubernetes directive
0000000000000000000000000000000000000000;;	func (r *Runtime) getNetworkNamespace(uid kubetypes.UID, latestPod *rktapi.Pod) (networkNamespace kubecontainer.ContainerID, err error) {
0000000000000000000000000000000000000000;;		serviceFiles, err := r.getPodSystemdServiceFiles()
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return networkNamespace, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		for _, f := range serviceFiles {
0000000000000000000000000000000000000000;;			fileName := f.Name()
0000000000000000000000000000000000000000;;			if latestPod.Id == getRktUUIDFromServiceFileName(fileName) {
0000000000000000000000000000000000000000;;				podService, err := r.unitGetter.getKubernetesDirective(serviceFilePath(fileName))
0000000000000000000000000000000000000000;;				if err != nil {
0000000000000000000000000000000000000000;;					return networkNamespace, err
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				return podService.networkNamespace, nil
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return networkNamespace, fmt.Errorf("Pod %q containing rktPod %q haven't find a corresponding NetworkNamespace in %d systemd units", uid, latestPod.Id, len(serviceFiles))
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// GetPodStatus returns the status for a pod specified by a given UID, name,
0000000000000000000000000000000000000000;;	// and namespace.  It will attempt to find pod's information via a request to
0000000000000000000000000000000000000000;;	// the rkt api server.
0000000000000000000000000000000000000000;;	// An error will be returned if the api server returns an error. If the api
0000000000000000000000000000000000000000;;	// server doesn't error, but doesn't provide meaningful information about the
0000000000000000000000000000000000000000;;	// pod, a status with no information (other than the passed in arguments) is
0000000000000000000000000000000000000000;;	// returned anyways.
0000000000000000000000000000000000000000;;	func (r *Runtime) GetPodStatus(uid kubetypes.UID, name, namespace string) (*kubecontainer.PodStatus, error) {
0000000000000000000000000000000000000000;;		podStatus := &kubecontainer.PodStatus{
0000000000000000000000000000000000000000;;			ID:        uid,
0000000000000000000000000000000000000000;;			Name:      name,
0000000000000000000000000000000000000000;;			Namespace: namespace,
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		ctx, cancel := context.WithTimeout(context.Background(), r.requestTimeout)
0000000000000000000000000000000000000000;;		defer cancel()
0000000000000000000000000000000000000000;;		listResp, err := r.apisvc.ListPods(ctx, &rktapi.ListPodsRequest{
0000000000000000000000000000000000000000;;			Detail:  true,
0000000000000000000000000000000000000000;;			Filters: kubernetesPodFilters(uid),
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return nil, fmt.Errorf("couldn't list pods: %v", err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		var latestPod *rktapi.Pod
0000000000000000000000000000000000000000;;		var latestRestartCount int = -1
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// In this loop, we group all containers from all pods together,
0000000000000000000000000000000000000000;;		// also we try to find the latest pod, so we can fill other info of the pod below.
0000000000000000000000000000000000000000;;		for _, pod := range listResp.Pods {
0000000000000000000000000000000000000000;;			manifest, restartCount, err := getPodInfo(pod)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				glog.Warningf("rkt: Couldn't get necessary info from the rkt pod, (uuid %q): %v", pod.Id, err)
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			if restartCount > latestRestartCount {
0000000000000000000000000000000000000000;;				latestPod = pod
0000000000000000000000000000000000000000;;				latestRestartCount = restartCount
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			finishedTime := r.podFinishedAt(uid, pod.Id)
0000000000000000000000000000000000000000;;			for i, app := range pod.Apps {
0000000000000000000000000000000000000000;;				// The order of the apps is determined by the rkt pod manifest.
0000000000000000000000000000000000000000;;				cs, err := populateContainerStatus(*pod, *app, manifest.Apps[i], restartCount, finishedTime)
0000000000000000000000000000000000000000;;				if err != nil {
0000000000000000000000000000000000000000;;					glog.Warningf("rkt: Failed to populate container status(uuid %q, app %q): %v", pod.Id, app.Name, err)
0000000000000000000000000000000000000000;;					continue
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				podStatus.ContainerStatuses = append(podStatus.ContainerStatuses, cs)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if latestPod == nil {
0000000000000000000000000000000000000000;;			glog.Warningf("No latestPod: rkt api-svc returns [%d]rktPods, cannot fill podStatus.IP", len(listResp.Pods))
0000000000000000000000000000000000000000;;			return podStatus, nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// If we are running no-op network plugin, then get the pod IP from the rkt pod status.
0000000000000000000000000000000000000000;;		if r.network.PluginName() == network.DefaultPluginName {
0000000000000000000000000000000000000000;;			for _, n := range latestPod.Networks {
0000000000000000000000000000000000000000;;				if n.Name == defaultNetworkName {
0000000000000000000000000000000000000000;;					podStatus.IP = n.Ipv4
0000000000000000000000000000000000000000;;					break
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			return podStatus, nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		networkNamespace, err := r.unitGetter.getNetworkNamespace(uid, latestPod)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			glog.Warningf("networkNamespace: %v", err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		status, err := r.network.GetPodNetworkStatus(namespace, name, networkNamespace)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			glog.Warningf("rkt: %v", err)
0000000000000000000000000000000000000000;;		} else if status != nil {
0000000000000000000000000000000000000000;;			// status can be nil when the pod is running on the host network,
0000000000000000000000000000000000000000;;			// in which case the pod IP will be populated by the upper layer.
0000000000000000000000000000000000000000;;			podStatus.IP = status.IP.String()
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return podStatus, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// getOSReleaseInfo reads /etc/os-release and returns a map
0000000000000000000000000000000000000000;;	// that contains the key value pairs in that file.
0000000000000000000000000000000000000000;;	func getOSReleaseInfo() (map[string]string, error) {
0000000000000000000000000000000000000000;;		result := make(map[string]string)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		path := "/etc/os-release"
0000000000000000000000000000000000000000;;		f, err := os.Open(path)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return nil, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		defer f.Close()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		scanner := bufio.NewScanner(f)
0000000000000000000000000000000000000000;;		for scanner.Scan() {
0000000000000000000000000000000000000000;;			line := scanner.Text()
0000000000000000000000000000000000000000;;			if len(strings.TrimSpace(line)) == 0 {
0000000000000000000000000000000000000000;;				// Skips empty lines
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			info := strings.SplitN(line, "=", 2)
0000000000000000000000000000000000000000;;			if len(info) != 2 {
0000000000000000000000000000000000000000;;				glog.Warningf("Unexpected entry in os-release %q", line)
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			result[info[0]] = info[1]
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if err := scanner.Err(); err != nil {
0000000000000000000000000000000000000000;;			return nil, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return result, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// convertKubeMounts creates appc volumes and mount points according to the given mounts.
0000000000000000000000000000000000000000;;	// Only one volume will be created for every unique host path.
0000000000000000000000000000000000000000;;	// Only one mount point will be created for every unique container path.
0000000000000000000000000000000000000000;;	func convertKubeMounts(mounts []kubecontainer.Mount) ([]appctypes.Volume, []appctypes.MountPoint) {
0000000000000000000000000000000000000000;;		volumeMap := make(map[string]*appctypes.Volume)
0000000000000000000000000000000000000000;;		mountPointMap := make(map[string]*appctypes.MountPoint)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		for _, mnt := range mounts {
0000000000000000000000000000000000000000;;			readOnly := mnt.ReadOnly
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			if _, existed := volumeMap[mnt.HostPath]; !existed {
0000000000000000000000000000000000000000;;				volumeMap[mnt.HostPath] = &appctypes.Volume{
0000000000000000000000000000000000000000;;					Name:     *appctypes.MustACName(string(uuid.NewUUID())),
0000000000000000000000000000000000000000;;					Kind:     "host",
0000000000000000000000000000000000000000;;					Source:   mnt.HostPath,
0000000000000000000000000000000000000000;;					ReadOnly: &readOnly,
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			if _, existed := mountPointMap[mnt.ContainerPath]; existed {
0000000000000000000000000000000000000000;;				glog.Warningf("Multiple mount points with the same container path %v, ignore it", mnt)
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			mountPointMap[mnt.ContainerPath] = &appctypes.MountPoint{
0000000000000000000000000000000000000000;;				Name:     volumeMap[mnt.HostPath].Name,
0000000000000000000000000000000000000000;;				Path:     mnt.ContainerPath,
0000000000000000000000000000000000000000;;				ReadOnly: readOnly,
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		volumes := make([]appctypes.Volume, 0, len(volumeMap))
0000000000000000000000000000000000000000;;		mountPoints := make([]appctypes.MountPoint, 0, len(mountPointMap))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		for _, vol := range volumeMap {
0000000000000000000000000000000000000000;;			volumes = append(volumes, *vol)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		for _, mnt := range mountPointMap {
0000000000000000000000000000000000000000;;			mountPoints = append(mountPoints, *mnt)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return volumes, mountPoints
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// convertKubePortMappings creates appc container ports and host ports according to the given port mappings.
0000000000000000000000000000000000000000;;	// The container ports and host ports are mapped by PortMapping.Name.
0000000000000000000000000000000000000000;;	func convertKubePortMappings(portMappings []kubecontainer.PortMapping) ([]appctypes.Port, []appctypes.ExposedPort) {
0000000000000000000000000000000000000000;;		containerPorts := make([]appctypes.Port, 0, len(portMappings))
0000000000000000000000000000000000000000;;		hostPorts := make([]appctypes.ExposedPort, 0, len(portMappings))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		for _, p := range portMappings {
0000000000000000000000000000000000000000;;			// This matches the docker code's behaviour.
0000000000000000000000000000000000000000;;			if p.HostPort == 0 {
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			portName := convertToACName(p.Name)
0000000000000000000000000000000000000000;;			containerPorts = append(containerPorts, appctypes.Port{
0000000000000000000000000000000000000000;;				Name:     portName,
0000000000000000000000000000000000000000;;				Protocol: string(p.Protocol),
0000000000000000000000000000000000000000;;				Port:     uint(p.ContainerPort),
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			hostPorts = append(hostPorts, appctypes.ExposedPort{
0000000000000000000000000000000000000000;;				Name:     portName,
0000000000000000000000000000000000000000;;				HostPort: uint(p.HostPort),
0000000000000000000000000000000000000000;;			})
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return containerPorts, hostPorts
0000000000000000000000000000000000000000;;	}
