0000000000000000000000000000000000000000;;	/*
0000000000000000000000000000000000000000;;	Copyright 2015 The Kubernetes Authors.
fe7fe6fc26af42dc9bf695598abdef7aea48278c;pkg/registry/service/ipallocator/controller/repair.go[pkg/registry/service/ipallocator/controller/repair.go][pkg/registry/core/service/ipallocator/controller/repair.go];	
0000000000000000000000000000000000000000;;	Licensed under the Apache License, Version 2.0 (the "License");
0000000000000000000000000000000000000000;;	you may not use this file except in compliance with the License.
0000000000000000000000000000000000000000;;	You may obtain a copy of the License at
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	    http://www.apache.org/licenses/LICENSE-2.0
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	Unless required by applicable law or agreed to in writing, software
0000000000000000000000000000000000000000;;	distributed under the License is distributed on an "AS IS" BASIS,
0000000000000000000000000000000000000000;;	WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
0000000000000000000000000000000000000000;;	See the License for the specific language governing permissions and
0000000000000000000000000000000000000000;;	limitations under the License.
0000000000000000000000000000000000000000;;	*/
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	package controller
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	import (
0000000000000000000000000000000000000000;;		"fmt"
0000000000000000000000000000000000000000;;		"net"
0000000000000000000000000000000000000000;;		"time"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/api/errors"
0000000000000000000000000000000000000000;;		metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/util/runtime"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/util/wait"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/api"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/api/helper"
0000000000000000000000000000000000000000;;		coreclient "k8s.io/kubernetes/pkg/client/clientset_generated/internalclientset/typed/core/internalversion"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/client/retry"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/registry/core/rangeallocation"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/registry/core/service/ipallocator"
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Repair is a controller loop that periodically examines all service ClusterIP allocations
0000000000000000000000000000000000000000;;	// and logs any errors, and then sets the compacted and accurate list of all allocated IPs.
0000000000000000000000000000000000000000;;	//
0000000000000000000000000000000000000000;;	// Handles:
0000000000000000000000000000000000000000;;	// * Duplicate ClusterIP assignments caused by operator action or undetected race conditions
0000000000000000000000000000000000000000;;	// * ClusterIPs that do not match the currently configured range
0000000000000000000000000000000000000000;;	// * Allocations to services that were not actually created due to a crash or powerloss
0000000000000000000000000000000000000000;;	// * Migrates old versions of Kubernetes services into the atomic ipallocator model automatically
0000000000000000000000000000000000000000;;	//
0000000000000000000000000000000000000000;;	// Can be run at infrequent intervals, and is best performed on startup of the master.
0000000000000000000000000000000000000000;;	// Is level driven and idempotent - all valid ClusterIPs will be updated into the ipallocator
0000000000000000000000000000000000000000;;	// map at the end of a single execution loop if no race is encountered.
0000000000000000000000000000000000000000;;	//
0000000000000000000000000000000000000000;;	// TODO: allocate new IPs if necessary
0000000000000000000000000000000000000000;;	// TODO: perform repair?
0000000000000000000000000000000000000000;;	type Repair struct {
0000000000000000000000000000000000000000;;		interval      time.Duration
0000000000000000000000000000000000000000;;		serviceClient coreclient.ServicesGetter
0000000000000000000000000000000000000000;;		network       *net.IPNet
0000000000000000000000000000000000000000;;		alloc         rangeallocation.RangeRegistry
0000000000000000000000000000000000000000;;		leaks         map[string]int // counter per leaked IP
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// How many times we need to detect a leak before we clean up.  This is to
0000000000000000000000000000000000000000;;	// avoid races between allocating an IP and using it.
0000000000000000000000000000000000000000;;	const numRepairsBeforeLeakCleanup = 3
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// NewRepair creates a controller that periodically ensures that all clusterIPs are uniquely allocated across the cluster
0000000000000000000000000000000000000000;;	// and generates informational warnings for a cluster that is not in sync.
0000000000000000000000000000000000000000;;	func NewRepair(interval time.Duration, serviceClient coreclient.ServicesGetter, network *net.IPNet, alloc rangeallocation.RangeRegistry) *Repair {
0000000000000000000000000000000000000000;;		return &Repair{
0000000000000000000000000000000000000000;;			interval:      interval,
0000000000000000000000000000000000000000;;			serviceClient: serviceClient,
0000000000000000000000000000000000000000;;			network:       network,
0000000000000000000000000000000000000000;;			alloc:         alloc,
0000000000000000000000000000000000000000;;			leaks:         map[string]int{},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// RunUntil starts the controller until the provided ch is closed.
0000000000000000000000000000000000000000;;	func (c *Repair) RunUntil(ch chan struct{}) {
0000000000000000000000000000000000000000;;		wait.Until(func() {
0000000000000000000000000000000000000000;;			if err := c.RunOnce(); err != nil {
0000000000000000000000000000000000000000;;				runtime.HandleError(err)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}, c.interval, ch)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// RunOnce verifies the state of the cluster IP allocations and returns an error if an unrecoverable problem occurs.
0000000000000000000000000000000000000000;;	func (c *Repair) RunOnce() error {
0000000000000000000000000000000000000000;;		return retry.RetryOnConflict(retry.DefaultBackoff, c.runOnce)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// runOnce verifies the state of the cluster IP allocations and returns an error if an unrecoverable problem occurs.
0000000000000000000000000000000000000000;;	func (c *Repair) runOnce() error {
0000000000000000000000000000000000000000;;		// TODO: (per smarterclayton) if Get() or ListServices() is a weak consistency read,
0000000000000000000000000000000000000000;;		// or if they are executed against different leaders,
0000000000000000000000000000000000000000;;		// the ordering guarantee required to ensure no IP is allocated twice is violated.
0000000000000000000000000000000000000000;;		// ListServices must return a ResourceVersion higher than the etcd index Get triggers,
0000000000000000000000000000000000000000;;		// and the release code must not release services that have had IPs allocated but not yet been created
0000000000000000000000000000000000000000;;		// See #8295
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// If etcd server is not running we should wait for some time and fail only then. This is particularly
0000000000000000000000000000000000000000;;		// important when we start apiserver and etcd at the same time.
0000000000000000000000000000000000000000;;		var snapshot *api.RangeAllocation
0000000000000000000000000000000000000000;;		err := wait.PollImmediate(time.Second, 10*time.Second, func() (bool, error) {
0000000000000000000000000000000000000000;;			var err error
0000000000000000000000000000000000000000;;			snapshot, err = c.alloc.Get()
0000000000000000000000000000000000000000;;			return err == nil, err
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return fmt.Errorf("unable to refresh the service IP block: %v", err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		// If not yet initialized.
0000000000000000000000000000000000000000;;		if snapshot.Range == "" {
0000000000000000000000000000000000000000;;			snapshot.Range = c.network.String()
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		// Create an allocator because it is easy to use.
0000000000000000000000000000000000000000;;		stored, err := ipallocator.NewFromSnapshot(snapshot)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return fmt.Errorf("unable to rebuild allocator from snapshot: %v", err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// We explicitly send no resource version, since the resource version
0000000000000000000000000000000000000000;;		// of 'snapshot' is from a different collection, it's not comparable to
0000000000000000000000000000000000000000;;		// the service collection. The caching layer keeps per-collection RVs,
0000000000000000000000000000000000000000;;		// and this is proper, since in theory the collections could be hosted
0000000000000000000000000000000000000000;;		// in separate etcd (or even non-etcd) instances.
0000000000000000000000000000000000000000;;		list, err := c.serviceClient.Services(metav1.NamespaceAll).List(metav1.ListOptions{})
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return fmt.Errorf("unable to refresh the service IP block: %v", err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		rebuilt := ipallocator.NewCIDRRange(c.network)
0000000000000000000000000000000000000000;;		// Check every Service's ClusterIP, and rebuild the state as we think it should be.
0000000000000000000000000000000000000000;;		for _, svc := range list.Items {
0000000000000000000000000000000000000000;;			if !helper.IsServiceIPSet(&svc) {
0000000000000000000000000000000000000000;;				// didn't need a cluster IP
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			ip := net.ParseIP(svc.Spec.ClusterIP)
0000000000000000000000000000000000000000;;			if ip == nil {
0000000000000000000000000000000000000000;;				// cluster IP is corrupt
0000000000000000000000000000000000000000;;				runtime.HandleError(fmt.Errorf("the cluster IP %s for service %s/%s is not a valid IP; please recreate", svc.Spec.ClusterIP, svc.Name, svc.Namespace))
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			// mark it as in-use
0000000000000000000000000000000000000000;;			switch err := rebuilt.Allocate(ip); err {
0000000000000000000000000000000000000000;;			case nil:
0000000000000000000000000000000000000000;;				if stored.Has(ip) {
0000000000000000000000000000000000000000;;					// remove it from the old set, so we can find leaks
0000000000000000000000000000000000000000;;					stored.Release(ip)
0000000000000000000000000000000000000000;;				} else {
0000000000000000000000000000000000000000;;					// cluster IP doesn't seem to be allocated
0000000000000000000000000000000000000000;;					runtime.HandleError(fmt.Errorf("the cluster IP %s for service %s/%s is not allocated; repairing", svc.Spec.ClusterIP, svc.Name, svc.Namespace))
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				delete(c.leaks, ip.String()) // it is used, so it can't be leaked
0000000000000000000000000000000000000000;;			case ipallocator.ErrAllocated:
0000000000000000000000000000000000000000;;				// TODO: send event
0000000000000000000000000000000000000000;;				// cluster IP is duplicate
0000000000000000000000000000000000000000;;				runtime.HandleError(fmt.Errorf("the cluster IP %s for service %s/%s was assigned to multiple services; please recreate", ip, svc.Name, svc.Namespace))
0000000000000000000000000000000000000000;;			case ipallocator.ErrNotInRange:
0000000000000000000000000000000000000000;;				// TODO: send event
0000000000000000000000000000000000000000;;				// cluster IP is out of range
0000000000000000000000000000000000000000;;				runtime.HandleError(fmt.Errorf("the cluster IP %s for service %s/%s is not within the service CIDR %s; please recreate", ip, svc.Name, svc.Namespace, c.network))
0000000000000000000000000000000000000000;;			case ipallocator.ErrFull:
0000000000000000000000000000000000000000;;				// TODO: send event
0000000000000000000000000000000000000000;;				// somehow we are out of IPs
0000000000000000000000000000000000000000;;				return fmt.Errorf("the service CIDR %v is full; you must widen the CIDR in order to create new services", rebuilt)
0000000000000000000000000000000000000000;;			default:
0000000000000000000000000000000000000000;;				return fmt.Errorf("unable to allocate cluster IP %s for service %s/%s due to an unknown error, exiting: %v", ip, svc.Name, svc.Namespace, err)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Check for IPs that are left in the old set.  They appear to have been leaked.
0000000000000000000000000000000000000000;;		stored.ForEach(func(ip net.IP) {
0000000000000000000000000000000000000000;;			count, found := c.leaks[ip.String()]
0000000000000000000000000000000000000000;;			switch {
0000000000000000000000000000000000000000;;			case !found:
0000000000000000000000000000000000000000;;				// flag it to be cleaned up after any races (hopefully) are gone
0000000000000000000000000000000000000000;;				runtime.HandleError(fmt.Errorf("the cluster IP %s may have leaked: flagging for later clean up", ip))
0000000000000000000000000000000000000000;;				count = numRepairsBeforeLeakCleanup - 1
0000000000000000000000000000000000000000;;				fallthrough
0000000000000000000000000000000000000000;;			case count > 0:
0000000000000000000000000000000000000000;;				// pretend it is still in use until count expires
0000000000000000000000000000000000000000;;				c.leaks[ip.String()] = count - 1
0000000000000000000000000000000000000000;;				if err := rebuilt.Allocate(ip); err != nil {
0000000000000000000000000000000000000000;;					runtime.HandleError(fmt.Errorf("the cluster IP %s may have leaked, but can not be allocated: %v", ip, err))
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			default:
0000000000000000000000000000000000000000;;				// do not add it to the rebuilt set, which means it will be available for reuse
0000000000000000000000000000000000000000;;				runtime.HandleError(fmt.Errorf("the cluster IP %s appears to have leaked: cleaning up", ip))
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		})
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Blast the rebuilt state into storage.
0000000000000000000000000000000000000000;;		if err := rebuilt.Snapshot(snapshot); err != nil {
0000000000000000000000000000000000000000;;			return fmt.Errorf("unable to snapshot the updated service IP allocations: %v", err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if err := c.alloc.CreateOrUpdate(snapshot); err != nil {
0000000000000000000000000000000000000000;;			if errors.IsConflict(err) {
0000000000000000000000000000000000000000;;				return err
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			return fmt.Errorf("unable to persist the updated service IP allocations: %v", err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return nil
0000000000000000000000000000000000000000;;	}
