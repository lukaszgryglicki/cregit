0000000000000000000000000000000000000000;;	/*
0000000000000000000000000000000000000000;;	Copyright 2015 The Kubernetes Authors.
b98b1b5e44095a3b8a3d099e2337b1e168588132;;	
0000000000000000000000000000000000000000;;	Licensed under the Apache License, Version 2.0 (the "License");
0000000000000000000000000000000000000000;;	you may not use this file except in compliance with the License.
0000000000000000000000000000000000000000;;	You may obtain a copy of the License at
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	    http://www.apache.org/licenses/LICENSE-2.0
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	Unless required by applicable law or agreed to in writing, software
0000000000000000000000000000000000000000;;	distributed under the License is distributed on an "AS IS" BASIS,
0000000000000000000000000000000000000000;;	WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
0000000000000000000000000000000000000000;;	See the License for the specific language governing permissions and
0000000000000000000000000000000000000000;;	limitations under the License.
0000000000000000000000000000000000000000;;	*/
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	package iptables
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	//
0000000000000000000000000000000000000000;;	// NOTE: this needs to be tested in e2e since it uses iptables for everything.
0000000000000000000000000000000000000000;;	//
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	import (
0000000000000000000000000000000000000000;;		"bytes"
0000000000000000000000000000000000000000;;		"crypto/sha256"
0000000000000000000000000000000000000000;;		"encoding/base32"
0000000000000000000000000000000000000000;;		"fmt"
0000000000000000000000000000000000000000;;		"net"
0000000000000000000000000000000000000000;;		"reflect"
0000000000000000000000000000000000000000;;		"strconv"
0000000000000000000000000000000000000000;;		"strings"
0000000000000000000000000000000000000000;;		"sync"
0000000000000000000000000000000000000000;;		"sync/atomic"
0000000000000000000000000000000000000000;;		"time"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		"github.com/golang/glog"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		clientv1 "k8s.io/api/core/v1"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/types"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/util/sets"
0000000000000000000000000000000000000000;;		"k8s.io/apimachinery/pkg/util/wait"
0000000000000000000000000000000000000000;;		utilfeature "k8s.io/apiserver/pkg/util/feature"
0000000000000000000000000000000000000000;;		"k8s.io/client-go/tools/record"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/api"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/api/helper"
0000000000000000000000000000000000000000;;		apiservice "k8s.io/kubernetes/pkg/api/service"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/features"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/proxy"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/proxy/healthcheck"
0000000000000000000000000000000000000000;;		utilproxy "k8s.io/kubernetes/pkg/proxy/util"
0000000000000000000000000000000000000000;;		"k8s.io/kubernetes/pkg/util/async"
0000000000000000000000000000000000000000;;		utilexec "k8s.io/kubernetes/pkg/util/exec"
0000000000000000000000000000000000000000;;		utiliptables "k8s.io/kubernetes/pkg/util/iptables"
0000000000000000000000000000000000000000;;		utilsysctl "k8s.io/kubernetes/pkg/util/sysctl"
0000000000000000000000000000000000000000;;		utilversion "k8s.io/kubernetes/pkg/util/version"
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	const (
0000000000000000000000000000000000000000;;		// iptablesMinVersion is the minimum version of iptables for which we will use the Proxier
0000000000000000000000000000000000000000;;		// from this package instead of the userspace Proxier.  While most of the
0000000000000000000000000000000000000000;;		// features we need were available earlier, the '-C' flag was added more
0000000000000000000000000000000000000000;;		// recently.  We use that indirectly in Ensure* functions, and if we don't
0000000000000000000000000000000000000000;;		// have it, we have to be extra careful about the exact args we feed in being
0000000000000000000000000000000000000000;;		// the same as the args we read back (iptables itself normalizes some args).
0000000000000000000000000000000000000000;;		// This is the "new" Proxier, so we require "new" versions of tools.
0000000000000000000000000000000000000000;;		iptablesMinVersion = utiliptables.MinCheckVersion
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// the services chain
0000000000000000000000000000000000000000;;		kubeServicesChain utiliptables.Chain = "KUBE-SERVICES"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// the nodeports chain
0000000000000000000000000000000000000000;;		kubeNodePortsChain utiliptables.Chain = "KUBE-NODEPORTS"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// the kubernetes postrouting chain
0000000000000000000000000000000000000000;;		kubePostroutingChain utiliptables.Chain = "KUBE-POSTROUTING"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// the mark-for-masquerade chain
0000000000000000000000000000000000000000;;		KubeMarkMasqChain utiliptables.Chain = "KUBE-MARK-MASQ"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// the mark-for-drop chain
0000000000000000000000000000000000000000;;		KubeMarkDropChain utiliptables.Chain = "KUBE-MARK-DROP"
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// IPTablesVersioner can query the current iptables version.
0000000000000000000000000000000000000000;;	type IPTablesVersioner interface {
0000000000000000000000000000000000000000;;		// returns "X.Y.Z"
0000000000000000000000000000000000000000;;		GetVersion() (string, error)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// KernelCompatTester tests whether the required kernel capabilities are
0000000000000000000000000000000000000000;;	// present to run the iptables proxier.
0000000000000000000000000000000000000000;;	type KernelCompatTester interface {
0000000000000000000000000000000000000000;;		IsCompatible() error
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// CanUseIPTablesProxier returns true if we should use the iptables Proxier
0000000000000000000000000000000000000000;;	// instead of the "classic" userspace Proxier.  This is determined by checking
0000000000000000000000000000000000000000;;	// the iptables version and for the existence of kernel features. It may return
0000000000000000000000000000000000000000;;	// an error if it fails to get the iptables version without error, in which
0000000000000000000000000000000000000000;;	// case it will also return false.
0000000000000000000000000000000000000000;;	func CanUseIPTablesProxier(iptver IPTablesVersioner, kcompat KernelCompatTester) (bool, error) {
0000000000000000000000000000000000000000;;		minVersion, err := utilversion.ParseGeneric(iptablesMinVersion)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return false, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		versionString, err := iptver.GetVersion()
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return false, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		version, err := utilversion.ParseGeneric(versionString)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return false, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if version.LessThan(minVersion) {
0000000000000000000000000000000000000000;;			return false, nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Check that the kernel supports what we need.
0000000000000000000000000000000000000000;;		if err := kcompat.IsCompatible(); err != nil {
0000000000000000000000000000000000000000;;			return false, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return true, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type LinuxKernelCompatTester struct{}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (lkct LinuxKernelCompatTester) IsCompatible() error {
0000000000000000000000000000000000000000;;		// Check for the required sysctls.  We don't care about the value, just
0000000000000000000000000000000000000000;;		// that it exists.  If this Proxier is chosen, we'll initialize it as we
0000000000000000000000000000000000000000;;		// need.
0000000000000000000000000000000000000000;;		_, err := utilsysctl.New().GetSysctl(sysctlRouteLocalnet)
0000000000000000000000000000000000000000;;		return err
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	const sysctlRouteLocalnet = "net/ipv4/conf/all/route_localnet"
0000000000000000000000000000000000000000;;	const sysctlBridgeCallIPTables = "net/bridge/bridge-nf-call-iptables"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// internal struct for string service information
0000000000000000000000000000000000000000;;	type serviceInfo struct {
0000000000000000000000000000000000000000;;		clusterIP                net.IP
0000000000000000000000000000000000000000;;		port                     int
0000000000000000000000000000000000000000;;		protocol                 api.Protocol
0000000000000000000000000000000000000000;;		nodePort                 int
0000000000000000000000000000000000000000;;		loadBalancerStatus       api.LoadBalancerStatus
0000000000000000000000000000000000000000;;		sessionAffinityType      api.ServiceAffinity
0000000000000000000000000000000000000000;;		stickyMaxAgeMinutes      int
0000000000000000000000000000000000000000;;		externalIPs              []string
0000000000000000000000000000000000000000;;		loadBalancerSourceRanges []string
0000000000000000000000000000000000000000;;		onlyNodeLocalEndpoints   bool
0000000000000000000000000000000000000000;;		healthCheckNodePort      int
0000000000000000000000000000000000000000;;		// The following fields are computed and stored for performance reasons.
0000000000000000000000000000000000000000;;		serviceNameString        string
0000000000000000000000000000000000000000;;		servicePortChainName     utiliptables.Chain
0000000000000000000000000000000000000000;;		serviceFirewallChainName utiliptables.Chain
0000000000000000000000000000000000000000;;		serviceLBChainName       utiliptables.Chain
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// internal struct for endpoints information
0000000000000000000000000000000000000000;;	type endpointsInfo struct {
0000000000000000000000000000000000000000;;		endpoint string // TODO: should be an endpointString type
0000000000000000000000000000000000000000;;		isLocal  bool
0000000000000000000000000000000000000000;;		// The following fields we lazily compute and store here for performance
0000000000000000000000000000000000000000;;		// reasons. If the protocol is the same as you expect it to be, then the
0000000000000000000000000000000000000000;;		// chainName can be reused, otherwise it should be recomputed.
0000000000000000000000000000000000000000;;		protocol  string
0000000000000000000000000000000000000000;;		chainName utiliptables.Chain
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Returns just the IP part of the endpoint.
0000000000000000000000000000000000000000;;	func (e *endpointsInfo) IPPart() string {
0000000000000000000000000000000000000000;;		if index := strings.Index(e.endpoint, ":"); index != -1 {
0000000000000000000000000000000000000000;;			return e.endpoint[0:index]
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return e.endpoint
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Returns the endpoint chain name for a given endpointsInfo.
0000000000000000000000000000000000000000;;	func (e *endpointsInfo) endpointChain(svcNameString, protocol string) utiliptables.Chain {
0000000000000000000000000000000000000000;;		if e.protocol != protocol {
0000000000000000000000000000000000000000;;			e.protocol = protocol
0000000000000000000000000000000000000000;;			e.chainName = servicePortEndpointChainName(svcNameString, protocol, e.endpoint)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return e.chainName
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (e *endpointsInfo) String() string {
0000000000000000000000000000000000000000;;		return fmt.Sprintf("%v", *e)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// returns a new serviceInfo struct
0000000000000000000000000000000000000000;;	func newServiceInfo(svcPortName proxy.ServicePortName, port *api.ServicePort, service *api.Service) *serviceInfo {
0000000000000000000000000000000000000000;;		onlyNodeLocalEndpoints := false
0000000000000000000000000000000000000000;;		if utilfeature.DefaultFeatureGate.Enabled(features.ExternalTrafficLocalOnly) &&
0000000000000000000000000000000000000000;;			apiservice.RequestsOnlyLocalTraffic(service) {
0000000000000000000000000000000000000000;;			onlyNodeLocalEndpoints = true
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		info := &serviceInfo{
0000000000000000000000000000000000000000;;			clusterIP: net.ParseIP(service.Spec.ClusterIP),
0000000000000000000000000000000000000000;;			port:      int(port.Port),
0000000000000000000000000000000000000000;;			protocol:  port.Protocol,
0000000000000000000000000000000000000000;;			nodePort:  int(port.NodePort),
0000000000000000000000000000000000000000;;			// Deep-copy in case the service instance changes
0000000000000000000000000000000000000000;;			loadBalancerStatus:       *helper.LoadBalancerStatusDeepCopy(&service.Status.LoadBalancer),
0000000000000000000000000000000000000000;;			sessionAffinityType:      service.Spec.SessionAffinity,
0000000000000000000000000000000000000000;;			stickyMaxAgeMinutes:      180, // TODO: paramaterize this in the API.
0000000000000000000000000000000000000000;;			externalIPs:              make([]string, len(service.Spec.ExternalIPs)),
0000000000000000000000000000000000000000;;			loadBalancerSourceRanges: make([]string, len(service.Spec.LoadBalancerSourceRanges)),
0000000000000000000000000000000000000000;;			onlyNodeLocalEndpoints:   onlyNodeLocalEndpoints,
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		copy(info.loadBalancerSourceRanges, service.Spec.LoadBalancerSourceRanges)
0000000000000000000000000000000000000000;;		copy(info.externalIPs, service.Spec.ExternalIPs)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if apiservice.NeedsHealthCheck(service) {
0000000000000000000000000000000000000000;;			p := apiservice.GetServiceHealthCheckNodePort(service)
0000000000000000000000000000000000000000;;			if p == 0 {
0000000000000000000000000000000000000000;;				glog.Errorf("Service %q has no healthcheck nodeport", svcPortName.NamespacedName.String())
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				info.healthCheckNodePort = int(p)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Store the following for performance reasons.
0000000000000000000000000000000000000000;;		protocol := strings.ToLower(string(info.protocol))
0000000000000000000000000000000000000000;;		info.serviceNameString = svcPortName.String()
0000000000000000000000000000000000000000;;		info.servicePortChainName = servicePortChainName(info.serviceNameString, protocol)
0000000000000000000000000000000000000000;;		info.serviceFirewallChainName = serviceFirewallChainName(info.serviceNameString, protocol)
0000000000000000000000000000000000000000;;		info.serviceLBChainName = serviceLBChainName(info.serviceNameString, protocol)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return info
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type endpointsChange struct {
0000000000000000000000000000000000000000;;		previous proxyEndpointsMap
0000000000000000000000000000000000000000;;		current  proxyEndpointsMap
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type endpointsChangeMap struct {
0000000000000000000000000000000000000000;;		lock     sync.Mutex
0000000000000000000000000000000000000000;;		hostname string
0000000000000000000000000000000000000000;;		items    map[types.NamespacedName]*endpointsChange
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type serviceChange struct {
0000000000000000000000000000000000000000;;		previous proxyServiceMap
0000000000000000000000000000000000000000;;		current  proxyServiceMap
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type serviceChangeMap struct {
0000000000000000000000000000000000000000;;		lock  sync.Mutex
0000000000000000000000000000000000000000;;		items map[types.NamespacedName]*serviceChange
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type updateEndpointMapResult struct {
0000000000000000000000000000000000000000;;		hcEndpoints       map[types.NamespacedName]int
0000000000000000000000000000000000000000;;		staleEndpoints    map[endpointServicePair]bool
0000000000000000000000000000000000000000;;		staleServiceNames map[proxy.ServicePortName]bool
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type updateServiceMapResult struct {
0000000000000000000000000000000000000000;;		hcServices    map[types.NamespacedName]uint16
0000000000000000000000000000000000000000;;		staleServices sets.String
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type proxyServiceMap map[proxy.ServicePortName]*serviceInfo
0000000000000000000000000000000000000000;;	type proxyEndpointsMap map[proxy.ServicePortName][]*endpointsInfo
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func newEndpointsChangeMap(hostname string) endpointsChangeMap {
0000000000000000000000000000000000000000;;		return endpointsChangeMap{
0000000000000000000000000000000000000000;;			hostname: hostname,
0000000000000000000000000000000000000000;;			items:    make(map[types.NamespacedName]*endpointsChange),
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (ecm *endpointsChangeMap) update(namespacedName *types.NamespacedName, previous, current *api.Endpoints) bool {
0000000000000000000000000000000000000000;;		ecm.lock.Lock()
0000000000000000000000000000000000000000;;		defer ecm.lock.Unlock()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		change, exists := ecm.items[*namespacedName]
0000000000000000000000000000000000000000;;		if !exists {
0000000000000000000000000000000000000000;;			change = &endpointsChange{}
0000000000000000000000000000000000000000;;			change.previous = endpointsToEndpointsMap(previous, ecm.hostname)
0000000000000000000000000000000000000000;;			ecm.items[*namespacedName] = change
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		change.current = endpointsToEndpointsMap(current, ecm.hostname)
0000000000000000000000000000000000000000;;		if reflect.DeepEqual(change.previous, change.current) {
0000000000000000000000000000000000000000;;			delete(ecm.items, *namespacedName)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return len(ecm.items) > 0
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func newServiceChangeMap() serviceChangeMap {
0000000000000000000000000000000000000000;;		return serviceChangeMap{
0000000000000000000000000000000000000000;;			items: make(map[types.NamespacedName]*serviceChange),
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (scm *serviceChangeMap) update(namespacedName *types.NamespacedName, previous, current *api.Service) bool {
0000000000000000000000000000000000000000;;		scm.lock.Lock()
0000000000000000000000000000000000000000;;		defer scm.lock.Unlock()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		change, exists := scm.items[*namespacedName]
0000000000000000000000000000000000000000;;		if !exists {
0000000000000000000000000000000000000000;;			change = &serviceChange{}
0000000000000000000000000000000000000000;;			change.previous = serviceToServiceMap(previous)
0000000000000000000000000000000000000000;;			scm.items[*namespacedName] = change
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		change.current = serviceToServiceMap(current)
0000000000000000000000000000000000000000;;		if reflect.DeepEqual(change.previous, change.current) {
0000000000000000000000000000000000000000;;			delete(scm.items, *namespacedName)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return len(scm.items) > 0
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (sm *proxyServiceMap) merge(other proxyServiceMap) sets.String {
0000000000000000000000000000000000000000;;		existingPorts := sets.NewString()
0000000000000000000000000000000000000000;;		for svcPortName, info := range other {
0000000000000000000000000000000000000000;;			existingPorts.Insert(svcPortName.Port)
0000000000000000000000000000000000000000;;			_, exists := (*sm)[svcPortName]
0000000000000000000000000000000000000000;;			if !exists {
0000000000000000000000000000000000000000;;				glog.V(1).Infof("Adding new service port %q at %s:%d/%s", svcPortName, info.clusterIP, info.port, info.protocol)
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				glog.V(1).Infof("Updating existing service port %q at %s:%d/%s", svcPortName, info.clusterIP, info.port, info.protocol)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			(*sm)[svcPortName] = info
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return existingPorts
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (sm *proxyServiceMap) unmerge(other proxyServiceMap, existingPorts, staleServices sets.String) {
0000000000000000000000000000000000000000;;		for svcPortName := range other {
0000000000000000000000000000000000000000;;			if existingPorts.Has(svcPortName.Port) {
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			info, exists := (*sm)[svcPortName]
0000000000000000000000000000000000000000;;			if exists {
0000000000000000000000000000000000000000;;				glog.V(1).Infof("Removing service port %q", svcPortName)
0000000000000000000000000000000000000000;;				if info.protocol == api.ProtocolUDP {
0000000000000000000000000000000000000000;;					staleServices.Insert(info.clusterIP.String())
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				delete(*sm, svcPortName)
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				glog.Errorf("Service port %q removed, but doesn't exists", svcPortName)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (em proxyEndpointsMap) merge(other proxyEndpointsMap) {
0000000000000000000000000000000000000000;;		for svcPortName := range other {
0000000000000000000000000000000000000000;;			em[svcPortName] = other[svcPortName]
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (em proxyEndpointsMap) unmerge(other proxyEndpointsMap) {
0000000000000000000000000000000000000000;;		for svcPortName := range other {
0000000000000000000000000000000000000000;;			delete(em, svcPortName)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Proxier is an iptables based proxy for connections between a localhost:lport
0000000000000000000000000000000000000000;;	// and services that provide the actual backends.
0000000000000000000000000000000000000000;;	type Proxier struct {
0000000000000000000000000000000000000000;;		// endpointsChanges and serviceChanges contains all changes to endpoints and
0000000000000000000000000000000000000000;;		// services that happened since iptables was synced. For a single object,
0000000000000000000000000000000000000000;;		// changes are accumulated, i.e. previous is state from before all of them,
0000000000000000000000000000000000000000;;		// current is state after applying all of those.
0000000000000000000000000000000000000000;;		endpointsChanges endpointsChangeMap
0000000000000000000000000000000000000000;;		serviceChanges   serviceChangeMap
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		mu           sync.Mutex // protects the following fields
0000000000000000000000000000000000000000;;		serviceMap   proxyServiceMap
0000000000000000000000000000000000000000;;		endpointsMap proxyEndpointsMap
0000000000000000000000000000000000000000;;		portsMap     map[localPort]closeable
0000000000000000000000000000000000000000;;		// endpointsSynced and servicesSynced are set to true when corresponding
0000000000000000000000000000000000000000;;		// objects are synced after startup. This is used to avoid updating iptables
0000000000000000000000000000000000000000;;		// with some partial data after kube-proxy restart.
0000000000000000000000000000000000000000;;		endpointsSynced bool
0000000000000000000000000000000000000000;;		servicesSynced  bool
0000000000000000000000000000000000000000;;		initialized     int32
0000000000000000000000000000000000000000;;		syncRunner      *async.BoundedFrequencyRunner // governs calls to syncProxyRules
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// These are effectively const and do not need the mutex to be held.
0000000000000000000000000000000000000000;;		iptables       utiliptables.Interface
0000000000000000000000000000000000000000;;		masqueradeAll  bool
0000000000000000000000000000000000000000;;		masqueradeMark string
0000000000000000000000000000000000000000;;		exec           utilexec.Interface
0000000000000000000000000000000000000000;;		clusterCIDR    string
0000000000000000000000000000000000000000;;		hostname       string
0000000000000000000000000000000000000000;;		nodeIP         net.IP
0000000000000000000000000000000000000000;;		portMapper     portOpener
0000000000000000000000000000000000000000;;		recorder       record.EventRecorder
0000000000000000000000000000000000000000;;		healthChecker  healthcheck.Server
0000000000000000000000000000000000000000;;		healthzServer  healthcheck.HealthzUpdater
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Since converting probabilities (floats) to strings is expensive
0000000000000000000000000000000000000000;;		// and we are using only probabilities in the format of 1/n, we are
0000000000000000000000000000000000000000;;		// precomputing some number of those and cache for future reuse.
0000000000000000000000000000000000000000;;		precomputedProbabilities []string
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// The following buffers are used to reuse memory and avoid allocations
0000000000000000000000000000000000000000;;		// that are significantly impacting performance.
0000000000000000000000000000000000000000;;		iptablesData *bytes.Buffer
0000000000000000000000000000000000000000;;		filterChains *bytes.Buffer
0000000000000000000000000000000000000000;;		filterRules  *bytes.Buffer
0000000000000000000000000000000000000000;;		natChains    *bytes.Buffer
0000000000000000000000000000000000000000;;		natRules     *bytes.Buffer
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type localPort struct {
0000000000000000000000000000000000000000;;		desc     string
0000000000000000000000000000000000000000;;		ip       string
0000000000000000000000000000000000000000;;		port     int
0000000000000000000000000000000000000000;;		protocol string
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (lp *localPort) String() string {
0000000000000000000000000000000000000000;;		return fmt.Sprintf("%q (%s:%d/%s)", lp.desc, lp.ip, lp.port, lp.protocol)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type closeable interface {
0000000000000000000000000000000000000000;;		Close() error
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// portOpener is an interface around port opening/closing.
0000000000000000000000000000000000000000;;	// Abstracted out for testing.
0000000000000000000000000000000000000000;;	type portOpener interface {
0000000000000000000000000000000000000000;;		OpenLocalPort(lp *localPort) (closeable, error)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// listenPortOpener opens ports by calling bind() and listen().
0000000000000000000000000000000000000000;;	type listenPortOpener struct{}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// OpenLocalPort holds the given local port open.
0000000000000000000000000000000000000000;;	func (l *listenPortOpener) OpenLocalPort(lp *localPort) (closeable, error) {
0000000000000000000000000000000000000000;;		return openLocalPort(lp)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Proxier implements ProxyProvider
0000000000000000000000000000000000000000;;	var _ proxy.ProxyProvider = &Proxier{}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// NewProxier returns a new Proxier given an iptables Interface instance.
0000000000000000000000000000000000000000;;	// Because of the iptables logic, it is assumed that there is only a single Proxier active on a machine.
0000000000000000000000000000000000000000;;	// An error will be returned if iptables fails to update or acquire the initial lock.
0000000000000000000000000000000000000000;;	// Once a proxier is created, it will keep iptables up to date in the background and
0000000000000000000000000000000000000000;;	// will not terminate if a particular iptables call fails.
0000000000000000000000000000000000000000;;	func NewProxier(ipt utiliptables.Interface,
0000000000000000000000000000000000000000;;		sysctl utilsysctl.Interface,
0000000000000000000000000000000000000000;;		exec utilexec.Interface,
0000000000000000000000000000000000000000;;		syncPeriod time.Duration,
0000000000000000000000000000000000000000;;		minSyncPeriod time.Duration,
0000000000000000000000000000000000000000;;		masqueradeAll bool,
0000000000000000000000000000000000000000;;		masqueradeBit int,
0000000000000000000000000000000000000000;;		clusterCIDR string,
0000000000000000000000000000000000000000;;		hostname string,
0000000000000000000000000000000000000000;;		nodeIP net.IP,
0000000000000000000000000000000000000000;;		recorder record.EventRecorder,
0000000000000000000000000000000000000000;;		healthzServer healthcheck.HealthzUpdater,
0000000000000000000000000000000000000000;;	) (*Proxier, error) {
0000000000000000000000000000000000000000;;		// check valid user input
0000000000000000000000000000000000000000;;		if minSyncPeriod > syncPeriod {
0000000000000000000000000000000000000000;;			return nil, fmt.Errorf("minSyncPeriod (%v) must be <= syncPeriod (%v)", minSyncPeriod, syncPeriod)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Set the route_localnet sysctl we need for
0000000000000000000000000000000000000000;;		if err := sysctl.SetSysctl(sysctlRouteLocalnet, 1); err != nil {
0000000000000000000000000000000000000000;;			return nil, fmt.Errorf("can't set sysctl %s: %v", sysctlRouteLocalnet, err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Proxy needs br_netfilter and bridge-nf-call-iptables=1 when containers
0000000000000000000000000000000000000000;;		// are connected to a Linux bridge (but not SDN bridges).  Until most
0000000000000000000000000000000000000000;;		// plugins handle this, log when config is missing
0000000000000000000000000000000000000000;;		if val, err := sysctl.GetSysctl(sysctlBridgeCallIPTables); err == nil && val != 1 {
0000000000000000000000000000000000000000;;			glog.Warningf("missing br-netfilter module or unset sysctl br-nf-call-iptables; proxy may not work as intended")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Generate the masquerade mark to use for SNAT rules.
0000000000000000000000000000000000000000;;		if masqueradeBit < 0 || masqueradeBit > 31 {
0000000000000000000000000000000000000000;;			return nil, fmt.Errorf("invalid iptables-masquerade-bit %v not in [0, 31]", masqueradeBit)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		masqueradeValue := 1 << uint(masqueradeBit)
0000000000000000000000000000000000000000;;		masqueradeMark := fmt.Sprintf("%#08x/%#08x", masqueradeValue, masqueradeValue)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if nodeIP == nil {
0000000000000000000000000000000000000000;;			glog.Warningf("invalid nodeIP, initializing kube-proxy with 127.0.0.1 as nodeIP")
0000000000000000000000000000000000000000;;			nodeIP = net.ParseIP("127.0.0.1")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if len(clusterCIDR) == 0 {
0000000000000000000000000000000000000000;;			glog.Warningf("clusterCIDR not specified, unable to distinguish between internal and external traffic")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		healthChecker := healthcheck.NewServer(hostname, recorder, nil, nil) // use default implementations of deps
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		proxier := &Proxier{
0000000000000000000000000000000000000000;;			portsMap:                 make(map[localPort]closeable),
0000000000000000000000000000000000000000;;			serviceMap:               make(proxyServiceMap),
0000000000000000000000000000000000000000;;			serviceChanges:           newServiceChangeMap(),
0000000000000000000000000000000000000000;;			endpointsMap:             make(proxyEndpointsMap),
0000000000000000000000000000000000000000;;			endpointsChanges:         newEndpointsChangeMap(hostname),
0000000000000000000000000000000000000000;;			iptables:                 ipt,
0000000000000000000000000000000000000000;;			masqueradeAll:            masqueradeAll,
0000000000000000000000000000000000000000;;			masqueradeMark:           masqueradeMark,
0000000000000000000000000000000000000000;;			exec:                     exec,
0000000000000000000000000000000000000000;;			clusterCIDR:              clusterCIDR,
0000000000000000000000000000000000000000;;			hostname:                 hostname,
0000000000000000000000000000000000000000;;			nodeIP:                   nodeIP,
0000000000000000000000000000000000000000;;			portMapper:               &listenPortOpener{},
0000000000000000000000000000000000000000;;			recorder:                 recorder,
0000000000000000000000000000000000000000;;			healthChecker:            healthChecker,
0000000000000000000000000000000000000000;;			healthzServer:            healthzServer,
0000000000000000000000000000000000000000;;			precomputedProbabilities: make([]string, 0, 1001),
0000000000000000000000000000000000000000;;			iptablesData:             bytes.NewBuffer(nil),
0000000000000000000000000000000000000000;;			filterChains:             bytes.NewBuffer(nil),
0000000000000000000000000000000000000000;;			filterRules:              bytes.NewBuffer(nil),
0000000000000000000000000000000000000000;;			natChains:                bytes.NewBuffer(nil),
0000000000000000000000000000000000000000;;			natRules:                 bytes.NewBuffer(nil),
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		burstSyncs := 2
0000000000000000000000000000000000000000;;		glog.V(3).Infof("minSyncPeriod: %v, syncPeriod: %v, burstSyncs: %d", minSyncPeriod, syncPeriod, burstSyncs)
0000000000000000000000000000000000000000;;		proxier.syncRunner = async.NewBoundedFrequencyRunner("sync-runner", proxier.syncProxyRules, minSyncPeriod, syncPeriod, burstSyncs)
0000000000000000000000000000000000000000;;		return proxier, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// CleanupLeftovers removes all iptables rules and chains created by the Proxier
0000000000000000000000000000000000000000;;	// It returns true if an error was encountered. Errors are logged.
0000000000000000000000000000000000000000;;	func CleanupLeftovers(ipt utiliptables.Interface) (encounteredError bool) {
0000000000000000000000000000000000000000;;		// Unlink the services chain.
0000000000000000000000000000000000000000;;		args := []string{
0000000000000000000000000000000000000000;;			"-m", "comment", "--comment", "kubernetes service portals",
0000000000000000000000000000000000000000;;			"-j", string(kubeServicesChain),
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		tableChainsWithJumpServices := []struct {
0000000000000000000000000000000000000000;;			table utiliptables.Table
0000000000000000000000000000000000000000;;			chain utiliptables.Chain
0000000000000000000000000000000000000000;;		}{
0000000000000000000000000000000000000000;;			{utiliptables.TableFilter, utiliptables.ChainInput},
0000000000000000000000000000000000000000;;			{utiliptables.TableFilter, utiliptables.ChainOutput},
0000000000000000000000000000000000000000;;			{utiliptables.TableNAT, utiliptables.ChainOutput},
0000000000000000000000000000000000000000;;			{utiliptables.TableNAT, utiliptables.ChainPrerouting},
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		for _, tc := range tableChainsWithJumpServices {
0000000000000000000000000000000000000000;;			if err := ipt.DeleteRule(tc.table, tc.chain, args...); err != nil {
0000000000000000000000000000000000000000;;				if !utiliptables.IsNotFoundError(err) {
0000000000000000000000000000000000000000;;					glog.Errorf("Error removing pure-iptables proxy rule: %v", err)
0000000000000000000000000000000000000000;;					encounteredError = true
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Unlink the postrouting chain.
0000000000000000000000000000000000000000;;		args = []string{
0000000000000000000000000000000000000000;;			"-m", "comment", "--comment", "kubernetes postrouting rules",
0000000000000000000000000000000000000000;;			"-j", string(kubePostroutingChain),
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if err := ipt.DeleteRule(utiliptables.TableNAT, utiliptables.ChainPostrouting, args...); err != nil {
0000000000000000000000000000000000000000;;			if !utiliptables.IsNotFoundError(err) {
0000000000000000000000000000000000000000;;				glog.Errorf("Error removing pure-iptables proxy rule: %v", err)
0000000000000000000000000000000000000000;;				encounteredError = true
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Flush and remove all of our chains.
0000000000000000000000000000000000000000;;		iptablesData := bytes.NewBuffer(nil)
0000000000000000000000000000000000000000;;		if err := ipt.SaveInto(utiliptables.TableNAT, iptablesData); err != nil {
0000000000000000000000000000000000000000;;			glog.Errorf("Failed to execute iptables-save for %s: %v", utiliptables.TableNAT, err)
0000000000000000000000000000000000000000;;			encounteredError = true
0000000000000000000000000000000000000000;;		} else {
0000000000000000000000000000000000000000;;			existingNATChains := utiliptables.GetChainLines(utiliptables.TableNAT, iptablesData.Bytes())
0000000000000000000000000000000000000000;;			natChains := bytes.NewBuffer(nil)
0000000000000000000000000000000000000000;;			natRules := bytes.NewBuffer(nil)
0000000000000000000000000000000000000000;;			writeLine(natChains, "*nat")
0000000000000000000000000000000000000000;;			// Start with chains we know we need to remove.
0000000000000000000000000000000000000000;;			for _, chain := range []utiliptables.Chain{kubeServicesChain, kubeNodePortsChain, kubePostroutingChain, KubeMarkMasqChain} {
0000000000000000000000000000000000000000;;				if _, found := existingNATChains[chain]; found {
0000000000000000000000000000000000000000;;					chainString := string(chain)
0000000000000000000000000000000000000000;;					writeLine(natChains, existingNATChains[chain]) // flush
0000000000000000000000000000000000000000;;					writeLine(natRules, "-X", chainString)         // delete
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			// Hunt for service and endpoint chains.
0000000000000000000000000000000000000000;;			for chain := range existingNATChains {
0000000000000000000000000000000000000000;;				chainString := string(chain)
0000000000000000000000000000000000000000;;				if strings.HasPrefix(chainString, "KUBE-SVC-") || strings.HasPrefix(chainString, "KUBE-SEP-") || strings.HasPrefix(chainString, "KUBE-FW-") || strings.HasPrefix(chainString, "KUBE-XLB-") {
0000000000000000000000000000000000000000;;					writeLine(natChains, existingNATChains[chain]) // flush
0000000000000000000000000000000000000000;;					writeLine(natRules, "-X", chainString)         // delete
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			writeLine(natRules, "COMMIT")
0000000000000000000000000000000000000000;;			natLines := append(natChains.Bytes(), natRules.Bytes()...)
0000000000000000000000000000000000000000;;			// Write it.
0000000000000000000000000000000000000000;;			err = ipt.Restore(utiliptables.TableNAT, natLines, utiliptables.NoFlushTables, utiliptables.RestoreCounters)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				glog.Errorf("Failed to execute iptables-restore for %s: %v", utiliptables.TableNAT, err)
0000000000000000000000000000000000000000;;				encounteredError = true
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		{
0000000000000000000000000000000000000000;;			filterBuf := bytes.NewBuffer(nil)
0000000000000000000000000000000000000000;;			writeLine(filterBuf, "*filter")
0000000000000000000000000000000000000000;;			writeLine(filterBuf, fmt.Sprintf(":%s - [0:0]", kubeServicesChain))
0000000000000000000000000000000000000000;;			writeLine(filterBuf, fmt.Sprintf("-X %s", kubeServicesChain))
0000000000000000000000000000000000000000;;			writeLine(filterBuf, "COMMIT")
0000000000000000000000000000000000000000;;			// Write it.
0000000000000000000000000000000000000000;;			if err := ipt.Restore(utiliptables.TableFilter, filterBuf.Bytes(), utiliptables.NoFlushTables, utiliptables.RestoreCounters); err != nil {
0000000000000000000000000000000000000000;;				glog.Errorf("Failed to execute iptables-restore for %s: %v", utiliptables.TableFilter, err)
0000000000000000000000000000000000000000;;				encounteredError = true
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return encounteredError
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func computeProbability(n int) string {
0000000000000000000000000000000000000000;;		return fmt.Sprintf("%0.5f", 1.0/float64(n))
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// This assumes proxier.mu is held
0000000000000000000000000000000000000000;;	func (proxier *Proxier) precomputeProbabilities(numberOfPrecomputed int) {
0000000000000000000000000000000000000000;;		if len(proxier.precomputedProbabilities) == 0 {
0000000000000000000000000000000000000000;;			proxier.precomputedProbabilities = append(proxier.precomputedProbabilities, "<bad value>")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		for i := len(proxier.precomputedProbabilities); i <= numberOfPrecomputed; i++ {
0000000000000000000000000000000000000000;;			proxier.precomputedProbabilities = append(proxier.precomputedProbabilities, computeProbability(i))
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// This assumes proxier.mu is held
0000000000000000000000000000000000000000;;	func (proxier *Proxier) probability(n int) string {
0000000000000000000000000000000000000000;;		if n >= len(proxier.precomputedProbabilities) {
0000000000000000000000000000000000000000;;			proxier.precomputeProbabilities(n)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return proxier.precomputedProbabilities[n]
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Sync is called to synchronize the proxier state to iptables as soon as possible.
0000000000000000000000000000000000000000;;	func (proxier *Proxier) Sync() {
0000000000000000000000000000000000000000;;		proxier.syncRunner.Run()
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// SyncLoop runs periodic work.  This is expected to run as a goroutine or as the main loop of the app.  It does not return.
0000000000000000000000000000000000000000;;	func (proxier *Proxier) SyncLoop() {
0000000000000000000000000000000000000000;;		// Update healthz timestamp at beginning in case Sync() never succeeds.
0000000000000000000000000000000000000000;;		if proxier.healthzServer != nil {
0000000000000000000000000000000000000000;;			proxier.healthzServer.UpdateTimestamp()
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		proxier.syncRunner.Loop(wait.NeverStop)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (proxier *Proxier) setInitialized(value bool) {
0000000000000000000000000000000000000000;;		var initialized int32
0000000000000000000000000000000000000000;;		if value {
0000000000000000000000000000000000000000;;			initialized = 1
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		atomic.StoreInt32(&proxier.initialized, initialized)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (proxier *Proxier) isInitialized() bool {
0000000000000000000000000000000000000000;;		return atomic.LoadInt32(&proxier.initialized) > 0
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (proxier *Proxier) OnServiceAdd(service *api.Service) {
0000000000000000000000000000000000000000;;		namespacedName := types.NamespacedName{Namespace: service.Namespace, Name: service.Name}
0000000000000000000000000000000000000000;;		if proxier.serviceChanges.update(&namespacedName, nil, service) && proxier.isInitialized() {
0000000000000000000000000000000000000000;;			proxier.syncRunner.Run()
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (proxier *Proxier) OnServiceUpdate(oldService, service *api.Service) {
0000000000000000000000000000000000000000;;		namespacedName := types.NamespacedName{Namespace: service.Namespace, Name: service.Name}
0000000000000000000000000000000000000000;;		if proxier.serviceChanges.update(&namespacedName, oldService, service) && proxier.isInitialized() {
0000000000000000000000000000000000000000;;			proxier.syncRunner.Run()
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (proxier *Proxier) OnServiceDelete(service *api.Service) {
0000000000000000000000000000000000000000;;		namespacedName := types.NamespacedName{Namespace: service.Namespace, Name: service.Name}
0000000000000000000000000000000000000000;;		if proxier.serviceChanges.update(&namespacedName, service, nil) && proxier.isInitialized() {
0000000000000000000000000000000000000000;;			proxier.syncRunner.Run()
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (proxier *Proxier) OnServiceSynced() {
0000000000000000000000000000000000000000;;		proxier.mu.Lock()
0000000000000000000000000000000000000000;;		proxier.servicesSynced = true
0000000000000000000000000000000000000000;;		proxier.setInitialized(proxier.servicesSynced && proxier.endpointsSynced)
0000000000000000000000000000000000000000;;		proxier.mu.Unlock()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Sync unconditionally - this is called once per lifetime.
0000000000000000000000000000000000000000;;		proxier.syncProxyRules()
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func shouldSkipService(svcName types.NamespacedName, service *api.Service) bool {
0000000000000000000000000000000000000000;;		// if ClusterIP is "None" or empty, skip proxying
0000000000000000000000000000000000000000;;		if !helper.IsServiceIPSet(service) {
0000000000000000000000000000000000000000;;			glog.V(3).Infof("Skipping service %s due to clusterIP = %q", svcName, service.Spec.ClusterIP)
0000000000000000000000000000000000000000;;			return true
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		// Even if ClusterIP is set, ServiceTypeExternalName services don't get proxied
0000000000000000000000000000000000000000;;		if service.Spec.Type == api.ServiceTypeExternalName {
0000000000000000000000000000000000000000;;			glog.V(3).Infof("Skipping service %s due to Type=ExternalName", svcName)
0000000000000000000000000000000000000000;;			return true
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return false
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// <serviceMap> is updated by this function (based on the given changes).
0000000000000000000000000000000000000000;;	// <changes> map is cleared after applying them.
0000000000000000000000000000000000000000;;	func updateServiceMap(
0000000000000000000000000000000000000000;;		serviceMap proxyServiceMap,
0000000000000000000000000000000000000000;;		changes *serviceChangeMap) (result updateServiceMapResult) {
0000000000000000000000000000000000000000;;		result.staleServices = sets.NewString()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		func() {
0000000000000000000000000000000000000000;;			changes.lock.Lock()
0000000000000000000000000000000000000000;;			defer changes.lock.Unlock()
0000000000000000000000000000000000000000;;			for _, change := range changes.items {
0000000000000000000000000000000000000000;;				existingPorts := serviceMap.merge(change.current)
0000000000000000000000000000000000000000;;				serviceMap.unmerge(change.previous, existingPorts, result.staleServices)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			changes.items = make(map[types.NamespacedName]*serviceChange)
0000000000000000000000000000000000000000;;		}()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// TODO: If this will appear to be computationally expensive, consider
0000000000000000000000000000000000000000;;		// computing this incrementally similarly to serviceMap.
0000000000000000000000000000000000000000;;		result.hcServices = make(map[types.NamespacedName]uint16)
0000000000000000000000000000000000000000;;		for svcPortName, info := range serviceMap {
0000000000000000000000000000000000000000;;			if info.healthCheckNodePort != 0 {
0000000000000000000000000000000000000000;;				result.hcServices[svcPortName.NamespacedName] = uint16(info.healthCheckNodePort)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return result
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (proxier *Proxier) OnEndpointsAdd(endpoints *api.Endpoints) {
0000000000000000000000000000000000000000;;		namespacedName := types.NamespacedName{Namespace: endpoints.Namespace, Name: endpoints.Name}
0000000000000000000000000000000000000000;;		if proxier.endpointsChanges.update(&namespacedName, nil, endpoints) && proxier.isInitialized() {
0000000000000000000000000000000000000000;;			proxier.syncRunner.Run()
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (proxier *Proxier) OnEndpointsUpdate(oldEndpoints, endpoints *api.Endpoints) {
0000000000000000000000000000000000000000;;		namespacedName := types.NamespacedName{Namespace: endpoints.Namespace, Name: endpoints.Name}
0000000000000000000000000000000000000000;;		if proxier.endpointsChanges.update(&namespacedName, oldEndpoints, endpoints) && proxier.isInitialized() {
0000000000000000000000000000000000000000;;			proxier.syncRunner.Run()
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (proxier *Proxier) OnEndpointsDelete(endpoints *api.Endpoints) {
0000000000000000000000000000000000000000;;		namespacedName := types.NamespacedName{Namespace: endpoints.Namespace, Name: endpoints.Name}
0000000000000000000000000000000000000000;;		if proxier.endpointsChanges.update(&namespacedName, endpoints, nil) && proxier.isInitialized() {
0000000000000000000000000000000000000000;;			proxier.syncRunner.Run()
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (proxier *Proxier) OnEndpointsSynced() {
0000000000000000000000000000000000000000;;		proxier.mu.Lock()
0000000000000000000000000000000000000000;;		proxier.endpointsSynced = true
0000000000000000000000000000000000000000;;		proxier.setInitialized(proxier.servicesSynced && proxier.endpointsSynced)
0000000000000000000000000000000000000000;;		proxier.mu.Unlock()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Sync unconditionally - this is called once per lifetime.
0000000000000000000000000000000000000000;;		proxier.syncProxyRules()
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// <endpointsMap> is updated by this function (based on the given changes).
0000000000000000000000000000000000000000;;	// <changes> map is cleared after applying them.
0000000000000000000000000000000000000000;;	func updateEndpointsMap(
0000000000000000000000000000000000000000;;		endpointsMap proxyEndpointsMap,
0000000000000000000000000000000000000000;;		changes *endpointsChangeMap,
0000000000000000000000000000000000000000;;		hostname string) (result updateEndpointMapResult) {
0000000000000000000000000000000000000000;;		result.staleEndpoints = make(map[endpointServicePair]bool)
0000000000000000000000000000000000000000;;		result.staleServiceNames = make(map[proxy.ServicePortName]bool)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		func() {
0000000000000000000000000000000000000000;;			changes.lock.Lock()
0000000000000000000000000000000000000000;;			defer changes.lock.Unlock()
0000000000000000000000000000000000000000;;			for _, change := range changes.items {
0000000000000000000000000000000000000000;;				endpointsMap.unmerge(change.previous)
0000000000000000000000000000000000000000;;				endpointsMap.merge(change.current)
0000000000000000000000000000000000000000;;				detectStaleConnections(change.previous, change.current, result.staleEndpoints, result.staleServiceNames)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			changes.items = make(map[types.NamespacedName]*endpointsChange)
0000000000000000000000000000000000000000;;		}()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		if !utilfeature.DefaultFeatureGate.Enabled(features.ExternalTrafficLocalOnly) {
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// TODO: If this will appear to be computationally expensive, consider
0000000000000000000000000000000000000000;;		// computing this incrementally similarly to endpointsMap.
0000000000000000000000000000000000000000;;		result.hcEndpoints = make(map[types.NamespacedName]int)
0000000000000000000000000000000000000000;;		localIPs := getLocalIPs(endpointsMap)
0000000000000000000000000000000000000000;;		for nsn, ips := range localIPs {
0000000000000000000000000000000000000000;;			result.hcEndpoints[nsn] = len(ips)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		return result
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// <staleEndpoints> and <staleServices> are modified by this function with detected stale connections.
0000000000000000000000000000000000000000;;	func detectStaleConnections(oldEndpointsMap, newEndpointsMap proxyEndpointsMap, staleEndpoints map[endpointServicePair]bool, staleServiceNames map[proxy.ServicePortName]bool) {
0000000000000000000000000000000000000000;;		for svcPortName, epList := range oldEndpointsMap {
0000000000000000000000000000000000000000;;			for _, ep := range epList {
0000000000000000000000000000000000000000;;				stale := true
0000000000000000000000000000000000000000;;				for i := range newEndpointsMap[svcPortName] {
0000000000000000000000000000000000000000;;					if *newEndpointsMap[svcPortName][i] == *ep {
0000000000000000000000000000000000000000;;						stale = false
0000000000000000000000000000000000000000;;						break
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				if stale {
0000000000000000000000000000000000000000;;					glog.V(4).Infof("Stale endpoint %v -> %v", svcPortName, ep.endpoint)
0000000000000000000000000000000000000000;;					staleEndpoints[endpointServicePair{endpoint: ep.endpoint, servicePortName: svcPortName}] = true
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		for svcPortName, epList := range newEndpointsMap {
0000000000000000000000000000000000000000;;			// For udp service, if its backend changes from 0 to non-0. There may exist a conntrack entry that could blackhole traffic to the service.
0000000000000000000000000000000000000000;;			if len(epList) > 0 && len(oldEndpointsMap[svcPortName]) == 0 {
0000000000000000000000000000000000000000;;				staleServiceNames[svcPortName] = true
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func getLocalIPs(endpointsMap proxyEndpointsMap) map[types.NamespacedName]sets.String {
0000000000000000000000000000000000000000;;		localIPs := make(map[types.NamespacedName]sets.String)
0000000000000000000000000000000000000000;;		for svcPortName := range endpointsMap {
0000000000000000000000000000000000000000;;			for _, ep := range endpointsMap[svcPortName] {
0000000000000000000000000000000000000000;;				if ep.isLocal {
0000000000000000000000000000000000000000;;					nsn := svcPortName.NamespacedName
0000000000000000000000000000000000000000;;					if localIPs[nsn] == nil {
0000000000000000000000000000000000000000;;						localIPs[nsn] = sets.NewString()
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					localIPs[nsn].Insert(ep.IPPart()) // just the IP part
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return localIPs
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Translates single Endpoints object to proxyEndpointsMap.
0000000000000000000000000000000000000000;;	// This function is used for incremental updated of endpointsMap.
0000000000000000000000000000000000000000;;	//
0000000000000000000000000000000000000000;;	// NOTE: endpoints object should NOT be modified.
0000000000000000000000000000000000000000;;	func endpointsToEndpointsMap(endpoints *api.Endpoints, hostname string) proxyEndpointsMap {
0000000000000000000000000000000000000000;;		if endpoints == nil {
0000000000000000000000000000000000000000;;			return nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		endpointsMap := make(proxyEndpointsMap)
0000000000000000000000000000000000000000;;		// We need to build a map of portname -> all ip:ports for that
0000000000000000000000000000000000000000;;		// portname.  Explode Endpoints.Subsets[*] into this structure.
0000000000000000000000000000000000000000;;		for i := range endpoints.Subsets {
0000000000000000000000000000000000000000;;			ss := &endpoints.Subsets[i]
0000000000000000000000000000000000000000;;			for i := range ss.Ports {
0000000000000000000000000000000000000000;;				port := &ss.Ports[i]
0000000000000000000000000000000000000000;;				if port.Port == 0 {
0000000000000000000000000000000000000000;;					glog.Warningf("ignoring invalid endpoint port %s", port.Name)
0000000000000000000000000000000000000000;;					continue
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				svcPortName := proxy.ServicePortName{
0000000000000000000000000000000000000000;;					NamespacedName: types.NamespacedName{Namespace: endpoints.Namespace, Name: endpoints.Name},
0000000000000000000000000000000000000000;;					Port:           port.Name,
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				for i := range ss.Addresses {
0000000000000000000000000000000000000000;;					addr := &ss.Addresses[i]
0000000000000000000000000000000000000000;;					if addr.IP == "" {
0000000000000000000000000000000000000000;;						glog.Warningf("ignoring invalid endpoint port %s with empty host", port.Name)
0000000000000000000000000000000000000000;;						continue
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					epInfo := &endpointsInfo{
0000000000000000000000000000000000000000;;						endpoint: net.JoinHostPort(addr.IP, strconv.Itoa(int(port.Port))),
0000000000000000000000000000000000000000;;						isLocal:  addr.NodeName != nil && *addr.NodeName == hostname,
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					endpointsMap[svcPortName] = append(endpointsMap[svcPortName], epInfo)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				if glog.V(3) {
0000000000000000000000000000000000000000;;					newEPList := []string{}
0000000000000000000000000000000000000000;;					for _, ep := range endpointsMap[svcPortName] {
0000000000000000000000000000000000000000;;						newEPList = append(newEPList, ep.endpoint)
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					glog.Infof("Setting endpoints for %q to %+v", svcPortName, newEPList)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return endpointsMap
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Translates single Service object to proxyServiceMap.
0000000000000000000000000000000000000000;;	//
0000000000000000000000000000000000000000;;	// NOTE: service object should NOT be modified.
0000000000000000000000000000000000000000;;	func serviceToServiceMap(service *api.Service) proxyServiceMap {
0000000000000000000000000000000000000000;;		if service == nil {
0000000000000000000000000000000000000000;;			return nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		svcName := types.NamespacedName{Namespace: service.Namespace, Name: service.Name}
0000000000000000000000000000000000000000;;		if shouldSkipService(svcName, service) {
0000000000000000000000000000000000000000;;			return nil
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		serviceMap := make(proxyServiceMap)
0000000000000000000000000000000000000000;;		for i := range service.Spec.Ports {
0000000000000000000000000000000000000000;;			servicePort := &service.Spec.Ports[i]
0000000000000000000000000000000000000000;;			svcPortName := proxy.ServicePortName{NamespacedName: svcName, Port: servicePort.Name}
0000000000000000000000000000000000000000;;			serviceMap[svcPortName] = newServiceInfo(svcPortName, servicePort, service)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return serviceMap
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// portProtoHash takes the ServicePortName and protocol for a service
0000000000000000000000000000000000000000;;	// returns the associated 16 character hash. This is computed by hashing (sha256)
0000000000000000000000000000000000000000;;	// then encoding to base32 and truncating to 16 chars. We do this because IPTables
0000000000000000000000000000000000000000;;	// Chain Names must be <= 28 chars long, and the longer they are the harder they are to read.
0000000000000000000000000000000000000000;;	func portProtoHash(servicePortName string, protocol string) string {
0000000000000000000000000000000000000000;;		hash := sha256.Sum256([]byte(servicePortName + protocol))
0000000000000000000000000000000000000000;;		encoded := base32.StdEncoding.EncodeToString(hash[:])
0000000000000000000000000000000000000000;;		return encoded[:16]
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// servicePortChainName takes the ServicePortName for a service and
0000000000000000000000000000000000000000;;	// returns the associated iptables chain.  This is computed by hashing (sha256)
0000000000000000000000000000000000000000;;	// then encoding to base32 and truncating with the prefix "KUBE-SVC-".
0000000000000000000000000000000000000000;;	func servicePortChainName(servicePortName string, protocol string) utiliptables.Chain {
0000000000000000000000000000000000000000;;		return utiliptables.Chain("KUBE-SVC-" + portProtoHash(servicePortName, protocol))
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// serviceFirewallChainName takes the ServicePortName for a service and
0000000000000000000000000000000000000000;;	// returns the associated iptables chain.  This is computed by hashing (sha256)
0000000000000000000000000000000000000000;;	// then encoding to base32 and truncating with the prefix "KUBE-FW-".
0000000000000000000000000000000000000000;;	func serviceFirewallChainName(servicePortName string, protocol string) utiliptables.Chain {
0000000000000000000000000000000000000000;;		return utiliptables.Chain("KUBE-FW-" + portProtoHash(servicePortName, protocol))
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// serviceLBPortChainName takes the ServicePortName for a service and
0000000000000000000000000000000000000000;;	// returns the associated iptables chain.  This is computed by hashing (sha256)
0000000000000000000000000000000000000000;;	// then encoding to base32 and truncating with the prefix "KUBE-XLB-".  We do
0000000000000000000000000000000000000000;;	// this because IPTables Chain Names must be <= 28 chars long, and the longer
0000000000000000000000000000000000000000;;	// they are the harder they are to read.
0000000000000000000000000000000000000000;;	func serviceLBChainName(servicePortName string, protocol string) utiliptables.Chain {
0000000000000000000000000000000000000000;;		return utiliptables.Chain("KUBE-XLB-" + portProtoHash(servicePortName, protocol))
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// This is the same as servicePortChainName but with the endpoint included.
0000000000000000000000000000000000000000;;	func servicePortEndpointChainName(servicePortName string, protocol string, endpoint string) utiliptables.Chain {
0000000000000000000000000000000000000000;;		hash := sha256.Sum256([]byte(servicePortName + protocol + endpoint))
0000000000000000000000000000000000000000;;		encoded := base32.StdEncoding.EncodeToString(hash[:])
0000000000000000000000000000000000000000;;		return utiliptables.Chain("KUBE-SEP-" + encoded[:16])
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	type endpointServicePair struct {
0000000000000000000000000000000000000000;;		endpoint        string
0000000000000000000000000000000000000000;;		servicePortName proxy.ServicePortName
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func (esp *endpointServicePair) IPPart() string {
0000000000000000000000000000000000000000;;		if index := strings.Index(esp.endpoint, ":"); index != -1 {
0000000000000000000000000000000000000000;;			return esp.endpoint[0:index]
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return esp.endpoint
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	const noConnectionToDelete = "0 flow entries have been deleted"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// After a UDP endpoint has been removed, we must flush any pending conntrack entries to it, or else we
0000000000000000000000000000000000000000;;	// risk sending more traffic to it, all of which will be lost (because UDP).
0000000000000000000000000000000000000000;;	// This assumes the proxier mutex is held
0000000000000000000000000000000000000000;;	func (proxier *Proxier) deleteEndpointConnections(connectionMap map[endpointServicePair]bool) {
0000000000000000000000000000000000000000;;		for epSvcPair := range connectionMap {
0000000000000000000000000000000000000000;;			if svcInfo, ok := proxier.serviceMap[epSvcPair.servicePortName]; ok && svcInfo.protocol == api.ProtocolUDP {
0000000000000000000000000000000000000000;;				endpointIP := epSvcPair.endpoint[0:strings.Index(epSvcPair.endpoint, ":")]
0000000000000000000000000000000000000000;;				glog.V(2).Infof("Deleting connection tracking state for service IP %s, endpoint IP %s", svcInfo.clusterIP.String(), endpointIP)
0000000000000000000000000000000000000000;;				err := utilproxy.ExecConntrackTool(proxier.exec, "-D", "--orig-dst", svcInfo.clusterIP.String(), "--dst-nat", endpointIP, "-p", "udp")
0000000000000000000000000000000000000000;;				if err != nil && !strings.Contains(err.Error(), noConnectionToDelete) {
0000000000000000000000000000000000000000;;					// TODO: Better handling for deletion failure. When failure occur, stale udp connection may not get flushed.
0000000000000000000000000000000000000000;;					// These stale udp connection will keep black hole traffic. Making this a best effort operation for now, since it
0000000000000000000000000000000000000000;;					// is expensive to baby sit all udp connections to kubernetes services.
0000000000000000000000000000000000000000;;					glog.Errorf("conntrack return with error: %v", err)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// This is where all of the iptables-save/restore calls happen.
0000000000000000000000000000000000000000;;	// The only other iptables rules are those that are setup in iptablesInit()
0000000000000000000000000000000000000000;;	// This assumes proxier.mu is NOT held
0000000000000000000000000000000000000000;;	func (proxier *Proxier) syncProxyRules() {
0000000000000000000000000000000000000000;;		proxier.mu.Lock()
0000000000000000000000000000000000000000;;		defer proxier.mu.Unlock()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		start := time.Now()
0000000000000000000000000000000000000000;;		defer func() {
0000000000000000000000000000000000000000;;			SyncProxyRulesLatency.Observe(sinceInMicroseconds(start))
0000000000000000000000000000000000000000;;			glog.V(4).Infof("syncProxyRules took %v", time.Since(start))
0000000000000000000000000000000000000000;;		}()
0000000000000000000000000000000000000000;;		// don't sync rules till we've received services and endpoints
0000000000000000000000000000000000000000;;		if !proxier.endpointsSynced || !proxier.servicesSynced {
0000000000000000000000000000000000000000;;			glog.V(2).Info("Not syncing iptables until Services and Endpoints have been received from master")
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// We assume that if this was called, we really want to sync them,
0000000000000000000000000000000000000000;;		// even if nothing changed in the meantime. In other words, callers are
0000000000000000000000000000000000000000;;		// responsible for detecting no-op changes and not calling this function.
0000000000000000000000000000000000000000;;		serviceUpdateResult := updateServiceMap(
0000000000000000000000000000000000000000;;			proxier.serviceMap, &proxier.serviceChanges)
0000000000000000000000000000000000000000;;		endpointUpdateResult := updateEndpointsMap(
0000000000000000000000000000000000000000;;			proxier.endpointsMap, &proxier.endpointsChanges, proxier.hostname)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		staleServices := serviceUpdateResult.staleServices
0000000000000000000000000000000000000000;;		// merge stale services gathered from updateEndpointsMap
0000000000000000000000000000000000000000;;		for svcPortName := range endpointUpdateResult.staleServiceNames {
0000000000000000000000000000000000000000;;			if svcInfo, ok := proxier.serviceMap[svcPortName]; ok && svcInfo != nil && svcInfo.protocol == api.ProtocolUDP {
0000000000000000000000000000000000000000;;				glog.V(2).Infof("Stale udp service %v -> %s", svcPortName, svcInfo.clusterIP.String())
0000000000000000000000000000000000000000;;				staleServices.Insert(svcInfo.clusterIP.String())
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		glog.V(3).Infof("Syncing iptables rules")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Create and link the kube services chain.
0000000000000000000000000000000000000000;;		{
0000000000000000000000000000000000000000;;			tablesNeedServicesChain := []utiliptables.Table{utiliptables.TableFilter, utiliptables.TableNAT}
0000000000000000000000000000000000000000;;			for _, table := range tablesNeedServicesChain {
0000000000000000000000000000000000000000;;				if _, err := proxier.iptables.EnsureChain(table, kubeServicesChain); err != nil {
0000000000000000000000000000000000000000;;					glog.Errorf("Failed to ensure that %s chain %s exists: %v", table, kubeServicesChain, err)
0000000000000000000000000000000000000000;;					return
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			tableChainsNeedJumpServices := []struct {
0000000000000000000000000000000000000000;;				table utiliptables.Table
0000000000000000000000000000000000000000;;				chain utiliptables.Chain
0000000000000000000000000000000000000000;;			}{
0000000000000000000000000000000000000000;;				{utiliptables.TableFilter, utiliptables.ChainInput},
0000000000000000000000000000000000000000;;				{utiliptables.TableFilter, utiliptables.ChainOutput},
0000000000000000000000000000000000000000;;				{utiliptables.TableNAT, utiliptables.ChainOutput},
0000000000000000000000000000000000000000;;				{utiliptables.TableNAT, utiliptables.ChainPrerouting},
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			comment := "kubernetes service portals"
0000000000000000000000000000000000000000;;			args := []string{"-m", "comment", "--comment", comment, "-j", string(kubeServicesChain)}
0000000000000000000000000000000000000000;;			for _, tc := range tableChainsNeedJumpServices {
0000000000000000000000000000000000000000;;				if _, err := proxier.iptables.EnsureRule(utiliptables.Prepend, tc.table, tc.chain, args...); err != nil {
0000000000000000000000000000000000000000;;					glog.Errorf("Failed to ensure that %s chain %s jumps to %s: %v", tc.table, tc.chain, kubeServicesChain, err)
0000000000000000000000000000000000000000;;					return
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Create and link the kube postrouting chain.
0000000000000000000000000000000000000000;;		{
0000000000000000000000000000000000000000;;			if _, err := proxier.iptables.EnsureChain(utiliptables.TableNAT, kubePostroutingChain); err != nil {
0000000000000000000000000000000000000000;;				glog.Errorf("Failed to ensure that %s chain %s exists: %v", utiliptables.TableNAT, kubePostroutingChain, err)
0000000000000000000000000000000000000000;;				return
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			comment := "kubernetes postrouting rules"
0000000000000000000000000000000000000000;;			args := []string{"-m", "comment", "--comment", comment, "-j", string(kubePostroutingChain)}
0000000000000000000000000000000000000000;;			if _, err := proxier.iptables.EnsureRule(utiliptables.Prepend, utiliptables.TableNAT, utiliptables.ChainPostrouting, args...); err != nil {
0000000000000000000000000000000000000000;;				glog.Errorf("Failed to ensure that %s chain %s jumps to %s: %v", utiliptables.TableNAT, utiliptables.ChainPostrouting, kubePostroutingChain, err)
0000000000000000000000000000000000000000;;				return
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		//
0000000000000000000000000000000000000000;;		// Below this point we will not return until we try to write the iptables rules.
0000000000000000000000000000000000000000;;		//
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Get iptables-save output so we can check for existing chains and rules.
0000000000000000000000000000000000000000;;		// This will be a map of chain name to chain with rules as stored in iptables-save/iptables-restore
0000000000000000000000000000000000000000;;		existingFilterChains := make(map[utiliptables.Chain]string)
0000000000000000000000000000000000000000;;		proxier.iptablesData.Reset()
0000000000000000000000000000000000000000;;		err := proxier.iptables.SaveInto(utiliptables.TableFilter, proxier.iptablesData)
0000000000000000000000000000000000000000;;		if err != nil { // if we failed to get any rules
0000000000000000000000000000000000000000;;			glog.Errorf("Failed to execute iptables-save, syncing all rules: %v", err)
0000000000000000000000000000000000000000;;		} else { // otherwise parse the output
0000000000000000000000000000000000000000;;			existingFilterChains = utiliptables.GetChainLines(utiliptables.TableFilter, proxier.iptablesData.Bytes())
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		existingNATChains := make(map[utiliptables.Chain]string)
0000000000000000000000000000000000000000;;		proxier.iptablesData.Reset()
0000000000000000000000000000000000000000;;		err = proxier.iptables.SaveInto(utiliptables.TableNAT, proxier.iptablesData)
0000000000000000000000000000000000000000;;		if err != nil { // if we failed to get any rules
0000000000000000000000000000000000000000;;			glog.Errorf("Failed to execute iptables-save, syncing all rules: %v", err)
0000000000000000000000000000000000000000;;		} else { // otherwise parse the output
0000000000000000000000000000000000000000;;			existingNATChains = utiliptables.GetChainLines(utiliptables.TableNAT, proxier.iptablesData.Bytes())
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Reset all buffers used later.
0000000000000000000000000000000000000000;;		// This is to avoid memory reallocations and thus improve performance.
0000000000000000000000000000000000000000;;		proxier.filterChains.Reset()
0000000000000000000000000000000000000000;;		proxier.filterRules.Reset()
0000000000000000000000000000000000000000;;		proxier.natChains.Reset()
0000000000000000000000000000000000000000;;		proxier.natRules.Reset()
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Write table headers.
0000000000000000000000000000000000000000;;		writeLine(proxier.filterChains, "*filter")
0000000000000000000000000000000000000000;;		writeLine(proxier.natChains, "*nat")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Make sure we keep stats for the top-level chains, if they existed
0000000000000000000000000000000000000000;;		// (which most should have because we created them above).
0000000000000000000000000000000000000000;;		if chain, ok := existingFilterChains[kubeServicesChain]; ok {
0000000000000000000000000000000000000000;;			writeLine(proxier.filterChains, chain)
0000000000000000000000000000000000000000;;		} else {
0000000000000000000000000000000000000000;;			writeLine(proxier.filterChains, utiliptables.MakeChainLine(kubeServicesChain))
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if chain, ok := existingNATChains[kubeServicesChain]; ok {
0000000000000000000000000000000000000000;;			writeLine(proxier.natChains, chain)
0000000000000000000000000000000000000000;;		} else {
0000000000000000000000000000000000000000;;			writeLine(proxier.natChains, utiliptables.MakeChainLine(kubeServicesChain))
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if chain, ok := existingNATChains[kubeNodePortsChain]; ok {
0000000000000000000000000000000000000000;;			writeLine(proxier.natChains, chain)
0000000000000000000000000000000000000000;;		} else {
0000000000000000000000000000000000000000;;			writeLine(proxier.natChains, utiliptables.MakeChainLine(kubeNodePortsChain))
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if chain, ok := existingNATChains[kubePostroutingChain]; ok {
0000000000000000000000000000000000000000;;			writeLine(proxier.natChains, chain)
0000000000000000000000000000000000000000;;		} else {
0000000000000000000000000000000000000000;;			writeLine(proxier.natChains, utiliptables.MakeChainLine(kubePostroutingChain))
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if chain, ok := existingNATChains[KubeMarkMasqChain]; ok {
0000000000000000000000000000000000000000;;			writeLine(proxier.natChains, chain)
0000000000000000000000000000000000000000;;		} else {
0000000000000000000000000000000000000000;;			writeLine(proxier.natChains, utiliptables.MakeChainLine(KubeMarkMasqChain))
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Install the kubernetes-specific postrouting rules. We use a whole chain for
0000000000000000000000000000000000000000;;		// this so that it is easier to flush and change, for example if the mark
0000000000000000000000000000000000000000;;		// value should ever change.
0000000000000000000000000000000000000000;;		writeLine(proxier.natRules, []string{
0000000000000000000000000000000000000000;;			"-A", string(kubePostroutingChain),
0000000000000000000000000000000000000000;;			"-m", "comment", "--comment", `"kubernetes service traffic requiring SNAT"`,
0000000000000000000000000000000000000000;;			"-m", "mark", "--mark", proxier.masqueradeMark,
0000000000000000000000000000000000000000;;			"-j", "MASQUERADE",
0000000000000000000000000000000000000000;;		}...)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Install the kubernetes-specific masquerade mark rule. We use a whole chain for
0000000000000000000000000000000000000000;;		// this so that it is easier to flush and change, for example if the mark
0000000000000000000000000000000000000000;;		// value should ever change.
0000000000000000000000000000000000000000;;		writeLine(proxier.natRules, []string{
0000000000000000000000000000000000000000;;			"-A", string(KubeMarkMasqChain),
0000000000000000000000000000000000000000;;			"-j", "MARK", "--set-xmark", proxier.masqueradeMark,
0000000000000000000000000000000000000000;;		}...)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Accumulate NAT chains to keep.
0000000000000000000000000000000000000000;;		activeNATChains := map[utiliptables.Chain]bool{} // use a map as a set
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Accumulate the set of local ports that we will be holding open once this update is complete
0000000000000000000000000000000000000000;;		replacementPortsMap := map[localPort]closeable{}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// We are creating those slices ones here to avoid memory reallocations
0000000000000000000000000000000000000000;;		// in every loop. Note that reuse the memory, instead of doing:
0000000000000000000000000000000000000000;;		//   slice = <some new slice>
0000000000000000000000000000000000000000;;		// you should always do one of the below:
0000000000000000000000000000000000000000;;		//   slice = slice[:0] // and then append to it
0000000000000000000000000000000000000000;;		//   slice = append(slice[:0], ...)
0000000000000000000000000000000000000000;;		endpoints := make([]*endpointsInfo, 0)
0000000000000000000000000000000000000000;;		endpointChains := make([]utiliptables.Chain, 0)
0000000000000000000000000000000000000000;;		// To avoid growing this slice, we arbitrarily set its size to 64,
0000000000000000000000000000000000000000;;		// there is never more than that many arguments for a single line.
0000000000000000000000000000000000000000;;		// Note that even if we go over 64, it will still be correct - it
0000000000000000000000000000000000000000;;		// is just for efficiency, not correctness.
0000000000000000000000000000000000000000;;		args := make([]string, 64)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Build rules for each service.
0000000000000000000000000000000000000000;;		var svcNameString string
0000000000000000000000000000000000000000;;		for svcName, svcInfo := range proxier.serviceMap {
0000000000000000000000000000000000000000;;			protocol := strings.ToLower(string(svcInfo.protocol))
0000000000000000000000000000000000000000;;			svcNameString = svcInfo.serviceNameString
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Create the per-service chain, retaining counters if possible.
0000000000000000000000000000000000000000;;			svcChain := svcInfo.servicePortChainName
0000000000000000000000000000000000000000;;			if chain, ok := existingNATChains[svcChain]; ok {
0000000000000000000000000000000000000000;;				writeLine(proxier.natChains, chain)
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				writeLine(proxier.natChains, utiliptables.MakeChainLine(svcChain))
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			activeNATChains[svcChain] = true
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			svcXlbChain := svcInfo.serviceLBChainName
0000000000000000000000000000000000000000;;			if svcInfo.onlyNodeLocalEndpoints {
0000000000000000000000000000000000000000;;				// Only for services request OnlyLocal traffic
0000000000000000000000000000000000000000;;				// create the per-service LB chain, retaining counters if possible.
0000000000000000000000000000000000000000;;				if lbChain, ok := existingNATChains[svcXlbChain]; ok {
0000000000000000000000000000000000000000;;					writeLine(proxier.natChains, lbChain)
0000000000000000000000000000000000000000;;				} else {
0000000000000000000000000000000000000000;;					writeLine(proxier.natChains, utiliptables.MakeChainLine(svcXlbChain))
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				activeNATChains[svcXlbChain] = true
0000000000000000000000000000000000000000;;			} else if activeNATChains[svcXlbChain] {
0000000000000000000000000000000000000000;;				// Cleanup the previously created XLB chain for this service
0000000000000000000000000000000000000000;;				delete(activeNATChains, svcXlbChain)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Capture the clusterIP.
0000000000000000000000000000000000000000;;			args = append(args[:0],
0000000000000000000000000000000000000000;;				"-A", string(kubeServicesChain),
0000000000000000000000000000000000000000;;				"-m", "comment", "--comment", fmt.Sprintf(`"%s cluster IP"`, svcNameString),
0000000000000000000000000000000000000000;;				"-m", protocol, "-p", protocol,
0000000000000000000000000000000000000000;;				"-d", fmt.Sprintf("%s/32", svcInfo.clusterIP.String()),
0000000000000000000000000000000000000000;;				"--dport", strconv.Itoa(svcInfo.port),
0000000000000000000000000000000000000000;;			)
0000000000000000000000000000000000000000;;			if proxier.masqueradeAll {
0000000000000000000000000000000000000000;;				writeLine(proxier.natRules, append(args, "-j", string(KubeMarkMasqChain))...)
0000000000000000000000000000000000000000;;			} else if len(proxier.clusterCIDR) > 0 {
0000000000000000000000000000000000000000;;				// This masquerades off-cluster traffic to a service VIP.  The idea
0000000000000000000000000000000000000000;;				// is that you can establish a static route for your Service range,
0000000000000000000000000000000000000000;;				// routing to any node, and that node will bridge into the Service
0000000000000000000000000000000000000000;;				// for you.  Since that might bounce off-node, we masquerade here.
0000000000000000000000000000000000000000;;				// If/when we support "Local" policy for VIPs, we should update this.
0000000000000000000000000000000000000000;;				writeLine(proxier.natRules, append(args, "! -s", proxier.clusterCIDR, "-j", string(KubeMarkMasqChain))...)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			writeLine(proxier.natRules, append(args, "-j", string(svcChain))...)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Capture externalIPs.
0000000000000000000000000000000000000000;;			for _, externalIP := range svcInfo.externalIPs {
0000000000000000000000000000000000000000;;				// If the "external" IP happens to be an IP that is local to this
0000000000000000000000000000000000000000;;				// machine, hold the local port open so no other process can open it
0000000000000000000000000000000000000000;;				// (because the socket might open but it would never work).
0000000000000000000000000000000000000000;;				if local, err := isLocalIP(externalIP); err != nil {
0000000000000000000000000000000000000000;;					glog.Errorf("can't determine if IP is local, assuming not: %v", err)
0000000000000000000000000000000000000000;;				} else if local {
0000000000000000000000000000000000000000;;					lp := localPort{
0000000000000000000000000000000000000000;;						desc:     "externalIP for " + svcNameString,
0000000000000000000000000000000000000000;;						ip:       externalIP,
0000000000000000000000000000000000000000;;						port:     svcInfo.port,
0000000000000000000000000000000000000000;;						protocol: protocol,
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					if proxier.portsMap[lp] != nil {
0000000000000000000000000000000000000000;;						glog.V(4).Infof("Port %s was open before and is still needed", lp.String())
0000000000000000000000000000000000000000;;						replacementPortsMap[lp] = proxier.portsMap[lp]
0000000000000000000000000000000000000000;;					} else {
0000000000000000000000000000000000000000;;						socket, err := proxier.portMapper.OpenLocalPort(&lp)
0000000000000000000000000000000000000000;;						if err != nil {
0000000000000000000000000000000000000000;;							msg := fmt.Sprintf("can't open %s, skipping this externalIP: %v", lp.String(), err)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;							proxier.recorder.Eventf(
0000000000000000000000000000000000000000;;								&clientv1.ObjectReference{
0000000000000000000000000000000000000000;;									Kind:      "Node",
0000000000000000000000000000000000000000;;									Name:      proxier.hostname,
0000000000000000000000000000000000000000;;									UID:       types.UID(proxier.hostname),
0000000000000000000000000000000000000000;;									Namespace: "",
0000000000000000000000000000000000000000;;								}, api.EventTypeWarning, err.Error(), msg)
0000000000000000000000000000000000000000;;							glog.Error(msg)
0000000000000000000000000000000000000000;;							continue
0000000000000000000000000000000000000000;;						}
0000000000000000000000000000000000000000;;						replacementPortsMap[lp] = socket
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;				} // We're holding the port, so it's OK to install iptables rules.
0000000000000000000000000000000000000000;;				args = append(args[:0],
0000000000000000000000000000000000000000;;					"-A", string(kubeServicesChain),
0000000000000000000000000000000000000000;;					"-m", "comment", "--comment", fmt.Sprintf(`"%s external IP"`, svcNameString),
0000000000000000000000000000000000000000;;					"-m", protocol, "-p", protocol,
0000000000000000000000000000000000000000;;					"-d", fmt.Sprintf("%s/32", externalIP),
0000000000000000000000000000000000000000;;					"--dport", strconv.Itoa(svcInfo.port),
0000000000000000000000000000000000000000;;				)
0000000000000000000000000000000000000000;;				// We have to SNAT packets to external IPs.
0000000000000000000000000000000000000000;;				writeLine(proxier.natRules, append(args, "-j", string(KubeMarkMasqChain))...)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				// Allow traffic for external IPs that does not come from a bridge (i.e. not from a container)
0000000000000000000000000000000000000000;;				// nor from a local process to be forwarded to the service.
0000000000000000000000000000000000000000;;				// This rule roughly translates to "all traffic from off-machine".
0000000000000000000000000000000000000000;;				// This is imperfect in the face of network plugins that might not use a bridge, but we can revisit that later.
0000000000000000000000000000000000000000;;				externalTrafficOnlyArgs := append(args,
0000000000000000000000000000000000000000;;					"-m", "physdev", "!", "--physdev-is-in",
0000000000000000000000000000000000000000;;					"-m", "addrtype", "!", "--src-type", "LOCAL")
0000000000000000000000000000000000000000;;				writeLine(proxier.natRules, append(externalTrafficOnlyArgs, "-j", string(svcChain))...)
0000000000000000000000000000000000000000;;				dstLocalOnlyArgs := append(args, "-m", "addrtype", "--dst-type", "LOCAL")
0000000000000000000000000000000000000000;;				// Allow traffic bound for external IPs that happen to be recognized as local IPs to stay local.
0000000000000000000000000000000000000000;;				// This covers cases like GCE load-balancers which get added to the local routing table.
0000000000000000000000000000000000000000;;				writeLine(proxier.natRules, append(dstLocalOnlyArgs, "-j", string(svcChain))...)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				// If the service has no endpoints then reject packets coming via externalIP
0000000000000000000000000000000000000000;;				// Install ICMP Reject rule in filter table for destination=externalIP and dport=svcport
0000000000000000000000000000000000000000;;				if len(proxier.endpointsMap[svcName]) == 0 {
0000000000000000000000000000000000000000;;					writeLine(proxier.filterRules,
0000000000000000000000000000000000000000;;						"-A", string(kubeServicesChain),
0000000000000000000000000000000000000000;;						"-m", "comment", "--comment", fmt.Sprintf(`"%s has no endpoints"`, svcNameString),
0000000000000000000000000000000000000000;;						"-m", protocol, "-p", protocol,
0000000000000000000000000000000000000000;;						"-d", fmt.Sprintf("%s/32", externalIP),
0000000000000000000000000000000000000000;;						"--dport", strconv.Itoa(svcInfo.port),
0000000000000000000000000000000000000000;;						"-j", "REJECT",
0000000000000000000000000000000000000000;;					)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Capture load-balancer ingress.
0000000000000000000000000000000000000000;;			fwChain := svcInfo.serviceFirewallChainName
0000000000000000000000000000000000000000;;			for _, ingress := range svcInfo.loadBalancerStatus.Ingress {
0000000000000000000000000000000000000000;;				if ingress.IP != "" {
0000000000000000000000000000000000000000;;					// create service firewall chain
0000000000000000000000000000000000000000;;					if chain, ok := existingNATChains[fwChain]; ok {
0000000000000000000000000000000000000000;;						writeLine(proxier.natChains, chain)
0000000000000000000000000000000000000000;;					} else {
0000000000000000000000000000000000000000;;						writeLine(proxier.natChains, utiliptables.MakeChainLine(fwChain))
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					activeNATChains[fwChain] = true
0000000000000000000000000000000000000000;;					// The service firewall rules are created based on ServiceSpec.loadBalancerSourceRanges field.
0000000000000000000000000000000000000000;;					// This currently works for loadbalancers that preserves source ips.
0000000000000000000000000000000000000000;;					// For loadbalancers which direct traffic to service NodePort, the firewall rules will not apply.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;					args = append(args[:0],
0000000000000000000000000000000000000000;;						"-A", string(kubeServicesChain),
0000000000000000000000000000000000000000;;						"-m", "comment", "--comment", fmt.Sprintf(`"%s loadbalancer IP"`, svcNameString),
0000000000000000000000000000000000000000;;						"-m", protocol, "-p", protocol,
0000000000000000000000000000000000000000;;						"-d", fmt.Sprintf("%s/32", ingress.IP),
0000000000000000000000000000000000000000;;						"--dport", strconv.Itoa(svcInfo.port),
0000000000000000000000000000000000000000;;					)
0000000000000000000000000000000000000000;;					// jump to service firewall chain
0000000000000000000000000000000000000000;;					writeLine(proxier.natRules, append(args, "-j", string(fwChain))...)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;					args = append(args[:0],
0000000000000000000000000000000000000000;;						"-A", string(fwChain),
0000000000000000000000000000000000000000;;						"-m", "comment", "--comment", fmt.Sprintf(`"%s loadbalancer IP"`, svcNameString),
0000000000000000000000000000000000000000;;					)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;					// Each source match rule in the FW chain may jump to either the SVC or the XLB chain
0000000000000000000000000000000000000000;;					chosenChain := svcXlbChain
0000000000000000000000000000000000000000;;					// If we are proxying globally, we need to masquerade in case we cross nodes.
0000000000000000000000000000000000000000;;					// If we are proxying only locally, we can retain the source IP.
0000000000000000000000000000000000000000;;					if !svcInfo.onlyNodeLocalEndpoints {
0000000000000000000000000000000000000000;;						writeLine(proxier.natRules, append(args, "-j", string(KubeMarkMasqChain))...)
0000000000000000000000000000000000000000;;						chosenChain = svcChain
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;					if len(svcInfo.loadBalancerSourceRanges) == 0 {
0000000000000000000000000000000000000000;;						// allow all sources, so jump directly to the KUBE-SVC or KUBE-XLB chain
0000000000000000000000000000000000000000;;						writeLine(proxier.natRules, append(args, "-j", string(chosenChain))...)
0000000000000000000000000000000000000000;;					} else {
0000000000000000000000000000000000000000;;						// firewall filter based on each source range
0000000000000000000000000000000000000000;;						allowFromNode := false
0000000000000000000000000000000000000000;;						for _, src := range svcInfo.loadBalancerSourceRanges {
0000000000000000000000000000000000000000;;							writeLine(proxier.natRules, append(args, "-s", src, "-j", string(chosenChain))...)
0000000000000000000000000000000000000000;;							// ignore error because it has been validated
0000000000000000000000000000000000000000;;							_, cidr, _ := net.ParseCIDR(src)
0000000000000000000000000000000000000000;;							if cidr.Contains(proxier.nodeIP) {
0000000000000000000000000000000000000000;;								allowFromNode = true
0000000000000000000000000000000000000000;;							}
0000000000000000000000000000000000000000;;						}
0000000000000000000000000000000000000000;;						// generally, ip route rule was added to intercept request to loadbalancer vip from the
0000000000000000000000000000000000000000;;						// loadbalancer's backend hosts. In this case, request will not hit the loadbalancer but loop back directly.
0000000000000000000000000000000000000000;;						// Need to add the following rule to allow request on host.
0000000000000000000000000000000000000000;;						if allowFromNode {
0000000000000000000000000000000000000000;;							writeLine(proxier.natRules, append(args, "-s", fmt.Sprintf("%s/32", ingress.IP), "-j", string(chosenChain))...)
0000000000000000000000000000000000000000;;						}
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;					// If the packet was able to reach the end of firewall chain, then it did not get DNATed.
0000000000000000000000000000000000000000;;					// It means the packet cannot go thru the firewall, then mark it for DROP
0000000000000000000000000000000000000000;;					writeLine(proxier.natRules, append(args, "-j", string(KubeMarkDropChain))...)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Capture nodeports.  If we had more than 2 rules it might be
0000000000000000000000000000000000000000;;			// worthwhile to make a new per-service chain for nodeport rules, but
0000000000000000000000000000000000000000;;			// with just 2 rules it ends up being a waste and a cognitive burden.
0000000000000000000000000000000000000000;;			if svcInfo.nodePort != 0 {
0000000000000000000000000000000000000000;;				// Hold the local port open so no other process can open it
0000000000000000000000000000000000000000;;				// (because the socket might open but it would never work).
0000000000000000000000000000000000000000;;				lp := localPort{
0000000000000000000000000000000000000000;;					desc:     "nodePort for " + svcNameString,
0000000000000000000000000000000000000000;;					ip:       "",
0000000000000000000000000000000000000000;;					port:     svcInfo.nodePort,
0000000000000000000000000000000000000000;;					protocol: protocol,
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				if proxier.portsMap[lp] != nil {
0000000000000000000000000000000000000000;;					glog.V(4).Infof("Port %s was open before and is still needed", lp.String())
0000000000000000000000000000000000000000;;					replacementPortsMap[lp] = proxier.portsMap[lp]
0000000000000000000000000000000000000000;;				} else {
0000000000000000000000000000000000000000;;					socket, err := proxier.portMapper.OpenLocalPort(&lp)
0000000000000000000000000000000000000000;;					if err != nil {
0000000000000000000000000000000000000000;;						glog.Errorf("can't open %s, skipping this nodePort: %v", lp.String(), err)
0000000000000000000000000000000000000000;;						continue
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					if lp.protocol == "udp" {
0000000000000000000000000000000000000000;;						proxier.clearUDPConntrackForPort(lp.port)
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					replacementPortsMap[lp] = socket
0000000000000000000000000000000000000000;;				} // We're holding the port, so it's OK to install iptables rules.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				args = append(args[:0],
0000000000000000000000000000000000000000;;					"-A", string(kubeNodePortsChain),
0000000000000000000000000000000000000000;;					"-m", "comment", "--comment", svcNameString,
0000000000000000000000000000000000000000;;					"-m", protocol, "-p", protocol,
0000000000000000000000000000000000000000;;					"--dport", strconv.Itoa(svcInfo.nodePort),
0000000000000000000000000000000000000000;;				)
0000000000000000000000000000000000000000;;				if !svcInfo.onlyNodeLocalEndpoints {
0000000000000000000000000000000000000000;;					// Nodeports need SNAT, unless they're local.
0000000000000000000000000000000000000000;;					writeLine(proxier.natRules, append(args, "-j", string(KubeMarkMasqChain))...)
0000000000000000000000000000000000000000;;					// Jump to the service chain.
0000000000000000000000000000000000000000;;					writeLine(proxier.natRules, append(args, "-j", string(svcChain))...)
0000000000000000000000000000000000000000;;				} else {
0000000000000000000000000000000000000000;;					// TODO: Make all nodePorts jump to the firewall chain.
0000000000000000000000000000000000000000;;					// Currently we only create it for loadbalancers (#33586).
0000000000000000000000000000000000000000;;					writeLine(proxier.natRules, append(args, "-j", string(svcXlbChain))...)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				// If the service has no endpoints then reject packets.  The filter
0000000000000000000000000000000000000000;;				// table doesn't currently have the same per-service structure that
0000000000000000000000000000000000000000;;				// the nat table does, so we just stick this into the kube-services
0000000000000000000000000000000000000000;;				// chain.
0000000000000000000000000000000000000000;;				if len(proxier.endpointsMap[svcName]) == 0 {
0000000000000000000000000000000000000000;;					writeLine(proxier.filterRules,
0000000000000000000000000000000000000000;;						"-A", string(kubeServicesChain),
0000000000000000000000000000000000000000;;						"-m", "comment", "--comment", fmt.Sprintf(`"%s has no endpoints"`, svcNameString),
0000000000000000000000000000000000000000;;						"-m", "addrtype", "--dst-type", "LOCAL",
0000000000000000000000000000000000000000;;						"-m", protocol, "-p", protocol,
0000000000000000000000000000000000000000;;						"--dport", strconv.Itoa(svcInfo.nodePort),
0000000000000000000000000000000000000000;;						"-j", "REJECT",
0000000000000000000000000000000000000000;;					)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// If the service has no endpoints then reject packets.
0000000000000000000000000000000000000000;;			if len(proxier.endpointsMap[svcName]) == 0 {
0000000000000000000000000000000000000000;;				writeLine(proxier.filterRules,
0000000000000000000000000000000000000000;;					"-A", string(kubeServicesChain),
0000000000000000000000000000000000000000;;					"-m", "comment", "--comment", fmt.Sprintf(`"%s has no endpoints"`, svcNameString),
0000000000000000000000000000000000000000;;					"-m", protocol, "-p", protocol,
0000000000000000000000000000000000000000;;					"-d", fmt.Sprintf("%s/32", svcInfo.clusterIP.String()),
0000000000000000000000000000000000000000;;					"--dport", strconv.Itoa(svcInfo.port),
0000000000000000000000000000000000000000;;					"-j", "REJECT",
0000000000000000000000000000000000000000;;				)
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// From here on, we assume there are active endpoints.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Generate the per-endpoint chains.  We do this in multiple passes so we
0000000000000000000000000000000000000000;;			// can group rules together.
0000000000000000000000000000000000000000;;			// These two slices parallel each other - keep in sync
0000000000000000000000000000000000000000;;			endpoints = endpoints[:0]
0000000000000000000000000000000000000000;;			endpointChains = endpointChains[:0]
0000000000000000000000000000000000000000;;			var endpointChain utiliptables.Chain
0000000000000000000000000000000000000000;;			for _, ep := range proxier.endpointsMap[svcName] {
0000000000000000000000000000000000000000;;				endpoints = append(endpoints, ep)
0000000000000000000000000000000000000000;;				endpointChain = ep.endpointChain(svcNameString, protocol)
0000000000000000000000000000000000000000;;				endpointChains = append(endpointChains, endpointChain)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				// Create the endpoint chain, retaining counters if possible.
0000000000000000000000000000000000000000;;				if chain, ok := existingNATChains[utiliptables.Chain(endpointChain)]; ok {
0000000000000000000000000000000000000000;;					writeLine(proxier.natChains, chain)
0000000000000000000000000000000000000000;;				} else {
0000000000000000000000000000000000000000;;					writeLine(proxier.natChains, utiliptables.MakeChainLine(endpointChain))
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				activeNATChains[endpointChain] = true
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// First write session affinity rules, if applicable.
0000000000000000000000000000000000000000;;			if svcInfo.sessionAffinityType == api.ServiceAffinityClientIP {
0000000000000000000000000000000000000000;;				for _, endpointChain := range endpointChains {
0000000000000000000000000000000000000000;;					writeLine(proxier.natRules,
0000000000000000000000000000000000000000;;						"-A", string(svcChain),
0000000000000000000000000000000000000000;;						"-m", "comment", "--comment", svcNameString,
0000000000000000000000000000000000000000;;						"-m", "recent", "--name", string(endpointChain),
0000000000000000000000000000000000000000;;						"--rcheck", "--seconds", strconv.Itoa(svcInfo.stickyMaxAgeMinutes*60), "--reap",
0000000000000000000000000000000000000000;;						"-j", string(endpointChain))
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Now write loadbalancing & DNAT rules.
0000000000000000000000000000000000000000;;			n := len(endpointChains)
0000000000000000000000000000000000000000;;			for i, endpointChain := range endpointChains {
0000000000000000000000000000000000000000;;				// Balancing rules in the per-service chain.
0000000000000000000000000000000000000000;;				args = append(args[:0], []string{
0000000000000000000000000000000000000000;;					"-A", string(svcChain),
0000000000000000000000000000000000000000;;					"-m", "comment", "--comment", svcNameString,
0000000000000000000000000000000000000000;;				}...)
0000000000000000000000000000000000000000;;				if i < (n - 1) {
0000000000000000000000000000000000000000;;					// Each rule is a probabilistic match.
0000000000000000000000000000000000000000;;					args = append(args,
0000000000000000000000000000000000000000;;						"-m", "statistic",
0000000000000000000000000000000000000000;;						"--mode", "random",
0000000000000000000000000000000000000000;;						"--probability", proxier.probability(n-i))
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				// The final (or only if n == 1) rule is a guaranteed match.
0000000000000000000000000000000000000000;;				args = append(args, "-j", string(endpointChain))
0000000000000000000000000000000000000000;;				writeLine(proxier.natRules, args...)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;				// Rules in the per-endpoint chain.
0000000000000000000000000000000000000000;;				args = append(args[:0],
0000000000000000000000000000000000000000;;					"-A", string(endpointChain),
0000000000000000000000000000000000000000;;					"-m", "comment", "--comment", svcNameString,
0000000000000000000000000000000000000000;;				)
0000000000000000000000000000000000000000;;				// Handle traffic that loops back to the originator with SNAT.
0000000000000000000000000000000000000000;;				writeLine(proxier.natRules, append(args,
0000000000000000000000000000000000000000;;					"-s", fmt.Sprintf("%s/32", endpoints[i].IPPart()),
0000000000000000000000000000000000000000;;					"-j", string(KubeMarkMasqChain))...)
0000000000000000000000000000000000000000;;				// Update client-affinity lists.
0000000000000000000000000000000000000000;;				if svcInfo.sessionAffinityType == api.ServiceAffinityClientIP {
0000000000000000000000000000000000000000;;					args = append(args, "-m", "recent", "--name", string(endpointChain), "--set")
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				// DNAT to final destination.
0000000000000000000000000000000000000000;;				args = append(args, "-m", protocol, "-p", protocol, "-j", "DNAT", "--to-destination", endpoints[i].endpoint)
0000000000000000000000000000000000000000;;				writeLine(proxier.natRules, args...)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// The logic below this applies only if this service is marked as OnlyLocal
0000000000000000000000000000000000000000;;			if !svcInfo.onlyNodeLocalEndpoints {
0000000000000000000000000000000000000000;;				continue
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			// Now write ingress loadbalancing & DNAT rules only for services that request OnlyLocal traffic.
0000000000000000000000000000000000000000;;			// TODO - This logic may be combinable with the block above that creates the svc balancer chain
0000000000000000000000000000000000000000;;			localEndpoints := make([]*endpointsInfo, 0)
0000000000000000000000000000000000000000;;			localEndpointChains := make([]utiliptables.Chain, 0)
0000000000000000000000000000000000000000;;			for i := range endpointChains {
0000000000000000000000000000000000000000;;				if endpoints[i].isLocal {
0000000000000000000000000000000000000000;;					// These slices parallel each other; must be kept in sync
0000000000000000000000000000000000000000;;					localEndpoints = append(localEndpoints, endpoints[i])
0000000000000000000000000000000000000000;;					localEndpointChains = append(localEndpointChains, endpointChains[i])
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			// First rule in the chain redirects all pod -> external VIP traffic to the
0000000000000000000000000000000000000000;;			// Service's ClusterIP instead. This happens whether or not we have local
0000000000000000000000000000000000000000;;			// endpoints; only if clusterCIDR is specified
0000000000000000000000000000000000000000;;			if len(proxier.clusterCIDR) > 0 {
0000000000000000000000000000000000000000;;				args = append(args[:0],
0000000000000000000000000000000000000000;;					"-A", string(svcXlbChain),
0000000000000000000000000000000000000000;;					"-m", "comment", "--comment",
0000000000000000000000000000000000000000;;					`"Redirect pods trying to reach external loadbalancer VIP to clusterIP"`,
0000000000000000000000000000000000000000;;					"-s", proxier.clusterCIDR,
0000000000000000000000000000000000000000;;					"-j", string(svcChain),
0000000000000000000000000000000000000000;;				)
0000000000000000000000000000000000000000;;				writeLine(proxier.natRules, args...)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;			numLocalEndpoints := len(localEndpointChains)
0000000000000000000000000000000000000000;;			if numLocalEndpoints == 0 {
0000000000000000000000000000000000000000;;				// Blackhole all traffic since there are no local endpoints
0000000000000000000000000000000000000000;;				args = append(args[:0],
0000000000000000000000000000000000000000;;					"-A", string(svcXlbChain),
0000000000000000000000000000000000000000;;					"-m", "comment", "--comment",
0000000000000000000000000000000000000000;;					fmt.Sprintf(`"%s has no local endpoints"`, svcNameString),
0000000000000000000000000000000000000000;;					"-j",
0000000000000000000000000000000000000000;;					string(KubeMarkDropChain),
0000000000000000000000000000000000000000;;				)
0000000000000000000000000000000000000000;;				writeLine(proxier.natRules, args...)
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				// Setup probability filter rules only over local endpoints
0000000000000000000000000000000000000000;;				for i, endpointChain := range localEndpointChains {
0000000000000000000000000000000000000000;;					// Balancing rules in the per-service chain.
0000000000000000000000000000000000000000;;					args = append(args[:0],
0000000000000000000000000000000000000000;;						"-A", string(svcXlbChain),
0000000000000000000000000000000000000000;;						"-m", "comment", "--comment",
0000000000000000000000000000000000000000;;						fmt.Sprintf(`"Balancing rule %d for %s"`, i, svcNameString),
0000000000000000000000000000000000000000;;					)
0000000000000000000000000000000000000000;;					if i < (numLocalEndpoints - 1) {
0000000000000000000000000000000000000000;;						// Each rule is a probabilistic match.
0000000000000000000000000000000000000000;;						args = append(args,
0000000000000000000000000000000000000000;;							"-m", "statistic",
0000000000000000000000000000000000000000;;							"--mode", "random",
0000000000000000000000000000000000000000;;							"--probability", proxier.probability(numLocalEndpoints-i))
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;					// The final (or only if n == 1) rule is a guaranteed match.
0000000000000000000000000000000000000000;;					args = append(args, "-j", string(endpointChain))
0000000000000000000000000000000000000000;;					writeLine(proxier.natRules, args...)
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Delete chains no longer in use.
0000000000000000000000000000000000000000;;		for chain := range existingNATChains {
0000000000000000000000000000000000000000;;			if !activeNATChains[chain] {
0000000000000000000000000000000000000000;;				chainString := string(chain)
0000000000000000000000000000000000000000;;				if !strings.HasPrefix(chainString, "KUBE-SVC-") && !strings.HasPrefix(chainString, "KUBE-SEP-") && !strings.HasPrefix(chainString, "KUBE-FW-") && !strings.HasPrefix(chainString, "KUBE-XLB-") {
0000000000000000000000000000000000000000;;					// Ignore chains that aren't ours.
0000000000000000000000000000000000000000;;					continue
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;				// We must (as per iptables) write a chain-line for it, which has
0000000000000000000000000000000000000000;;				// the nice effect of flushing the chain.  Then we can remove the
0000000000000000000000000000000000000000;;				// chain.
0000000000000000000000000000000000000000;;				writeLine(proxier.natChains, existingNATChains[chain])
0000000000000000000000000000000000000000;;				writeLine(proxier.natRules, "-X", chainString)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Finally, tail-call to the nodeports chain.  This needs to be after all
0000000000000000000000000000000000000000;;		// other service portal rules.
0000000000000000000000000000000000000000;;		writeLine(proxier.natRules,
0000000000000000000000000000000000000000;;			"-A", string(kubeServicesChain),
0000000000000000000000000000000000000000;;			"-m", "comment", "--comment", `"kubernetes service nodeports; NOTE: this must be the last rule in this chain"`,
0000000000000000000000000000000000000000;;			"-m", "addrtype", "--dst-type", "LOCAL",
0000000000000000000000000000000000000000;;			"-j", string(kubeNodePortsChain))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Write the end-of-table markers.
0000000000000000000000000000000000000000;;		writeLine(proxier.filterRules, "COMMIT")
0000000000000000000000000000000000000000;;		writeLine(proxier.natRules, "COMMIT")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Sync rules.
0000000000000000000000000000000000000000;;		// NOTE: NoFlushTables is used so we don't flush non-kubernetes chains in the table
0000000000000000000000000000000000000000;;		proxier.iptablesData.Reset()
0000000000000000000000000000000000000000;;		proxier.iptablesData.Write(proxier.filterChains.Bytes())
0000000000000000000000000000000000000000;;		proxier.iptablesData.Write(proxier.filterRules.Bytes())
0000000000000000000000000000000000000000;;		proxier.iptablesData.Write(proxier.natChains.Bytes())
0000000000000000000000000000000000000000;;		proxier.iptablesData.Write(proxier.natRules.Bytes())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		glog.V(5).Infof("Restoring iptables rules: %s", proxier.iptablesData.Bytes())
0000000000000000000000000000000000000000;;		err = proxier.iptables.RestoreAll(proxier.iptablesData.Bytes(), utiliptables.NoFlushTables, utiliptables.RestoreCounters)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			glog.Errorf("Failed to execute iptables-restore: %v", err)
0000000000000000000000000000000000000000;;			glog.V(2).Infof("Rules:\n%s", proxier.iptablesData.Bytes())
0000000000000000000000000000000000000000;;			// Revert new local ports.
0000000000000000000000000000000000000000;;			revertPorts(replacementPortsMap, proxier.portsMap)
0000000000000000000000000000000000000000;;			return
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Close old local ports and save new ones.
0000000000000000000000000000000000000000;;		for k, v := range proxier.portsMap {
0000000000000000000000000000000000000000;;			if replacementPortsMap[k] == nil {
0000000000000000000000000000000000000000;;				v.Close()
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		proxier.portsMap = replacementPortsMap
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Update healthz timestamp.
0000000000000000000000000000000000000000;;		if proxier.healthzServer != nil {
0000000000000000000000000000000000000000;;			proxier.healthzServer.UpdateTimestamp()
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Update healthchecks.  The endpoints list might include services that are
0000000000000000000000000000000000000000;;		// not "OnlyLocal", but the services list will not, and the healthChecker
0000000000000000000000000000000000000000;;		// will just drop those endpoints.
0000000000000000000000000000000000000000;;		if err := proxier.healthChecker.SyncServices(serviceUpdateResult.hcServices); err != nil {
0000000000000000000000000000000000000000;;			glog.Errorf("Error syncing healtcheck services: %v", err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		if err := proxier.healthChecker.SyncEndpoints(endpointUpdateResult.hcEndpoints); err != nil {
0000000000000000000000000000000000000000;;			glog.Errorf("Error syncing healthcheck endoints: %v", err)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		// Finish housekeeping.
0000000000000000000000000000000000000000;;		// TODO: these and clearUDPConntrackForPort() could be made more consistent.
0000000000000000000000000000000000000000;;		utilproxy.DeleteServiceConnections(proxier.exec, staleServices.List())
0000000000000000000000000000000000000000;;		proxier.deleteEndpointConnections(endpointUpdateResult.staleEndpoints)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Clear UDP conntrack for port or all conntrack entries when port equal zero.
0000000000000000000000000000000000000000;;	// When a packet arrives, it will not go through NAT table again, because it is not "the first" packet.
0000000000000000000000000000000000000000;;	// The solution is clearing the conntrack. Known issus:
0000000000000000000000000000000000000000;;	// https://github.com/docker/docker/issues/8795
0000000000000000000000000000000000000000;;	// https://github.com/kubernetes/kubernetes/issues/31983
0000000000000000000000000000000000000000;;	func (proxier *Proxier) clearUDPConntrackForPort(port int) {
0000000000000000000000000000000000000000;;		glog.V(2).Infof("Deleting conntrack entries for udp connections")
0000000000000000000000000000000000000000;;		if port > 0 {
0000000000000000000000000000000000000000;;			err := utilproxy.ExecConntrackTool(proxier.exec, "-D", "-p", "udp", "--dport", strconv.Itoa(port))
0000000000000000000000000000000000000000;;			if err != nil && !strings.Contains(err.Error(), noConnectionToDelete) {
0000000000000000000000000000000000000000;;				glog.Errorf("conntrack return with error: %v", err)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		} else {
0000000000000000000000000000000000000000;;			glog.Errorf("Wrong port number. The port number must be greater than zero")
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Join all words with spaces, terminate with newline and write to buf.
0000000000000000000000000000000000000000;;	func writeLine(buf *bytes.Buffer, words ...string) {
0000000000000000000000000000000000000000;;		// We avoid strings.Join for performance reasons.
0000000000000000000000000000000000000000;;		for i := range words {
0000000000000000000000000000000000000000;;			buf.WriteString(words[i])
0000000000000000000000000000000000000000;;			if i < len(words)-1 {
0000000000000000000000000000000000000000;;				buf.WriteByte(' ')
0000000000000000000000000000000000000000;;			} else {
0000000000000000000000000000000000000000;;				buf.WriteByte('\n')
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func isLocalIP(ip string) (bool, error) {
0000000000000000000000000000000000000000;;		addrs, err := net.InterfaceAddrs()
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			return false, err
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		for i := range addrs {
0000000000000000000000000000000000000000;;			intf, _, err := net.ParseCIDR(addrs[i].String())
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				return false, err
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			if net.ParseIP(ip).Equal(intf) {
0000000000000000000000000000000000000000;;				return true, nil
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		return false, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	func openLocalPort(lp *localPort) (closeable, error) {
0000000000000000000000000000000000000000;;		// For ports on node IPs, open the actual port and hold it, even though we
0000000000000000000000000000000000000000;;		// use iptables to redirect traffic.
0000000000000000000000000000000000000000;;		// This ensures a) that it's safe to use that port and b) that (a) stays
0000000000000000000000000000000000000000;;		// true.  The risk is that some process on the node (e.g. sshd or kubelet)
0000000000000000000000000000000000000000;;		// is using a port and we give that same port out to a Service.  That would
0000000000000000000000000000000000000000;;		// be bad because iptables would silently claim the traffic but the process
0000000000000000000000000000000000000000;;		// would never know.
0000000000000000000000000000000000000000;;		// NOTE: We should not need to have a real listen()ing socket - bind()
0000000000000000000000000000000000000000;;		// should be enough, but I can't figure out a way to e2e test without
0000000000000000000000000000000000000000;;		// it.  Tools like 'ss' and 'netstat' do not show sockets that are
0000000000000000000000000000000000000000;;		// bind()ed but not listen()ed, and at least the default debian netcat
0000000000000000000000000000000000000000;;		// has no way to avoid about 10 seconds of retries.
0000000000000000000000000000000000000000;;		var socket closeable
0000000000000000000000000000000000000000;;		switch lp.protocol {
0000000000000000000000000000000000000000;;		case "tcp":
0000000000000000000000000000000000000000;;			listener, err := net.Listen("tcp", net.JoinHostPort(lp.ip, strconv.Itoa(lp.port)))
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				return nil, err
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			socket = listener
0000000000000000000000000000000000000000;;		case "udp":
0000000000000000000000000000000000000000;;			addr, err := net.ResolveUDPAddr("udp", net.JoinHostPort(lp.ip, strconv.Itoa(lp.port)))
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				return nil, err
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			conn, err := net.ListenUDP("udp", addr)
0000000000000000000000000000000000000000;;			if err != nil {
0000000000000000000000000000000000000000;;				return nil, err
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			socket = conn
0000000000000000000000000000000000000000;;		default:
0000000000000000000000000000000000000000;;			return nil, fmt.Errorf("unknown protocol %q", lp.protocol)
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		glog.V(2).Infof("Opened local port %s", lp.String())
0000000000000000000000000000000000000000;;		return socket, nil
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// revertPorts is closing ports in replacementPortsMap but not in originalPortsMap. In other words, it only
0000000000000000000000000000000000000000;;	// closes the ports opened in this sync.
0000000000000000000000000000000000000000;;	func revertPorts(replacementPortsMap, originalPortsMap map[localPort]closeable) {
0000000000000000000000000000000000000000;;		for k, v := range replacementPortsMap {
0000000000000000000000000000000000000000;;			// Only close newly opened local ports - leave ones that were open before this update
0000000000000000000000000000000000000000;;			if originalPortsMap[k] == nil {
0000000000000000000000000000000000000000;;				glog.V(2).Infof("Closing local port %s after iptables-restore failure", k.String())
0000000000000000000000000000000000000000;;				v.Close()
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
