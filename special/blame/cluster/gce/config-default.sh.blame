0000000000000000000000000000000000000000;;	#!/bin/bash
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Copyright 2014 The Kubernetes Authors.
0000000000000000000000000000000000000000;;	#
0000000000000000000000000000000000000000;;	# Licensed under the Apache License, Version 2.0 (the "License");
0000000000000000000000000000000000000000;;	# you may not use this file except in compliance with the License.
0000000000000000000000000000000000000000;;	# You may obtain a copy of the License at
0000000000000000000000000000000000000000;;	#
0000000000000000000000000000000000000000;;	#     http://www.apache.org/licenses/LICENSE-2.0
0000000000000000000000000000000000000000;;	#
0000000000000000000000000000000000000000;;	# Unless required by applicable law or agreed to in writing, software
0000000000000000000000000000000000000000;;	# distributed under the License is distributed on an "AS IS" BASIS,
0000000000000000000000000000000000000000;;	# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
0000000000000000000000000000000000000000;;	# See the License for the specific language governing permissions and
0000000000000000000000000000000000000000;;	# limitations under the License.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# TODO(jbeda): Provide a way to override project
0000000000000000000000000000000000000000;;	# gcloud multiplexing for shared GCE/GKE tests.
0000000000000000000000000000000000000000;;	KUBE_ROOT=$(dirname "${BASH_SOURCE}")/../..
0000000000000000000000000000000000000000;;	source "${KUBE_ROOT}/cluster/gce/config-common.sh"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Specifying KUBE_GCE_API_ENDPOINT will override the default GCE Compute API endpoint (https://www.googleapis.com/compute/v1/).
0000000000000000000000000000000000000000;;	# This endpoint has to be pointing to v1 api. For example, https://www.googleapis.com/compute/staging_v1/
0000000000000000000000000000000000000000;;	GCE_API_ENDPOINT=${KUBE_GCE_API_ENDPOINT:-}
0000000000000000000000000000000000000000;;	GCLOUD=gcloud
0000000000000000000000000000000000000000;;	ZONE=${KUBE_GCE_ZONE:-us-central1-b}
0000000000000000000000000000000000000000;;	REGION=${ZONE%-*}
0000000000000000000000000000000000000000;;	RELEASE_REGION_FALLBACK=${RELEASE_REGION_FALLBACK:-false}
0000000000000000000000000000000000000000;;	REGIONAL_KUBE_ADDONS=${REGIONAL_KUBE_ADDONS:-true}
0000000000000000000000000000000000000000;;	NODE_SIZE=${NODE_SIZE:-n1-standard-2}
0000000000000000000000000000000000000000;;	NUM_NODES=${NUM_NODES:-3}
0000000000000000000000000000000000000000;;	MASTER_SIZE=${MASTER_SIZE:-n1-standard-$(get-master-size)}
0000000000000000000000000000000000000000;;	MASTER_DISK_TYPE=pd-ssd
0000000000000000000000000000000000000000;;	MASTER_DISK_SIZE=${MASTER_DISK_SIZE:-20GB}
0000000000000000000000000000000000000000;;	NODE_DISK_TYPE=${NODE_DISK_TYPE:-pd-standard}
0000000000000000000000000000000000000000;;	NODE_DISK_SIZE=${NODE_DISK_SIZE:-100GB}
0000000000000000000000000000000000000000;;	NODE_LOCAL_SSDS=${NODE_LOCAL_SSDS:-0}
0000000000000000000000000000000000000000;;	# Accelerators to be attached to each node. Format "type=<accelerator-type>,count=<accelerator-count>"
0000000000000000000000000000000000000000;;	# More information on available GPUs here - https://cloud.google.com/compute/docs/gpus/
0000000000000000000000000000000000000000;;	NODE_ACCELERATORS=${NODE_ACCELERATORS:-""}
0000000000000000000000000000000000000000;;	REGISTER_MASTER_KUBELET=${REGISTER_MASTER:-true}
0000000000000000000000000000000000000000;;	PREEMPTIBLE_NODE=${PREEMPTIBLE_NODE:-false}
0000000000000000000000000000000000000000;;	PREEMPTIBLE_MASTER=${PREEMPTIBLE_MASTER:-false}
0000000000000000000000000000000000000000;;	KUBE_DELETE_NODES=${KUBE_DELETE_NODES:-true}
0000000000000000000000000000000000000000;;	KUBE_DELETE_NETWORK=${KUBE_DELETE_NETWORK:-false}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	MASTER_OS_DISTRIBUTION=${KUBE_MASTER_OS_DISTRIBUTION:-${KUBE_OS_DISTRIBUTION:-gci}}
0000000000000000000000000000000000000000;;	NODE_OS_DISTRIBUTION=${KUBE_NODE_OS_DISTRIBUTION:-${KUBE_OS_DISTRIBUTION:-gci}}
0000000000000000000000000000000000000000;;	if [[ "${MASTER_OS_DISTRIBUTION}" == "coreos" ]]; then
0000000000000000000000000000000000000000;;	    MASTER_OS_DISTRIBUTION="container-linux"
0000000000000000000000000000000000000000;;	fi
0000000000000000000000000000000000000000;;	if [[ "${NODE_OS_DISTRIBUTION}" == "coreos" ]]; then
0000000000000000000000000000000000000000;;	    NODE_OS_DISTRIBUTION="container-linux"
0000000000000000000000000000000000000000;;	fi
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	if [[ "${MASTER_OS_DISTRIBUTION}" == "cos" ]]; then
0000000000000000000000000000000000000000;;	    MASTER_OS_DISTRIBUTION="gci"
0000000000000000000000000000000000000000;;	fi
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	if [[ "${NODE_OS_DISTRIBUTION}" == "cos" ]]; then
0000000000000000000000000000000000000000;;	    NODE_OS_DISTRIBUTION="gci"
0000000000000000000000000000000000000000;;	fi
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# GPUs supported in GCE do not have compatible drivers in Debian 7.
0000000000000000000000000000000000000000;;	if [[ "${NODE_OS_DISTRIBUTION}" == "debian" ]]; then
0000000000000000000000000000000000000000;;	    NODE_ACCELERATORS=""
0000000000000000000000000000000000000000;;	fi
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# By default a cluster will be started with the master and nodes
0000000000000000000000000000000000000000;;	# on Container-optimized OS (cos, previously known as gci). If
0000000000000000000000000000000000000000;;	# you are updating the os image versions, update this variable.
0000000000000000000000000000000000000000;;	# Also please update corresponding image for node e2e at:
0000000000000000000000000000000000000000;;	# https://github.com/kubernetes/kubernetes/blob/master/test/e2e_node/jenkins/image-config.yaml
0000000000000000000000000000000000000000;;	CVM_VERSION=${CVM_VERSION:-container-vm-v20170627}
0000000000000000000000000000000000000000;;	GCI_VERSION=${KUBE_GCI_VERSION:-cos-stable-59-9460-64-0}
0000000000000000000000000000000000000000;;	MASTER_IMAGE=${KUBE_GCE_MASTER_IMAGE:-}
0000000000000000000000000000000000000000;;	MASTER_IMAGE_PROJECT=${KUBE_GCE_MASTER_PROJECT:-cos-cloud}
0000000000000000000000000000000000000000;;	NODE_IMAGE=${KUBE_GCE_NODE_IMAGE:-${GCI_VERSION}}
0000000000000000000000000000000000000000;;	NODE_IMAGE_PROJECT=${KUBE_GCE_NODE_PROJECT:-cos-cloud}
0000000000000000000000000000000000000000;;	CONTAINER_RUNTIME=${KUBE_CONTAINER_RUNTIME:-docker}
0000000000000000000000000000000000000000;;	RKT_VERSION=${KUBE_RKT_VERSION:-1.23.0}
0000000000000000000000000000000000000000;;	RKT_STAGE1_IMAGE=${KUBE_RKT_STAGE1_IMAGE:-coreos.com/rkt/stage1-coreos}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	NETWORK=${KUBE_GCE_NETWORK:-default}
0000000000000000000000000000000000000000;;	INSTANCE_PREFIX="${KUBE_GCE_INSTANCE_PREFIX:-kubernetes}"
0000000000000000000000000000000000000000;;	CLUSTER_NAME="${CLUSTER_NAME:-${INSTANCE_PREFIX}}"
0000000000000000000000000000000000000000;;	MASTER_NAME="${INSTANCE_PREFIX}-master"
0000000000000000000000000000000000000000;;	AGGREGATOR_MASTER_NAME="${INSTANCE_PREFIX}-aggregator"
0000000000000000000000000000000000000000;;	INITIAL_ETCD_CLUSTER="${MASTER_NAME}"
0000000000000000000000000000000000000000;;	ETCD_QUORUM_READ="${ENABLE_ETCD_QUORUM_READ:-false}"
0000000000000000000000000000000000000000;;	MASTER_TAG="${INSTANCE_PREFIX}-master"
0000000000000000000000000000000000000000;;	NODE_TAG="${INSTANCE_PREFIX}-minion"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	CLUSTER_IP_RANGE="${CLUSTER_IP_RANGE:-10.244.0.0/14}"
0000000000000000000000000000000000000000;;	MASTER_IP_RANGE="${MASTER_IP_RANGE:-10.246.0.0/24}"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	if [[ "${FEDERATION:-}" == true ]]; then
0000000000000000000000000000000000000000;;	    NODE_SCOPES="${NODE_SCOPES:-compute-rw,monitoring,logging-write,storage-ro,https://www.googleapis.com/auth/ndev.clouddns.readwrite}"
0000000000000000000000000000000000000000;;	else
0000000000000000000000000000000000000000;;	    NODE_SCOPES="${NODE_SCOPES:-compute-rw,monitoring,logging-write,storage-ro}"
0000000000000000000000000000000000000000;;	fi
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Extra docker options for nodes.
0000000000000000000000000000000000000000;;	EXTRA_DOCKER_OPTS="${EXTRA_DOCKER_OPTS:-}"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	SERVICE_CLUSTER_IP_RANGE="${SERVICE_CLUSTER_IP_RANGE:-10.0.0.0/16}"  # formerly PORTAL_NET
0000000000000000000000000000000000000000;;	ALLOCATE_NODE_CIDRS=true
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# When set to true, Docker Cache is enabled by default as part of the cluster bring up.
0000000000000000000000000000000000000000;;	ENABLE_DOCKER_REGISTRY_CACHE=true
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Optional: Deploy a L7 loadbalancer controller to fulfill Ingress requests:
0000000000000000000000000000000000000000;;	#   glbc           - CE L7 Load Balancer Controller
0000000000000000000000000000000000000000;;	ENABLE_L7_LOADBALANCING="${KUBE_ENABLE_L7_LOADBALANCING:-glbc}"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Optional: Cluster monitoring to setup as part of the cluster bring up:
0000000000000000000000000000000000000000;;	#   none           - No cluster monitoring setup
0000000000000000000000000000000000000000;;	#   influxdb       - Heapster, InfluxDB, and Grafana
0000000000000000000000000000000000000000;;	#   google         - Heapster, Google Cloud Monitoring, and Google Cloud Logging
0000000000000000000000000000000000000000;;	#   stackdriver    - Heapster, Google Cloud Monitoring (schema container), and Google Cloud Logging
0000000000000000000000000000000000000000;;	#   googleinfluxdb - Enable influxdb and google (except GCM)
0000000000000000000000000000000000000000;;	#   standalone     - Heapster only. Metrics available via Heapster REST API.
0000000000000000000000000000000000000000;;	ENABLE_CLUSTER_MONITORING="${KUBE_ENABLE_CLUSTER_MONITORING:-influxdb}"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# One special node out of NUM_NODES would be created of this type if specified.
0000000000000000000000000000000000000000;;	# Useful for scheduling heapster in large clusters with nodes of small size.
0000000000000000000000000000000000000000;;	HEAPSTER_MACHINE_TYPE="${HEAPSTER_MACHINE_TYPE:-}"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Historically fluentd was a manifest pod and then was migrated to DaemonSet.
0000000000000000000000000000000000000000;;	# To avoid situation during cluster upgrade when there are two instances
0000000000000000000000000000000000000000;;	# of fluentd running on a node, kubelet need to mark node on which
0000000000000000000000000000000000000000;;	# fluentd is not running as a manifest pod with appropriate label.
0000000000000000000000000000000000000000;;	# TODO(piosz): remove this in 1.8
0000000000000000000000000000000000000000;;	NODE_LABELS="${KUBE_NODE_LABELS:-beta.kubernetes.io/fluentd-ds-ready=true}"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# To avoid running Calico on a node that is not configured appropriately,
0000000000000000000000000000000000000000;;	# label each Node so that the DaemonSet can run the Pods only on ready Nodes.
0000000000000000000000000000000000000000;;	if [[ ${NETWORK_POLICY_PROVIDER:-} == "calico" ]]; then
0000000000000000000000000000000000000000;;		NODE_LABELS="${NODE_LABELS},projectcalico.org/ds-ready=true"
0000000000000000000000000000000000000000;;	fi
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Turn the simple metadata proxy on by default.
0000000000000000000000000000000000000000;;	ENABLE_METADATA_PROXY="${ENABLE_METADATA_PROXY:-simple}"
0000000000000000000000000000000000000000;;	if [[ ${ENABLE_METADATA_PROXY} != "false" ]]; then
0000000000000000000000000000000000000000;;	        NODE_LABELS="${NODE_LABELS},beta.kubernetes.io/metadata-proxy-ready=true"
0000000000000000000000000000000000000000;;	fi
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Optional: Enable node logging.
0000000000000000000000000000000000000000;;	ENABLE_NODE_LOGGING="${KUBE_ENABLE_NODE_LOGGING:-true}"
0000000000000000000000000000000000000000;;	LOGGING_DESTINATION="${KUBE_LOGGING_DESTINATION:-gcp}" # options: elasticsearch, gcp
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Optional: When set to true, Elasticsearch and Kibana will be setup as part of the cluster bring up.
0000000000000000000000000000000000000000;;	ENABLE_CLUSTER_LOGGING="${KUBE_ENABLE_CLUSTER_LOGGING:-true}"
0000000000000000000000000000000000000000;;	ELASTICSEARCH_LOGGING_REPLICAS=1
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Optional: Don't require https for registries in our local RFC1918 network
0000000000000000000000000000000000000000;;	if [[ ${KUBE_ENABLE_INSECURE_REGISTRY:-false} == "true" ]]; then
0000000000000000000000000000000000000000;;	  EXTRA_DOCKER_OPTS="${EXTRA_DOCKER_OPTS} --insecure-registry 10.0.0.0/8"
0000000000000000000000000000000000000000;;	fi
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Optional: customize runtime config
0000000000000000000000000000000000000000;;	RUNTIME_CONFIG="${KUBE_RUNTIME_CONFIG:-}"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Optional: set feature gates
0000000000000000000000000000000000000000;;	FEATURE_GATES="${KUBE_FEATURE_GATES:-ExperimentalCriticalPodAnnotation=true}"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	if [[ ! -z "${NODE_ACCELERATORS}" ]]; then
0000000000000000000000000000000000000000;;	    FEATURE_GATES="${FEATURE_GATES},Accelerators=true"
0000000000000000000000000000000000000000;;	fi
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Optional: Install cluster DNS.
0000000000000000000000000000000000000000;;	ENABLE_CLUSTER_DNS="${KUBE_ENABLE_CLUSTER_DNS:-true}"
0000000000000000000000000000000000000000;;	DNS_SERVER_IP="${KUBE_DNS_SERVER_IP:-10.0.0.10}"
0000000000000000000000000000000000000000;;	DNS_DOMAIN="${KUBE_DNS_DOMAIN:-cluster.local}"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Optional: Enable DNS horizontal autoscaler
0000000000000000000000000000000000000000;;	ENABLE_DNS_HORIZONTAL_AUTOSCALER="${KUBE_ENABLE_DNS_HORIZONTAL_AUTOSCALER:-true}"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Optional: Install cluster docker registry.
0000000000000000000000000000000000000000;;	ENABLE_CLUSTER_REGISTRY="${KUBE_ENABLE_CLUSTER_REGISTRY:-false}"
0000000000000000000000000000000000000000;;	CLUSTER_REGISTRY_DISK="${CLUSTER_REGISTRY_PD:-${INSTANCE_PREFIX}-kube-system-kube-registry}"
0000000000000000000000000000000000000000;;	CLUSTER_REGISTRY_DISK_SIZE="${CLUSTER_REGISTRY_DISK_SIZE:-200GB}"
0000000000000000000000000000000000000000;;	CLUSTER_REGISTRY_DISK_TYPE_GCE="${CLUSTER_REGISTRY_DISK_TYPE_GCE:-pd-standard}"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Optional: Install Kubernetes UI
0000000000000000000000000000000000000000;;	ENABLE_CLUSTER_UI="${KUBE_ENABLE_CLUSTER_UI:-true}"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Optional: Install node problem detector.
0000000000000000000000000000000000000000;;	#   none           - Not run node problem detector.
0000000000000000000000000000000000000000;;	#   daemonset      - Run node problem detector as daemonset.
0000000000000000000000000000000000000000;;	#   standalone     - Run node problem detector as standalone system daemon.
0000000000000000000000000000000000000000;;	if [[ "${NODE_OS_DISTRIBUTION}" == "gci" ]]; then
0000000000000000000000000000000000000000;;	  # Enable standalone mode by default for gci.
0000000000000000000000000000000000000000;;	  ENABLE_NODE_PROBLEM_DETECTOR="${KUBE_ENABLE_NODE_PROBLEM_DETECTOR:-standalone}"
0000000000000000000000000000000000000000;;	else
0000000000000000000000000000000000000000;;	  ENABLE_NODE_PROBLEM_DETECTOR="${KUBE_ENABLE_NODE_PROBLEM_DETECTOR:-daemonset}"
0000000000000000000000000000000000000000;;	fi
0000000000000000000000000000000000000000;;	NODE_PROBLEM_DETECTOR_VERSION="${NODE_PROBLEM_DETECTOR_VERSION:-}"
0000000000000000000000000000000000000000;;	NODE_PROBLEM_DETECTOR_TAR_HASH="${NODE_PROBLEM_DETECTOR_TAR_HASH:-}"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Optional: Create autoscaler for cluster's nodes.
0000000000000000000000000000000000000000;;	ENABLE_CLUSTER_AUTOSCALER="${KUBE_ENABLE_CLUSTER_AUTOSCALER:-false}"
0000000000000000000000000000000000000000;;	if [[ "${ENABLE_CLUSTER_AUTOSCALER}" == "true" ]]; then
0000000000000000000000000000000000000000;;	  AUTOSCALER_MIN_NODES="${KUBE_AUTOSCALER_MIN_NODES:-}"
0000000000000000000000000000000000000000;;	  AUTOSCALER_MAX_NODES="${KUBE_AUTOSCALER_MAX_NODES:-}"
0000000000000000000000000000000000000000;;	  AUTOSCALER_ENABLE_SCALE_DOWN="${KUBE_AUTOSCALER_ENABLE_SCALE_DOWN:-true}"
0000000000000000000000000000000000000000;;	  AUTOSCALER_EXPANDER_CONFIG="${KUBE_AUTOSCALER_EXPANDER_CONFIG:---expander=price}"
0000000000000000000000000000000000000000;;	fi
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Optional: Enable Rescheduler
0000000000000000000000000000000000000000;;	ENABLE_RESCHEDULER="${KUBE_ENABLE_RESCHEDULER:-true}"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Optional: Enable allocation of pod IPs using IP aliases.
0000000000000000000000000000000000000000;;	#
0000000000000000000000000000000000000000;;	# BETA FEATURE.
0000000000000000000000000000000000000000;;	#
0000000000000000000000000000000000000000;;	# IP_ALIAS_SIZE is the size of the podCIDR allocated to a node.
0000000000000000000000000000000000000000;;	# IP_ALIAS_SUBNETWORK is the subnetwork to allocate from. If empty, a
0000000000000000000000000000000000000000;;	#   new subnetwork will be created for the cluster.
0000000000000000000000000000000000000000;;	ENABLE_IP_ALIASES=${KUBE_GCE_ENABLE_IP_ALIASES:-false}
0000000000000000000000000000000000000000;;	if [ ${ENABLE_IP_ALIASES} = true ]; then
0000000000000000000000000000000000000000;;	  # Size of ranges allocated to each node. Currently supports only /32 and /24.
0000000000000000000000000000000000000000;;	  IP_ALIAS_SIZE=${KUBE_GCE_IP_ALIAS_SIZE:-/24}
0000000000000000000000000000000000000000;;	  IP_ALIAS_SUBNETWORK=${KUBE_GCE_IP_ALIAS_SUBNETWORK:-${INSTANCE_PREFIX}-subnet-default}
0000000000000000000000000000000000000000;;	  # Reserve the services IP space to avoid being allocated for other GCP resources.
0000000000000000000000000000000000000000;;	  SERVICE_CLUSTER_IP_SUBNETWORK=${KUBE_GCE_SERVICE_CLUSTER_IP_SUBNETWORK:-${INSTANCE_PREFIX}-subnet-services}
0000000000000000000000000000000000000000;;	  # NODE_IP_RANGE is used when ENABLE_IP_ALIASES=true. It is the primary range in
0000000000000000000000000000000000000000;;	  # the subnet and is the range used for node instance IPs.
0000000000000000000000000000000000000000;;	  NODE_IP_RANGE="$(get-node-ip-range)"
0000000000000000000000000000000000000000;;	  # Add to the provider custom variables.
0000000000000000000000000000000000000000;;	  PROVIDER_VARS="${PROVIDER_VARS} ENABLE_IP_ALIASES"
0000000000000000000000000000000000000000;;	fi
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Admission Controllers to invoke prior to persisting objects in cluster
0000000000000000000000000000000000000000;;	# If we included ResourceQuota, we should keep it at the end of the list to prevent incrementing quota usage prematurely.
0000000000000000000000000000000000000000;;	ADMISSION_CONTROL=Initializers,NamespaceLifecycle,LimitRanger,ServiceAccount,PersistentVolumeLabel,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,ResourceQuota
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Optional: if set to true kube-up will automatically check for existing resources and clean them up.
0000000000000000000000000000000000000000;;	KUBE_UP_AUTOMATIC_CLEANUP=${KUBE_UP_AUTOMATIC_CLEANUP:-false}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Storage backend. 'etcd2' supported, 'etcd3' experimental.
0000000000000000000000000000000000000000;;	STORAGE_BACKEND=${STORAGE_BACKEND:-}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Networking plugin specific settings.
0000000000000000000000000000000000000000;;	NETWORK_PROVIDER="${NETWORK_PROVIDER:-kubenet}" # none, opencontrail, kubenet
0000000000000000000000000000000000000000;;	OPENCONTRAIL_TAG="${OPENCONTRAIL_TAG:-R2.20}"
0000000000000000000000000000000000000000;;	OPENCONTRAIL_KUBERNETES_TAG="${OPENCONTRAIL_KUBERNETES_TAG:-master}"
0000000000000000000000000000000000000000;;	OPENCONTRAIL_PUBLIC_SUBNET="${OPENCONTRAIL_PUBLIC_SUBNET:-10.1.0.0/16}"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Network Policy plugin specific settings.
0000000000000000000000000000000000000000;;	NETWORK_POLICY_PROVIDER="${NETWORK_POLICY_PROVIDER:-none}" # calico
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# How should the kubelet configure hairpin mode?
0000000000000000000000000000000000000000;;	HAIRPIN_MODE="${HAIRPIN_MODE:-promiscuous-bridge}" # promiscuous-bridge, hairpin-veth, none
0000000000000000000000000000000000000000;;	# Optional: if set to true, kube-up will configure the cluster to run e2e tests.
0000000000000000000000000000000000000000;;	E2E_STORAGE_TEST_ENVIRONMENT="${KUBE_E2E_STORAGE_TEST_ENVIRONMENT:-false}"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Evict pods whenever compute resource availability on the nodes gets below a threshold.
0000000000000000000000000000000000000000;;	EVICTION_HARD="${EVICTION_HARD:-memory.available<250Mi,nodefs.available<10%,nodefs.inodesFree<5%}"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Optional: custom scheduling algorithm
0000000000000000000000000000000000000000;;	SCHEDULING_ALGORITHM_PROVIDER="${SCHEDULING_ALGORITHM_PROVIDER:-}"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Optional: install a default StorageClass
0000000000000000000000000000000000000000;;	ENABLE_DEFAULT_STORAGE_CLASS="${ENABLE_DEFAULT_STORAGE_CLASS:-true}"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Optional: Enable legacy ABAC policy that makes all service accounts superusers.
0000000000000000000000000000000000000000;;	ENABLE_LEGACY_ABAC="${ENABLE_LEGACY_ABAC:-true}" # true, false
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# TODO(dawn1107): Remove this once the flag is built into CVM image.
0000000000000000000000000000000000000000;;	# Kernel panic upon soft lockup issue
0000000000000000000000000000000000000000;;	SOFTLOCKUP_PANIC="${SOFTLOCKUP_PANIC:-false}" # true, false
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Indicates if the values (i.e. KUBE_USER and KUBE_PASSWORD for basic
0000000000000000000000000000000000000000;;	# authentication) in metadata should be treated as canonical, and therefore disk
0000000000000000000000000000000000000000;;	# copies ought to be recreated/clobbered.
0000000000000000000000000000000000000000;;	METADATA_CLOBBERS_CONFIG="${METADATA_CLOBBERS_CONFIG:-false}"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	ENABLE_BIG_CLUSTER_SUBNETS="${ENABLE_BIG_CLUSTER_SUBNETS:-false}"
