0000000000000000000000000000000000000000;;	#!/bin/bash
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Copyright 2016 The Kubernetes Authors.
0000000000000000000000000000000000000000;;	#
0000000000000000000000000000000000000000;;	# Licensed under the Apache License, Version 2.0 (the "License");
0000000000000000000000000000000000000000;;	# you may not use this file except in compliance with the License.
0000000000000000000000000000000000000000;;	# You may obtain a copy of the License at
0000000000000000000000000000000000000000;;	#
0000000000000000000000000000000000000000;;	#     http://www.apache.org/licenses/LICENSE-2.0
0000000000000000000000000000000000000000;;	#
0000000000000000000000000000000000000000;;	# Unless required by applicable law or agreed to in writing, software
0000000000000000000000000000000000000000;;	# distributed under the License is distributed on an "AS IS" BASIS,
0000000000000000000000000000000000000000;;	# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
0000000000000000000000000000000000000000;;	# See the License for the specific language governing permissions and
0000000000000000000000000000000000000000;;	# limitations under the License.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# This script is for configuring kubernetes master and node instances. It is
0000000000000000000000000000000000000000;;	# uploaded in the manifests tar ball.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# TODO: this script duplicates templating logic from cluster/saltbase/salt
0000000000000000000000000000000000000000;;	# using sed. It should use an actual template parser on the manifest
0000000000000000000000000000000000000000;;	# files.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	set -o errexit
0000000000000000000000000000000000000000;;	set -o nounset
0000000000000000000000000000000000000000;;	set -o pipefail
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	function setup-os-params {
0000000000000000000000000000000000000000;;	  # Reset core_pattern. On GCI, the default core_pattern pipes the core dumps to
0000000000000000000000000000000000000000;;	  # /sbin/crash_reporter which is more restrictive in saving crash dumps. So for
0000000000000000000000000000000000000000;;	  # now, set a generic core_pattern that users can work with.
0000000000000000000000000000000000000000;;	  echo "core.%e.%p.%t" > /proc/sys/kernel/core_pattern
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Vars assumed:
0000000000000000000000000000000000000000;;	#   NUM_NODES
0000000000000000000000000000000000000000;;	function get-calico-node-cpu {
0000000000000000000000000000000000000000;;	  local suggested_calico_cpus=100m
0000000000000000000000000000000000000000;;	  if [[ "${NUM_NODES}" -gt "10" ]]; then
0000000000000000000000000000000000000000;;	    suggested_calico_cpus=250m
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ "${NUM_NODES}" -gt "100" ]]; then
0000000000000000000000000000000000000000;;	    suggested_calico_cpus=500m
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ "${NUM_NODES}" -gt "500" ]]; then
0000000000000000000000000000000000000000;;	    suggested_calico_cpus=1000m
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  echo "${suggested_calico_cpus}"
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Vars assumed:
0000000000000000000000000000000000000000;;	#    NUM_NODES
0000000000000000000000000000000000000000;;	function get-calico-typha-replicas {
0000000000000000000000000000000000000000;;	  local typha_count=1
0000000000000000000000000000000000000000;;	  if [[ "${NUM_NODES}" -gt "10" ]]; then
0000000000000000000000000000000000000000;;	    typha_count=2
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ "${NUM_NODES}" -gt "100" ]]; then
0000000000000000000000000000000000000000;;	    typha_count=3
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ "${NUM_NODES}" -gt "250" ]]; then
0000000000000000000000000000000000000000;;	    typha_count=4
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ "${NUM_NODES}" -gt "500" ]]; then
0000000000000000000000000000000000000000;;	    typha_count=5
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  echo "${typha_count}"
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Vars assumed:
0000000000000000000000000000000000000000;;	#    NUM_NODES
0000000000000000000000000000000000000000;;	function get-calico-typha-cpu {
0000000000000000000000000000000000000000;;	  local typha_cpu=200m
0000000000000000000000000000000000000000;;	  if [[ "${NUM_NODES}" -gt "10" ]]; then
0000000000000000000000000000000000000000;;	    typha_cpu=500m
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ "${NUM_NODES}" -gt "100" ]]; then
0000000000000000000000000000000000000000;;	    typha_cpu=1000m
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  echo "${typha_cpu}"
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	function config-ip-firewall {
0000000000000000000000000000000000000000;;	  echo "Configuring IP firewall rules"
0000000000000000000000000000000000000000;;	  # The GCI image has host firewall which drop most inbound/forwarded packets.
0000000000000000000000000000000000000000;;	  # We need to add rules to accept all TCP/UDP/ICMP packets.
0000000000000000000000000000000000000000;;	  if iptables -L INPUT | grep "Chain INPUT (policy DROP)" > /dev/null; then
0000000000000000000000000000000000000000;;	    echo "Add rules to accept all inbound TCP/UDP/ICMP packets"
0000000000000000000000000000000000000000;;	    iptables -A INPUT -w -p TCP -j ACCEPT
0000000000000000000000000000000000000000;;	    iptables -A INPUT -w -p UDP -j ACCEPT
0000000000000000000000000000000000000000;;	    iptables -A INPUT -w -p ICMP -j ACCEPT
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if iptables -L FORWARD | grep "Chain FORWARD (policy DROP)" > /dev/null; then
0000000000000000000000000000000000000000;;	    echo "Add rules to accept all forwarded TCP/UDP/ICMP packets"
0000000000000000000000000000000000000000;;	    iptables -A FORWARD -w -p TCP -j ACCEPT
0000000000000000000000000000000000000000;;	    iptables -A FORWARD -w -p UDP -j ACCEPT
0000000000000000000000000000000000000000;;	    iptables -A FORWARD -w -p ICMP -j ACCEPT
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  iptables -N KUBE-METADATA-SERVER
0000000000000000000000000000000000000000;;	  iptables -I FORWARD -p tcp -d 169.254.169.254 --dport 80 -j KUBE-METADATA-SERVER
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  if [[ -n "${KUBE_FIREWALL_METADATA_SERVER:-}" ]]; then
0000000000000000000000000000000000000000;;	    iptables -A KUBE-METADATA-SERVER -j DROP
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	function create-dirs {
0000000000000000000000000000000000000000;;	  echo "Creating required directories"
0000000000000000000000000000000000000000;;	  mkdir -p /var/lib/kubelet
0000000000000000000000000000000000000000;;	  mkdir -p /etc/kubernetes/manifests
0000000000000000000000000000000000000000;;	  if [[ "${KUBERNETES_MASTER:-}" == "false" ]]; then
0000000000000000000000000000000000000000;;	    mkdir -p /var/lib/kube-proxy
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Formats the given device ($1) if needed and mounts it at given mount point
0000000000000000000000000000000000000000;;	# ($2).
0000000000000000000000000000000000000000;;	function safe-format-and-mount() {
0000000000000000000000000000000000000000;;	  device=$1
0000000000000000000000000000000000000000;;	  mountpoint=$2
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  # Format only if the disk is not already formatted.
0000000000000000000000000000000000000000;;	  if ! tune2fs -l "${device}" ; then
0000000000000000000000000000000000000000;;	    echo "Formatting '${device}'"
0000000000000000000000000000000000000000;;	    mkfs.ext4 -F "${device}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  mkdir -p "${mountpoint}"
0000000000000000000000000000000000000000;;	  echo "Mounting '${device}' at '${mountpoint}'"
0000000000000000000000000000000000000000;;	  mount -o discard,defaults "${device}" "${mountpoint}"
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Local ssds, if present, are mounted at /mnt/disks/ssdN.
0000000000000000000000000000000000000000;;	function ensure-local-ssds() {
0000000000000000000000000000000000000000;;	  for ssd in /dev/disk/by-id/google-local-ssd-*; do
0000000000000000000000000000000000000000;;	    if [ -e "${ssd}" ]; then
0000000000000000000000000000000000000000;;	      ssdnum=`echo ${ssd} | sed -e 's/\/dev\/disk\/by-id\/google-local-ssd-\([0-9]*\)/\1/'`
0000000000000000000000000000000000000000;;	      ssdmount="/mnt/disks/ssd${ssdnum}/"
0000000000000000000000000000000000000000;;	      mkdir -p ${ssdmount}
0000000000000000000000000000000000000000;;	      safe-format-and-mount "${ssd}" ${ssdmount}
0000000000000000000000000000000000000000;;	      echo "Mounted local SSD $ssd at ${ssdmount}"
0000000000000000000000000000000000000000;;	      chmod a+w ${ssdmount}
0000000000000000000000000000000000000000;;	    else
0000000000000000000000000000000000000000;;	      echo "No local SSD disks found."
0000000000000000000000000000000000000000;;	    fi
0000000000000000000000000000000000000000;;	  done
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Installs logrotate configuration files
0000000000000000000000000000000000000000;;	function setup-logrotate() {
0000000000000000000000000000000000000000;;	  mkdir -p /etc/logrotate.d/
0000000000000000000000000000000000000000;;	  # Configure log rotation for all logs in /var/log, which is where k8s services
0000000000000000000000000000000000000000;;	  # are configured to write their log files. Whenever logrotate is ran, this
0000000000000000000000000000000000000000;;	  # config will:
0000000000000000000000000000000000000000;;	  # * rotate the log file if its size is > 100Mb OR if one day has elapsed
0000000000000000000000000000000000000000;;	  # * save rotated logs into a gzipped timestamped backup
0000000000000000000000000000000000000000;;	  # * log file timestamp (controlled by 'dateformat') includes seconds too. This
0000000000000000000000000000000000000000;;	  #   ensures that logrotate can generate unique logfiles during each rotation
0000000000000000000000000000000000000000;;	  #   (otherwise it skips rotation if 'maxsize' is reached multiple times in a
0000000000000000000000000000000000000000;;	  #   day).
0000000000000000000000000000000000000000;;	  # * keep only 5 old (rotated) logs, and will discard older logs.
0000000000000000000000000000000000000000;;	  cat > /etc/logrotate.d/allvarlogs <<EOF
0000000000000000000000000000000000000000;;	/var/log/*.log {
0000000000000000000000000000000000000000;;	    rotate 5
0000000000000000000000000000000000000000;;	    copytruncate
0000000000000000000000000000000000000000;;	    missingok
0000000000000000000000000000000000000000;;	    notifempty
0000000000000000000000000000000000000000;;	    compress
0000000000000000000000000000000000000000;;	    maxsize 100M
0000000000000000000000000000000000000000;;	    daily
0000000000000000000000000000000000000000;;	    dateext
0000000000000000000000000000000000000000;;	    dateformat -%Y%m%d-%s
0000000000000000000000000000000000000000;;	    create 0644 root root
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	EOF
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Finds the master PD device; returns it in MASTER_PD_DEVICE
0000000000000000000000000000000000000000;;	function find-master-pd {
0000000000000000000000000000000000000000;;	  MASTER_PD_DEVICE=""
0000000000000000000000000000000000000000;;	  if [[ ! -e /dev/disk/by-id/google-master-pd ]]; then
0000000000000000000000000000000000000000;;	    return
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  device_info=$(ls -l /dev/disk/by-id/google-master-pd)
0000000000000000000000000000000000000000;;	  relative_path=${device_info##* }
0000000000000000000000000000000000000000;;	  MASTER_PD_DEVICE="/dev/disk/by-id/${relative_path}"
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Mounts a persistent disk (formatting if needed) to store the persistent data
0000000000000000000000000000000000000000;;	# on the master -- etcd's data, a few settings, and security certs/keys/tokens.
0000000000000000000000000000000000000000;;	# safe-format-and-mount only formats an unformatted disk, and mkdir -p will
0000000000000000000000000000000000000000;;	# leave a directory be if it already exists.
0000000000000000000000000000000000000000;;	function mount-master-pd {
0000000000000000000000000000000000000000;;	  find-master-pd
0000000000000000000000000000000000000000;;	  if [[ -z "${MASTER_PD_DEVICE:-}" ]]; then
0000000000000000000000000000000000000000;;	    return
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  echo "Mounting master-pd"
0000000000000000000000000000000000000000;;	  local -r pd_path="/dev/disk/by-id/google-master-pd"
0000000000000000000000000000000000000000;;	  local -r mount_point="/mnt/disks/master-pd"
0000000000000000000000000000000000000000;;	  # Format and mount the disk, create directories on it for all of the master's
0000000000000000000000000000000000000000;;	  # persistent data, and link them to where they're used.
0000000000000000000000000000000000000000;;	  mkdir -p "${mount_point}"
0000000000000000000000000000000000000000;;	  safe-format-and-mount "${pd_path}" "${mount_point}"
0000000000000000000000000000000000000000;;	  echo "Mounted master-pd '${pd_path}' at '${mount_point}'"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  # NOTE: These locations on the PD store persistent data, so to maintain
0000000000000000000000000000000000000000;;	  # upgradeability, these locations should not change.  If they do, take care
0000000000000000000000000000000000000000;;	  # to maintain a migration path from these locations to whatever new
0000000000000000000000000000000000000000;;	  # locations.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  # Contains all the data stored in etcd.
0000000000000000000000000000000000000000;;	  mkdir -m 700 -p "${mount_point}/var/etcd"
0000000000000000000000000000000000000000;;	  ln -s -f "${mount_point}/var/etcd" /var/etcd
0000000000000000000000000000000000000000;;	  mkdir -p /etc/srv
0000000000000000000000000000000000000000;;	  # Contains the dynamically generated apiserver auth certs and keys.
0000000000000000000000000000000000000000;;	  mkdir -p "${mount_point}/srv/kubernetes"
0000000000000000000000000000000000000000;;	  ln -s -f "${mount_point}/srv/kubernetes" /etc/srv/kubernetes
0000000000000000000000000000000000000000;;	  # Directory for kube-apiserver to store SSH key (if necessary).
0000000000000000000000000000000000000000;;	  mkdir -p "${mount_point}/srv/sshproxy"
0000000000000000000000000000000000000000;;	  ln -s -f "${mount_point}/srv/sshproxy" /etc/srv/sshproxy
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  if ! id etcd &>/dev/null; then
0000000000000000000000000000000000000000;;	    useradd -s /sbin/nologin -d /var/etcd etcd
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  chown -R etcd "${mount_point}/var/etcd"
0000000000000000000000000000000000000000;;	  chgrp -R etcd "${mount_point}/var/etcd"
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# append_or_replace_prefixed_line ensures:
0000000000000000000000000000000000000000;;	# 1. the specified file exists
0000000000000000000000000000000000000000;;	# 2. existing lines with the specified ${prefix} are removed
0000000000000000000000000000000000000000;;	# 3. a new line with the specified ${prefix}${suffix} is appended
0000000000000000000000000000000000000000;;	function append_or_replace_prefixed_line {
0000000000000000000000000000000000000000;;	  local -r file="${1:-}"
0000000000000000000000000000000000000000;;	  local -r prefix="${2:-}"
0000000000000000000000000000000000000000;;	  local -r suffix="${3:-}"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  touch "${file}"
0000000000000000000000000000000000000000;;	  awk "substr(\$0,0,length(\"${prefix}\")) != \"${prefix}\" { print }" "${file}" > "${file}.filtered"  && mv "${file}.filtered" "${file}"
0000000000000000000000000000000000000000;;	  echo "${prefix}${suffix}" >> "${file}"
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	function create-node-pki {
0000000000000000000000000000000000000000;;	  echo "Creating node pki files"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  local -r pki_dir="/etc/srv/kubernetes/pki"
0000000000000000000000000000000000000000;;	  mkdir -p "${pki_dir}"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  if [[ -z "${CA_CERT_BUNDLE:-}" ]]; then
0000000000000000000000000000000000000000;;	    CA_CERT_BUNDLE="${CA_CERT}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  CA_CERT_BUNDLE_PATH="${pki_dir}/ca-certificates.crt"
0000000000000000000000000000000000000000;;	  echo "${CA_CERT_BUNDLE}" | base64 --decode > "${CA_CERT_BUNDLE_PATH}"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  if [[ ! -z "${KUBELET_CERT:-}" && ! -z "${KUBELET_KEY:-}" ]]; then
0000000000000000000000000000000000000000;;	    KUBELET_CERT_PATH="${pki_dir}/kubelet.crt"
0000000000000000000000000000000000000000;;	    echo "${KUBELET_CERT}" | base64 --decode > "${KUBELET_CERT_PATH}"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	    KUBELET_KEY_PATH="${pki_dir}/kubelet.key"
0000000000000000000000000000000000000000;;	    echo "${KUBELET_KEY}" | base64 --decode > "${KUBELET_KEY_PATH}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  # TODO(mikedanese): remove this when we don't support downgrading to versions
0000000000000000000000000000000000000000;;	  # < 1.6.
0000000000000000000000000000000000000000;;	  ln -sf "${CA_CERT_BUNDLE_PATH}" /etc/srv/kubernetes/ca.crt
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	function create-master-pki {
0000000000000000000000000000000000000000;;	  echo "Creating master pki files"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  local -r pki_dir="/etc/srv/kubernetes/pki"
0000000000000000000000000000000000000000;;	  mkdir -p "${pki_dir}"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  CA_CERT_PATH="${pki_dir}/ca.crt"
0000000000000000000000000000000000000000;;	  echo "${CA_CERT}" | base64 --decode > "${CA_CERT_PATH}"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  # this is not true on GKE
0000000000000000000000000000000000000000;;	  if [[ ! -z "${CA_KEY:-}" ]]; then
0000000000000000000000000000000000000000;;	    CA_KEY_PATH="${pki_dir}/ca.key"
0000000000000000000000000000000000000000;;	    echo "${CA_KEY}" | base64 --decode > "${CA_KEY_PATH}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  if [[ -z "${APISERVER_SERVER_CERT:-}" || -z "${APISERVER_SERVER_KEY:-}" ]]; then
0000000000000000000000000000000000000000;;	    APISERVER_SERVER_CERT="${MASTER_CERT}"
0000000000000000000000000000000000000000;;	    APISERVER_SERVER_KEY="${MASTER_KEY}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  APISERVER_SERVER_CERT_PATH="${pki_dir}/apiserver.crt"
0000000000000000000000000000000000000000;;	  echo "${APISERVER_SERVER_CERT}" | base64 --decode > "${APISERVER_SERVER_CERT_PATH}"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  APISERVER_SERVER_KEY_PATH="${pki_dir}/apiserver.key"
0000000000000000000000000000000000000000;;	  echo "${APISERVER_SERVER_KEY}" | base64 --decode > "${APISERVER_SERVER_KEY_PATH}"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  if [[ -z "${APISERVER_CLIENT_CERT:-}" || -z "${APISERVER_CLIENT_KEY:-}" ]]; then
0000000000000000000000000000000000000000;;	    APISERVER_CLIENT_CERT="${KUBEAPISERVER_CERT}"
0000000000000000000000000000000000000000;;	    APISERVER_CLIENT_KEY="${KUBEAPISERVER_KEY}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  APISERVER_CLIENT_CERT_PATH="${pki_dir}/apiserver-client.crt"
0000000000000000000000000000000000000000;;	  echo "${APISERVER_CLIENT_CERT}" | base64 --decode > "${APISERVER_CLIENT_CERT_PATH}"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  APISERVER_CLIENT_KEY_PATH="${pki_dir}/apiserver-client.key"
0000000000000000000000000000000000000000;;	  echo "${APISERVER_CLIENT_KEY}" | base64 --decode > "${APISERVER_CLIENT_KEY_PATH}"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  if [[ -z "${SERVICEACCOUNT_CERT:-}" || -z "${SERVICEACCOUNT_KEY:-}" ]]; then
0000000000000000000000000000000000000000;;	    SERVICEACCOUNT_CERT="${MASTER_CERT}"
0000000000000000000000000000000000000000;;	    SERVICEACCOUNT_KEY="${MASTER_KEY}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  SERVICEACCOUNT_CERT_PATH="${pki_dir}/serviceaccount.crt"
0000000000000000000000000000000000000000;;	  echo "${SERVICEACCOUNT_CERT}" | base64 --decode > "${SERVICEACCOUNT_CERT_PATH}"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  SERVICEACCOUNT_KEY_PATH="${pki_dir}/serviceaccount.key"
0000000000000000000000000000000000000000;;	  echo "${SERVICEACCOUNT_KEY}" | base64 --decode > "${SERVICEACCOUNT_KEY_PATH}"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  # TODO(mikedanese): remove this when we don't support downgrading to versions
0000000000000000000000000000000000000000;;	  # < 1.6.
0000000000000000000000000000000000000000;;	  ln -sf "${APISERVER_SERVER_KEY_PATH}" /etc/srv/kubernetes/server.key
0000000000000000000000000000000000000000;;	  ln -sf "${APISERVER_SERVER_CERT_PATH}" /etc/srv/kubernetes/server.cert
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  AGGREGATOR_CA_KEY_PATH="${pki_dir}/aggr_ca.key"
0000000000000000000000000000000000000000;;	  echo "${AGGREGATOR_CA_KEY:-}" | base64 --decode > "${AGGREGATOR_CA_KEY_PATH}"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  REQUESTHEADER_CA_CERT_PATH="${pki_dir}/aggr_ca.crt"
0000000000000000000000000000000000000000;;	  echo "${REQUESTHEADER_CA_CERT:-}" | base64 --decode > "${REQUESTHEADER_CA_CERT_PATH}"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  PROXY_CLIENT_KEY_PATH="${pki_dir}/proxy_client.key"
0000000000000000000000000000000000000000;;	  echo "${PROXY_CLIENT_KEY:-}" | base64 --decode > "${PROXY_CLIENT_KEY_PATH}"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  PROXY_CLIENT_CERT_PATH="${pki_dir}/proxy_client.crt"
0000000000000000000000000000000000000000;;	  echo "${PROXY_CLIENT_CERT:-}" | base64 --decode > "${PROXY_CLIENT_CERT_PATH}"
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# After the first boot and on upgrade, these files exist on the master-pd
0000000000000000000000000000000000000000;;	# and should never be touched again (except perhaps an additional service
0000000000000000000000000000000000000000;;	# account, see NB below.) One exception is if METADATA_CLOBBERS_CONFIG is
0000000000000000000000000000000000000000;;	# enabled. In that case the basic_auth.csv file will be rewritten to make
0000000000000000000000000000000000000000;;	# sure it matches the metadata source of truth.
0000000000000000000000000000000000000000;;	function create-master-auth {
0000000000000000000000000000000000000000;;	  echo "Creating master auth files"
0000000000000000000000000000000000000000;;	  local -r auth_dir="/etc/srv/kubernetes"
0000000000000000000000000000000000000000;;	  local -r basic_auth_csv="${auth_dir}/basic_auth.csv"
0000000000000000000000000000000000000000;;	  if [[ -n "${KUBE_PASSWORD:-}" && -n "${KUBE_USER:-}" ]]; then
0000000000000000000000000000000000000000;;	    if [[ -e "${basic_auth_csv}" && "${METADATA_CLOBBERS_CONFIG:-false}" == "true" ]]; then
0000000000000000000000000000000000000000;;	      # If METADATA_CLOBBERS_CONFIG is true, we want to rewrite the file
0000000000000000000000000000000000000000;;	      # completely, because if we're changing KUBE_USER and KUBE_PASSWORD, we
0000000000000000000000000000000000000000;;	      # have nothing to match on.  The file is replaced just below with
0000000000000000000000000000000000000000;;	      # append_or_replace_prefixed_line.
0000000000000000000000000000000000000000;;	      rm "${basic_auth_csv}"
0000000000000000000000000000000000000000;;	    fi
0000000000000000000000000000000000000000;;	    append_or_replace_prefixed_line "${basic_auth_csv}" "${KUBE_PASSWORD},${KUBE_USER},"      "admin,system:masters"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  local -r known_tokens_csv="${auth_dir}/known_tokens.csv"
0000000000000000000000000000000000000000;;	  if [[ -n "${KUBE_BEARER_TOKEN:-}" ]]; then
0000000000000000000000000000000000000000;;	    append_or_replace_prefixed_line "${known_tokens_csv}" "${KUBE_BEARER_TOKEN},"             "admin,admin,system:masters"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ -n "${KUBE_CONTROLLER_MANAGER_TOKEN:-}" ]]; then
0000000000000000000000000000000000000000;;	    append_or_replace_prefixed_line "${known_tokens_csv}" "${KUBE_CONTROLLER_MANAGER_TOKEN}," "system:kube-controller-manager,uid:system:kube-controller-manager"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ -n "${KUBE_SCHEDULER_TOKEN:-}" ]]; then
0000000000000000000000000000000000000000;;	    append_or_replace_prefixed_line "${known_tokens_csv}" "${KUBE_SCHEDULER_TOKEN},"          "system:kube-scheduler,uid:system:kube-scheduler"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ -n "${KUBELET_TOKEN:-}" ]]; then
0000000000000000000000000000000000000000;;	    append_or_replace_prefixed_line "${known_tokens_csv}" "${KUBELET_TOKEN},"                 "kubelet,uid:kubelet,system:nodes"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ -n "${KUBE_PROXY_TOKEN:-}" ]]; then
0000000000000000000000000000000000000000;;	    append_or_replace_prefixed_line "${known_tokens_csv}" "${KUBE_PROXY_TOKEN},"              "system:kube-proxy,uid:kube_proxy"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ -n "${NODE_PROBLEM_DETECTOR_TOKEN:-}" ]]; then
0000000000000000000000000000000000000000;;	    append_or_replace_prefixed_line "${known_tokens_csv}" "${NODE_PROBLEM_DETECTOR_TOKEN},"   "system:node-problem-detector,uid:node-problem-detector"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  local use_cloud_config="false"
0000000000000000000000000000000000000000;;	  cat <<EOF >/etc/gce.conf
0000000000000000000000000000000000000000;;	[global]
0000000000000000000000000000000000000000;;	EOF
0000000000000000000000000000000000000000;;	  if [[ -n "${GCE_API_ENDPOINT:-}" ]]; then
0000000000000000000000000000000000000000;;	    cat <<EOF >>/etc/gce.conf
0000000000000000000000000000000000000000;;	api-endpoint = ${GCE_API_ENDPOINT}
0000000000000000000000000000000000000000;;	EOF
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ -n "${PROJECT_ID:-}" && -n "${TOKEN_URL:-}" && -n "${TOKEN_BODY:-}" && -n "${NODE_NETWORK:-}" ]]; then
0000000000000000000000000000000000000000;;	    use_cloud_config="true"
0000000000000000000000000000000000000000;;	    cat <<EOF >>/etc/gce.conf
0000000000000000000000000000000000000000;;	token-url = ${TOKEN_URL}
0000000000000000000000000000000000000000;;	token-body = ${TOKEN_BODY}
0000000000000000000000000000000000000000;;	project-id = ${PROJECT_ID}
0000000000000000000000000000000000000000;;	network-name = ${NODE_NETWORK}
0000000000000000000000000000000000000000;;	EOF
0000000000000000000000000000000000000000;;	    if [[ -n "${NETWORK_PROJECT_ID:-}" ]]; then
0000000000000000000000000000000000000000;;	        cat <<EOF >>/etc/gce.conf
0000000000000000000000000000000000000000;;	network-project-id = ${NETWORK_PROJECT_ID}
0000000000000000000000000000000000000000;;	EOF
0000000000000000000000000000000000000000;;	    fi
0000000000000000000000000000000000000000;;	    if [[ -n "${NODE_SUBNETWORK:-}" ]]; then
0000000000000000000000000000000000000000;;	      cat <<EOF >>/etc/gce.conf
0000000000000000000000000000000000000000;;	subnetwork-name = ${NODE_SUBNETWORK}
0000000000000000000000000000000000000000;;	EOF
0000000000000000000000000000000000000000;;	    fi
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ -n "${NODE_INSTANCE_PREFIX:-}" ]]; then
0000000000000000000000000000000000000000;;	    use_cloud_config="true"
0000000000000000000000000000000000000000;;	    if [[ -n "${NODE_TAGS:-}" ]]; then
0000000000000000000000000000000000000000;;	      local -r node_tags="${NODE_TAGS}"
0000000000000000000000000000000000000000;;	    else
0000000000000000000000000000000000000000;;	      local -r node_tags="${NODE_INSTANCE_PREFIX}"
0000000000000000000000000000000000000000;;	    fi
0000000000000000000000000000000000000000;;	    cat <<EOF >>/etc/gce.conf
0000000000000000000000000000000000000000;;	node-tags = ${node_tags}
0000000000000000000000000000000000000000;;	node-instance-prefix = ${NODE_INSTANCE_PREFIX}
0000000000000000000000000000000000000000;;	EOF
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ -n "${MULTIZONE:-}" ]]; then
0000000000000000000000000000000000000000;;	    use_cloud_config="true"
0000000000000000000000000000000000000000;;	    cat <<EOF >>/etc/gce.conf
0000000000000000000000000000000000000000;;	multizone = ${MULTIZONE}
0000000000000000000000000000000000000000;;	EOF
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ "${use_cloud_config}" != "true" ]]; then
0000000000000000000000000000000000000000;;	    rm -f /etc/gce.conf
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  if [[ -n "${GCP_AUTHN_URL:-}" ]]; then
0000000000000000000000000000000000000000;;	    cat <<EOF >/etc/gcp_authn.config
0000000000000000000000000000000000000000;;	clusters:
0000000000000000000000000000000000000000;;	  - name: gcp-authentication-server
0000000000000000000000000000000000000000;;	    cluster:
0000000000000000000000000000000000000000;;	      server: ${GCP_AUTHN_URL}
0000000000000000000000000000000000000000;;	users:
0000000000000000000000000000000000000000;;	  - name: kube-apiserver
0000000000000000000000000000000000000000;;	    user:
0000000000000000000000000000000000000000;;	      auth-provider:
0000000000000000000000000000000000000000;;	        name: gcp
0000000000000000000000000000000000000000;;	current-context: webhook
0000000000000000000000000000000000000000;;	contexts:
0000000000000000000000000000000000000000;;	- context:
0000000000000000000000000000000000000000;;	    cluster: gcp-authentication-server
0000000000000000000000000000000000000000;;	    user: kube-apiserver
0000000000000000000000000000000000000000;;	  name: webhook
0000000000000000000000000000000000000000;;	EOF
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  if [[ -n "${GCP_AUTHZ_URL:-}" ]]; then
0000000000000000000000000000000000000000;;	    cat <<EOF >/etc/gcp_authz.config
0000000000000000000000000000000000000000;;	clusters:
0000000000000000000000000000000000000000;;	  - name: gcp-authorization-server
0000000000000000000000000000000000000000;;	    cluster:
0000000000000000000000000000000000000000;;	      server: ${GCP_AUTHZ_URL}
0000000000000000000000000000000000000000;;	users:
0000000000000000000000000000000000000000;;	  - name: kube-apiserver
0000000000000000000000000000000000000000;;	    user:
0000000000000000000000000000000000000000;;	      auth-provider:
0000000000000000000000000000000000000000;;	        name: gcp
0000000000000000000000000000000000000000;;	current-context: webhook
0000000000000000000000000000000000000000;;	contexts:
0000000000000000000000000000000000000000;;	- context:
0000000000000000000000000000000000000000;;	    cluster: gcp-authorization-server
0000000000000000000000000000000000000000;;	    user: kube-apiserver
0000000000000000000000000000000000000000;;	  name: webhook
0000000000000000000000000000000000000000;;	EOF
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	if [[ -n "${GCP_IMAGE_VERIFICATION_URL:-}" ]]; then
0000000000000000000000000000000000000000;;	    # This is the config file for the image review webhook.
0000000000000000000000000000000000000000;;	    cat <<EOF >/etc/gcp_image_review.config
0000000000000000000000000000000000000000;;	clusters:
0000000000000000000000000000000000000000;;	  - name: gcp-image-review-server
0000000000000000000000000000000000000000;;	    cluster:
0000000000000000000000000000000000000000;;	      server: ${GCP_IMAGE_VERIFICATION_URL}
0000000000000000000000000000000000000000;;	users:
0000000000000000000000000000000000000000;;	  - name: kube-apiserver
0000000000000000000000000000000000000000;;	    user:
0000000000000000000000000000000000000000;;	      auth-provider:
0000000000000000000000000000000000000000;;	        name: gcp
0000000000000000000000000000000000000000;;	current-context: webhook
0000000000000000000000000000000000000000;;	contexts:
0000000000000000000000000000000000000000;;	- context:
0000000000000000000000000000000000000000;;	    cluster: gcp-image-review-server
0000000000000000000000000000000000000000;;	    user: kube-apiserver
0000000000000000000000000000000000000000;;	  name: webhook
0000000000000000000000000000000000000000;;	EOF
0000000000000000000000000000000000000000;;	    # This is the config for the image review admission controller.
0000000000000000000000000000000000000000;;	    cat <<EOF >/etc/admission_controller.config
0000000000000000000000000000000000000000;;	imagePolicy:
0000000000000000000000000000000000000000;;	  kubeConfigFile: /etc/gcp_image_review.config
0000000000000000000000000000000000000000;;	  allowTTL: 30
0000000000000000000000000000000000000000;;	  denyTTL: 30
0000000000000000000000000000000000000000;;	  retryBackoff: 500
0000000000000000000000000000000000000000;;	  defaultAllow: true
0000000000000000000000000000000000000000;;	EOF
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Write the config for the audit policy.
0000000000000000000000000000000000000000;;	function create-master-audit-policy {
0000000000000000000000000000000000000000;;	  local -r path="${1}"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  # Known api groups
0000000000000000000000000000000000000000;;	  local -r known_apis='
0000000000000000000000000000000000000000;;	      - group: "" # core
0000000000000000000000000000000000000000;;	      - group: "admissionregistration.k8s.io"
0000000000000000000000000000000000000000;;	      - group: "apps"
0000000000000000000000000000000000000000;;	      - group: "authentication.k8s.io"
0000000000000000000000000000000000000000;;	      - group: "authorization.k8s.io"
0000000000000000000000000000000000000000;;	      - group: "autoscaling"
0000000000000000000000000000000000000000;;	      - group: "batch"
0000000000000000000000000000000000000000;;	      - group: "certificates.k8s.io"
0000000000000000000000000000000000000000;;	      - group: "extensions"
0000000000000000000000000000000000000000;;	      - group: "networking.k8s.io"
0000000000000000000000000000000000000000;;	      - group: "policy"
0000000000000000000000000000000000000000;;	      - group: "rbac.authorization.k8s.io"
0000000000000000000000000000000000000000;;	      - group: "settings.k8s.io"
0000000000000000000000000000000000000000;;	      - group: "storage.k8s.io"'
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  cat <<EOF >"${path}"
0000000000000000000000000000000000000000;;	rules:
0000000000000000000000000000000000000000;;	  # The following requests were manually identified as high-volume and low-risk,
0000000000000000000000000000000000000000;;	  # so drop them.
0000000000000000000000000000000000000000;;	  - level: None
0000000000000000000000000000000000000000;;	    users: ["system:kube-proxy"]
0000000000000000000000000000000000000000;;	    verbs: ["watch"]
0000000000000000000000000000000000000000;;	    resources:
0000000000000000000000000000000000000000;;	      - group: "" # core
0000000000000000000000000000000000000000;;	        resources: ["endpoints", "services"]
0000000000000000000000000000000000000000;;	  - level: None
0000000000000000000000000000000000000000;;	    # Ingress controller reads `configmaps/ingress-uid` through the unsecured port.
0000000000000000000000000000000000000000;;	    # TODO(#46983): Change this to the ingress controller service account.
0000000000000000000000000000000000000000;;	    users: ["system:unsecured"]
0000000000000000000000000000000000000000;;	    namespaces: ["kube-system"]
0000000000000000000000000000000000000000;;	    verbs: ["get"]
0000000000000000000000000000000000000000;;	    resources:
0000000000000000000000000000000000000000;;	      - group: "" # core
0000000000000000000000000000000000000000;;	        resources: ["configmaps"]
0000000000000000000000000000000000000000;;	  - level: None
0000000000000000000000000000000000000000;;	    users: ["kubelet"] # legacy kubelet identity
0000000000000000000000000000000000000000;;	    verbs: ["get"]
0000000000000000000000000000000000000000;;	    resources:
0000000000000000000000000000000000000000;;	      - group: "" # core
0000000000000000000000000000000000000000;;	        resources: ["nodes"]
0000000000000000000000000000000000000000;;	  - level: None
0000000000000000000000000000000000000000;;	    userGroups: ["system:nodes"]
0000000000000000000000000000000000000000;;	    verbs: ["get"]
0000000000000000000000000000000000000000;;	    resources:
0000000000000000000000000000000000000000;;	      - group: "" # core
0000000000000000000000000000000000000000;;	        resources: ["nodes"]
0000000000000000000000000000000000000000;;	  - level: None
0000000000000000000000000000000000000000;;	    users:
0000000000000000000000000000000000000000;;	      - system:kube-controller-manager
0000000000000000000000000000000000000000;;	      - system:kube-scheduler
0000000000000000000000000000000000000000;;	      - system:serviceaccount:kube-system:endpoint-controller
0000000000000000000000000000000000000000;;	    verbs: ["get", "update"]
0000000000000000000000000000000000000000;;	    namespaces: ["kube-system"]
0000000000000000000000000000000000000000;;	    resources:
0000000000000000000000000000000000000000;;	      - group: "" # core
0000000000000000000000000000000000000000;;	        resources: ["endpoints"]
0000000000000000000000000000000000000000;;	  - level: None
0000000000000000000000000000000000000000;;	    users: ["system:apiserver"]
0000000000000000000000000000000000000000;;	    verbs: ["get"]
0000000000000000000000000000000000000000;;	    resources:
0000000000000000000000000000000000000000;;	      - group: "" # core
0000000000000000000000000000000000000000;;	        resources: ["namespaces"]
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  # Don't log these read-only URLs.
0000000000000000000000000000000000000000;;	  - level: None
0000000000000000000000000000000000000000;;	    nonResourceURLs:
0000000000000000000000000000000000000000;;	      - /healthz*
0000000000000000000000000000000000000000;;	      - /version
0000000000000000000000000000000000000000;;	      - /swagger*
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  # Don't log events requests.
0000000000000000000000000000000000000000;;	  - level: None
0000000000000000000000000000000000000000;;	    resources:
0000000000000000000000000000000000000000;;	      - group: "" # core
0000000000000000000000000000000000000000;;	        resources: ["events"]
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  # Secrets, ConfigMaps, and TokenReviews can contain sensitive & binary data,
0000000000000000000000000000000000000000;;	  # so only log at the Metadata level.
0000000000000000000000000000000000000000;;	  - level: Metadata
0000000000000000000000000000000000000000;;	    resources:
0000000000000000000000000000000000000000;;	      - group: "" # core
0000000000000000000000000000000000000000;;	        resources: ["secrets", "configmaps"]
0000000000000000000000000000000000000000;;	      - group: authentication.k8s.io
0000000000000000000000000000000000000000;;	        resources: ["tokenreviews"]
0000000000000000000000000000000000000000;;	  # Get repsonses can be large; skip them.
0000000000000000000000000000000000000000;;	  - level: Request
0000000000000000000000000000000000000000;;	    verbs: ["get", "list", "watch"]
0000000000000000000000000000000000000000;;	    resources: ${known_apis}
0000000000000000000000000000000000000000;;	  # Default level for known APIs
0000000000000000000000000000000000000000;;	  - level: RequestResponse
0000000000000000000000000000000000000000;;	    resources: ${known_apis}
0000000000000000000000000000000000000000;;	  # Default level for all other requests.
0000000000000000000000000000000000000000;;	  - level: Metadata
0000000000000000000000000000000000000000;;	EOF
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Writes the configuration file used by the webhook advanced auditing backend.
0000000000000000000000000000000000000000;;	function create-master-audit-webhook-config {
0000000000000000000000000000000000000000;;	  local -r path="${1}"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  if [[ -n "${GCP_AUDIT_URL:-}" ]]; then
0000000000000000000000000000000000000000;;	    # The webhook config file is a kubeconfig file describing the webhook endpoint.
0000000000000000000000000000000000000000;;	    cat <<EOF >"${path}"
0000000000000000000000000000000000000000;;	clusters:
0000000000000000000000000000000000000000;;	  - name: gcp-audit-server
0000000000000000000000000000000000000000;;	    cluster:
0000000000000000000000000000000000000000;;	      server: ${GCP_AUDIT_URL}
0000000000000000000000000000000000000000;;	users:
0000000000000000000000000000000000000000;;	  - name: kube-apiserver
0000000000000000000000000000000000000000;;	    user:
0000000000000000000000000000000000000000;;	      auth-provider:
0000000000000000000000000000000000000000;;	        name: gcp
0000000000000000000000000000000000000000;;	current-context: webhook
0000000000000000000000000000000000000000;;	contexts:
0000000000000000000000000000000000000000;;	- context:
0000000000000000000000000000000000000000;;	    cluster: gcp-audit-server
0000000000000000000000000000000000000000;;	    user: kube-apiserver
0000000000000000000000000000000000000000;;	  name: webhook
0000000000000000000000000000000000000000;;	EOF
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	function create-kubelet-kubeconfig {
0000000000000000000000000000000000000000;;	  echo "Creating kubelet kubeconfig file"
0000000000000000000000000000000000000000;;	  cat <<EOF >/var/lib/kubelet/bootstrap-kubeconfig
0000000000000000000000000000000000000000;;	apiVersion: v1
0000000000000000000000000000000000000000;;	kind: Config
0000000000000000000000000000000000000000;;	users:
0000000000000000000000000000000000000000;;	- name: kubelet
0000000000000000000000000000000000000000;;	  user:
0000000000000000000000000000000000000000;;	    client-certificate: ${KUBELET_CERT_PATH}
0000000000000000000000000000000000000000;;	    client-key: ${KUBELET_KEY_PATH}
0000000000000000000000000000000000000000;;	clusters:
0000000000000000000000000000000000000000;;	- name: local
0000000000000000000000000000000000000000;;	  cluster:
0000000000000000000000000000000000000000;;	    certificate-authority: ${CA_CERT_BUNDLE_PATH}
0000000000000000000000000000000000000000;;	    server: https://${KUBERNETES_MASTER_NAME}
0000000000000000000000000000000000000000;;	contexts:
0000000000000000000000000000000000000000;;	- context:
0000000000000000000000000000000000000000;;	    cluster: local
0000000000000000000000000000000000000000;;	    user: kubelet
0000000000000000000000000000000000000000;;	  name: service-account-context
0000000000000000000000000000000000000000;;	current-context: service-account-context
0000000000000000000000000000000000000000;;	EOF
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Uses KUBELET_CA_CERT (falling back to CA_CERT), KUBELET_CERT, and KUBELET_KEY
0000000000000000000000000000000000000000;;	# to generate a kubeconfig file for the kubelet to securely connect to the apiserver.
0000000000000000000000000000000000000000;;	# Set REGISTER_MASTER_KUBELET to true if kubelet on the master node
0000000000000000000000000000000000000000;;	# should register to the apiserver.
0000000000000000000000000000000000000000;;	function create-master-kubelet-auth {
0000000000000000000000000000000000000000;;	  # Only configure the kubelet on the master if the required variables are
0000000000000000000000000000000000000000;;	  # set in the environment.
0000000000000000000000000000000000000000;;	  if [[ -n "${KUBELET_APISERVER:-}" && -n "${KUBELET_CERT:-}" && -n "${KUBELET_KEY:-}" ]]; then
0000000000000000000000000000000000000000;;	    REGISTER_MASTER_KUBELET="true"
0000000000000000000000000000000000000000;;	    create-kubelet-kubeconfig
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	function create-kubeproxy-kubeconfig {
0000000000000000000000000000000000000000;;	  echo "Creating kube-proxy kubeconfig file"
0000000000000000000000000000000000000000;;	  cat <<EOF >/var/lib/kube-proxy/kubeconfig
0000000000000000000000000000000000000000;;	apiVersion: v1
0000000000000000000000000000000000000000;;	kind: Config
0000000000000000000000000000000000000000;;	users:
0000000000000000000000000000000000000000;;	- name: kube-proxy
0000000000000000000000000000000000000000;;	  user:
0000000000000000000000000000000000000000;;	    token: ${KUBE_PROXY_TOKEN}
0000000000000000000000000000000000000000;;	clusters:
0000000000000000000000000000000000000000;;	- name: local
0000000000000000000000000000000000000000;;	  cluster:
0000000000000000000000000000000000000000;;	    certificate-authority-data: ${CA_CERT_BUNDLE}
0000000000000000000000000000000000000000;;	contexts:
0000000000000000000000000000000000000000;;	- context:
0000000000000000000000000000000000000000;;	    cluster: local
0000000000000000000000000000000000000000;;	    user: kube-proxy
0000000000000000000000000000000000000000;;	  name: service-account-context
0000000000000000000000000000000000000000;;	current-context: service-account-context
0000000000000000000000000000000000000000;;	EOF
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	function create-kubecontrollermanager-kubeconfig {
0000000000000000000000000000000000000000;;	  echo "Creating kube-controller-manager kubeconfig file"
0000000000000000000000000000000000000000;;	  mkdir -p /etc/srv/kubernetes/kube-controller-manager
0000000000000000000000000000000000000000;;	  cat <<EOF >/etc/srv/kubernetes/kube-controller-manager/kubeconfig
0000000000000000000000000000000000000000;;	apiVersion: v1
0000000000000000000000000000000000000000;;	kind: Config
0000000000000000000000000000000000000000;;	users:
0000000000000000000000000000000000000000;;	- name: kube-controller-manager
0000000000000000000000000000000000000000;;	  user:
0000000000000000000000000000000000000000;;	    token: ${KUBE_CONTROLLER_MANAGER_TOKEN}
0000000000000000000000000000000000000000;;	clusters:
0000000000000000000000000000000000000000;;	- name: local
0000000000000000000000000000000000000000;;	  cluster:
0000000000000000000000000000000000000000;;	    insecure-skip-tls-verify: true
0000000000000000000000000000000000000000;;	    server: https://localhost:443
0000000000000000000000000000000000000000;;	contexts:
0000000000000000000000000000000000000000;;	- context:
0000000000000000000000000000000000000000;;	    cluster: local
0000000000000000000000000000000000000000;;	    user: kube-controller-manager
0000000000000000000000000000000000000000;;	  name: service-account-context
0000000000000000000000000000000000000000;;	current-context: service-account-context
0000000000000000000000000000000000000000;;	EOF
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	function create-kubescheduler-kubeconfig {
0000000000000000000000000000000000000000;;	  echo "Creating kube-scheduler kubeconfig file"
0000000000000000000000000000000000000000;;	  mkdir -p /etc/srv/kubernetes/kube-scheduler
0000000000000000000000000000000000000000;;	  cat <<EOF >/etc/srv/kubernetes/kube-scheduler/kubeconfig
0000000000000000000000000000000000000000;;	apiVersion: v1
0000000000000000000000000000000000000000;;	kind: Config
0000000000000000000000000000000000000000;;	users:
0000000000000000000000000000000000000000;;	- name: kube-scheduler
0000000000000000000000000000000000000000;;	  user:
0000000000000000000000000000000000000000;;	    token: ${KUBE_SCHEDULER_TOKEN}
0000000000000000000000000000000000000000;;	clusters:
0000000000000000000000000000000000000000;;	- name: local
0000000000000000000000000000000000000000;;	  cluster:
0000000000000000000000000000000000000000;;	    insecure-skip-tls-verify: true
0000000000000000000000000000000000000000;;	    server: https://localhost:443
0000000000000000000000000000000000000000;;	contexts:
0000000000000000000000000000000000000000;;	- context:
0000000000000000000000000000000000000000;;	    cluster: local
0000000000000000000000000000000000000000;;	    user: kube-scheduler
0000000000000000000000000000000000000000;;	  name: kube-scheduler
0000000000000000000000000000000000000000;;	current-context: kube-scheduler
0000000000000000000000000000000000000000;;	EOF
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	function create-node-problem-detector-kubeconfig {
0000000000000000000000000000000000000000;;	  echo "Creating node-problem-detector kubeconfig file"
0000000000000000000000000000000000000000;;	  mkdir -p /var/lib/node-problem-detector
0000000000000000000000000000000000000000;;	  cat <<EOF >/var/lib/node-problem-detector/kubeconfig
0000000000000000000000000000000000000000;;	apiVersion: v1
0000000000000000000000000000000000000000;;	kind: Config
0000000000000000000000000000000000000000;;	users:
0000000000000000000000000000000000000000;;	- name: node-problem-detector
0000000000000000000000000000000000000000;;	  user:
0000000000000000000000000000000000000000;;	    token: ${NODE_PROBLEM_DETECTOR_TOKEN}
0000000000000000000000000000000000000000;;	clusters:
0000000000000000000000000000000000000000;;	- name: local
0000000000000000000000000000000000000000;;	  cluster:
0000000000000000000000000000000000000000;;	    certificate-authority-data: ${CA_CERT}
0000000000000000000000000000000000000000;;	contexts:
0000000000000000000000000000000000000000;;	- context:
0000000000000000000000000000000000000000;;	    cluster: local
0000000000000000000000000000000000000000;;	    user: node-problem-detector
0000000000000000000000000000000000000000;;	  name: service-account-context
0000000000000000000000000000000000000000;;	current-context: service-account-context
0000000000000000000000000000000000000000;;	EOF
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	function create-master-etcd-auth {
0000000000000000000000000000000000000000;;	  if [[ -n "${ETCD_CA_CERT:-}" && -n "${ETCD_PEER_KEY:-}" && -n "${ETCD_PEER_CERT:-}" ]]; then
0000000000000000000000000000000000000000;;	    local -r auth_dir="/etc/srv/kubernetes"
0000000000000000000000000000000000000000;;	    echo "${ETCD_CA_CERT}" | base64 --decode | gunzip > "${auth_dir}/etcd-ca.crt"
0000000000000000000000000000000000000000;;	    echo "${ETCD_PEER_KEY}" | base64 --decode > "${auth_dir}/etcd-peer.key"
0000000000000000000000000000000000000000;;	    echo "${ETCD_PEER_CERT}" | base64 --decode | gunzip > "${auth_dir}/etcd-peer.crt"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	function assemble-docker-flags {
0000000000000000000000000000000000000000;;	  echo "Assemble docker command line flags"
0000000000000000000000000000000000000000;;	  local docker_opts="-p /var/run/docker.pid --iptables=false --ip-masq=false"
0000000000000000000000000000000000000000;;	  if [[ "${TEST_CLUSTER:-}" == "true" ]]; then
0000000000000000000000000000000000000000;;	    docker_opts+=" --log-level=debug"
0000000000000000000000000000000000000000;;	  else
0000000000000000000000000000000000000000;;	    docker_opts+=" --log-level=warn"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  local use_net_plugin="true"
0000000000000000000000000000000000000000;;	  if [[ "${NETWORK_PROVIDER:-}" == "kubenet" || "${NETWORK_PROVIDER:-}" == "cni" ]]; then
0000000000000000000000000000000000000000;;	    # set docker0 cidr to private ip address range to avoid conflict with cbr0 cidr range
0000000000000000000000000000000000000000;;	    docker_opts+=" --bip=169.254.123.1/24"
0000000000000000000000000000000000000000;;	  else
0000000000000000000000000000000000000000;;	    use_net_plugin="false"
0000000000000000000000000000000000000000;;	    docker_opts+=" --bridge=cbr0"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  # Decide whether to enable a docker registry mirror. This is taken from
0000000000000000000000000000000000000000;;	  # the "kube-env" metadata value.
0000000000000000000000000000000000000000;;	  if [[ -n "${DOCKER_REGISTRY_MIRROR_URL:-}" ]]; then
0000000000000000000000000000000000000000;;	    echo "Enable docker registry mirror at: ${DOCKER_REGISTRY_MIRROR_URL}"
0000000000000000000000000000000000000000;;	    docker_opts+=" --registry-mirror=${DOCKER_REGISTRY_MIRROR_URL}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  # Configure docker logging
0000000000000000000000000000000000000000;;	  docker_opts+=" --log-driver=${DOCKER_LOG_DRIVER:-json-file}"
0000000000000000000000000000000000000000;;	  docker_opts+=" --log-opt=max-size=${DOCKER_LOG_MAX_SIZE:-10m}"
0000000000000000000000000000000000000000;;	  docker_opts+=" --log-opt=max-file=${DOCKER_LOG_MAX_FILE:-5}"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  echo "DOCKER_OPTS=\"${docker_opts} ${EXTRA_DOCKER_OPTS:-}\"" > /etc/default/docker
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  if [[ "${use_net_plugin}" == "true" ]]; then
0000000000000000000000000000000000000000;;	    # If using a network plugin, extend the docker configuration to always remove
0000000000000000000000000000000000000000;;	    # the network checkpoint to avoid corrupt checkpoints.
0000000000000000000000000000000000000000;;	    # (https://github.com/docker/docker/issues/18283).
0000000000000000000000000000000000000000;;	    echo "Extend the default docker.service configuration"
0000000000000000000000000000000000000000;;	    mkdir -p /etc/systemd/system/docker.service.d
0000000000000000000000000000000000000000;;	    cat <<EOF >/etc/systemd/system/docker.service.d/01network.conf
0000000000000000000000000000000000000000;;	[Service]
0000000000000000000000000000000000000000;;	ExecStartPre=/bin/sh -x -c "rm -rf /var/lib/docker/network"
0000000000000000000000000000000000000000;;	EOF
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	    systemctl daemon-reload
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	    # If using a network plugin, we need to explicitly restart docker daemon, because
0000000000000000000000000000000000000000;;	    # kubelet will not do it.
0000000000000000000000000000000000000000;;	    echo "Docker command line is updated. Restart docker to pick it up"
0000000000000000000000000000000000000000;;	    systemctl restart docker
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# A helper function for loading a docker image. It keeps trying up to 5 times.
0000000000000000000000000000000000000000;;	#
0000000000000000000000000000000000000000;;	# $1: Full path of the docker image
0000000000000000000000000000000000000000;;	function try-load-docker-image {
0000000000000000000000000000000000000000;;	  local -r img=$1
0000000000000000000000000000000000000000;;	  echo "Try to load docker image file ${img}"
0000000000000000000000000000000000000000;;	  # Temporarily turn off errexit, because we don't want to exit on first failure.
0000000000000000000000000000000000000000;;	  set +e
0000000000000000000000000000000000000000;;	  local -r max_attempts=5
0000000000000000000000000000000000000000;;	  local -i attempt_num=1
0000000000000000000000000000000000000000;;	  until timeout 30 docker load -i "${img}"; do
0000000000000000000000000000000000000000;;	    if [[ "${attempt_num}" == "${max_attempts}" ]]; then
0000000000000000000000000000000000000000;;	      echo "Fail to load docker image file ${img} after ${max_attempts} retries. Exit!!"
0000000000000000000000000000000000000000;;	      exit 1
0000000000000000000000000000000000000000;;	    else
0000000000000000000000000000000000000000;;	      attempt_num=$((attempt_num+1))
0000000000000000000000000000000000000000;;	      sleep 5
0000000000000000000000000000000000000000;;	    fi
0000000000000000000000000000000000000000;;	  done
0000000000000000000000000000000000000000;;	  # Re-enable errexit.
0000000000000000000000000000000000000000;;	  set -e
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Loads kube-system docker images. It is better to do it before starting kubelet,
0000000000000000000000000000000000000000;;	# as kubelet will restart docker daemon, which may interfere with loading images.
0000000000000000000000000000000000000000;;	function load-docker-images {
0000000000000000000000000000000000000000;;	  echo "Start loading kube-system docker images"
0000000000000000000000000000000000000000;;	  local -r img_dir="${KUBE_HOME}/kube-docker-files"
0000000000000000000000000000000000000000;;	  if [[ "${KUBERNETES_MASTER:-}" == "true" ]]; then
0000000000000000000000000000000000000000;;	    try-load-docker-image "${img_dir}/kube-apiserver.tar"
0000000000000000000000000000000000000000;;	    try-load-docker-image "${img_dir}/kube-controller-manager.tar"
0000000000000000000000000000000000000000;;	    try-load-docker-image "${img_dir}/kube-scheduler.tar"
0000000000000000000000000000000000000000;;	  else
0000000000000000000000000000000000000000;;	    try-load-docker-image "${img_dir}/kube-proxy.tar"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# This function assembles the kubelet systemd service file and starts it
0000000000000000000000000000000000000000;;	# using systemctl.
0000000000000000000000000000000000000000;;	function start-kubelet {
0000000000000000000000000000000000000000;;	  echo "Start kubelet"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  local -r kubelet_cert_dir="/var/lib/kubelet/pki/"
0000000000000000000000000000000000000000;;	  mkdir -p "${kubelet_cert_dir}"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  local kubelet_bin="${KUBE_HOME}/bin/kubelet"
0000000000000000000000000000000000000000;;	  local -r version="$("${kubelet_bin}" --version=true | cut -f2 -d " ")"
0000000000000000000000000000000000000000;;	  local -r builtin_kubelet="/usr/bin/kubelet"
0000000000000000000000000000000000000000;;	  if [[ "${TEST_CLUSTER:-}" == "true" ]]; then
0000000000000000000000000000000000000000;;	    # Determine which binary to use on test clusters. We use the built-in
0000000000000000000000000000000000000000;;	    # version only if the downloaded version is the same as the built-in
0000000000000000000000000000000000000000;;	    # version. This allows GCI to run some of the e2e tests to qualify the
0000000000000000000000000000000000000000;;	    # built-in kubelet.
0000000000000000000000000000000000000000;;	    if [[ -x "${builtin_kubelet}" ]]; then
0000000000000000000000000000000000000000;;	      local -r builtin_version="$("${builtin_kubelet}"  --version=true | cut -f2 -d " ")"
0000000000000000000000000000000000000000;;	      if [[ "${builtin_version}" == "${version}" ]]; then
0000000000000000000000000000000000000000;;	        kubelet_bin="${builtin_kubelet}"
0000000000000000000000000000000000000000;;	      fi
0000000000000000000000000000000000000000;;	    fi
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  echo "Using kubelet binary at ${kubelet_bin}"
0000000000000000000000000000000000000000;;	  local flags="${KUBELET_TEST_LOG_LEVEL:-"--v=2"} ${KUBELET_TEST_ARGS:-}"
0000000000000000000000000000000000000000;;	  flags+=" --allow-privileged=true"
0000000000000000000000000000000000000000;;	  flags+=" --cgroup-root=/"
0000000000000000000000000000000000000000;;	  flags+=" --cloud-provider=gce"
0000000000000000000000000000000000000000;;	  flags+=" --cluster-dns=${DNS_SERVER_IP}"
0000000000000000000000000000000000000000;;	  flags+=" --cluster-domain=${DNS_DOMAIN}"
0000000000000000000000000000000000000000;;	  flags+=" --pod-manifest-path=/etc/kubernetes/manifests"
0000000000000000000000000000000000000000;;	  flags+=" --experimental-mounter-path=${CONTAINERIZED_MOUNTER_HOME}/mounter"
0000000000000000000000000000000000000000;;	  flags+=" --experimental-check-node-capabilities-before-mount=true"
0000000000000000000000000000000000000000;;	  flags+=" --cert-dir=${kubelet_cert_dir}"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  if [[ -n "${KUBELET_PORT:-}" ]]; then
0000000000000000000000000000000000000000;;	    flags+=" --port=${KUBELET_PORT}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ "${KUBERNETES_MASTER:-}" == "true" ]]; then
0000000000000000000000000000000000000000;;	    flags+=" ${MASTER_KUBELET_TEST_ARGS:-}"
0000000000000000000000000000000000000000;;	    flags+=" --enable-debugging-handlers=false"
0000000000000000000000000000000000000000;;	    flags+=" --hairpin-mode=none"
0000000000000000000000000000000000000000;;	    if [[ "${REGISTER_MASTER_KUBELET:-false}" == "true" ]]; then
0000000000000000000000000000000000000000;;	      #TODO(mikedanese): allow static pods to start before creating a client
0000000000000000000000000000000000000000;;	      #flags+=" --bootstrap-kubeconfig=/var/lib/kubelet/bootstrap-kubeconfig"
0000000000000000000000000000000000000000;;	      #flags+=" --kubeconfig=/var/lib/kubelet/kubeconfig"
0000000000000000000000000000000000000000;;	      flags+=" --kubeconfig=/var/lib/kubelet/bootstrap-kubeconfig"
0000000000000000000000000000000000000000;;	      flags+=" --require-kubeconfig"
0000000000000000000000000000000000000000;;	      flags+=" --register-schedulable=false"
0000000000000000000000000000000000000000;;	    else
0000000000000000000000000000000000000000;;	      # Standalone mode (not widely used?)
0000000000000000000000000000000000000000;;	      flags+=" --pod-cidr=${MASTER_IP_RANGE}"
0000000000000000000000000000000000000000;;	    fi
0000000000000000000000000000000000000000;;	  else # For nodes
0000000000000000000000000000000000000000;;	    flags+=" ${NODE_KUBELET_TEST_ARGS:-}"
0000000000000000000000000000000000000000;;	    flags+=" --enable-debugging-handlers=true"
0000000000000000000000000000000000000000;;	    flags+=" --bootstrap-kubeconfig=/var/lib/kubelet/bootstrap-kubeconfig"
0000000000000000000000000000000000000000;;	    flags+=" --require-kubeconfig"
0000000000000000000000000000000000000000;;	    flags+=" --kubeconfig=/var/lib/kubelet/kubeconfig"
0000000000000000000000000000000000000000;;	    if [[ "${HAIRPIN_MODE:-}" == "promiscuous-bridge" ]] || \
0000000000000000000000000000000000000000;;	       [[ "${HAIRPIN_MODE:-}" == "hairpin-veth" ]] || \
0000000000000000000000000000000000000000;;	       [[ "${HAIRPIN_MODE:-}" == "none" ]]; then
0000000000000000000000000000000000000000;;	      flags+=" --hairpin-mode=${HAIRPIN_MODE}"
0000000000000000000000000000000000000000;;	    fi
0000000000000000000000000000000000000000;;	    flags+=" --anonymous-auth=false --authorization-mode=Webhook --client-ca-file=${CA_CERT_BUNDLE_PATH}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  # Network plugin
0000000000000000000000000000000000000000;;	  if [[ -n "${NETWORK_PROVIDER:-}" || -n "${NETWORK_POLICY_PROVIDER:-}" ]]; then
0000000000000000000000000000000000000000;;	    flags+=" --cni-bin-dir=/home/kubernetes/bin"
0000000000000000000000000000000000000000;;	    if [[ "${NETWORK_POLICY_PROVIDER:-}" == "calico" ]]; then
0000000000000000000000000000000000000000;;	      # Calico uses CNI always.
0000000000000000000000000000000000000000;;	      if [[ "${KUBERNETES_PRIVATE_MASTER:-}" == "true" ]]; then
0000000000000000000000000000000000000000;;	        flags+=" --network-plugin=${NETWORK_PROVIDER}"
0000000000000000000000000000000000000000;;	      else
0000000000000000000000000000000000000000;;	        flags+=" --network-plugin=cni"
0000000000000000000000000000000000000000;;	      fi
0000000000000000000000000000000000000000;;	    else
0000000000000000000000000000000000000000;;	      # Otherwise use the configured value.
0000000000000000000000000000000000000000;;	      flags+=" --network-plugin=${NETWORK_PROVIDER}"
0000000000000000000000000000000000000000;;	    fi
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ -n "${NON_MASQUERADE_CIDR:-}" ]]; then
0000000000000000000000000000000000000000;;	    flags+=" --non-masquerade-cidr=${NON_MASQUERADE_CIDR}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  # FlexVolume plugin
0000000000000000000000000000000000000000;;	  if [[ -n "${VOLUME_PLUGIN_DIR:-}" ]]; then
0000000000000000000000000000000000000000;;	    flags+=" --volume-plugin-dir=${VOLUME_PLUGIN_DIR}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ "${ENABLE_MANIFEST_URL:-}" == "true" ]]; then
0000000000000000000000000000000000000000;;	    flags+=" --manifest-url=${MANIFEST_URL}"
0000000000000000000000000000000000000000;;	    flags+=" --manifest-url-header=${MANIFEST_URL_HEADER}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ -n "${ENABLE_CUSTOM_METRICS:-}" ]]; then
0000000000000000000000000000000000000000;;	    flags+=" --enable-custom-metrics=${ENABLE_CUSTOM_METRICS}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ -n "${NODE_LABELS:-}" ]]; then
0000000000000000000000000000000000000000;;	    flags+=" --node-labels=${NODE_LABELS}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ -n "${NODE_TAINTS:-}" ]]; then
0000000000000000000000000000000000000000;;	    flags+=" --register-with-taints=${NODE_TAINTS}"
0000000000000000000000000000000000000000;;	  fi  
0000000000000000000000000000000000000000;;	  if [[ -n "${EVICTION_HARD:-}" ]]; then
0000000000000000000000000000000000000000;;	    flags+=" --eviction-hard=${EVICTION_HARD}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ -n "${FEATURE_GATES:-}" ]]; then
0000000000000000000000000000000000000000;;	    flags+=" --feature-gates=${FEATURE_GATES}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  local -r kubelet_env_file="/etc/default/kubelet"
0000000000000000000000000000000000000000;;	  echo "KUBELET_OPTS=\"${flags}\"" > "${kubelet_env_file}"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  # Write the systemd service file for kubelet.
0000000000000000000000000000000000000000;;	  cat <<EOF >/etc/systemd/system/kubelet.service
0000000000000000000000000000000000000000;;	[Unit]
0000000000000000000000000000000000000000;;	Description=Kubernetes kubelet
0000000000000000000000000000000000000000;;	Requires=network-online.target
0000000000000000000000000000000000000000;;	After=network-online.target
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	[Service]
0000000000000000000000000000000000000000;;	Restart=always
0000000000000000000000000000000000000000;;	RestartSec=10
0000000000000000000000000000000000000000;;	EnvironmentFile=${kubelet_env_file}
0000000000000000000000000000000000000000;;	ExecStart=${kubelet_bin} \$KUBELET_OPTS
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	[Install]
0000000000000000000000000000000000000000;;	WantedBy=multi-user.target
0000000000000000000000000000000000000000;;	EOF
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  # Flush iptables nat table
0000000000000000000000000000000000000000;;	  iptables -t nat -F || true
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  systemctl start kubelet.service
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# This function assembles the node problem detector systemd service file and
0000000000000000000000000000000000000000;;	# starts it using systemctl.
0000000000000000000000000000000000000000;;	function start-node-problem-detector {
0000000000000000000000000000000000000000;;	  echo "Start node problem detector"
0000000000000000000000000000000000000000;;	  local -r npd_bin="${KUBE_HOME}/bin/node-problem-detector"
0000000000000000000000000000000000000000;;	  local -r km_config="${KUBE_HOME}/node-problem-detector/config/kernel-monitor.json"
0000000000000000000000000000000000000000;;	  local -r dm_config="${KUBE_HOME}/node-problem-detector/config/docker-monitor.json"
0000000000000000000000000000000000000000;;	  echo "Using node problem detector binary at ${npd_bin}"
0000000000000000000000000000000000000000;;	  local flags="${NPD_TEST_LOG_LEVEL:-"--v=2"} ${NPD_TEST_ARGS:-}"
0000000000000000000000000000000000000000;;	  flags+=" --logtostderr"
0000000000000000000000000000000000000000;;	  flags+=" --system-log-monitors=${km_config},${dm_config}"
0000000000000000000000000000000000000000;;	  flags+=" --apiserver-override=https://${KUBERNETES_MASTER_NAME}?inClusterConfig=false&auth=/var/lib/node-problem-detector/kubeconfig"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  # Write the systemd service file for node problem detector.
0000000000000000000000000000000000000000;;	  cat <<EOF >/etc/systemd/system/node-problem-detector.service
0000000000000000000000000000000000000000;;	[Unit]
0000000000000000000000000000000000000000;;	Description=Kubernetes node problem detector
0000000000000000000000000000000000000000;;	Requires=network-online.target
0000000000000000000000000000000000000000;;	After=network-online.target
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	[Service]
0000000000000000000000000000000000000000;;	Restart=always
0000000000000000000000000000000000000000;;	RestartSec=10
0000000000000000000000000000000000000000;;	ExecStart=${npd_bin} ${flags}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	[Install]
0000000000000000000000000000000000000000;;	WantedBy=multi-user.target
0000000000000000000000000000000000000000;;	EOF
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  systemctl start node-problem-detector.service
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Create the log file and set its properties.
0000000000000000000000000000000000000000;;	#
0000000000000000000000000000000000000000;;	# $1 is the file to create.
0000000000000000000000000000000000000000;;	function prepare-log-file {
0000000000000000000000000000000000000000;;	  touch $1
0000000000000000000000000000000000000000;;	  chmod 644 $1
0000000000000000000000000000000000000000;;	  chown root:root $1
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Starts kube-proxy pod.
0000000000000000000000000000000000000000;;	function start-kube-proxy {
0000000000000000000000000000000000000000;;	  echo "Start kube-proxy pod"
0000000000000000000000000000000000000000;;	  prepare-log-file /var/log/kube-proxy.log
0000000000000000000000000000000000000000;;	  local -r src_file="${KUBE_HOME}/kube-manifests/kubernetes/kube-proxy.manifest"
0000000000000000000000000000000000000000;;	  remove-salt-config-comments "${src_file}"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  local -r kubeconfig="--kubeconfig=/var/lib/kube-proxy/kubeconfig"
0000000000000000000000000000000000000000;;	  local kube_docker_registry="gcr.io/google_containers"
0000000000000000000000000000000000000000;;	  if [[ -n "${KUBE_DOCKER_REGISTRY:-}" ]]; then
0000000000000000000000000000000000000000;;	    kube_docker_registry=${KUBE_DOCKER_REGISTRY}
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  local -r kube_proxy_docker_tag=$(cat /home/kubernetes/kube-docker-files/kube-proxy.docker_tag)
0000000000000000000000000000000000000000;;	  local api_servers="--master=https://${KUBERNETES_MASTER_NAME}"
0000000000000000000000000000000000000000;;	  local params="${KUBEPROXY_TEST_LOG_LEVEL:-"--v=2"}"
0000000000000000000000000000000000000000;;	  if [[ -n "${FEATURE_GATES:-}" ]]; then
0000000000000000000000000000000000000000;;	    params+=" --feature-gates=${FEATURE_GATES}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  params+=" --iptables-sync-period=1m --iptables-min-sync-period=10s"
0000000000000000000000000000000000000000;;	  if [[ -n "${KUBEPROXY_TEST_ARGS:-}" ]]; then
0000000000000000000000000000000000000000;;	    params+=" ${KUBEPROXY_TEST_ARGS}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  local container_env=""
0000000000000000000000000000000000000000;;	  if [[ -n "${ENABLE_CACHE_MUTATION_DETECTOR:-}" ]]; then
0000000000000000000000000000000000000000;;	    container_env="env:\n    - name: KUBE_CACHE_MUTATION_DETECTOR\n    value: \"${ENABLE_CACHE_MUTATION_DETECTOR}\""
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{kubeconfig}}@${kubeconfig}@g" ${src_file}
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{pillar\['kube_docker_registry'\]}}@${kube_docker_registry}@g" ${src_file}
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{pillar\['kube-proxy_docker_tag'\]}}@${kube_proxy_docker_tag}@g" ${src_file}
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{params}}@${params}@g" ${src_file}
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{container_env}}@${container_env}@g" ${src_file}
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{ cpurequest }}@100m@g" ${src_file}
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{api_servers_with_port}}@${api_servers}@g" ${src_file}
0000000000000000000000000000000000000000;;	  if [[ -n "${CLUSTER_IP_RANGE:-}" ]]; then
0000000000000000000000000000000000000000;;	    sed -i -e "s@{{cluster_cidr}}@--cluster-cidr=${CLUSTER_IP_RANGE}@g" ${src_file}
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  cp "${src_file}" /etc/kubernetes/manifests
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Replaces the variables in the etcd manifest file with the real values, and then
0000000000000000000000000000000000000000;;	# copy the file to the manifest dir
0000000000000000000000000000000000000000;;	# $1: value for variable 'suffix'
0000000000000000000000000000000000000000;;	# $2: value for variable 'port'
0000000000000000000000000000000000000000;;	# $3: value for variable 'server_port'
0000000000000000000000000000000000000000;;	# $4: value for variable 'cpulimit'
0000000000000000000000000000000000000000;;	# $5: pod name, which should be either etcd or etcd-events
0000000000000000000000000000000000000000;;	function prepare-etcd-manifest {
0000000000000000000000000000000000000000;;	  local host_name=$(hostname)
0000000000000000000000000000000000000000;;	  local etcd_cluster=""
0000000000000000000000000000000000000000;;	  local cluster_state="new"
0000000000000000000000000000000000000000;;	  local etcd_protocol="http"
0000000000000000000000000000000000000000;;	  local etcd_creds=""
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  if [[ -n "${INITIAL_ETCD_CLUSTER_STATE:-}" ]]; then
0000000000000000000000000000000000000000;;	    cluster_state="${INITIAL_ETCD_CLUSTER_STATE}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ -n "${ETCD_CA_KEY:-}" && -n "${ETCD_CA_CERT:-}" && -n "${ETCD_PEER_KEY:-}" && -n "${ETCD_PEER_CERT:-}" ]]; then
0000000000000000000000000000000000000000;;	    etcd_creds=" --peer-trusted-ca-file /etc/srv/kubernetes/etcd-ca.crt --peer-cert-file /etc/srv/kubernetes/etcd-peer.crt --peer-key-file /etc/srv/kubernetes/etcd-peer.key -peer-client-cert-auth "
0000000000000000000000000000000000000000;;	    etcd_protocol="https"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  for host in $(echo "${INITIAL_ETCD_CLUSTER:-${host_name}}" | tr "," "\n"); do
0000000000000000000000000000000000000000;;	    etcd_host="etcd-${host}=${etcd_protocol}://${host}:$3"
0000000000000000000000000000000000000000;;	    if [[ -n "${etcd_cluster}" ]]; then
0000000000000000000000000000000000000000;;	      etcd_cluster+=","
0000000000000000000000000000000000000000;;	    fi
0000000000000000000000000000000000000000;;	    etcd_cluster+="${etcd_host}"
0000000000000000000000000000000000000000;;	  done
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  local -r temp_file="/tmp/$5"
0000000000000000000000000000000000000000;;	  cp "${KUBE_HOME}/kube-manifests/kubernetes/gci-trusty/etcd.manifest" "${temp_file}"
0000000000000000000000000000000000000000;;	  remove-salt-config-comments "${temp_file}"
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{ *suffix *}}@$1@g" "${temp_file}"
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{ *port *}}@$2@g" "${temp_file}"
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{ *server_port *}}@$3@g" "${temp_file}"
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{ *cpulimit *}}@\"$4\"@g" "${temp_file}"
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{ *hostname *}}@$host_name@g" "${temp_file}"
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{ *srv_kube_path *}}@/etc/srv/kubernetes@g" "${temp_file}"
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{ *etcd_cluster *}}@$etcd_cluster@g" "${temp_file}"
0000000000000000000000000000000000000000;;	  # Get default storage backend from manifest file.
0000000000000000000000000000000000000000;;	  local -r default_storage_backend=$(cat "${temp_file}" | \
0000000000000000000000000000000000000000;;	    grep -o "{{ *pillar\.get('storage_backend', '\(.*\)') *}}" | \
0000000000000000000000000000000000000000;;	    sed -e "s@{{ *pillar\.get('storage_backend', '\(.*\)') *}}@\1@g")
0000000000000000000000000000000000000000;;	  if [[ -n "${STORAGE_BACKEND:-}" ]]; then
0000000000000000000000000000000000000000;;	    sed -i -e "s@{{ *pillar\.get('storage_backend', '\(.*\)') *}}@${STORAGE_BACKEND}@g" "${temp_file}"
0000000000000000000000000000000000000000;;	  else
0000000000000000000000000000000000000000;;	    sed -i -e "s@{{ *pillar\.get('storage_backend', '\(.*\)') *}}@\1@g" "${temp_file}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ "${STORAGE_BACKEND:-${default_storage_backend}}" == "etcd3" ]]; then
0000000000000000000000000000000000000000;;	    sed -i -e "s@{{ *quota_bytes *}}@--quota-backend-bytes=4294967296@g" "${temp_file}"
0000000000000000000000000000000000000000;;	  else
0000000000000000000000000000000000000000;;	    sed -i -e "s@{{ *quota_bytes *}}@@g" "${temp_file}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{ *cluster_state *}}@$cluster_state@g" "${temp_file}"
0000000000000000000000000000000000000000;;	  if [[ -n "${ETCD_IMAGE:-}" ]]; then
0000000000000000000000000000000000000000;;	    sed -i -e "s@{{ *pillar\.get('etcd_docker_tag', '\(.*\)') *}}@${ETCD_IMAGE}@g" "${temp_file}"
0000000000000000000000000000000000000000;;	  else
0000000000000000000000000000000000000000;;	    sed -i -e "s@{{ *pillar\.get('etcd_docker_tag', '\(.*\)') *}}@\1@g" "${temp_file}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{ *etcd_protocol *}}@$etcd_protocol@g" "${temp_file}"
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{ *etcd_creds *}}@$etcd_creds@g" "${temp_file}"
0000000000000000000000000000000000000000;;	  if [[ -n "${ETCD_VERSION:-}" ]]; then
0000000000000000000000000000000000000000;;	    sed -i -e "s@{{ *pillar\.get('etcd_version', '\(.*\)') *}}@${ETCD_VERSION}@g" "${temp_file}"
0000000000000000000000000000000000000000;;	  else
0000000000000000000000000000000000000000;;	    sed -i -e "s@{{ *pillar\.get('etcd_version', '\(.*\)') *}}@\1@g" "${temp_file}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  # Replace the volume host path.
0000000000000000000000000000000000000000;;	  sed -i -e "s@/mnt/master-pd/var/etcd@/mnt/disks/master-pd/var/etcd@g" "${temp_file}"
0000000000000000000000000000000000000000;;	  mv "${temp_file}" /etc/kubernetes/manifests
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	function start-etcd-empty-dir-cleanup-pod {
0000000000000000000000000000000000000000;;	  cp "${KUBE_HOME}/kube-manifests/kubernetes/gci-trusty/etcd-empty-dir-cleanup/etcd-empty-dir-cleanup.yaml" "/etc/kubernetes/manifests"
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Starts etcd server pod (and etcd-events pod if needed).
0000000000000000000000000000000000000000;;	# More specifically, it prepares dirs and files, sets the variable value
0000000000000000000000000000000000000000;;	# in the manifests, and copies them to /etc/kubernetes/manifests.
0000000000000000000000000000000000000000;;	function start-etcd-servers {
0000000000000000000000000000000000000000;;	  echo "Start etcd pods"
0000000000000000000000000000000000000000;;	  if [[ -d /etc/etcd ]]; then
0000000000000000000000000000000000000000;;	    rm -rf /etc/etcd
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ -e /etc/default/etcd ]]; then
0000000000000000000000000000000000000000;;	    rm -f /etc/default/etcd
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ -e /etc/systemd/system/etcd.service ]]; then
0000000000000000000000000000000000000000;;	    rm -f /etc/systemd/system/etcd.service
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ -e /etc/init.d/etcd ]]; then
0000000000000000000000000000000000000000;;	    rm -f /etc/init.d/etcd
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  prepare-log-file /var/log/etcd.log
0000000000000000000000000000000000000000;;	  prepare-etcd-manifest "" "2379" "2380" "200m" "etcd.manifest"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  prepare-log-file /var/log/etcd-events.log
0000000000000000000000000000000000000000;;	  prepare-etcd-manifest "-events" "4002" "2381" "100m" "etcd-events.manifest"
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Calculates the following variables based on env variables, which will be used
0000000000000000000000000000000000000000;;	# by the manifests of several kube-master components.
0000000000000000000000000000000000000000;;	#   CLOUD_CONFIG_OPT
0000000000000000000000000000000000000000;;	#   CLOUD_CONFIG_VOLUME
0000000000000000000000000000000000000000;;	#   CLOUD_CONFIG_MOUNT
0000000000000000000000000000000000000000;;	#   DOCKER_REGISTRY
0000000000000000000000000000000000000000;;	function compute-master-manifest-variables {
0000000000000000000000000000000000000000;;	  CLOUD_CONFIG_OPT=""
0000000000000000000000000000000000000000;;	  CLOUD_CONFIG_VOLUME=""
0000000000000000000000000000000000000000;;	  CLOUD_CONFIG_MOUNT=""
0000000000000000000000000000000000000000;;	  if [[ -f /etc/gce.conf ]]; then
0000000000000000000000000000000000000000;;	    CLOUD_CONFIG_OPT="--cloud-config=/etc/gce.conf"
0000000000000000000000000000000000000000;;	    CLOUD_CONFIG_VOLUME="{\"name\": \"cloudconfigmount\",\"hostPath\": {\"path\": \"/etc/gce.conf\"}},"
0000000000000000000000000000000000000000;;	    CLOUD_CONFIG_MOUNT="{\"name\": \"cloudconfigmount\",\"mountPath\": \"/etc/gce.conf\", \"readOnly\": true},"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  DOCKER_REGISTRY="gcr.io/google_containers"
0000000000000000000000000000000000000000;;	  if [[ -n "${KUBE_DOCKER_REGISTRY:-}" ]]; then
0000000000000000000000000000000000000000;;	    DOCKER_REGISTRY="${KUBE_DOCKER_REGISTRY}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# A helper function that bind mounts kubelet dirs for running mount in a chroot
0000000000000000000000000000000000000000;;	function prepare-mounter-rootfs {
0000000000000000000000000000000000000000;;	  echo "Prepare containerized mounter"
0000000000000000000000000000000000000000;;	  mount --bind "${CONTAINERIZED_MOUNTER_HOME}" "${CONTAINERIZED_MOUNTER_HOME}"
0000000000000000000000000000000000000000;;	  mount -o remount,exec "${CONTAINERIZED_MOUNTER_HOME}"
0000000000000000000000000000000000000000;;	  CONTAINERIZED_MOUNTER_ROOTFS="${CONTAINERIZED_MOUNTER_HOME}/rootfs"
0000000000000000000000000000000000000000;;	  mount --rbind /var/lib/kubelet/ "${CONTAINERIZED_MOUNTER_ROOTFS}/var/lib/kubelet"
0000000000000000000000000000000000000000;;	  mount --make-rshared "${CONTAINERIZED_MOUNTER_ROOTFS}/var/lib/kubelet"
0000000000000000000000000000000000000000;;	  mount --bind -o ro /proc "${CONTAINERIZED_MOUNTER_ROOTFS}/proc"
0000000000000000000000000000000000000000;;	  mount --bind -o ro /dev "${CONTAINERIZED_MOUNTER_ROOTFS}/dev"
0000000000000000000000000000000000000000;;	  mount --bind -o ro /etc/resolv.conf "${CONTAINERIZED_MOUNTER_ROOTFS}/etc/resolv.conf"
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# A helper function for removing salt configuration and comments from a file.
0000000000000000000000000000000000000000;;	# This is mainly for preparing a manifest file.
0000000000000000000000000000000000000000;;	#
0000000000000000000000000000000000000000;;	# $1: Full path of the file to manipulate
0000000000000000000000000000000000000000;;	function remove-salt-config-comments {
0000000000000000000000000000000000000000;;	  # Remove salt configuration.
0000000000000000000000000000000000000000;;	  sed -i "/^[ |\t]*{[#|%]/d" $1
0000000000000000000000000000000000000000;;	  # Remove comments.
0000000000000000000000000000000000000000;;	  sed -i "/^[ |\t]*#/d" $1
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Starts kubernetes apiserver.
0000000000000000000000000000000000000000;;	# It prepares the log file, loads the docker image, calculates variables, sets them
0000000000000000000000000000000000000000;;	# in the manifest file, and then copies the manifest file to /etc/kubernetes/manifests.
0000000000000000000000000000000000000000;;	#
0000000000000000000000000000000000000000;;	# Assumed vars (which are calculated in function compute-master-manifest-variables)
0000000000000000000000000000000000000000;;	#   CLOUD_CONFIG_OPT
0000000000000000000000000000000000000000;;	#   CLOUD_CONFIG_VOLUME
0000000000000000000000000000000000000000;;	#   CLOUD_CONFIG_MOUNT
0000000000000000000000000000000000000000;;	#   DOCKER_REGISTRY
0000000000000000000000000000000000000000;;	function start-kube-apiserver {
0000000000000000000000000000000000000000;;	  echo "Start kubernetes api-server"
0000000000000000000000000000000000000000;;	  prepare-log-file /var/log/kube-apiserver.log
0000000000000000000000000000000000000000;;	  prepare-log-file /var/log/kube-apiserver-audit.log
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  # Calculate variables and assemble the command line.
0000000000000000000000000000000000000000;;	  local params="${API_SERVER_TEST_LOG_LEVEL:-"--v=2"} ${APISERVER_TEST_ARGS:-} ${CLOUD_CONFIG_OPT}"
0000000000000000000000000000000000000000;;	  params+=" --address=127.0.0.1"
0000000000000000000000000000000000000000;;	  params+=" --allow-privileged=true"
0000000000000000000000000000000000000000;;	  params+=" --cloud-provider=gce"
0000000000000000000000000000000000000000;;	  params+=" --client-ca-file=${CA_CERT_BUNDLE_PATH}"
0000000000000000000000000000000000000000;;	  params+=" --etcd-servers=http://127.0.0.1:2379"
0000000000000000000000000000000000000000;;	  params+=" --etcd-servers-overrides=/events#http://127.0.0.1:4002"
0000000000000000000000000000000000000000;;	  params+=" --secure-port=443"
0000000000000000000000000000000000000000;;	  params+=" --tls-cert-file=${APISERVER_SERVER_CERT_PATH}"
0000000000000000000000000000000000000000;;	  params+=" --tls-private-key-file=${APISERVER_SERVER_KEY_PATH}"
0000000000000000000000000000000000000000;;	  if [[ ! -z "${REQUESTHEADER_CA_CERT:-}" ]]; then
0000000000000000000000000000000000000000;;	    params+=" --requestheader-client-ca-file=${REQUESTHEADER_CA_CERT_PATH}"
0000000000000000000000000000000000000000;;	    params+=" --requestheader-allowed-names=aggregator"
0000000000000000000000000000000000000000;;	    params+=" --requestheader-extra-headers-prefix=X-Remote-Extra-"
0000000000000000000000000000000000000000;;	    params+=" --requestheader-group-headers=X-Remote-Group"
0000000000000000000000000000000000000000;;	    params+=" --requestheader-username-headers=X-Remote-User"
0000000000000000000000000000000000000000;;	    params+=" --proxy-client-cert-file=${PROXY_CLIENT_CERT_PATH}"
0000000000000000000000000000000000000000;;	    params+=" --proxy-client-key-file=${PROXY_CLIENT_KEY_PATH}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  params+=" --enable-aggregator-routing=true"
0000000000000000000000000000000000000000;;	  if [[ -e "${APISERVER_CLIENT_CERT_PATH}" ]] && [[ -e "${APISERVER_CLIENT_KEY_PATH}" ]]; then
0000000000000000000000000000000000000000;;	    params+=" --kubelet-client-certificate=${APISERVER_CLIENT_CERT_PATH}"
0000000000000000000000000000000000000000;;	    params+=" --kubelet-client-key=${APISERVER_CLIENT_KEY_PATH}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ -n "${SERVICEACCOUNT_CERT_PATH:-}" ]]; then
0000000000000000000000000000000000000000;;	    params+=" --service-account-key-file=${SERVICEACCOUNT_CERT_PATH}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  params+=" --token-auth-file=/etc/srv/kubernetes/known_tokens.csv"
0000000000000000000000000000000000000000;;	  if [[ -n "${KUBE_PASSWORD:-}" && -n "${KUBE_USER:-}" ]]; then
0000000000000000000000000000000000000000;;	    params+=" --basic-auth-file=/etc/srv/kubernetes/basic_auth.csv"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ -n "${STORAGE_BACKEND:-}" ]]; then
0000000000000000000000000000000000000000;;	    params+=" --storage-backend=${STORAGE_BACKEND}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ -n "${STORAGE_MEDIA_TYPE:-}" ]]; then
0000000000000000000000000000000000000000;;	    params+=" --storage-media-type=${STORAGE_MEDIA_TYPE}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ -n "${ENABLE_GARBAGE_COLLECTOR:-}" ]]; then
0000000000000000000000000000000000000000;;	    params+=" --enable-garbage-collector=${ENABLE_GARBAGE_COLLECTOR}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ -n "${NUM_NODES:-}" ]]; then
0000000000000000000000000000000000000000;;	    # If the cluster is large, increase max-requests-inflight limit in apiserver.
0000000000000000000000000000000000000000;;	    if [[ "${NUM_NODES}" -ge 1000 ]]; then
0000000000000000000000000000000000000000;;	      params+=" --max-requests-inflight=1500 --max-mutating-requests-inflight=500"
0000000000000000000000000000000000000000;;	    fi
0000000000000000000000000000000000000000;;	    # Set amount of memory available for apiserver based on number of nodes.
0000000000000000000000000000000000000000;;	    # TODO: Once we start setting proper requests and limits for apiserver
0000000000000000000000000000000000000000;;	    # we should reuse the same logic here instead of current heuristic.
0000000000000000000000000000000000000000;;	    params+=" --target-ram-mb=$((${NUM_NODES} * 60))"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ -n "${SERVICE_CLUSTER_IP_RANGE:-}" ]]; then
0000000000000000000000000000000000000000;;	    params+=" --service-cluster-ip-range=${SERVICE_CLUSTER_IP_RANGE}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ -n "${ETCD_QUORUM_READ:-}" ]]; then
0000000000000000000000000000000000000000;;	    params+=" --etcd-quorum-read=${ETCD_QUORUM_READ}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  local audit_policy_config_mount=""
0000000000000000000000000000000000000000;;	  local audit_policy_config_volume=""
0000000000000000000000000000000000000000;;	  local audit_webhook_config_mount=""
0000000000000000000000000000000000000000;;	  local audit_webhook_config_volume=""
0000000000000000000000000000000000000000;;	  if [[ "${ENABLE_APISERVER_BASIC_AUDIT:-}" == "true" ]]; then
0000000000000000000000000000000000000000;;	    # We currently only support enabling with a fixed path and with built-in log
0000000000000000000000000000000000000000;;	    # rotation "disabled" (large value) so it behaves like kube-apiserver.log.
0000000000000000000000000000000000000000;;	    # External log rotation should be set up the same as for kube-apiserver.log.
0000000000000000000000000000000000000000;;	    params+=" --audit-log-path=/var/log/kube-apiserver-audit.log"
0000000000000000000000000000000000000000;;	    params+=" --audit-log-maxage=0"
0000000000000000000000000000000000000000;;	    params+=" --audit-log-maxbackup=0"
0000000000000000000000000000000000000000;;	    # Lumberjack doesn't offer any way to disable size-based rotation. It also
0000000000000000000000000000000000000000;;	    # has an in-memory counter that doesn't notice if you truncate the file.
0000000000000000000000000000000000000000;;	    # 2000000000 (in MiB) is a large number that fits in 31 bits. If the log
0000000000000000000000000000000000000000;;	    # grows at 10MiB/s (~30K QPS), it will rotate after ~6 years if apiserver
0000000000000000000000000000000000000000;;	    # never restarts. Please manually restart apiserver before this time.
0000000000000000000000000000000000000000;;	    params+=" --audit-log-maxsize=2000000000"
0000000000000000000000000000000000000000;;	  elif [[ "${ENABLE_APISERVER_ADVANCED_AUDIT:-}" == "true" ]]; then
0000000000000000000000000000000000000000;;	    local -r audit_policy_file="/etc/audit_policy.config"
0000000000000000000000000000000000000000;;	    params+=" --audit-policy-file=${audit_policy_file}"
0000000000000000000000000000000000000000;;	    # Create the audit policy file, and mount it into the apiserver pod.
0000000000000000000000000000000000000000;;	    create-master-audit-policy "${audit_policy_file}"
0000000000000000000000000000000000000000;;	    audit_policy_config_mount="{\"name\": \"auditpolicyconfigmount\",\"mountPath\": \"${audit_policy_file}\", \"readOnly\": true},"
0000000000000000000000000000000000000000;;	    audit_policy_config_volume="{\"name\": \"auditpolicyconfigmount\",\"hostPath\": {\"path\": \"${audit_policy_file}\"}},"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	    if [[ "${ADVANCED_AUDIT_BACKEND:-log}" == *"log"* ]]; then
0000000000000000000000000000000000000000;;	      # The advanced audit log backend config matches the basic audit log config.
0000000000000000000000000000000000000000;;	      params+=" --audit-log-path=/var/log/kube-apiserver-audit.log"
0000000000000000000000000000000000000000;;	      params+=" --audit-log-maxage=0"
0000000000000000000000000000000000000000;;	      params+=" --audit-log-maxbackup=0"
0000000000000000000000000000000000000000;;	      # Lumberjack doesn't offer any way to disable size-based rotation. It also
0000000000000000000000000000000000000000;;	      # has an in-memory counter that doesn't notice if you truncate the file.
0000000000000000000000000000000000000000;;	      # 2000000000 (in MiB) is a large number that fits in 31 bits. If the log
0000000000000000000000000000000000000000;;	      # grows at 10MiB/s (~30K QPS), it will rotate after ~6 years if apiserver
0000000000000000000000000000000000000000;;	      # never restarts. Please manually restart apiserver before this time.
0000000000000000000000000000000000000000;;	      params+=" --audit-log-maxsize=2000000000"
0000000000000000000000000000000000000000;;	    fi
0000000000000000000000000000000000000000;;	    if [[ "${ADVANCED_AUDIT_BACKEND:-}" == *"webhook"* ]]; then
0000000000000000000000000000000000000000;;	      params+=" --audit-webhook-mode=batch"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	      # Create the audit webhook config file, and mount it into the apiserver pod.
0000000000000000000000000000000000000000;;	      local -r audit_webhook_config_file="/etc/audit_webhook.config"
0000000000000000000000000000000000000000;;	      params+=" --audit-webhook-config-file=${audit_webhook_config_file}"
0000000000000000000000000000000000000000;;	      create-master-audit-webhook-config "${audit_webhook_config_file}"
0000000000000000000000000000000000000000;;	      audit_webhook_config_mount="{\"name\": \"auditwebhookconfigmount\",\"mountPath\": \"${audit_webhook_config_file}\", \"readOnly\": true},"
0000000000000000000000000000000000000000;;	      audit_webhook_config_volume="{\"name\": \"auditwebhookconfigmount\",\"hostPath\": {\"path\": \"${audit_webhook_config_file}\"}},"
0000000000000000000000000000000000000000;;	    fi
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  if [[ "${ENABLE_APISERVER_LOGS_HANDLER:-}" == "false" ]]; then
0000000000000000000000000000000000000000;;	    params+=" --enable-logs-handler=false"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  local admission_controller_config_mount=""
0000000000000000000000000000000000000000;;	  local admission_controller_config_volume=""
0000000000000000000000000000000000000000;;	  local image_policy_webhook_config_mount=""
0000000000000000000000000000000000000000;;	  local image_policy_webhook_config_volume=""
0000000000000000000000000000000000000000;;	  if [[ -n "${ADMISSION_CONTROL:-}" ]]; then
0000000000000000000000000000000000000000;;	    params+=" --admission-control=${ADMISSION_CONTROL}"
0000000000000000000000000000000000000000;;	    if [[ ${ADMISSION_CONTROL} == *"ImagePolicyWebhook"* ]]; then
0000000000000000000000000000000000000000;;	      params+=" --admission-control-config-file=/etc/admission_controller.config"
0000000000000000000000000000000000000000;;	      # Mount the file to configure admission controllers if ImagePolicyWebhook is set.
0000000000000000000000000000000000000000;;	      admission_controller_config_mount="{\"name\": \"admissioncontrollerconfigmount\",\"mountPath\": \"/etc/admission_controller.config\", \"readOnly\": false},"
0000000000000000000000000000000000000000;;	      admission_controller_config_volume="{\"name\": \"admissioncontrollerconfigmount\",\"hostPath\": {\"path\": \"/etc/admission_controller.config\"}},"
0000000000000000000000000000000000000000;;	      # Mount the file to configure the ImagePolicyWebhook's webhook.
0000000000000000000000000000000000000000;;	      image_policy_webhook_config_mount="{\"name\": \"imagepolicywebhookconfigmount\",\"mountPath\": \"/etc/gcp_image_review.config\", \"readOnly\": false},"
0000000000000000000000000000000000000000;;	      image_policy_webhook_config_volume="{\"name\": \"imagepolicywebhookconfigmount\",\"hostPath\": {\"path\": \"/etc/gcp_image_review.config\"}},"
0000000000000000000000000000000000000000;;	    fi
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  if [[ -n "${KUBE_APISERVER_REQUEST_TIMEOUT:-}" ]]; then
0000000000000000000000000000000000000000;;	    params+=" --min-request-timeout=${KUBE_APISERVER_REQUEST_TIMEOUT}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ -n "${RUNTIME_CONFIG:-}" ]]; then
0000000000000000000000000000000000000000;;	    params+=" --runtime-config=${RUNTIME_CONFIG}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ -n "${FEATURE_GATES:-}" ]]; then
0000000000000000000000000000000000000000;;	    params+=" --feature-gates=${FEATURE_GATES}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ -n "${PROJECT_ID:-}" && -n "${TOKEN_URL:-}" && -n "${TOKEN_BODY:-}" && -n "${NODE_NETWORK:-}" ]]; then
0000000000000000000000000000000000000000;;	    local -r vm_external_ip=$(curl --retry 5 --retry-delay 3 --fail --silent -H 'Metadata-Flavor: Google' "http://metadata/computeMetadata/v1/instance/network-interfaces/0/access-configs/0/external-ip")
0000000000000000000000000000000000000000;;	    params+=" --advertise-address=${vm_external_ip}"
0000000000000000000000000000000000000000;;	    params+=" --ssh-user=${PROXY_SSH_USER}"
0000000000000000000000000000000000000000;;	    params+=" --ssh-keyfile=/etc/srv/sshproxy/.sshkeyfile"
0000000000000000000000000000000000000000;;	  elif [ -n "${MASTER_ADVERTISE_ADDRESS:-}" ]; then
0000000000000000000000000000000000000000;;	    params="${params} --advertise-address=${MASTER_ADVERTISE_ADDRESS}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  local webhook_authn_config_mount=""
0000000000000000000000000000000000000000;;	  local webhook_authn_config_volume=""
0000000000000000000000000000000000000000;;	  if [[ -n "${GCP_AUTHN_URL:-}" ]]; then
0000000000000000000000000000000000000000;;	    params+=" --authentication-token-webhook-config-file=/etc/gcp_authn.config"
0000000000000000000000000000000000000000;;	    webhook_authn_config_mount="{\"name\": \"webhookauthnconfigmount\",\"mountPath\": \"/etc/gcp_authn.config\", \"readOnly\": false},"
0000000000000000000000000000000000000000;;	    webhook_authn_config_volume="{\"name\": \"webhookauthnconfigmount\",\"hostPath\": {\"path\": \"/etc/gcp_authn.config\"}},"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  local authorization_mode="Node,RBAC"
0000000000000000000000000000000000000000;;	  local -r src_dir="${KUBE_HOME}/kube-manifests/kubernetes/gci-trusty"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  # Enable ABAC mode unless the user explicitly opts out with ENABLE_LEGACY_ABAC=false
0000000000000000000000000000000000000000;;	  if [[ "${ENABLE_LEGACY_ABAC:-}" != "false" ]]; then
0000000000000000000000000000000000000000;;	    echo "Warning: Enabling legacy ABAC policy. All service accounts will have superuser API access. Set ENABLE_LEGACY_ABAC=false to disable this."
0000000000000000000000000000000000000000;;	    # Create the ABAC file if it doesn't exist yet, or if we have a KUBE_USER set (to ensure the right user is given permissions)
0000000000000000000000000000000000000000;;	    if [[ -n "${KUBE_USER:-}" || ! -e /etc/srv/kubernetes/abac-authz-policy.jsonl ]]; then
0000000000000000000000000000000000000000;;	      local -r abac_policy_json="${src_dir}/abac-authz-policy.jsonl"
0000000000000000000000000000000000000000;;	      remove-salt-config-comments "${abac_policy_json}"
0000000000000000000000000000000000000000;;	      if [[ -n "${KUBE_USER:-}" ]]; then
0000000000000000000000000000000000000000;;	        sed -i -e "s/{{kube_user}}/${KUBE_USER}/g" "${abac_policy_json}"
0000000000000000000000000000000000000000;;	      else
0000000000000000000000000000000000000000;;	        sed -i -e "/{{kube_user}}/d" "${abac_policy_json}"
0000000000000000000000000000000000000000;;	      fi
0000000000000000000000000000000000000000;;	      cp "${abac_policy_json}" /etc/srv/kubernetes/
0000000000000000000000000000000000000000;;	    fi
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	    params+=" --authorization-policy-file=/etc/srv/kubernetes/abac-authz-policy.jsonl"
0000000000000000000000000000000000000000;;	    authorization_mode+=",ABAC"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  local webhook_config_mount=""
0000000000000000000000000000000000000000;;	  local webhook_config_volume=""
0000000000000000000000000000000000000000;;	  if [[ -n "${GCP_AUTHZ_URL:-}" ]]; then
0000000000000000000000000000000000000000;;	    authorization_mode+=",Webhook"
0000000000000000000000000000000000000000;;	    params+=" --authorization-webhook-config-file=/etc/gcp_authz.config"
0000000000000000000000000000000000000000;;	    webhook_config_mount="{\"name\": \"webhookconfigmount\",\"mountPath\": \"/etc/gcp_authz.config\", \"readOnly\": false},"
0000000000000000000000000000000000000000;;	    webhook_config_volume="{\"name\": \"webhookconfigmount\",\"hostPath\": {\"path\": \"/etc/gcp_authz.config\"}},"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  params+=" --authorization-mode=${authorization_mode}"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  local container_env=""
0000000000000000000000000000000000000000;;	  if [[ -n "${ENABLE_CACHE_MUTATION_DETECTOR:-}" ]]; then
0000000000000000000000000000000000000000;;	    container_env="\"name\": \"KUBE_CACHE_MUTATION_DETECTOR\", \"value\": \"${ENABLE_CACHE_MUTATION_DETECTOR}\""
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ -n "${ENABLE_PATCH_CONVERSION_DETECTOR:-}" ]]; then
0000000000000000000000000000000000000000;;	    if [[ -n "${container_env}" ]]; then
0000000000000000000000000000000000000000;;	      container_env="${container_env}, "
0000000000000000000000000000000000000000;;	    fi
0000000000000000000000000000000000000000;;	    container_env="\"name\": \"KUBE_PATCH_CONVERSION_DETECTOR\", \"value\": \"${ENABLE_PATCH_CONVERSION_DETECTOR}\""
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ -n "${container_env}" ]]; then
0000000000000000000000000000000000000000;;	    container_env="\"env\":[{${container_env}}],"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  if [[ -n "${ENCRYPTION_PROVIDER_CONFIG:-}" ]]; then
0000000000000000000000000000000000000000;;	    local encryption_provider_config_path="/etc/srv/kubernetes/encryption-provider-config.yml"
0000000000000000000000000000000000000000;;	    echo "${ENCRYPTION_PROVIDER_CONFIG}" | base64 --decode > "${encryption_provider_config_path}"
0000000000000000000000000000000000000000;;	    params+=" --experimental-encryption-provider-config=${encryption_provider_config_path}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  src_file="${src_dir}/kube-apiserver.manifest"
0000000000000000000000000000000000000000;;	  remove-salt-config-comments "${src_file}"
0000000000000000000000000000000000000000;;	  # Evaluate variables.
0000000000000000000000000000000000000000;;	  local -r kube_apiserver_docker_tag=$(cat /home/kubernetes/kube-docker-files/kube-apiserver.docker_tag)
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{params}}@${params}@g" "${src_file}"
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{container_env}}@${container_env}@g" ${src_file}
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{srv_kube_path}}@/etc/srv/kubernetes@g" "${src_file}"
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{srv_sshproxy_path}}@/etc/srv/sshproxy@g" "${src_file}"
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{cloud_config_mount}}@${CLOUD_CONFIG_MOUNT}@g" "${src_file}"
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{cloud_config_volume}}@${CLOUD_CONFIG_VOLUME}@g" "${src_file}"
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{pillar\['kube_docker_registry'\]}}@${DOCKER_REGISTRY}@g" "${src_file}"
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{pillar\['kube-apiserver_docker_tag'\]}}@${kube_apiserver_docker_tag}@g" "${src_file}"
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{pillar\['allow_privileged'\]}}@true@g" "${src_file}"
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{secure_port}}@443@g" "${src_file}"
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{secure_port}}@8080@g" "${src_file}"
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{additional_cloud_config_mount}}@@g" "${src_file}"
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{additional_cloud_config_volume}}@@g" "${src_file}"
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{webhook_authn_config_mount}}@${webhook_authn_config_mount}@g" "${src_file}"
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{webhook_authn_config_volume}}@${webhook_authn_config_volume}@g" "${src_file}"
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{webhook_config_mount}}@${webhook_config_mount}@g" "${src_file}"
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{webhook_config_volume}}@${webhook_config_volume}@g" "${src_file}"
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{audit_policy_config_mount}}@${audit_policy_config_mount}@g" "${src_file}"
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{audit_policy_config_volume}}@${audit_policy_config_volume}@g" "${src_file}"
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{audit_webhook_config_mount}}@${audit_webhook_config_mount}@g" "${src_file}"
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{audit_webhook_config_volume}}@${audit_webhook_config_volume}@g" "${src_file}"
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{admission_controller_config_mount}}@${admission_controller_config_mount}@g" "${src_file}"
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{admission_controller_config_volume}}@${admission_controller_config_volume}@g" "${src_file}"
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{image_policy_webhook_config_mount}}@${image_policy_webhook_config_mount}@g" "${src_file}"
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{image_policy_webhook_config_volume}}@${image_policy_webhook_config_volume}@g" "${src_file}"
0000000000000000000000000000000000000000;;	  cp "${src_file}" /etc/kubernetes/manifests
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Starts kubernetes controller manager.
0000000000000000000000000000000000000000;;	# It prepares the log file, loads the docker image, calculates variables, sets them
0000000000000000000000000000000000000000;;	# in the manifest file, and then copies the manifest file to /etc/kubernetes/manifests.
0000000000000000000000000000000000000000;;	#
0000000000000000000000000000000000000000;;	# Assumed vars (which are calculated in function compute-master-manifest-variables)
0000000000000000000000000000000000000000;;	#   CLOUD_CONFIG_OPT
0000000000000000000000000000000000000000;;	#   CLOUD_CONFIG_VOLUME
0000000000000000000000000000000000000000;;	#   CLOUD_CONFIG_MOUNT
0000000000000000000000000000000000000000;;	#   DOCKER_REGISTRY
0000000000000000000000000000000000000000;;	function start-kube-controller-manager {
0000000000000000000000000000000000000000;;	  echo "Start kubernetes controller-manager"
0000000000000000000000000000000000000000;;	  create-kubecontrollermanager-kubeconfig
0000000000000000000000000000000000000000;;	  prepare-log-file /var/log/kube-controller-manager.log
0000000000000000000000000000000000000000;;	  # Calculate variables and assemble the command line.
0000000000000000000000000000000000000000;;	  local params="${CONTROLLER_MANAGER_TEST_LOG_LEVEL:-"--v=2"} ${CONTROLLER_MANAGER_TEST_ARGS:-} ${CLOUD_CONFIG_OPT}"
0000000000000000000000000000000000000000;;	  params+=" --use-service-account-credentials"
0000000000000000000000000000000000000000;;	  params+=" --cloud-provider=gce"
0000000000000000000000000000000000000000;;	  params+=" --kubeconfig=/etc/srv/kubernetes/kube-controller-manager/kubeconfig"
0000000000000000000000000000000000000000;;	  params+=" --root-ca-file=${CA_CERT_BUNDLE_PATH}"
0000000000000000000000000000000000000000;;	  params+=" --service-account-private-key-file=${SERVICEACCOUNT_KEY_PATH}"
0000000000000000000000000000000000000000;;	  if [[ -n "${ENABLE_GARBAGE_COLLECTOR:-}" ]]; then
0000000000000000000000000000000000000000;;	    params+=" --enable-garbage-collector=${ENABLE_GARBAGE_COLLECTOR}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ -n "${INSTANCE_PREFIX:-}" ]]; then
0000000000000000000000000000000000000000;;	    params+=" --cluster-name=${INSTANCE_PREFIX}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ -n "${CLUSTER_IP_RANGE:-}" ]]; then
0000000000000000000000000000000000000000;;	    params+=" --cluster-cidr=${CLUSTER_IP_RANGE}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ -n "${CA_KEY:-}" ]]; then
0000000000000000000000000000000000000000;;	    params+=" --cluster-signing-cert-file=${CA_CERT_PATH}"
0000000000000000000000000000000000000000;;	    params+=" --cluster-signing-key-file=${CA_KEY_PATH}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ -n "${SERVICE_CLUSTER_IP_RANGE:-}" ]]; then
0000000000000000000000000000000000000000;;	    params+=" --service-cluster-ip-range=${SERVICE_CLUSTER_IP_RANGE}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ "${NETWORK_PROVIDER:-}" == "kubenet" ]]; then
0000000000000000000000000000000000000000;;	    params+=" --allocate-node-cidrs=true"
0000000000000000000000000000000000000000;;	  elif [[ -n "${ALLOCATE_NODE_CIDRS:-}" ]]; then
0000000000000000000000000000000000000000;;	    params+=" --allocate-node-cidrs=${ALLOCATE_NODE_CIDRS}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ -n "${TERMINATED_POD_GC_THRESHOLD:-}" ]]; then
0000000000000000000000000000000000000000;;	    params+=" --terminated-pod-gc-threshold=${TERMINATED_POD_GC_THRESHOLD}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ "${ENABLE_IP_ALIASES:-}" == 'true' ]]; then
0000000000000000000000000000000000000000;;	    params+=" --cidr-allocator-type=CloudAllocator"
0000000000000000000000000000000000000000;;	    params+=" --configure-cloud-routes=false"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ -n "${FEATURE_GATES:-}" ]]; then
0000000000000000000000000000000000000000;;	    params+=" --feature-gates=${FEATURE_GATES}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  local -r kube_rc_docker_tag=$(cat /home/kubernetes/kube-docker-files/kube-controller-manager.docker_tag)
0000000000000000000000000000000000000000;;	  local container_env=""
0000000000000000000000000000000000000000;;	  if [[ -n "${ENABLE_CACHE_MUTATION_DETECTOR:-}" ]]; then
0000000000000000000000000000000000000000;;	    container_env="\"env\":[{\"name\": \"KUBE_CACHE_MUTATION_DETECTOR\", \"value\": \"${ENABLE_CACHE_MUTATION_DETECTOR}\"}],"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  local -r src_file="${KUBE_HOME}/kube-manifests/kubernetes/gci-trusty/kube-controller-manager.manifest"
0000000000000000000000000000000000000000;;	  remove-salt-config-comments "${src_file}"
0000000000000000000000000000000000000000;;	  # Evaluate variables.
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{srv_kube_path}}@/etc/srv/kubernetes@g" "${src_file}"
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{pillar\['kube_docker_registry'\]}}@${DOCKER_REGISTRY}@g" "${src_file}"
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{pillar\['kube-controller-manager_docker_tag'\]}}@${kube_rc_docker_tag}@g" "${src_file}"
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{params}}@${params}@g" "${src_file}"
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{container_env}}@${container_env}@g" ${src_file}
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{cloud_config_mount}}@${CLOUD_CONFIG_MOUNT}@g" "${src_file}"
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{cloud_config_volume}}@${CLOUD_CONFIG_VOLUME}@g" "${src_file}"
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{additional_cloud_config_mount}}@@g" "${src_file}"
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{additional_cloud_config_volume}}@@g" "${src_file}"
0000000000000000000000000000000000000000;;	  cp "${src_file}" /etc/kubernetes/manifests
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Starts kubernetes scheduler.
0000000000000000000000000000000000000000;;	# It prepares the log file, loads the docker image, calculates variables, sets them
0000000000000000000000000000000000000000;;	# in the manifest file, and then copies the manifest file to /etc/kubernetes/manifests.
0000000000000000000000000000000000000000;;	#
0000000000000000000000000000000000000000;;	# Assumed vars (which are calculated in compute-master-manifest-variables)
0000000000000000000000000000000000000000;;	#   DOCKER_REGISTRY
0000000000000000000000000000000000000000;;	function start-kube-scheduler {
0000000000000000000000000000000000000000;;	  echo "Start kubernetes scheduler"
0000000000000000000000000000000000000000;;	  create-kubescheduler-kubeconfig
0000000000000000000000000000000000000000;;	  prepare-log-file /var/log/kube-scheduler.log
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  # Calculate variables and set them in the manifest.
0000000000000000000000000000000000000000;;	  params="${SCHEDULER_TEST_LOG_LEVEL:-"--v=2"} ${SCHEDULER_TEST_ARGS:-}"
0000000000000000000000000000000000000000;;	  params+=" --kubeconfig=/etc/srv/kubernetes/kube-scheduler/kubeconfig"
0000000000000000000000000000000000000000;;	  if [[ -n "${FEATURE_GATES:-}" ]]; then
0000000000000000000000000000000000000000;;	    params+=" --feature-gates=${FEATURE_GATES}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ -n "${SCHEDULING_ALGORITHM_PROVIDER:-}"  ]]; then
0000000000000000000000000000000000000000;;	    params+=" --algorithm-provider=${SCHEDULING_ALGORITHM_PROVIDER}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  local -r kube_scheduler_docker_tag=$(cat "${KUBE_HOME}/kube-docker-files/kube-scheduler.docker_tag")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  # Remove salt comments and replace variables with values.
0000000000000000000000000000000000000000;;	  local -r src_file="${KUBE_HOME}/kube-manifests/kubernetes/gci-trusty/kube-scheduler.manifest"
0000000000000000000000000000000000000000;;	  remove-salt-config-comments "${src_file}"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{srv_kube_path}}@/etc/srv/kubernetes@g" "${src_file}"
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{params}}@${params}@g" "${src_file}"
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{pillar\['kube_docker_registry'\]}}@${DOCKER_REGISTRY}@g" "${src_file}"
0000000000000000000000000000000000000000;;	  sed -i -e "s@{{pillar\['kube-scheduler_docker_tag'\]}}@${kube_scheduler_docker_tag}@g" "${src_file}"
0000000000000000000000000000000000000000;;	  cp "${src_file}" /etc/kubernetes/manifests
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Starts cluster autoscaler.
0000000000000000000000000000000000000000;;	# Assumed vars (which are calculated in function compute-master-manifest-variables)
0000000000000000000000000000000000000000;;	#   CLOUD_CONFIG_OPT
0000000000000000000000000000000000000000;;	#   CLOUD_CONFIG_VOLUME
0000000000000000000000000000000000000000;;	#   CLOUD_CONFIG_MOUNT
0000000000000000000000000000000000000000;;	function start-cluster-autoscaler {
0000000000000000000000000000000000000000;;	  if [[ "${ENABLE_CLUSTER_AUTOSCALER:-}" == "true" ]]; then
0000000000000000000000000000000000000000;;	    echo "Start kubernetes cluster autoscaler"
0000000000000000000000000000000000000000;;	    prepare-log-file /var/log/cluster-autoscaler.log
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	    # Remove salt comments and replace variables with values
0000000000000000000000000000000000000000;;	    local -r src_file="${KUBE_HOME}/kube-manifests/kubernetes/gci-trusty/cluster-autoscaler.manifest"
0000000000000000000000000000000000000000;;	    remove-salt-config-comments "${src_file}"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	    local params="${AUTOSCALER_MIG_CONFIG} ${CLOUD_CONFIG_OPT} ${AUTOSCALER_EXPANDER_CONFIG:-}"
0000000000000000000000000000000000000000;;	    sed -i -e "s@{{params}}@${params}@g" "${src_file}"
0000000000000000000000000000000000000000;;	    sed -i -e "s@{{cloud_config_mount}}@${CLOUD_CONFIG_MOUNT}@g" "${src_file}"
0000000000000000000000000000000000000000;;	    sed -i -e "s@{{cloud_config_volume}}@${CLOUD_CONFIG_VOLUME}@g" "${src_file}"
0000000000000000000000000000000000000000;;	    sed -i -e "s@{%.*%}@@g" "${src_file}"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	    cp "${src_file}" /etc/kubernetes/manifests
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# A helper function for copying addon manifests and set dir/files
0000000000000000000000000000000000000000;;	# permissions.
0000000000000000000000000000000000000000;;	#
0000000000000000000000000000000000000000;;	# $1: addon category under /etc/kubernetes
0000000000000000000000000000000000000000;;	# $2: manifest source dir
0000000000000000000000000000000000000000;;	function setup-addon-manifests {
0000000000000000000000000000000000000000;;	  local -r src_dir="${KUBE_HOME}/kube-manifests/kubernetes/gci-trusty/$2"
0000000000000000000000000000000000000000;;	  local -r dst_dir="/etc/kubernetes/$1/$2"
0000000000000000000000000000000000000000;;	  if [[ ! -d "${dst_dir}" ]]; then
0000000000000000000000000000000000000000;;	    mkdir -p "${dst_dir}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  local files=$(find "${src_dir}" -maxdepth 1 -name "*.yaml")
0000000000000000000000000000000000000000;;	  if [[ -n "${files}" ]]; then
0000000000000000000000000000000000000000;;	    cp "${src_dir}/"*.yaml "${dst_dir}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  files=$(find "${src_dir}" -maxdepth 1 -name "*.json")
0000000000000000000000000000000000000000;;	  if [[ -n "${files}" ]]; then
0000000000000000000000000000000000000000;;	    cp "${src_dir}/"*.json "${dst_dir}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  files=$(find "${src_dir}" -maxdepth 1 -name "*.yaml.in")
0000000000000000000000000000000000000000;;	  if [[ -n "${files}" ]]; then
0000000000000000000000000000000000000000;;	    cp "${src_dir}/"*.yaml.in "${dst_dir}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  chown -R root:root "${dst_dir}"
0000000000000000000000000000000000000000;;	  chmod 755 "${dst_dir}"
0000000000000000000000000000000000000000;;	  chmod 644 "${dst_dir}"/*
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Prepares the manifests of k8s addons, and starts the addon manager.
0000000000000000000000000000000000000000;;	# Vars assumed:
0000000000000000000000000000000000000000;;	#   CLUSTER_NAME
0000000000000000000000000000000000000000;;	function start-kube-addons {
0000000000000000000000000000000000000000;;	  echo "Prepare kube-addons manifests and start kube addon manager"
0000000000000000000000000000000000000000;;	  local -r src_dir="${KUBE_HOME}/kube-manifests/kubernetes/gci-trusty"
0000000000000000000000000000000000000000;;	  local -r dst_dir="/etc/kubernetes/addons"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  # prep addition kube-up specific rbac objects
0000000000000000000000000000000000000000;;	  setup-addon-manifests "addons" "rbac"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  # Set up manifests of other addons.
0000000000000000000000000000000000000000;;	  if [[ "${ENABLE_CLUSTER_MONITORING:-}" == "influxdb" ]] || \
0000000000000000000000000000000000000000;;	     [[ "${ENABLE_CLUSTER_MONITORING:-}" == "google" ]] || \
0000000000000000000000000000000000000000;;	     [[ "${ENABLE_CLUSTER_MONITORING:-}" == "stackdriver" ]] || \
0000000000000000000000000000000000000000;;	     [[ "${ENABLE_CLUSTER_MONITORING:-}" == "standalone" ]] || \
0000000000000000000000000000000000000000;;	     [[ "${ENABLE_CLUSTER_MONITORING:-}" == "googleinfluxdb" ]]; then
0000000000000000000000000000000000000000;;	    local -r file_dir="cluster-monitoring/${ENABLE_CLUSTER_MONITORING}"
0000000000000000000000000000000000000000;;	    setup-addon-manifests "addons" "cluster-monitoring"
0000000000000000000000000000000000000000;;	    setup-addon-manifests "addons" "${file_dir}"
0000000000000000000000000000000000000000;;	    # Replace the salt configurations with variable values.
0000000000000000000000000000000000000000;;	    base_metrics_memory="140Mi"
0000000000000000000000000000000000000000;;	    base_eventer_memory="190Mi"
0000000000000000000000000000000000000000;;	    base_metrics_cpu="80m"
0000000000000000000000000000000000000000;;	    nanny_memory="90Mi"
0000000000000000000000000000000000000000;;	    local -r metrics_memory_per_node="4"
0000000000000000000000000000000000000000;;	    local -r metrics_cpu_per_node="0.5"
0000000000000000000000000000000000000000;;	    local -r eventer_memory_per_node="500"
0000000000000000000000000000000000000000;;	    local -r nanny_memory_per_node="200"
0000000000000000000000000000000000000000;;	    if [[ -n "${NUM_NODES:-}" && "${NUM_NODES}" -ge 1 ]]; then
0000000000000000000000000000000000000000;;	      num_kube_nodes="$((${NUM_NODES}+1))"
0000000000000000000000000000000000000000;;	      nanny_memory="$((${num_kube_nodes} * ${nanny_memory_per_node} + 90 * 1024))Ki"
0000000000000000000000000000000000000000;;	    fi
0000000000000000000000000000000000000000;;	    controller_yaml="${dst_dir}/${file_dir}"
0000000000000000000000000000000000000000;;	    if [[ "${ENABLE_CLUSTER_MONITORING:-}" == "googleinfluxdb" ]]; then
0000000000000000000000000000000000000000;;	      controller_yaml="${controller_yaml}/heapster-controller-combined.yaml"
0000000000000000000000000000000000000000;;	    else
0000000000000000000000000000000000000000;;	      controller_yaml="${controller_yaml}/heapster-controller.yaml"
0000000000000000000000000000000000000000;;	    fi
0000000000000000000000000000000000000000;;	    remove-salt-config-comments "${controller_yaml}"
0000000000000000000000000000000000000000;;	    sed -i -e "s@{{ cluster_name }}@${CLUSTER_NAME}@g" "${controller_yaml}"
0000000000000000000000000000000000000000;;	    sed -i -e "s@{{ *base_metrics_memory *}}@${base_metrics_memory}@g" "${controller_yaml}"
0000000000000000000000000000000000000000;;	    sed -i -e "s@{{ *base_metrics_cpu *}}@${base_metrics_cpu}@g" "${controller_yaml}"
0000000000000000000000000000000000000000;;	    sed -i -e "s@{{ *base_eventer_memory *}}@${base_eventer_memory}@g" "${controller_yaml}"
0000000000000000000000000000000000000000;;	    sed -i -e "s@{{ *metrics_memory_per_node *}}@${metrics_memory_per_node}@g" "${controller_yaml}"
0000000000000000000000000000000000000000;;	    sed -i -e "s@{{ *eventer_memory_per_node *}}@${eventer_memory_per_node}@g" "${controller_yaml}"
0000000000000000000000000000000000000000;;	    sed -i -e "s@{{ *nanny_memory *}}@${nanny_memory}@g" "${controller_yaml}"
0000000000000000000000000000000000000000;;	    sed -i -e "s@{{ *metrics_cpu_per_node *}}@${metrics_cpu_per_node}@g" "${controller_yaml}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ "${ENABLE_CLUSTER_DNS:-}" == "true" ]]; then
0000000000000000000000000000000000000000;;	    setup-addon-manifests "addons" "dns"
0000000000000000000000000000000000000000;;	    local -r dns_controller_file="${dst_dir}/dns/kubedns-controller.yaml"
0000000000000000000000000000000000000000;;	    local -r dns_svc_file="${dst_dir}/dns/kubedns-svc.yaml"
0000000000000000000000000000000000000000;;	    mv "${dst_dir}/dns/kubedns-controller.yaml.in" "${dns_controller_file}"
0000000000000000000000000000000000000000;;	    mv "${dst_dir}/dns/kubedns-svc.yaml.in" "${dns_svc_file}"
0000000000000000000000000000000000000000;;	    # Replace the salt configurations with variable values.
0000000000000000000000000000000000000000;;	    sed -i -e "s@{{ *pillar\['dns_domain'\] *}}@${DNS_DOMAIN}@g" "${dns_controller_file}"
0000000000000000000000000000000000000000;;	    sed -i -e "s@{{ *pillar\['dns_server'\] *}}@${DNS_SERVER_IP}@g" "${dns_svc_file}"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	    if [[ "${ENABLE_DNS_HORIZONTAL_AUTOSCALER:-}" == "true" ]]; then
0000000000000000000000000000000000000000;;	      setup-addon-manifests "addons" "dns-horizontal-autoscaler"
0000000000000000000000000000000000000000;;	    fi
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ "${ENABLE_CLUSTER_REGISTRY:-}" == "true" ]]; then
0000000000000000000000000000000000000000;;	    setup-addon-manifests "addons" "registry"
0000000000000000000000000000000000000000;;	    local -r registry_pv_file="${dst_dir}/registry/registry-pv.yaml"
0000000000000000000000000000000000000000;;	    local -r registry_pvc_file="${dst_dir}/registry/registry-pvc.yaml"
0000000000000000000000000000000000000000;;	    mv "${dst_dir}/registry/registry-pv.yaml.in" "${registry_pv_file}"
0000000000000000000000000000000000000000;;	    mv "${dst_dir}/registry/registry-pvc.yaml.in" "${registry_pvc_file}"
0000000000000000000000000000000000000000;;	    # Replace the salt configurations with variable values.
0000000000000000000000000000000000000000;;	    remove-salt-config-comments "${controller_yaml}"
0000000000000000000000000000000000000000;;	    sed -i -e "s@{{ *pillar\['cluster_registry_disk_size'\] *}}@${CLUSTER_REGISTRY_DISK_SIZE}@g" "${registry_pv_file}"
0000000000000000000000000000000000000000;;	    sed -i -e "s@{{ *pillar\['cluster_registry_disk_size'\] *}}@${CLUSTER_REGISTRY_DISK_SIZE}@g" "${registry_pvc_file}"
0000000000000000000000000000000000000000;;	    sed -i -e "s@{{ *pillar\['cluster_registry_disk_name'\] *}}@${CLUSTER_REGISTRY_DISK}@g" "${registry_pvc_file}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ "${ENABLE_NODE_LOGGING:-}" == "true" ]] && \
0000000000000000000000000000000000000000;;	     [[ "${LOGGING_DESTINATION:-}" == "elasticsearch" ]] && \
0000000000000000000000000000000000000000;;	     [[ "${ENABLE_CLUSTER_LOGGING:-}" == "true" ]]; then
0000000000000000000000000000000000000000;;	    setup-addon-manifests "addons" "fluentd-elasticsearch"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ "${ENABLE_NODE_LOGGING:-}" == "true" ]] && \
0000000000000000000000000000000000000000;;	     [[ "${LOGGING_DESTINATION:-}" == "gcp" ]]; then
0000000000000000000000000000000000000000;;	    setup-addon-manifests "addons" "fluentd-gcp"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ "${ENABLE_CLUSTER_UI:-}" == "true" ]]; then
0000000000000000000000000000000000000000;;	    setup-addon-manifests "addons" "dashboard"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ "${ENABLE_NODE_PROBLEM_DETECTOR:-}" == "daemonset" ]]; then
0000000000000000000000000000000000000000;;	    setup-addon-manifests "addons" "node-problem-detector"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ "${ENABLE_NODE_PROBLEM_DETECTOR:-}" == "standalone" ]]; then
0000000000000000000000000000000000000000;;	    # Setup role binding for standalone node problem detector.
0000000000000000000000000000000000000000;;	    setup-addon-manifests "addons" "node-problem-detector/standalone"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if echo "${ADMISSION_CONTROL:-}" | grep -q "LimitRanger"; then
0000000000000000000000000000000000000000;;	    setup-addon-manifests "admission-controls" "limit-range"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ "${NETWORK_POLICY_PROVIDER:-}" == "calico" ]]; then
0000000000000000000000000000000000000000;;	    setup-addon-manifests "addons" "calico-policy-controller"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	    # Configure Calico based on cluster size and image type.
0000000000000000000000000000000000000000;;	    local -r ds_file="${dst_dir}/calico-policy-controller/calico-node-daemonset.yaml"
0000000000000000000000000000000000000000;;	    local -r typha_dep_file="${dst_dir}/calico-policy-controller/typha-deployment.yaml"
0000000000000000000000000000000000000000;;	    sed -i -e "s@__CALICO_CNI_DIR__@/home/kubernetes/bin@g" "${ds_file}"
0000000000000000000000000000000000000000;;	    sed -i -e "s@__CALICO_NODE_CPU__@$(get-calico-node-cpu)@g" "${ds_file}"
0000000000000000000000000000000000000000;;	    sed -i -e "s@__CALICO_TYPHA_CPU__@$(get-calico-typha-cpu)@g" "${typha_dep_file}"
0000000000000000000000000000000000000000;;	    sed -i -e "s@__CALICO_TYPHA_REPLICAS__@$(get-calico-typha-replicas)@g" "${typha_dep_file}"
0000000000000000000000000000000000000000;;	  else
0000000000000000000000000000000000000000;;	    # If not configured to use Calico, the set the typha replica count to 0, but only if the
0000000000000000000000000000000000000000;;	    # addon is present.
0000000000000000000000000000000000000000;;	    local -r typha_dep_file="${dst_dir}/calico-policy-controller/typha-deployment.yaml"
0000000000000000000000000000000000000000;;	    if [[ -e $typha_dep_file ]]; then
0000000000000000000000000000000000000000;;	      sed -i -e "s@__CALICO_TYPHA_REPLICAS__@0@g" "${typha_dep_file}"
0000000000000000000000000000000000000000;;	    fi
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ "${ENABLE_DEFAULT_STORAGE_CLASS:-}" == "true" ]]; then
0000000000000000000000000000000000000000;;	    setup-addon-manifests "addons" "storage-class/gce"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ "${ENABLE_IP_MASQ_AGENT:-}" == "true" ]]; then
0000000000000000000000000000000000000000;;	    setup-addon-manifests "addons" "ip-masq-agent"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ "${ENABLE_METADATA_PROXY:-}" == "simple" ]]; then
0000000000000000000000000000000000000000;;	    setup-addon-manifests "addons" "metadata-proxy/gce"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  # Place addon manager pod manifest.
0000000000000000000000000000000000000000;;	  cp "${src_dir}/kube-addon-manager.yaml" /etc/kubernetes/manifests
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Starts an image-puller - used in test clusters.
0000000000000000000000000000000000000000;;	function start-image-puller {
0000000000000000000000000000000000000000;;	  echo "Start image-puller"
0000000000000000000000000000000000000000;;	  cp "${KUBE_HOME}/kube-manifests/kubernetes/gci-trusty/e2e-image-puller.manifest" \
0000000000000000000000000000000000000000;;	    /etc/kubernetes/manifests/
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Starts kube-registry proxy
0000000000000000000000000000000000000000;;	function start-kube-registry-proxy {
0000000000000000000000000000000000000000;;	  echo "Start kube-registry-proxy"
0000000000000000000000000000000000000000;;	  cp "${KUBE_HOME}/kube-manifests/kubernetes/kube-registry-proxy.yaml" /etc/kubernetes/manifests
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Starts a l7 loadbalancing controller for ingress.
0000000000000000000000000000000000000000;;	function start-lb-controller {
0000000000000000000000000000000000000000;;	  if [[ "${ENABLE_L7_LOADBALANCING:-}" == "glbc" ]]; then
0000000000000000000000000000000000000000;;	    echo "Start GCE L7 pod"
0000000000000000000000000000000000000000;;	    prepare-log-file /var/log/glbc.log
0000000000000000000000000000000000000000;;	    setup-addon-manifests "addons" "cluster-loadbalancing/glbc"
0000000000000000000000000000000000000000;;	    cp "${KUBE_HOME}/kube-manifests/kubernetes/gci-trusty/glbc.manifest" \
0000000000000000000000000000000000000000;;	       /etc/kubernetes/manifests/
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Starts rescheduler.
0000000000000000000000000000000000000000;;	function start-rescheduler {
0000000000000000000000000000000000000000;;	  if [[ "${ENABLE_RESCHEDULER:-}" == "true" ]]; then
0000000000000000000000000000000000000000;;	    echo "Start Rescheduler"
0000000000000000000000000000000000000000;;	    prepare-log-file /var/log/rescheduler.log
0000000000000000000000000000000000000000;;	    cp "${KUBE_HOME}/kube-manifests/kubernetes/gci-trusty/rescheduler.manifest" \
0000000000000000000000000000000000000000;;	       /etc/kubernetes/manifests/
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Setup working directory for kubelet.
0000000000000000000000000000000000000000;;	function setup-kubelet-dir {
0000000000000000000000000000000000000000;;	    echo "Making /var/lib/kubelet executable for kubelet"
0000000000000000000000000000000000000000;;	    mount -B /var/lib/kubelet /var/lib/kubelet/
0000000000000000000000000000000000000000;;	    mount -B -o remount,exec,suid,dev /var/lib/kubelet
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	function reset-motd {
0000000000000000000000000000000000000000;;	  # kubelet is installed both on the master and nodes, and the version is easy to parse (unlike kubectl)
0000000000000000000000000000000000000000;;	  local -r version="$("${KUBE_HOME}"/bin/kubelet --version=true | cut -f2 -d " ")"
0000000000000000000000000000000000000000;;	  # This logic grabs either a release tag (v1.2.1 or v1.2.1-alpha.1),
0000000000000000000000000000000000000000;;	  # or the git hash that's in the build info.
0000000000000000000000000000000000000000;;	  local gitref="$(echo "${version}" | sed -r "s/(v[0-9]+\.[0-9]+\.[0-9]+)(-[a-z]+\.[0-9]+)?.*/\1\2/g")"
0000000000000000000000000000000000000000;;	  local devel=""
0000000000000000000000000000000000000000;;	  if [[ "${gitref}" != "${version}" ]]; then
0000000000000000000000000000000000000000;;	    devel="
0000000000000000000000000000000000000000;;	Note: This looks like a development version, which might not be present on GitHub.
0000000000000000000000000000000000000000;;	If it isn't, the closest tag is at:
0000000000000000000000000000000000000000;;	  https://github.com/kubernetes/kubernetes/tree/${gitref}
0000000000000000000000000000000000000000;;	"
0000000000000000000000000000000000000000;;	    gitref="${version//*+/}"
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  cat > /etc/motd <<EOF
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	Welcome to Kubernetes ${version}!
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	You can find documentation for Kubernetes at:
0000000000000000000000000000000000000000;;	  http://docs.kubernetes.io/
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	The source for this release can be found at:
0000000000000000000000000000000000000000;;	  /home/kubernetes/kubernetes-src.tar.gz
0000000000000000000000000000000000000000;;	Or you can download it at:
0000000000000000000000000000000000000000;;	  https://storage.googleapis.com/kubernetes-release/release/${version}/kubernetes-src.tar.gz
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	It is based on the Kubernetes source at:
0000000000000000000000000000000000000000;;	  https://github.com/kubernetes/kubernetes/tree/${gitref}
0000000000000000000000000000000000000000;;	${devel}
0000000000000000000000000000000000000000;;	For Kubernetes copyright and licensing information, see:
0000000000000000000000000000000000000000;;	  /home/kubernetes/LICENSES
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	EOF
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	function override-kubectl {
0000000000000000000000000000000000000000;;	    echo "overriding kubectl"
0000000000000000000000000000000000000000;;	    echo "export PATH=${KUBE_HOME}/bin:\$PATH" > /etc/profile.d/kube_env.sh
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	########### Main Function ###########
0000000000000000000000000000000000000000;;	echo "Start to configure instance for kubernetes"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	KUBE_HOME="/home/kubernetes"
0000000000000000000000000000000000000000;;	CONTAINERIZED_MOUNTER_HOME="${KUBE_HOME}/containerized_mounter"
0000000000000000000000000000000000000000;;	if [[ ! -e "${KUBE_HOME}/kube-env" ]]; then
0000000000000000000000000000000000000000;;	  echo "The ${KUBE_HOME}/kube-env file does not exist!! Terminate cluster initialization."
0000000000000000000000000000000000000000;;	  exit 1
0000000000000000000000000000000000000000;;	fi
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	source "${KUBE_HOME}/kube-env"
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	if [[ -e "${KUBE_HOME}/kube-master-certs" ]]; then
0000000000000000000000000000000000000000;;	  source "${KUBE_HOME}/kube-master-certs"
0000000000000000000000000000000000000000;;	fi
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	if [[ -n "${KUBE_USER:-}" ]]; then
0000000000000000000000000000000000000000;;	  if ! [[ "${KUBE_USER}" =~ ^[-._@a-zA-Z0-9]+$ ]]; then
0000000000000000000000000000000000000000;;	    echo "Bad KUBE_USER format."
0000000000000000000000000000000000000000;;	    exit 1
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	fi
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# generate the controller manager and scheduler tokens here since they are only used on the master.
0000000000000000000000000000000000000000;;	KUBE_CONTROLLER_MANAGER_TOKEN=$(dd if=/dev/urandom bs=128 count=1 2>/dev/null | base64 | tr -d "=+/" | dd bs=32 count=1 2>/dev/null)
0000000000000000000000000000000000000000;;	KUBE_SCHEDULER_TOKEN=$(dd if=/dev/urandom bs=128 count=1 2>/dev/null | base64 | tr -d "=+/" | dd bs=32 count=1 2>/dev/null)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	setup-os-params
0000000000000000000000000000000000000000;;	config-ip-firewall
0000000000000000000000000000000000000000;;	create-dirs
0000000000000000000000000000000000000000;;	setup-kubelet-dir
0000000000000000000000000000000000000000;;	ensure-local-ssds
0000000000000000000000000000000000000000;;	setup-logrotate
0000000000000000000000000000000000000000;;	if [[ "${KUBERNETES_MASTER:-}" == "true" ]]; then
0000000000000000000000000000000000000000;;	  mount-master-pd
0000000000000000000000000000000000000000;;	  create-node-pki
0000000000000000000000000000000000000000;;	  create-master-pki
0000000000000000000000000000000000000000;;	  create-master-auth
0000000000000000000000000000000000000000;;	  create-master-kubelet-auth
0000000000000000000000000000000000000000;;	  create-master-etcd-auth
0000000000000000000000000000000000000000;;	else
0000000000000000000000000000000000000000;;	  create-node-pki
0000000000000000000000000000000000000000;;	  create-kubelet-kubeconfig
0000000000000000000000000000000000000000;;	  create-kubeproxy-kubeconfig
0000000000000000000000000000000000000000;;	  if [[ "${ENABLE_NODE_PROBLEM_DETECTOR:-}" == "standalone" ]]; then
0000000000000000000000000000000000000000;;	    create-node-problem-detector-kubeconfig
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	fi
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	override-kubectl
0000000000000000000000000000000000000000;;	# Run the containerized mounter once to pre-cache the container image.
0000000000000000000000000000000000000000;;	assemble-docker-flags
0000000000000000000000000000000000000000;;	load-docker-images
0000000000000000000000000000000000000000;;	start-kubelet
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	if [[ "${KUBERNETES_MASTER:-}" == "true" ]]; then
0000000000000000000000000000000000000000;;	  compute-master-manifest-variables
0000000000000000000000000000000000000000;;	  start-etcd-servers
0000000000000000000000000000000000000000;;	  start-etcd-empty-dir-cleanup-pod
0000000000000000000000000000000000000000;;	  start-kube-apiserver
0000000000000000000000000000000000000000;;	  start-kube-controller-manager
0000000000000000000000000000000000000000;;	  start-kube-scheduler
0000000000000000000000000000000000000000;;	  start-kube-addons
0000000000000000000000000000000000000000;;	  start-cluster-autoscaler
0000000000000000000000000000000000000000;;	  start-lb-controller
0000000000000000000000000000000000000000;;	  start-rescheduler
0000000000000000000000000000000000000000;;	else
0000000000000000000000000000000000000000;;	  start-kube-proxy
0000000000000000000000000000000000000000;;	  # Kube-registry-proxy.
0000000000000000000000000000000000000000;;	  if [[ "${ENABLE_CLUSTER_REGISTRY:-}" == "true" ]]; then
0000000000000000000000000000000000000000;;	    start-kube-registry-proxy
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ "${PREPULL_E2E_IMAGES:-}" == "true" ]]; then
0000000000000000000000000000000000000000;;	    start-image-puller
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	  if [[ "${ENABLE_NODE_PROBLEM_DETECTOR:-}" == "standalone" ]]; then
0000000000000000000000000000000000000000;;	    start-node-problem-detector
0000000000000000000000000000000000000000;;	  fi
0000000000000000000000000000000000000000;;	fi
0000000000000000000000000000000000000000;;	reset-motd
0000000000000000000000000000000000000000;;	prepare-mounter-rootfs
0000000000000000000000000000000000000000;;	modprobe configs
0000000000000000000000000000000000000000;;	echo "Done for the configuration for kubernetes"
