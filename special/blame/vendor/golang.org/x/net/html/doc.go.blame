0000000000000000000000000000000000000000;;	// Copyright 2010 The Go Authors. All rights reserved.
0000000000000000000000000000000000000000;;	// Use of this source code is governed by a BSD-style
0000000000000000000000000000000000000000;;	// license that can be found in the LICENSE file.
c2bfd044362efe23765620d054edcdab7497bde5;third_party/src/code.google.com/p/go.net/html/doc.go[third_party/src/code.google.com/p/go.net/html/doc.go][vendor/golang.org/x/net/html/doc.go];	
0000000000000000000000000000000000000000;;	/*
0000000000000000000000000000000000000000;;	Package html implements an HTML5-compliant tokenizer and parser.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	Tokenization is done by creating a Tokenizer for an io.Reader r. It is the
0000000000000000000000000000000000000000;;	caller's responsibility to ensure that r provides UTF-8 encoded HTML.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		z := html.NewTokenizer(r)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	Given a Tokenizer z, the HTML is tokenized by repeatedly calling z.Next(),
0000000000000000000000000000000000000000;;	which parses the next token and returns its type, or an error:
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		for {
0000000000000000000000000000000000000000;;			tt := z.Next()
0000000000000000000000000000000000000000;;			if tt == html.ErrorToken {
0000000000000000000000000000000000000000;;				// ...
0000000000000000000000000000000000000000;;				return ...
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			// Process the current token.
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	There are two APIs for retrieving the current token. The high-level API is to
0000000000000000000000000000000000000000;;	call Token; the low-level API is to call Text or TagName / TagAttr. Both APIs
0000000000000000000000000000000000000000;;	allow optionally calling Raw after Next but before Token, Text, TagName, or
0000000000000000000000000000000000000000;;	TagAttr. In EBNF notation, the valid call sequence per token is:
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		Next {Raw} [ Token | Text | TagName {TagAttr} ]
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	Token returns an independent data structure that completely describes a token.
0000000000000000000000000000000000000000;;	Entities (such as "&lt;") are unescaped, tag names and attribute keys are
0000000000000000000000000000000000000000;;	lower-cased, and attributes are collected into a []Attribute. For example:
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		for {
0000000000000000000000000000000000000000;;			if z.Next() == html.ErrorToken {
0000000000000000000000000000000000000000;;				// Returning io.EOF indicates success.
0000000000000000000000000000000000000000;;				return z.Err()
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			emitToken(z.Token())
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	The low-level API performs fewer allocations and copies, but the contents of
0000000000000000000000000000000000000000;;	the []byte values returned by Text, TagName and TagAttr may change on the next
0000000000000000000000000000000000000000;;	call to Next. For example, to extract an HTML page's anchor text:
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		depth := 0
0000000000000000000000000000000000000000;;		for {
0000000000000000000000000000000000000000;;			tt := z.Next()
0000000000000000000000000000000000000000;;			switch tt {
0000000000000000000000000000000000000000;;			case ErrorToken:
0000000000000000000000000000000000000000;;				return z.Err()
0000000000000000000000000000000000000000;;			case TextToken:
0000000000000000000000000000000000000000;;				if depth > 0 {
0000000000000000000000000000000000000000;;					// emitBytes should copy the []byte it receives,
0000000000000000000000000000000000000000;;					// if it doesn't process it immediately.
0000000000000000000000000000000000000000;;					emitBytes(z.Text())
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			case StartTagToken, EndTagToken:
0000000000000000000000000000000000000000;;				tn, _ := z.TagName()
0000000000000000000000000000000000000000;;				if len(tn) == 1 && tn[0] == 'a' {
0000000000000000000000000000000000000000;;					if tt == StartTagToken {
0000000000000000000000000000000000000000;;						depth++
0000000000000000000000000000000000000000;;					} else {
0000000000000000000000000000000000000000;;						depth--
0000000000000000000000000000000000000000;;					}
0000000000000000000000000000000000000000;;				}
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	Parsing is done by calling Parse with an io.Reader, which returns the root of
0000000000000000000000000000000000000000;;	the parse tree (the document element) as a *Node. It is the caller's
0000000000000000000000000000000000000000;;	responsibility to ensure that the Reader provides UTF-8 encoded HTML. For
0000000000000000000000000000000000000000;;	example, to process each anchor node in depth-first order:
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;		doc, err := html.Parse(r)
0000000000000000000000000000000000000000;;		if err != nil {
0000000000000000000000000000000000000000;;			// ...
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		var f func(*html.Node)
0000000000000000000000000000000000000000;;		f = func(n *html.Node) {
0000000000000000000000000000000000000000;;			if n.Type == html.ElementNode && n.Data == "a" {
0000000000000000000000000000000000000000;;				// Do something with n...
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;			for c := n.FirstChild; c != nil; c = c.NextSibling {
0000000000000000000000000000000000000000;;				f(c)
0000000000000000000000000000000000000000;;			}
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		f(doc)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	The relevant specifications include:
0000000000000000000000000000000000000000;;	https://html.spec.whatwg.org/multipage/syntax.html and
0000000000000000000000000000000000000000;;	https://html.spec.whatwg.org/multipage/syntax.html#tokenization
0000000000000000000000000000000000000000;;	*/
0000000000000000000000000000000000000000;;	package html
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// The tokenization algorithm implemented by this package is not a line-by-line
0000000000000000000000000000000000000000;;	// transliteration of the relatively verbose state-machine in the WHATWG
0000000000000000000000000000000000000000;;	// specification. A more direct approach is used instead, where the program
0000000000000000000000000000000000000000;;	// counter implies the state, such as whether it is tokenizing a tag or a text
0000000000000000000000000000000000000000;;	// node. Specification compliance is verified by checking expected and actual
0000000000000000000000000000000000000000;;	// outputs over a test suite rather than aiming for algorithmic fidelity.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// TODO(nigeltao): Does a DOM API belong in this package or a separate one?
0000000000000000000000000000000000000000;;	// TODO(nigeltao): How does parsing interact with a JavaScript engine?
