0000000000000000000000000000000000000000;;	package ccache
550be6508d59ea184bfb64f8ae23c177b9e6d1c9;;	
0000000000000000000000000000000000000000;;	type Configuration struct {
0000000000000000000000000000000000000000;;		maxSize        int64
0000000000000000000000000000000000000000;;		buckets        int
0000000000000000000000000000000000000000;;		itemsToPrune   int
0000000000000000000000000000000000000000;;		deleteBuffer   int
0000000000000000000000000000000000000000;;		promoteBuffer  int
0000000000000000000000000000000000000000;;		getsPerPromote int32
0000000000000000000000000000000000000000;;		tracking       bool
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Creates a configuration object with sensible defaults
0000000000000000000000000000000000000000;;	// Use this as the start of the fluent configuration:
0000000000000000000000000000000000000000;;	// e.g.: ccache.New(ccache.Configure().MaxSize(10000))
0000000000000000000000000000000000000000;;	func Configure() *Configuration {
0000000000000000000000000000000000000000;;		return &Configuration{
0000000000000000000000000000000000000000;;			buckets:        16,
0000000000000000000000000000000000000000;;			itemsToPrune:   500,
0000000000000000000000000000000000000000;;			deleteBuffer:   1024,
0000000000000000000000000000000000000000;;			getsPerPromote: 3,
0000000000000000000000000000000000000000;;			promoteBuffer:  1024,
0000000000000000000000000000000000000000;;			maxSize:        5000,
0000000000000000000000000000000000000000;;			tracking:       false,
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// The max size for the cache
0000000000000000000000000000000000000000;;	// [5000]
0000000000000000000000000000000000000000;;	func (c *Configuration) MaxSize(max int64) *Configuration {
0000000000000000000000000000000000000000;;		c.maxSize = max
0000000000000000000000000000000000000000;;		return c
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Keys are hashed into % bucket count to provide greater concurrency (every set
0000000000000000000000000000000000000000;;	// requires a write lock on the bucket). Must be a power of 2 (1, 2, 4, 8, 16, ...)
0000000000000000000000000000000000000000;;	// [16]
0000000000000000000000000000000000000000;;	func (c *Configuration) Buckets(count uint32) *Configuration {
0000000000000000000000000000000000000000;;		if count == 0 || ((count&(^count+1)) == count) == false {
0000000000000000000000000000000000000000;;			count = 16
0000000000000000000000000000000000000000;;		}
0000000000000000000000000000000000000000;;		c.buckets = int(count)
0000000000000000000000000000000000000000;;		return c
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// The number of items to prune when memory is low
0000000000000000000000000000000000000000;;	// [500]
0000000000000000000000000000000000000000;;	func (c *Configuration) ItemsToPrune(count uint32) *Configuration {
0000000000000000000000000000000000000000;;		c.itemsToPrune = int(count)
0000000000000000000000000000000000000000;;		return c
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// The size of the queue for items which should be promoted. If the queue fills
0000000000000000000000000000000000000000;;	// up, promotions are skipped
0000000000000000000000000000000000000000;;	// [1024]
0000000000000000000000000000000000000000;;	func (c *Configuration) PromoteBuffer(size uint32) *Configuration {
0000000000000000000000000000000000000000;;		c.promoteBuffer = int(size)
0000000000000000000000000000000000000000;;		return c
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// The size of the queue for items which should be deleted. If the queue fills
0000000000000000000000000000000000000000;;	// up, calls to Delete() will block
0000000000000000000000000000000000000000;;	func (c *Configuration) DeleteBuffer(size uint32) *Configuration {
0000000000000000000000000000000000000000;;		c.deleteBuffer = int(size)
0000000000000000000000000000000000000000;;		return c
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Give a large cache with a high read / write ratio, it's usually unecessary
0000000000000000000000000000000000000000;;	// to promote an item on every Get. GetsPerPromote specifies the number of Gets
0000000000000000000000000000000000000000;;	// a key must have before being promoted
0000000000000000000000000000000000000000;;	// [3]
0000000000000000000000000000000000000000;;	func (c *Configuration) GetsPerPromote(count int32) *Configuration {
0000000000000000000000000000000000000000;;		c.getsPerPromote = count
0000000000000000000000000000000000000000;;		return c
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// Typically, a cache is agnostic about how cached values are use. This is fine
0000000000000000000000000000000000000000;;	// for a typical cache usage, where you fetch an item from the cache, do something
0000000000000000000000000000000000000000;;	// (write it out) and nothing else.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// However, if callers are going to keep a reference to a cached item for a long
0000000000000000000000000000000000000000;;	// time, things get messy. Specifically, the cache can evict the item, while
0000000000000000000000000000000000000000;;	// references still exist. Technically, this isn't an issue. However, if you reload
0000000000000000000000000000000000000000;;	// the item back into the cache, you end up with 2 objects representing the same
0000000000000000000000000000000000000000;;	// data. This is a waste of space and could lead to weird behavior (the type an
0000000000000000000000000000000000000000;;	// identity map is meant to solve).
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	// By turning tracking on and using the cache's TrackingGet, the cache
0000000000000000000000000000000000000000;;	// won't evict items which you haven't called Release() on. It's a simple reference
0000000000000000000000000000000000000000;;	// counter.
0000000000000000000000000000000000000000;;	func (c *Configuration) Track() *Configuration {
0000000000000000000000000000000000000000;;		c.tracking = true
0000000000000000000000000000000000000000;;		return c
0000000000000000000000000000000000000000;;	}
