0000000000000000000000000000000000000000;;	# CCache
0000000000000000000000000000000000000000;;	CCache is an LRU Cache, written in Go, focused on supporting high concurrency.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	Lock contention on the list is reduced by:
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	* Introducing a window which limits the frequency that an item can get promoted
0000000000000000000000000000000000000000;;	* Using a buffered channel to queue promotions for a single worker
0000000000000000000000000000000000000000;;	* Garbage collecting within the same thread as the worker
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	## Setup
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	First, download the project:
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	    go get github.com/karlseguin/ccache
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	## Configuration
0000000000000000000000000000000000000000;;	Next, import and create a `Cache` instance:
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	```go
0000000000000000000000000000000000000000;;	import (
0000000000000000000000000000000000000000;;	  "github.com/karlseguin/ccache"
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	var cache = ccache.New(ccache.Configure())
0000000000000000000000000000000000000000;;	```
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	`Configure` exposes a chainable API:
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	```go
0000000000000000000000000000000000000000;;	var cache = ccache.New(ccache.Configure().MaxSize(1000).ItemsToPrune(100))
0000000000000000000000000000000000000000;;	```
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	The most likely configuration options to tweak are:
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	* `MaxSize(int)` - the maximum number size  to store in the cache (default: 5000)
0000000000000000000000000000000000000000;;	* `GetsPerPromote(int)` - the number of times an item is fetched before we promote it. For large caches with long TTLs, it normally isn't necessary to promote an item after every fetch (default: 3)
0000000000000000000000000000000000000000;;	* `ItemsToPrune(int)` - the number of items to prune when we hit `MaxSize`. Freeing up more than 1 slot at a time improved performance (default: 500)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	Configurations that change the internals of the cache, which aren't as likely to need tweaking:
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	* `Buckets` - ccache shards its internal map to provide a greater amount of concurrency. Must be a power of 2 (default: 16).
0000000000000000000000000000000000000000;;	* `PromoteBuffer(int)` - the size of the buffer to use to queue promotions (default: 1024)
0000000000000000000000000000000000000000;;	* `DeleteBuffer(int)` the size of the buffer to use to queue deletions (default: 1024)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	## Usage
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	Once the cache is setup, you can  `Get`, `Set` and `Delete` items from it. A `Get` returns an `*Item`:
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	### Get
0000000000000000000000000000000000000000;;	```go
0000000000000000000000000000000000000000;;	item := cache.Get("user:4")
0000000000000000000000000000000000000000;;	if item == nil {
0000000000000000000000000000000000000000;;	  //handle
0000000000000000000000000000000000000000;;	} else {
0000000000000000000000000000000000000000;;	  user := item.Value().(*User)
0000000000000000000000000000000000000000;;	}
0000000000000000000000000000000000000000;;	```
0000000000000000000000000000000000000000;;	The returned `*Item` exposes a number of methods:
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	* `Value() interface{}` - the value cached
0000000000000000000000000000000000000000;;	* `Expired() bool` - whether the item is expired or not
0000000000000000000000000000000000000000;;	* `TTL() time.Duration` - the duration before the item expires (will be a negative value for expired items)
0000000000000000000000000000000000000000;;	* `Expires() time.Time` - the time the item will expire
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	By returning expired items, CCache lets you decide if you want to serve stale content or not. For example, you might decide to serve up slightly stale content (< 30 seconds old) while re-fetching newer data in the background. You might also decide to serve up infinitely stale content if you're unable to get new data from your source.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	### Set
0000000000000000000000000000000000000000;;	`Set` expects the key, value and ttl:
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	```go
0000000000000000000000000000000000000000;;	cache.Set("user:4", user, time.Minute * 10)
0000000000000000000000000000000000000000;;	```
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	### Fetch
0000000000000000000000000000000000000000;;	There's also a `Fetch` which mixes a `Get` and a `Set`:
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	```go
0000000000000000000000000000000000000000;;	item, err := cache.Fetch("user:4", time.Minute * 10, func() (interface{}, error) {
0000000000000000000000000000000000000000;;	  //code to fetch the data incase of a miss
0000000000000000000000000000000000000000;;	  //should return the data to cache and the error, if any
0000000000000000000000000000000000000000;;	})
0000000000000000000000000000000000000000;;	```
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	### Delete
0000000000000000000000000000000000000000;;	`Delete` expects the key to delete. It's ok to call `Delete` on a non-existant key:
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	```go
0000000000000000000000000000000000000000;;	cache.Delete("user:4")
0000000000000000000000000000000000000000;;	```
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	### Extend
0000000000000000000000000000000000000000;;	The life of an item can be changed via the `Extend` method. This will change the expiry of the item by the specified duration relative to the current time.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	### Replace
0000000000000000000000000000000000000000;;	The value of an item can be updated to a new value without renewing the item's TTL or it's position in the LRU:
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	```go
0000000000000000000000000000000000000000;;	cache.Replace("user:4", user)
0000000000000000000000000000000000000000;;	```
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	`Replace` returns true if the item existed (and thus was replaced). In the case where the key was not in the cache, the value *is not* inserted and false is returned.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	### Stop
0000000000000000000000000000000000000000;;	The cache's background worker can be stopped by calling `Stop`. Once `Stop` is called
0000000000000000000000000000000000000000;;	the cache should not be used (calls are likely to panic). Stop must be called in order to allow the garbage collector to reap the cache.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	## Tracking
0000000000000000000000000000000000000000;;	CCache supports a special tracking mode which is meant to be used in conjunction with other pieces of your code that maintains a long-lived reference to data.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	When you configure your cache with `Track()`:
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	```go
0000000000000000000000000000000000000000;;	cache = ccache.New(ccache.Configure().Track())
0000000000000000000000000000000000000000;;	```
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	The items retrieved via `TrackingGet` will not be eligible for purge until `Release` is called on them:
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	```go
0000000000000000000000000000000000000000;;	item := cache.TrackingGet("user:4")
0000000000000000000000000000000000000000;;	user := item.Value()   //will be nil if "user:4" didn't exist in the cache
0000000000000000000000000000000000000000;;	item.Release()  //can be called even if item.Value() returned nil
0000000000000000000000000000000000000000;;	```
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	In practive, `Release` wouldn't be called until later, at some other place in your code.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	There's a couple reason to use the tracking mode if other parts of your code also hold references to objects. First, if you're already going to hold a reference to these objects, there's really no reason not to have them in the cache - the memory is used up anyways.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	More important, it helps ensure that you're code returns consistent data. With tracking, "user:4" might be purged, and a subsequent `Fetch` would reload the data. This can result in different versions of "user:4" being returned by different parts of your system.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	## LayeredCache
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	CCache's `LayeredCache` stores and retrieves values by both a primary and secondary key. Deletion can happen against either the primary and secondary key, or the primary key only (removing all values that share the same primary key).
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	`LayeredCache` is useful for HTTP caching, when you want to purge all variations of a request.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	`LayeredCache` takes the same configuration object as the main cache, exposes the same optional tracking capabilities, but exposes a slightly different API:
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	```go
0000000000000000000000000000000000000000;;	cache := ccache.Layered(ccache.Configure())
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	cache.Set("/users/goku", "type:json", "{value_to_cache}", time.Minute * 5)
0000000000000000000000000000000000000000;;	cache.Set("/users/goku", "type:xml", "<value_to_cache>", time.Minute * 5)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	json := cache.Get("/users/goku", "type:json")
0000000000000000000000000000000000000000;;	xml := cache.Get("/users/goku", "type:xml")
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	cache.Delete("/users/goku", "type:json")
0000000000000000000000000000000000000000;;	cache.Delete("/users/goku", "type:xml")
0000000000000000000000000000000000000000;;	// OR
0000000000000000000000000000000000000000;;	cache.DeleteAll("/users/goku")
0000000000000000000000000000000000000000;;	```
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# SecondaryCache
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	In some cases, when using a `LayeredCache`, it may be desirable to always be acting on the secondary portion of the cache entry. This could be the case where the primary key is used as a key elsewhere in your code. The `SecondaryCache` is retrieved with:
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	```go
0000000000000000000000000000000000000000;;	cache := ccache.Layered(ccache.Configure())
0000000000000000000000000000000000000000;;	sCache := cache.GetOrCreateSecondaryCache("/users/goku")
0000000000000000000000000000000000000000;;	sCache.Set("type:json", "{value_to_cache}", time.Minute * 5)
0000000000000000000000000000000000000000;;	```
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	The semantics for interacting with the `SecondaryCache` are exactly the same as for a regular `Cache`. However, one difference is that `Get` will not return nil, but will return an empty 'cache' for a non-existent primary key.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	## Size
0000000000000000000000000000000000000000;;	By default, items added to a cache have a size of 1. This means that if you configure `MaxSize(10000)`, you'll be able to store 10000 items in the cache.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	However, if the values you set into the cache have a method `Size() int64`, this size will be used. Note that ccache has an overhead of ~350 bytes per entry, which isn't taken into account. In other words, given a filled up cache, with `MaxSize(4096000)` and items that return a `Size() int64` of 2048, we can expect to find 2000 items (4096000/2048) taking a total space of 4796000 bytes.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	## Want Something Simpler?
0000000000000000000000000000000000000000;;	For a simpler cache, checkout out [rcache](https://github.com/karlseguin/rcache)
