0000000000000000000000000000000000000000;;	# Go gRPC Interceptors for Prometheus monitoring 
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	[![Travis Build](https://travis-ci.org/grpc-ecosystem/go-grpc-prometheus.svg)](https://travis-ci.org/grpc-ecosystem/go-grpc-prometheus)
0000000000000000000000000000000000000000;;	[![Go Report Card](https://goreportcard.com/badge/github.com/grpc-ecosystem/go-grpc-prometheus)](http://goreportcard.com/report/grpc-ecosystem/go-grpc-prometheus)
0000000000000000000000000000000000000000;;	[![GoDoc](http://img.shields.io/badge/GoDoc-Reference-blue.svg)](https://godoc.org/github.com/grpc-ecosystem/go-grpc-prometheus)
0000000000000000000000000000000000000000;;	[![SourceGraph](https://sourcegraph.com/github.com/grpc-ecosystem/go-grpc-prometheus/-/badge.svg)](https://sourcegraph.com/github.com/grpc-ecosystem/go-grpc-prometheus/?badge)
0000000000000000000000000000000000000000;;	[![codecov](https://codecov.io/gh/grpc-ecosystem/go-grpc-prometheus/branch/master/graph/badge.svg)](https://codecov.io/gh/grpc-ecosystem/go-grpc-prometheus)
0000000000000000000000000000000000000000;;	[![Apache 2.0 License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](LICENSE)
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	[Prometheus](https://prometheus.io/) monitoring for your [gRPC Go](https://github.com/grpc/grpc-go) servers and clients.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	A sister implementation for [gRPC Java](https://github.com/grpc/grpc-java) (same metrics, same semantics) is in [grpc-ecosystem/java-grpc-prometheus](https://github.com/grpc-ecosystem/java-grpc-prometheus).
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	## Interceptors
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	[gRPC Go](https://github.com/grpc/grpc-go) recently acquired support for Interceptors, i.e. middleware that is executed
0000000000000000000000000000000000000000;;	by a gRPC Server before the request is passed onto the user's application logic. It is a perfect way to implement
0000000000000000000000000000000000000000;;	common patterns: auth, logging and... monitoring.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	To use Interceptors in chains, please see [`go-grpc-middleware`](https://github.com/mwitkow/go-grpc-middleware).
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	## Usage
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	There are two types of interceptors: client-side and server-side. This package provides monitoring Interceptors for both.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	### Server-side
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	```go
0000000000000000000000000000000000000000;;	import "github.com/grpc-ecosystem/go-grpc-prometheus"
0000000000000000000000000000000000000000;;	...
0000000000000000000000000000000000000000;;	    // Initialize your gRPC server's interceptor.
0000000000000000000000000000000000000000;;	    myServer := grpc.NewServer(
0000000000000000000000000000000000000000;;	        grpc.StreamInterceptor(grpc_prometheus.StreamServerInterceptor),
0000000000000000000000000000000000000000;;	        grpc.UnaryInterceptor(grpc_prometheus.UnaryServerInterceptor),
0000000000000000000000000000000000000000;;	    )
0000000000000000000000000000000000000000;;	    // Register your gRPC service implementations.
0000000000000000000000000000000000000000;;	    myservice.RegisterMyServiceServer(s.server, &myServiceImpl{})
0000000000000000000000000000000000000000;;	    // After all your registrations, make sure all of the Prometheus metrics are initialized.
0000000000000000000000000000000000000000;;	    grpc_prometheus.Register(myServer)
0000000000000000000000000000000000000000;;	    // Register Prometheus metrics handler.    
0000000000000000000000000000000000000000;;	    http.Handle("/metrics", prometheus.Handler())
0000000000000000000000000000000000000000;;	...
0000000000000000000000000000000000000000;;	```
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	### Client-side
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	```go
0000000000000000000000000000000000000000;;	import "github.com/grpc-ecosystem/go-grpc-prometheus"
0000000000000000000000000000000000000000;;	...
0000000000000000000000000000000000000000;;	   clientConn, err = grpc.Dial(
0000000000000000000000000000000000000000;;	       address,
0000000000000000000000000000000000000000;;			   grpc.WithUnaryInterceptor(UnaryClientInterceptor),
0000000000000000000000000000000000000000;;			   grpc.WithStreamInterceptor(StreamClientInterceptor)
0000000000000000000000000000000000000000;;	   )
0000000000000000000000000000000000000000;;	   client = pb_testproto.NewTestServiceClient(clientConn)
0000000000000000000000000000000000000000;;	   resp, err := client.PingEmpty(s.ctx, &myservice.Request{Msg: "hello"})
0000000000000000000000000000000000000000;;	...
0000000000000000000000000000000000000000;;	```
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	# Metrics
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	## Labels
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	All server-side metrics start with `grpc_server` as Prometheus subsystem name. All client-side metrics start with `grpc_client`. Both of them have mirror-concepts. Similarly all methods
0000000000000000000000000000000000000000;;	contain the same rich labels:
0000000000000000000000000000000000000000;;	  
0000000000000000000000000000000000000000;;	  * `grpc_service` - the [gRPC service](http://www.grpc.io/docs/#defining-a-service) name, which is the combination of protobuf `package` and
0000000000000000000000000000000000000000;;	    the `grpc_service` section name. E.g. for `package = mwitkow.testproto` and 
0000000000000000000000000000000000000000;;	     `service TestService` the label will be `grpc_service="mwitkow.testproto.TestService"`
0000000000000000000000000000000000000000;;	  * `grpc_method` - the name of the method called on the gRPC service. E.g.  
0000000000000000000000000000000000000000;;	    `grpc_method="Ping"`
0000000000000000000000000000000000000000;;	  * `grpc_type` - the gRPC [type of request](http://www.grpc.io/docs/guides/concepts.html#rpc-life-cycle). 
0000000000000000000000000000000000000000;;	    Differentiating between the two is important especially for latency measurements.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	     - `unary` is single request, single response RPC
0000000000000000000000000000000000000000;;	     - `client_stream` is a multi-request, single response RPC
0000000000000000000000000000000000000000;;	     - `server_stream` is a single request, multi-response RPC
0000000000000000000000000000000000000000;;	     - `bidi_stream` is a multi-request, multi-response RPC
0000000000000000000000000000000000000000;;	    
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	Additionally for completed RPCs, the following labels are used:
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	  * `grpc_code` - the human-readable [gRPC status code](https://github.com/grpc/grpc-go/blob/master/codes/codes.go).
0000000000000000000000000000000000000000;;	    The list of all statuses is to long, but here are some common ones:
0000000000000000000000000000000000000000;;	      
0000000000000000000000000000000000000000;;	      - `OK` - means the RPC was successful
0000000000000000000000000000000000000000;;	      - `IllegalArgument` - RPC contained bad values
0000000000000000000000000000000000000000;;	      - `Internal` - server-side error not disclosed to the clients
0000000000000000000000000000000000000000;;	      
0000000000000000000000000000000000000000;;	## Counters
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	The counters and their up to date documentation is in [server_reporter.go](server_reporter.go) and [client_reporter.go](client_reporter.go) 
0000000000000000000000000000000000000000;;	the respective Prometheus handler (usually `/metrics`). 
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	For the purpose of this documentation we will only discuss `grpc_server` metrics. The `grpc_client` ones contain mirror concepts.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	For simplicity, let's assume we're tracking a single server-side RPC call of [`mwitkow.testproto.TestService`](examples/testproto/test.proto),
0000000000000000000000000000000000000000;;	calling the method `PingList`. The call succeeds and returns 20 messages in the stream.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	First, immediately after the server receives the call it will increment the
0000000000000000000000000000000000000000;;	`grpc_server_started_total` and start the handling time clock (if histograms are enabled). 
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	```jsoniq
0000000000000000000000000000000000000000;;	grpc_server_started_total{grpc_method="PingList",grpc_service="mwitkow.testproto.TestService",grpc_type="server_stream"} 1
0000000000000000000000000000000000000000;;	```
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	Then the user logic gets invoked. It receives one message from the client containing the request 
0000000000000000000000000000000000000000;;	(it's a `server_stream`):
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	```jsoniq
0000000000000000000000000000000000000000;;	grpc_server_msg_received_total{grpc_method="PingList",grpc_service="mwitkow.testproto.TestService",grpc_type="server_stream"} 1
0000000000000000000000000000000000000000;;	```
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	The user logic may return an error, or send multiple messages back to the client. In this case, on 
0000000000000000000000000000000000000000;;	each of the 20 messages sent back, a counter will be incremented:
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	```jsoniq
0000000000000000000000000000000000000000;;	grpc_server_msg_sent_total{grpc_method="PingList",grpc_service="mwitkow.testproto.TestService",grpc_type="server_stream"} 20
0000000000000000000000000000000000000000;;	```
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	After the call completes, it's status (`OK` or other [gRPC status code](https://github.com/grpc/grpc-go/blob/master/codes/codes.go)) 
0000000000000000000000000000000000000000;;	and the relevant call labels increment the `grpc_server_handled_total` counter.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	```jsoniq
0000000000000000000000000000000000000000;;	grpc_server_handled_total{grpc_code="OK",grpc_method="PingList",grpc_service="mwitkow.testproto.TestService",grpc_type="server_stream"} 1
0000000000000000000000000000000000000000;;	```
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	## Histograms
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	[Prometheus histograms](https://prometheus.io/docs/concepts/metric_types/#histogram) are a great way
0000000000000000000000000000000000000000;;	to measure latency distributions of your RPCs. However since it is bad practice to have metrics
0000000000000000000000000000000000000000;;	of [high cardinality](https://prometheus.io/docs/practices/instrumentation/#do-not-overuse-labels))
0000000000000000000000000000000000000000;;	the latency monitoring metrics are disabled by default. To enable them please call the following
0000000000000000000000000000000000000000;;	in your server initialization code:
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	```jsoniq
0000000000000000000000000000000000000000;;	grpc_prometheus.EnableHandlingTimeHistogram()
0000000000000000000000000000000000000000;;	```
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	After the call completes, it's handling time will be recorded in a [Prometheus histogram](https://prometheus.io/docs/concepts/metric_types/#histogram)
0000000000000000000000000000000000000000;;	variable `grpc_server_handling_seconds`. It contains three sub-metrics:
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	 * `grpc_server_handling_seconds_count` - the count of all completed RPCs by status and method 
0000000000000000000000000000000000000000;;	 * `grpc_server_handling_seconds_sum` - cumulative time of RPCs by status and method, useful for 
0000000000000000000000000000000000000000;;	   calculating average handling times
0000000000000000000000000000000000000000;;	 * `grpc_server_handling_seconds_bucket` - contains the counts of RPCs by status and method in respective
0000000000000000000000000000000000000000;;	   handling-time buckets. These buckets can be used by Prometheus to estimate SLAs (see [here](https://prometheus.io/docs/practices/histograms/))
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	The counter values will look as follows:
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	```jsoniq
0000000000000000000000000000000000000000;;	grpc_server_handling_seconds_bucket{grpc_code="OK",grpc_method="PingList",grpc_service="mwitkow.testproto.TestService",grpc_type="server_stream",le="0.005"} 1
0000000000000000000000000000000000000000;;	grpc_server_handling_seconds_bucket{grpc_code="OK",grpc_method="PingList",grpc_service="mwitkow.testproto.TestService",grpc_type="server_stream",le="0.01"} 1
0000000000000000000000000000000000000000;;	grpc_server_handling_seconds_bucket{grpc_code="OK",grpc_method="PingList",grpc_service="mwitkow.testproto.TestService",grpc_type="server_stream",le="0.025"} 1
0000000000000000000000000000000000000000;;	grpc_server_handling_seconds_bucket{grpc_code="OK",grpc_method="PingList",grpc_service="mwitkow.testproto.TestService",grpc_type="server_stream",le="0.05"} 1
0000000000000000000000000000000000000000;;	grpc_server_handling_seconds_bucket{grpc_code="OK",grpc_method="PingList",grpc_service="mwitkow.testproto.TestService",grpc_type="server_stream",le="0.1"} 1
0000000000000000000000000000000000000000;;	grpc_server_handling_seconds_bucket{grpc_code="OK",grpc_method="PingList",grpc_service="mwitkow.testproto.TestService",grpc_type="server_stream",le="0.25"} 1
0000000000000000000000000000000000000000;;	grpc_server_handling_seconds_bucket{grpc_code="OK",grpc_method="PingList",grpc_service="mwitkow.testproto.TestService",grpc_type="server_stream",le="0.5"} 1
0000000000000000000000000000000000000000;;	grpc_server_handling_seconds_bucket{grpc_code="OK",grpc_method="PingList",grpc_service="mwitkow.testproto.TestService",grpc_type="server_stream",le="1"} 1
0000000000000000000000000000000000000000;;	grpc_server_handling_seconds_bucket{grpc_code="OK",grpc_method="PingList",grpc_service="mwitkow.testproto.TestService",grpc_type="server_stream",le="2.5"} 1
0000000000000000000000000000000000000000;;	grpc_server_handling_seconds_bucket{grpc_code="OK",grpc_method="PingList",grpc_service="mwitkow.testproto.TestService",grpc_type="server_stream",le="5"} 1
0000000000000000000000000000000000000000;;	grpc_server_handling_seconds_bucket{grpc_code="OK",grpc_method="PingList",grpc_service="mwitkow.testproto.TestService",grpc_type="server_stream",le="10"} 1
0000000000000000000000000000000000000000;;	grpc_server_handling_seconds_bucket{grpc_code="OK",grpc_method="PingList",grpc_service="mwitkow.testproto.TestService",grpc_type="server_stream",le="+Inf"} 1
0000000000000000000000000000000000000000;;	grpc_server_handling_seconds_sum{grpc_code="OK",grpc_method="PingList",grpc_service="mwitkow.testproto.TestService",grpc_type="server_stream"} 0.0003866430000000001
0000000000000000000000000000000000000000;;	grpc_server_handling_seconds_count{grpc_code="OK",grpc_method="PingList",grpc_service="mwitkow.testproto.TestService",grpc_type="server_stream"} 1
0000000000000000000000000000000000000000;;	```
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	## Useful query examples
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	Prometheus philosophy is to provide the most detailed metrics possible to the monitoring system, and
0000000000000000000000000000000000000000;;	let the aggregations be handled there. The verbosity of above metrics make it possible to have that
0000000000000000000000000000000000000000;;	flexibility. Here's a couple of useful monitoring queries:
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	### request inbound rate
0000000000000000000000000000000000000000;;	```jsoniq
0000000000000000000000000000000000000000;;	sum(rate(grpc_server_started_total{job="foo"}[1m])) by (grpc_service)
0000000000000000000000000000000000000000;;	```
0000000000000000000000000000000000000000;;	For `job="foo"` (common label to differentiate between Prometheus monitoring targets), calculate the
0000000000000000000000000000000000000000;;	rate of requests per second (1 minute window) for each gRPC `grpc_service` that the job has. Please note
0000000000000000000000000000000000000000;;	how the `grpc_method` is being omitted here: all methods of a given gRPC service will be summed together.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	### unary request error rate
0000000000000000000000000000000000000000;;	```jsoniq
0000000000000000000000000000000000000000;;	sum(rate(grpc_server_handled_total{job="foo",grpc_type="unary",grpc_code!="OK"}[1m])) by (grpc_service)
0000000000000000000000000000000000000000;;	```
0000000000000000000000000000000000000000;;	For `job="foo"`, calculate the per-`grpc_service` rate of `unary` (1:1) RPCs that failed, i.e. the 
0000000000000000000000000000000000000000;;	ones that didn't finish with `OK` code.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	### unary request error percentage
0000000000000000000000000000000000000000;;	```jsoniq
0000000000000000000000000000000000000000;;	sum(rate(grpc_server_handled_total{job="foo",grpc_type="unary",grpc_code!="OK"}[1m])) by (grpc_service)
0000000000000000000000000000000000000000;;	 / 
0000000000000000000000000000000000000000;;	sum(rate(grpc_server_started_total{job="foo",grpc_type="unary"}[1m])) by (grpc_service)
0000000000000000000000000000000000000000;;	 * 100.0
0000000000000000000000000000000000000000;;	```
0000000000000000000000000000000000000000;;	For `job="foo"`, calculate the percentage of failed requests by service. It's easy to notice that
0000000000000000000000000000000000000000;;	this is a combination of the two above examples. This is an example of a query you would like to
0000000000000000000000000000000000000000;;	[alert on](https://prometheus.io/docs/alerting/rules/) in your system for SLA violations, e.g.
0000000000000000000000000000000000000000;;	"no more than 1% requests should fail".
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	### average response stream size
0000000000000000000000000000000000000000;;	```jsoniq
0000000000000000000000000000000000000000;;	sum(rate(grpc_server_msg_sent_total{job="foo",grpc_type="server_stream"}[10m])) by (grpc_service)
0000000000000000000000000000000000000000;;	 /
0000000000000000000000000000000000000000;;	sum(rate(grpc_server_started_total{job="foo",grpc_type="server_stream"}[10m])) by (grpc_service)
0000000000000000000000000000000000000000;;	```
0000000000000000000000000000000000000000;;	For `job="foo"` what is the `grpc_service`-wide `10m` average of messages returned for all `
0000000000000000000000000000000000000000;;	server_stream` RPCs. This allows you to track the stream sizes returned by your system, e.g. allows 
0000000000000000000000000000000000000000;;	you to track when clients started to send "wide" queries that ret
0000000000000000000000000000000000000000;;	Note the divisor is the number of started RPCs, in order to account for in-flight requests.
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	### 99%-tile latency of unary requests
0000000000000000000000000000000000000000;;	```jsoniq
0000000000000000000000000000000000000000;;	histogram_quantile(0.99, 
0000000000000000000000000000000000000000;;	  sum(rate(grpc_server_handling_seconds_bucket{job="foo",grpc_type="unary"}[5m])) by (grpc_service,le)
0000000000000000000000000000000000000000;;	)
0000000000000000000000000000000000000000;;	```
0000000000000000000000000000000000000000;;	For `job="foo"`, returns an 99%-tile [quantile estimation](https://prometheus.io/docs/practices/histograms/#quantiles)
0000000000000000000000000000000000000000;;	of the handling time of RPCs per service. Please note the `5m` rate, this means that the quantile
0000000000000000000000000000000000000000;;	estimation will take samples in a rolling `5m` window. When combined with other quantiles
0000000000000000000000000000000000000000;;	(e.g. 50%, 90%), this query gives you tremendous insight into the responsiveness of your system 
0000000000000000000000000000000000000000;;	(e.g. impact of caching).
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	### percentage of slow unary queries (>250ms)
0000000000000000000000000000000000000000;;	```jsoniq
0000000000000000000000000000000000000000;;	100.0 - (
0000000000000000000000000000000000000000;;	sum(rate(grpc_server_handling_seconds_bucket{job="foo",grpc_type="unary",le="0.25"}[5m])) by (grpc_service)
0000000000000000000000000000000000000000;;	 / 
0000000000000000000000000000000000000000;;	sum(rate(grpc_server_handling_seconds_count{job="foo",grpc_type="unary"}[5m])) by (grpc_service)
0000000000000000000000000000000000000000;;	) * 100.0
0000000000000000000000000000000000000000;;	```
0000000000000000000000000000000000000000;;	For `job="foo"` calculate the by-`grpc_service` fraction of slow requests that took longer than `0.25` 
0000000000000000000000000000000000000000;;	seconds. This query is relatively complex, since the Prometheus aggregations use `le` (less or equal)
0000000000000000000000000000000000000000;;	buckets, meaning that counting "fast" requests fractions is easier. However, simple maths helps.
0000000000000000000000000000000000000000;;	This is an example of a query you would like to alert on in your system for SLA violations, 
0000000000000000000000000000000000000000;;	e.g. "less than 1% of requests are slower than 250ms".
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	## Status
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	This code has been used since August 2015 as the basis for monitoring of *production* gRPC micro services  at [Improbable](https://improbable.io).
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	## License
0000000000000000000000000000000000000000;;	
0000000000000000000000000000000000000000;;	`go-grpc-prometheus` is released under the Apache 2.0 license. See the [LICENSE](LICENSE) file for details.
